{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_org, y_train_org), (X_test_org, y_test_org) = fashion_mnist.load_data()\n",
    "\n",
    "X_train_org = X_train_org.reshape(-1, 28, 28, 1)\n",
    "X_test_org = X_test_org.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_org = X_train_org.astype('float32')\n",
    "X_test_org = X_test_org.astype('float32')\n",
    "X_train_org /= 255\n",
    "X_test_org /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.05\n",
      "0.07500000000000001\n",
      "0.1\n",
      "0.125\n",
      "0.15\n",
      "0.17500000000000002\n",
      "0.2\n",
      "0.225\n",
      "0.25\n",
      "0.275\n",
      "0.30000000000000004\n",
      "0.32500000000000007\n",
      "0.35000000000000003\n",
      "0.37500000000000006\n",
      "0.4\n",
      "0.42500000000000004\n",
      "0.45000000000000007\n",
      "0.47500000000000003\n",
      "0.5\n",
      "0.525\n",
      "0.55\n",
      "0.5750000000000001\n",
      "0.6000000000000001\n",
      "0.6250000000000001\n",
      "0.65\n",
      "0.675\n",
      "0.7000000000000001\n",
      "0.7250000000000001\n",
      "0.7500000000000001\n",
      "0.775\n",
      "0.8\n",
      "0.8250000000000001\n",
      "0.8500000000000001\n",
      "0.8750000000000001\n",
      "0.9\n",
      "0.925\n",
      "0.9500000000000001\n",
      "0.9750000000000001\n"
     ]
    }
   ],
   "source": [
    "# 1,2,5,10 conv2d\n",
    "# 5, 10, 15 epok\n",
    "# 100, 1000 wag\n",
    "# 2500, 5000, 10000 sampli, 0.8 ratio\n",
    "\n",
    "def gen_3a_svm():\n",
    "    for ratio in np.arange(0.025, 1.0, 0.025):\n",
    "        train_samples = int(10000 * ratio)\n",
    "        test_samples = 10000 - train_samples\n",
    "        X_train, y_train = resample(X_train_org, y_train_org, random_state=0, n_samples=train_samples)\n",
    "        X_test, y_test = resample(X_test_org, y_test_org, random_state=0, n_samples=test_samples)\n",
    "        \n",
    "        svc = SVC(C=5.0, kernel='rbf')\n",
    "        svc.fit(X_train.reshape(-1, 784), y_train)\n",
    "        y_pred = svc.predict(X_test.reshape(-1, 784))\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(ratio)\n",
    "        yield ratio, accuracy, 'SVM'\n",
    "\n",
    "results_3a_svm = pd.DataFrame(gen_3a_svm(), columns=['ratio', 'accuracy', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 9750 samples\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/sample - loss: 1.9365 - accuracy: 0.3200 - val_loss: 1.5902 - val_accuracy: 0.5207\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 1.1908 - accuracy: 0.6760 - val_loss: 1.0872 - val_accuracy: 0.6218\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.7998 - accuracy: 0.7520 - val_loss: 0.8905 - val_accuracy: 0.7127\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.6381 - accuracy: 0.8280 - val_loss: 0.7989 - val_accuracy: 0.7264\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.5215 - accuracy: 0.8440 - val_loss: 0.8378 - val_accuracy: 0.7143\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.4536 - accuracy: 0.8520 - val_loss: 0.6992 - val_accuracy: 0.7513\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.3835 - accuracy: 0.8720 - val_loss: 0.7436 - val_accuracy: 0.7498\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.3251 - accuracy: 0.9040 - val_loss: 0.7675 - val_accuracy: 0.7284\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.3118 - accuracy: 0.9160 - val_loss: 0.6935 - val_accuracy: 0.7642\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.2621 - accuracy: 0.9280 - val_loss: 0.7109 - val_accuracy: 0.7474\n",
      "Train on 500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.5628 - accuracy: 0.8300 - val_loss: 0.6480 - val_accuracy: 0.7715\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4238 - accuracy: 0.8660 - val_loss: 0.6265 - val_accuracy: 0.7666\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3757 - accuracy: 0.8820 - val_loss: 0.6449 - val_accuracy: 0.7618\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3193 - accuracy: 0.9000 - val_loss: 0.6205 - val_accuracy: 0.7742\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2734 - accuracy: 0.9200 - val_loss: 0.6175 - val_accuracy: 0.7856\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2568 - accuracy: 0.9280 - val_loss: 0.6034 - val_accuracy: 0.7782\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2155 - accuracy: 0.9300 - val_loss: 0.6102 - val_accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2030 - accuracy: 0.9460 - val_loss: 0.5799 - val_accuracy: 0.8028\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.1950 - accuracy: 0.9440 - val_loss: 0.6310 - val_accuracy: 0.7860\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.1869 - accuracy: 0.9440 - val_loss: 0.6671 - val_accuracy: 0.7681\n",
      "Train on 750 samples, validate on 9250 samples\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 1s 2ms/sample - loss: 0.3659 - accuracy: 0.8813 - val_loss: 0.6835 - val_accuracy: 0.7521\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 1s 747us/sample - loss: 0.2940 - accuracy: 0.8987 - val_loss: 0.6066 - val_accuracy: 0.8064\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 1s 737us/sample - loss: 0.2396 - accuracy: 0.9293 - val_loss: 0.5429 - val_accuracy: 0.8152\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 1s 755us/sample - loss: 0.2102 - accuracy: 0.9347 - val_loss: 0.5617 - val_accuracy: 0.8095\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 1s 868us/sample - loss: 0.1932 - accuracy: 0.9440 - val_loss: 0.5595 - val_accuracy: 0.8080\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 1s 755us/sample - loss: 0.1586 - accuracy: 0.9587 - val_loss: 0.5874 - val_accuracy: 0.8106\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 1s 747us/sample - loss: 0.1574 - accuracy: 0.9600 - val_loss: 0.6278 - val_accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 1s 748us/sample - loss: 0.1305 - accuracy: 0.9680 - val_loss: 0.5865 - val_accuracy: 0.8112\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 1s 743us/sample - loss: 0.1223 - accuracy: 0.9653 - val_loss: 0.5537 - val_accuracy: 0.8177\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 1s 839us/sample - loss: 0.1002 - accuracy: 0.9773 - val_loss: 0.5966 - val_accuracy: 0.8139\n",
      "Train on 1000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 963us/sample - loss: 0.2295 - accuracy: 0.9280 - val_loss: 0.5431 - val_accuracy: 0.8216\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 564us/sample - loss: 0.1710 - accuracy: 0.9500 - val_loss: 0.5328 - val_accuracy: 0.8206\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 566us/sample - loss: 0.1372 - accuracy: 0.9610 - val_loss: 0.5617 - val_accuracy: 0.8217\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 571us/sample - loss: 0.1163 - accuracy: 0.9660 - val_loss: 0.5665 - val_accuracy: 0.8171\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 772us/sample - loss: 0.1001 - accuracy: 0.9730 - val_loss: 0.5679 - val_accuracy: 0.8221\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 572us/sample - loss: 0.0928 - accuracy: 0.9800 - val_loss: 0.6019 - val_accuracy: 0.8090\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 567us/sample - loss: 0.0689 - accuracy: 0.9860 - val_loss: 0.6446 - val_accuracy: 0.8122\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 571us/sample - loss: 0.0726 - accuracy: 0.9820 - val_loss: 0.5973 - val_accuracy: 0.8189\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 568us/sample - loss: 0.0785 - accuracy: 0.9750 - val_loss: 0.6282 - val_accuracy: 0.8129\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 570us/sample - loss: 0.0546 - accuracy: 0.9910 - val_loss: 0.6329 - val_accuracy: 0.8154\n",
      "Train on 1250 samples, validate on 8750 samples\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 1s 753us/sample - loss: 0.1918 - accuracy: 0.9496 - val_loss: 0.6414 - val_accuracy: 0.7993\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 1s 454us/sample - loss: 0.1236 - accuracy: 0.9672 - val_loss: 0.6062 - val_accuracy: 0.8166\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 1s 450us/sample - loss: 0.0912 - accuracy: 0.9776 - val_loss: 0.6008 - val_accuracy: 0.8202\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 1s 549us/sample - loss: 0.0911 - accuracy: 0.9712 - val_loss: 0.5990 - val_accuracy: 0.8168\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 1s 471us/sample - loss: 0.0634 - accuracy: 0.9888 - val_loss: 0.6097 - val_accuracy: 0.8207\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 1s 458us/sample - loss: 0.0602 - accuracy: 0.9848 - val_loss: 0.6735 - val_accuracy: 0.8218\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 1s 457us/sample - loss: 0.0542 - accuracy: 0.9856 - val_loss: 0.5979 - val_accuracy: 0.8269\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1s 466us/sample - loss: 0.0670 - accuracy: 0.9816 - val_loss: 0.6304 - val_accuracy: 0.8304\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1s 535us/sample - loss: 0.0362 - accuracy: 0.9936 - val_loss: 0.6639 - val_accuracy: 0.8170\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1s 520us/sample - loss: 0.0283 - accuracy: 0.9960 - val_loss: 0.6650 - val_accuracy: 0.8198\n",
      "Train on 1500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 681us/sample - loss: 0.1878 - accuracy: 0.9513 - val_loss: 0.5658 - val_accuracy: 0.8329\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 535us/sample - loss: 0.1024 - accuracy: 0.9740 - val_loss: 0.5795 - val_accuracy: 0.8338\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 467us/sample - loss: 0.0797 - accuracy: 0.9807 - val_loss: 0.5956 - val_accuracy: 0.8361\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 463us/sample - loss: 0.0598 - accuracy: 0.9873 - val_loss: 0.5988 - val_accuracy: 0.8322\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 399us/sample - loss: 0.0488 - accuracy: 0.9900 - val_loss: 0.6026 - val_accuracy: 0.8312\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 389us/sample - loss: 0.0372 - accuracy: 0.9940 - val_loss: 0.5962 - val_accuracy: 0.8372\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 386us/sample - loss: 0.0355 - accuracy: 0.9927 - val_loss: 0.6265 - val_accuracy: 0.8315\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 431us/sample - loss: 0.0202 - accuracy: 0.9980 - val_loss: 0.6886 - val_accuracy: 0.8279\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 391us/sample - loss: 0.0202 - accuracy: 0.9993 - val_loss: 0.6345 - val_accuracy: 0.8321\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 380us/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.6693 - val_accuracy: 0.8351\n",
      "Train on 1750 samples, validate on 8250 samples\n",
      "Epoch 1/10\n",
      "1750/1750 [==============================] - 1s 551us/sample - loss: 0.1085 - accuracy: 0.9771 - val_loss: 0.6343 - val_accuracy: 0.8272\n",
      "Epoch 2/10\n",
      "1750/1750 [==============================] - 1s 338us/sample - loss: 0.0612 - accuracy: 0.9834 - val_loss: 0.6340 - val_accuracy: 0.8353\n",
      "Epoch 3/10\n",
      "1750/1750 [==============================] - 1s 335us/sample - loss: 0.0396 - accuracy: 0.9891 - val_loss: 0.7075 - val_accuracy: 0.8238\n",
      "Epoch 4/10\n",
      "1750/1750 [==============================] - 1s 338us/sample - loss: 0.0306 - accuracy: 0.9914 - val_loss: 0.6498 - val_accuracy: 0.8378\n",
      "Epoch 5/10\n",
      "1750/1750 [==============================] - 1s 344us/sample - loss: 0.0203 - accuracy: 0.9983 - val_loss: 0.6322 - val_accuracy: 0.8398\n",
      "Epoch 6/10\n",
      "1750/1750 [==============================] - 1s 332us/sample - loss: 0.0145 - accuracy: 0.9994 - val_loss: 0.6626 - val_accuracy: 0.8384\n",
      "Epoch 7/10\n",
      "1750/1750 [==============================] - 1s 334us/sample - loss: 0.0136 - accuracy: 0.9989 - val_loss: 0.6991 - val_accuracy: 0.8373\n",
      "Epoch 8/10\n",
      "1750/1750 [==============================] - 1s 331us/sample - loss: 0.0104 - accuracy: 0.9994 - val_loss: 0.6761 - val_accuracy: 0.8410\n",
      "Epoch 9/10\n",
      "1750/1750 [==============================] - 1s 385us/sample - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.6981 - val_accuracy: 0.8422\n",
      "Epoch 10/10\n",
      "1750/1750 [==============================] - 1s 364us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8389\n",
      "Train on 2000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 630us/sample - loss: 0.1243 - accuracy: 0.9700 - val_loss: 0.6536 - val_accuracy: 0.8351\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 277us/sample - loss: 0.0826 - accuracy: 0.9765 - val_loss: 0.6007 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 259us/sample - loss: 0.0538 - accuracy: 0.9850 - val_loss: 0.6611 - val_accuracy: 0.8409\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 295us/sample - loss: 0.0476 - accuracy: 0.9865 - val_loss: 0.6296 - val_accuracy: 0.8419\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 271us/sample - loss: 0.0283 - accuracy: 0.9940 - val_loss: 0.6511 - val_accuracy: 0.8401\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 259us/sample - loss: 0.0192 - accuracy: 0.9980 - val_loss: 0.6541 - val_accuracy: 0.8382\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 271us/sample - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.6623 - val_accuracy: 0.8411\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 258us/sample - loss: 0.0138 - accuracy: 0.9980 - val_loss: 0.6848 - val_accuracy: 0.8397\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 377us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 267us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.8478\n",
      "Train on 2250 samples, validate on 7750 samples\n",
      "Epoch 1/10\n",
      "2250/2250 [==============================] - 1s 513us/sample - loss: 0.1419 - accuracy: 0.9693 - val_loss: 0.6568 - val_accuracy: 0.8325\n",
      "Epoch 2/10\n",
      "2250/2250 [==============================] - 1s 305us/sample - loss: 0.0672 - accuracy: 0.9844 - val_loss: 0.6607 - val_accuracy: 0.8339\n",
      "Epoch 3/10\n",
      "2250/2250 [==============================] - 1s 268us/sample - loss: 0.0446 - accuracy: 0.9902 - val_loss: 0.6167 - val_accuracy: 0.8497\n",
      "Epoch 4/10\n",
      "2250/2250 [==============================] - 1s 355us/sample - loss: 0.0293 - accuracy: 0.9938 - val_loss: 0.6546 - val_accuracy: 0.8461\n",
      "Epoch 5/10\n",
      "2250/2250 [==============================] - 1s 415us/sample - loss: 0.0191 - accuracy: 0.9960 - val_loss: 0.6411 - val_accuracy: 0.8470\n",
      "Epoch 6/10\n",
      "2250/2250 [==============================] - 1s 340us/sample - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.6546 - val_accuracy: 0.8477\n",
      "Epoch 7/10\n",
      "2250/2250 [==============================] - 1s 277us/sample - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.6785 - val_accuracy: 0.8475\n",
      "Epoch 8/10\n",
      "2250/2250 [==============================] - 1s 319us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8493\n",
      "Epoch 9/10\n",
      "2250/2250 [==============================] - 1s 265us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8493\n",
      "Epoch 10/10\n",
      "2250/2250 [==============================] - 1s 253us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8490\n",
      "Train on 2500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 376us/sample - loss: 0.1114 - accuracy: 0.9752 - val_loss: 0.6775 - val_accuracy: 0.8449\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 236us/sample - loss: 0.0685 - accuracy: 0.9848 - val_loss: 0.6609 - val_accuracy: 0.8425\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 255us/sample - loss: 0.0407 - accuracy: 0.9900 - val_loss: 0.6828 - val_accuracy: 0.8468\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 252us/sample - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.7257 - val_accuracy: 0.8393\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.6693 - val_accuracy: 0.8476\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 294us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8537\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 260us/sample - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.6898 - val_accuracy: 0.8489\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 299us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8533\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 230us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8512\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 228us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.8523\n",
      "Train on 2750 samples, validate on 7250 samples\n",
      "Epoch 1/10\n",
      "2750/2750 [==============================] - 1s 347us/sample - loss: 0.0666 - accuracy: 0.9855 - val_loss: 0.7631 - val_accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "2750/2750 [==============================] - 1s 212us/sample - loss: 0.0321 - accuracy: 0.9935 - val_loss: 0.6990 - val_accuracy: 0.8513\n",
      "Epoch 3/10\n",
      "2750/2750 [==============================] - 1s 241us/sample - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.7020 - val_accuracy: 0.8521\n",
      "Epoch 4/10\n",
      "2750/2750 [==============================] - 1s 263us/sample - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.7535 - val_accuracy: 0.8497\n",
      "Epoch 5/10\n",
      "2750/2750 [==============================] - 1s 234us/sample - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.7478 - val_accuracy: 0.8521\n",
      "Epoch 6/10\n",
      "2750/2750 [==============================] - 1s 215us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.8499\n",
      "Epoch 7/10\n",
      "2750/2750 [==============================] - 1s 209us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8537\n",
      "Epoch 8/10\n",
      "2750/2750 [==============================] - 1s 222us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "2750/2750 [==============================] - 1s 218us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8549\n",
      "Epoch 10/10\n",
      "2750/2750 [==============================] - 1s 217us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.8527\n",
      "Train on 3000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 374us/sample - loss: 0.0857 - accuracy: 0.9800 - val_loss: 0.7349 - val_accuracy: 0.8489\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 245us/sample - loss: 0.0402 - accuracy: 0.9880 - val_loss: 0.7740 - val_accuracy: 0.8464\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 233us/sample - loss: 0.0191 - accuracy: 0.9970 - val_loss: 0.7403 - val_accuracy: 0.8540\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 222us/sample - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.8095 - val_accuracy: 0.8453\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 206us/sample - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.8145 - val_accuracy: 0.8497\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 207us/sample - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.7781 - val_accuracy: 0.8564\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 269us/sample - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.7698 - val_accuracy: 0.8596\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 218us/sample - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.7751 - val_accuracy: 0.8590\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 231us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.8570\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 271us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.8560\n",
      "Train on 3250 samples, validate on 6750 samples\n",
      "Epoch 1/10\n",
      "3250/3250 [==============================] - 1s 311us/sample - loss: 0.0846 - accuracy: 0.9809 - val_loss: 0.7412 - val_accuracy: 0.8535\n",
      "Epoch 2/10\n",
      "3250/3250 [==============================] - 1s 191us/sample - loss: 0.0338 - accuracy: 0.9914 - val_loss: 0.7403 - val_accuracy: 0.8524\n",
      "Epoch 3/10\n",
      "3250/3250 [==============================] - 1s 232us/sample - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.7336 - val_accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "3250/3250 [==============================] - 1s 233us/sample - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.7361 - val_accuracy: 0.8585\n",
      "Epoch 5/10\n",
      "3250/3250 [==============================] - 1s 230us/sample - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.8189 - val_accuracy: 0.8486\n",
      "Epoch 6/10\n",
      "3250/3250 [==============================] - 1s 247us/sample - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.8114 - val_accuracy: 0.8551\n",
      "Epoch 7/10\n",
      "3250/3250 [==============================] - 1s 243us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.8575\n",
      "Epoch 8/10\n",
      "3250/3250 [==============================] - 1s 195us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.8581\n",
      "Epoch 9/10\n",
      "3250/3250 [==============================] - 1s 181us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8182 - val_accuracy: 0.8596\n",
      "Epoch 10/10\n",
      "3250/3250 [==============================] - 1s 182us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8340 - val_accuracy: 0.8582\n",
      "Train on 3500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 346us/sample - loss: 0.0608 - accuracy: 0.9866 - val_loss: 0.7668 - val_accuracy: 0.8531\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 168us/sample - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.7335 - val_accuracy: 0.8558\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 172us/sample - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.7608 - val_accuracy: 0.8551\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 173us/sample - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.7901 - val_accuracy: 0.8566\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 179us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8591\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 187us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 185us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.8586\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 218us/sample - loss: 9.8130e-04 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.8606\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 211us/sample - loss: 8.5721e-04 - accuracy: 1.0000 - val_loss: 0.8253 - val_accuracy: 0.8582\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 211us/sample - loss: 7.3784e-04 - accuracy: 1.0000 - val_loss: 0.8398 - val_accuracy: 0.8578\n",
      "Train on 3750 samples, validate on 6250 samples\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 1s 277us/sample - loss: 0.0833 - accuracy: 0.9840 - val_loss: 0.7830 - val_accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 1s 173us/sample - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.7679 - val_accuracy: 0.8578\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 1s 161us/sample - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.7729 - val_accuracy: 0.8614\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 1s 167us/sample - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.7723 - val_accuracy: 0.8557\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 1s 190us/sample - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.7695 - val_accuracy: 0.8602\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 1s 191us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.8568\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 1s 182us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.8568\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 1s 256us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.8606\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 1s 231us/sample - loss: 9.4772e-04 - accuracy: 1.0000 - val_loss: 0.8246 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 1s 185us/sample - loss: 8.1264e-04 - accuracy: 1.0000 - val_loss: 0.8320 - val_accuracy: 0.8576\n",
      "Train on 4000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 287us/sample - loss: 0.0747 - accuracy: 0.9858 - val_loss: 0.7521 - val_accuracy: 0.8540\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 188us/sample - loss: 0.0320 - accuracy: 0.9940 - val_loss: 0.7762 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 145us/sample - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.7622 - val_accuracy: 0.8507\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 178us/sample - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.7588 - val_accuracy: 0.8552\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 308us/sample - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.7710 - val_accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 207us/sample - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.7679 - val_accuracy: 0.8568\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 178us/sample - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.8192 - val_accuracy: 0.8598\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 177us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.7937 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 214us/sample - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.7850 - val_accuracy: 0.8478\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 198us/sample - loss: 0.0213 - accuracy: 0.9923 - val_loss: 0.7947 - val_accuracy: 0.8587\n",
      "Train on 4250 samples, validate on 5750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 0.0582 - accuracy: 0.9847 - val_loss: 0.7523 - val_accuracy: 0.8543\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 167us/sample - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.7757 - val_accuracy: 0.8574\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 146us/sample - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.7870 - val_accuracy: 0.8537\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 148us/sample - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.7803 - val_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 160us/sample - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.7810 - val_accuracy: 0.8597\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 162us/sample - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.7744 - val_accuracy: 0.8605\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.7834 - val_accuracy: 0.8652\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 9.1468e-04 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.8656\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 147us/sample - loss: 6.6968e-04 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.8659\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 5.5834e-04 - accuracy: 1.0000 - val_loss: 0.8229 - val_accuracy: 0.8675\n",
      "Train on 4500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 1s 310us/sample - loss: 0.0479 - accuracy: 0.9896 - val_loss: 0.7904 - val_accuracy: 0.8513\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 248us/sample - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.7590 - val_accuracy: 0.8615\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 195us/sample - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.8084 - val_accuracy: 0.8551\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 204us/sample - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.8357 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 189us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.8647\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 203us/sample - loss: 7.8475e-04 - accuracy: 1.0000 - val_loss: 0.8134 - val_accuracy: 0.8649\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 182us/sample - loss: 5.7298e-04 - accuracy: 1.0000 - val_loss: 0.8208 - val_accuracy: 0.8651\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 183us/sample - loss: 4.7143e-04 - accuracy: 1.0000 - val_loss: 0.8295 - val_accuracy: 0.8678\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 175us/sample - loss: 4.1718e-04 - accuracy: 1.0000 - val_loss: 0.8403 - val_accuracy: 0.8651\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 160us/sample - loss: 3.7109e-04 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.8673\n",
      "Train on 4750 samples, validate on 5250 samples\n",
      "Epoch 1/10\n",
      "4750/4750 [==============================] - 1s 309us/sample - loss: 0.0532 - accuracy: 0.9895 - val_loss: 0.8202 - val_accuracy: 0.8543\n",
      "Epoch 2/10\n",
      "4750/4750 [==============================] - 1s 168us/sample - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.7879 - val_accuracy: 0.8630\n",
      "Epoch 3/10\n",
      "4750/4750 [==============================] - 1s 180us/sample - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.8139 - val_accuracy: 0.8611\n",
      "Epoch 4/10\n",
      "4750/4750 [==============================] - 1s 151us/sample - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.8191 - val_accuracy: 0.8608\n",
      "Epoch 5/10\n",
      "4750/4750 [==============================] - 1s 135us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.8634\n",
      "Epoch 6/10\n",
      "4750/4750 [==============================] - 1s 138us/sample - loss: 7.2096e-04 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.8650\n",
      "Epoch 7/10\n",
      "4750/4750 [==============================] - 1s 142us/sample - loss: 5.8613e-04 - accuracy: 1.0000 - val_loss: 0.8419 - val_accuracy: 0.8651\n",
      "Epoch 8/10\n",
      "4750/4750 [==============================] - 1s 168us/sample - loss: 4.9158e-04 - accuracy: 1.0000 - val_loss: 0.8518 - val_accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "4750/4750 [==============================] - 1s 153us/sample - loss: 4.2400e-04 - accuracy: 1.0000 - val_loss: 0.8573 - val_accuracy: 0.8650\n",
      "Epoch 10/10\n",
      "4750/4750 [==============================] - 1s 152us/sample - loss: 3.7766e-04 - accuracy: 1.0000 - val_loss: 0.8679 - val_accuracy: 0.8657\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.0557 - accuracy: 0.9888 - val_loss: 0.7928 - val_accuracy: 0.8612\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 137us/sample - loss: 0.0233 - accuracy: 0.9940 - val_loss: 0.7839 - val_accuracy: 0.8646\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 130us/sample - loss: 0.0124 - accuracy: 0.9966 - val_loss: 1.0148 - val_accuracy: 0.8420\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 139us/sample - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.8215 - val_accuracy: 0.8570\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 129us/sample - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.8321 - val_accuracy: 0.8620\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 126us/sample - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.8273 - val_accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 130us/sample - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.8090 - val_accuracy: 0.8612\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 127us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.8331 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 128us/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.8174 - val_accuracy: 0.8618\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 130us/sample - loss: 8.7791e-04 - accuracy: 1.0000 - val_loss: 0.8334 - val_accuracy: 0.8636\n",
      "Train on 5250 samples, validate on 4750 samples\n",
      "Epoch 1/10\n",
      "5250/5250 [==============================] - 1s 198us/sample - loss: 0.0619 - accuracy: 0.9893 - val_loss: 0.7858 - val_accuracy: 0.8528\n",
      "Epoch 2/10\n",
      "5250/5250 [==============================] - 1s 124us/sample - loss: 0.0214 - accuracy: 0.9966 - val_loss: 0.7961 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "5250/5250 [==============================] - 1s 124us/sample - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.7961 - val_accuracy: 0.8621\n",
      "Epoch 4/10\n",
      "5250/5250 [==============================] - 1s 124us/sample - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.8174 - val_accuracy: 0.8615\n",
      "Epoch 5/10\n",
      "5250/5250 [==============================] - 1s 124us/sample - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.8195 - val_accuracy: 0.8623\n",
      "Epoch 6/10\n",
      "5250/5250 [==============================] - 1s 124us/sample - loss: 9.0769e-04 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.8627\n",
      "Epoch 7/10\n",
      "5250/5250 [==============================] - 1s 122us/sample - loss: 6.2475e-04 - accuracy: 1.0000 - val_loss: 0.8501 - val_accuracy: 0.8642\n",
      "Epoch 8/10\n",
      "5250/5250 [==============================] - 1s 127us/sample - loss: 4.7391e-04 - accuracy: 1.0000 - val_loss: 0.8606 - val_accuracy: 0.8627\n",
      "Epoch 9/10\n",
      "5250/5250 [==============================] - 1s 124us/sample - loss: 4.0566e-04 - accuracy: 1.0000 - val_loss: 0.8739 - val_accuracy: 0.8611\n",
      "Epoch 10/10\n",
      "5250/5250 [==============================] - 1s 122us/sample - loss: 3.4546e-04 - accuracy: 1.0000 - val_loss: 0.8806 - val_accuracy: 0.8625\n",
      "Train on 5500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 1s 192us/sample - loss: 0.0416 - accuracy: 0.9915 - val_loss: 0.8458 - val_accuracy: 0.8602\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 121us/sample - loss: 0.0204 - accuracy: 0.9953 - val_loss: 0.8592 - val_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 119us/sample - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.8485 - val_accuracy: 0.8562\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 119us/sample - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.8587 - val_accuracy: 0.8622\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 1s 120us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.8624\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 118us/sample - loss: 0.0046 - accuracy: 0.9980 - val_loss: 0.8835 - val_accuracy: 0.8647\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 122us/sample - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.8804 - val_accuracy: 0.8611\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 119us/sample - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.9287 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 121us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9147 - val_accuracy: 0.8640\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 119us/sample - loss: 5.4642e-04 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.8638\n",
      "Train on 5750 samples, validate on 4250 samples\n",
      "Epoch 1/10\n",
      "5750/5750 [==============================] - 1s 184us/sample - loss: 0.0406 - accuracy: 0.9908 - val_loss: 0.8524 - val_accuracy: 0.8631\n",
      "Epoch 2/10\n",
      "5750/5750 [==============================] - 1s 114us/sample - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.8952 - val_accuracy: 0.8602\n",
      "Epoch 3/10\n",
      "5750/5750 [==============================] - 1s 114us/sample - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.8672 - val_accuracy: 0.8635\n",
      "Epoch 4/10\n",
      "5750/5750 [==============================] - 1s 116us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.8853 - val_accuracy: 0.8652\n",
      "Epoch 5/10\n",
      "5750/5750 [==============================] - 1s 115us/sample - loss: 7.3236e-04 - accuracy: 1.0000 - val_loss: 0.9165 - val_accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "5750/5750 [==============================] - 1s 115us/sample - loss: 4.8062e-04 - accuracy: 1.0000 - val_loss: 0.9098 - val_accuracy: 0.8673\n",
      "Epoch 7/10\n",
      "5750/5750 [==============================] - 1s 114us/sample - loss: 2.4611e-04 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "5750/5750 [==============================] - 1s 115us/sample - loss: 2.0092e-04 - accuracy: 1.0000 - val_loss: 0.9203 - val_accuracy: 0.8654\n",
      "Epoch 9/10\n",
      "5750/5750 [==============================] - 1s 114us/sample - loss: 1.7734e-04 - accuracy: 1.0000 - val_loss: 0.9285 - val_accuracy: 0.8661\n",
      "Epoch 10/10\n",
      "5750/5750 [==============================] - 1s 115us/sample - loss: 1.5314e-04 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.8666\n",
      "Train on 6000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 1s 167us/sample - loss: 0.0386 - accuracy: 0.9940 - val_loss: 0.9181 - val_accuracy: 0.8652\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 108us/sample - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.8737 - val_accuracy: 0.8683\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 104us/sample - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.8946 - val_accuracy: 0.8690\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 107us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.8811 - val_accuracy: 0.8658\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 107us/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.9037 - val_accuracy: 0.8675\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 113us/sample - loss: 4.0416e-04 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.8668\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 127us/sample - loss: 2.3688e-04 - accuracy: 1.0000 - val_loss: 0.9187 - val_accuracy: 0.8687\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 108us/sample - loss: 2.0029e-04 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.8670\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 107us/sample - loss: 1.6940e-04 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 103us/sample - loss: 1.4705e-04 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.8677\n",
      "Train on 6250 samples, validate on 3750 samples\n",
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 1s 221us/sample - loss: 0.0446 - accuracy: 0.9914 - val_loss: 0.9781 - val_accuracy: 0.8560\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 1s 105us/sample - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.9786 - val_accuracy: 0.8541\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 1s 106us/sample - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.8566 - val_accuracy: 0.8712\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 1s 105us/sample - loss: 9.4602e-04 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.8693\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 1s 107us/sample - loss: 6.9247e-04 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.8712\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 1s 107us/sample - loss: 4.0023e-04 - accuracy: 1.0000 - val_loss: 0.9120 - val_accuracy: 0.8715\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 1s 105us/sample - loss: 2.9412e-04 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.8712\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 1s 108us/sample - loss: 2.2144e-04 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.8728\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 1s 106us/sample - loss: 1.9202e-04 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.8723\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 1s 108us/sample - loss: 1.6453e-04 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.8736\n",
      "Train on 6500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 1s 163us/sample - loss: 0.0451 - accuracy: 0.9920 - val_loss: 0.7982 - val_accuracy: 0.8677\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 114us/sample - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.8607 - val_accuracy: 0.8671\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 108us/sample - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.8557 - val_accuracy: 0.8677\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 104us/sample - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.8973 - val_accuracy: 0.8657\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 103us/sample - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.9170 - val_accuracy: 0.8609\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 106us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.8793 - val_accuracy: 0.8683\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 104us/sample - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.8940 - val_accuracy: 0.8737\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 104us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.8887 - val_accuracy: 0.8714\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 106us/sample - loss: 2.7862e-04 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.8723\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 103us/sample - loss: 1.9619e-04 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.8709\n",
      "Train on 6750 samples, validate on 3250 samples\n",
      "Epoch 1/10\n",
      "6750/6750 [==============================] - 1s 156us/sample - loss: 0.0412 - accuracy: 0.9933 - val_loss: 0.8900 - val_accuracy: 0.8665\n",
      "Epoch 2/10\n",
      "6750/6750 [==============================] - 1s 101us/sample - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.8085 - val_accuracy: 0.8754\n",
      "Epoch 3/10\n",
      "6750/6750 [==============================] - 1s 102us/sample - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.8345 - val_accuracy: 0.8772\n",
      "Epoch 4/10\n",
      "6750/6750 [==============================] - 1s 99us/sample - loss: 7.8473e-04 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.8754\n",
      "Epoch 5/10\n",
      "6750/6750 [==============================] - 1s 104us/sample - loss: 3.2866e-04 - accuracy: 1.0000 - val_loss: 0.8676 - val_accuracy: 0.8766\n",
      "Epoch 6/10\n",
      "6750/6750 [==============================] - 1s 101us/sample - loss: 2.4840e-04 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "6750/6750 [==============================] - 1s 99us/sample - loss: 1.9594e-04 - accuracy: 1.0000 - val_loss: 0.8818 - val_accuracy: 0.8772\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750/6750 [==============================] - 1s 100us/sample - loss: 1.6376e-04 - accuracy: 1.0000 - val_loss: 0.8965 - val_accuracy: 0.8757\n",
      "Epoch 9/10\n",
      "6750/6750 [==============================] - 1s 101us/sample - loss: 1.4121e-04 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.8763\n",
      "Epoch 10/10\n",
      "6750/6750 [==============================] - 1s 99us/sample - loss: 1.2222e-04 - accuracy: 1.0000 - val_loss: 0.9165 - val_accuracy: 0.8766\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 1s 152us/sample - loss: 0.0332 - accuracy: 0.9939 - val_loss: 0.8417 - val_accuracy: 0.8743\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 99us/sample - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.9117 - val_accuracy: 0.8673\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.8891 - val_accuracy: 0.8653\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 99us/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.8580 - val_accuracy: 0.8770\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 97us/sample - loss: 9.5217e-04 - accuracy: 0.9997 - val_loss: 0.8725 - val_accuracy: 0.8780\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 97us/sample - loss: 2.6600e-04 - accuracy: 1.0000 - val_loss: 0.8835 - val_accuracy: 0.8780\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 99us/sample - loss: 1.9211e-04 - accuracy: 1.0000 - val_loss: 0.8922 - val_accuracy: 0.8787\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 99us/sample - loss: 1.5528e-04 - accuracy: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.8793\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 98us/sample - loss: 1.3194e-04 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.8797\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 99us/sample - loss: 1.1552e-04 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.8783\n",
      "Train on 7250 samples, validate on 2750 samples\n",
      "Epoch 1/10\n",
      "7250/7250 [==============================] - 1s 149us/sample - loss: 0.0318 - accuracy: 0.9948 - val_loss: 0.9417 - val_accuracy: 0.8709\n",
      "Epoch 2/10\n",
      "7250/7250 [==============================] - 1s 95us/sample - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.8980 - val_accuracy: 0.8782\n",
      "Epoch 3/10\n",
      "7250/7250 [==============================] - 1s 96us/sample - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.9194 - val_accuracy: 0.8756\n",
      "Epoch 4/10\n",
      "7250/7250 [==============================] - 1s 97us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.9213 - val_accuracy: 0.8785\n",
      "Epoch 5/10\n",
      "7250/7250 [==============================] - 1s 96us/sample - loss: 3.5950e-04 - accuracy: 1.0000 - val_loss: 0.9346 - val_accuracy: 0.8796\n",
      "Epoch 6/10\n",
      "7250/7250 [==============================] - 1s 95us/sample - loss: 2.1178e-04 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.8775\n",
      "Epoch 7/10\n",
      "7250/7250 [==============================] - 1s 95us/sample - loss: 1.6125e-04 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.8782\n",
      "Epoch 8/10\n",
      "7250/7250 [==============================] - 1s 97us/sample - loss: 1.3582e-04 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.8785\n",
      "Epoch 9/10\n",
      "7250/7250 [==============================] - 1s 97us/sample - loss: 1.1608e-04 - accuracy: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.8778\n",
      "Epoch 10/10\n",
      "7250/7250 [==============================] - 1s 96us/sample - loss: 1.0030e-04 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.8785\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0452 - accuracy: 0.9932 - val_loss: 0.9118 - val_accuracy: 0.8656\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 93us/sample - loss: 0.0192 - accuracy: 0.9959 - val_loss: 0.9089 - val_accuracy: 0.8660\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 92us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.9183 - val_accuracy: 0.8684\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 92us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.9105 - val_accuracy: 0.8724\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 93us/sample - loss: 4.9762e-04 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.8716\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 91us/sample - loss: 2.3534e-04 - accuracy: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.8752\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 91us/sample - loss: 1.9374e-04 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 92us/sample - loss: 1.5915e-04 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.8740\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 92us/sample - loss: 1.3889e-04 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.8752\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 97us/sample - loss: 1.1828e-04 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.8760\n",
      "Train on 7750 samples, validate on 2250 samples\n",
      "Epoch 1/10\n",
      "7750/7750 [==============================] - 1s 138us/sample - loss: 0.0316 - accuracy: 0.9925 - val_loss: 1.0109 - val_accuracy: 0.8662\n",
      "Epoch 2/10\n",
      "7750/7750 [==============================] - 1s 91us/sample - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.9227 - val_accuracy: 0.8813\n",
      "Epoch 3/10\n",
      "7750/7750 [==============================] - 1s 89us/sample - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.9093 - val_accuracy: 0.8778\n",
      "Epoch 4/10\n",
      "7750/7750 [==============================] - 1s 89us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.9395 - val_accuracy: 0.8716\n",
      "Epoch 5/10\n",
      "7750/7750 [==============================] - 1s 91us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.8788 - val_accuracy: 0.8853\n",
      "Epoch 6/10\n",
      "7750/7750 [==============================] - 1s 89us/sample - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.9069 - val_accuracy: 0.8836\n",
      "Epoch 7/10\n",
      "7750/7750 [==============================] - 1s 89us/sample - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.9460 - val_accuracy: 0.8631\n",
      "Epoch 8/10\n",
      "7750/7750 [==============================] - 1s 92us/sample - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.8443 - val_accuracy: 0.8849\n",
      "Epoch 9/10\n",
      "7750/7750 [==============================] - 1s 89us/sample - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.8514 - val_accuracy: 0.8804\n",
      "Epoch 10/10\n",
      "7750/7750 [==============================] - 1s 91us/sample - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.8724 - val_accuracy: 0.8751\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 0.0357 - accuracy: 0.9935 - val_loss: 0.8457 - val_accuracy: 0.8780\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.8055 - val_accuracy: 0.8875\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.8473 - val_accuracy: 0.8805\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.8410 - val_accuracy: 0.8895\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 6.9964e-04 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.8825\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 2.6461e-04 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.8870\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 1.7053e-04 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.8885\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 1.3606e-04 - accuracy: 1.0000 - val_loss: 0.8955 - val_accuracy: 0.8870\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 1.1348e-04 - accuracy: 1.0000 - val_loss: 0.9040 - val_accuracy: 0.8890\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 9.7148e-05 - accuracy: 1.0000 - val_loss: 0.9150 - val_accuracy: 0.8900\n",
      "Train on 8250 samples, validate on 1750 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8250/8250 [==============================] - 1s 149us/sample - loss: 0.0514 - accuracy: 0.9919 - val_loss: 0.8259 - val_accuracy: 0.8846\n",
      "Epoch 2/10\n",
      "8250/8250 [==============================] - 1s 84us/sample - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.8809 - val_accuracy: 0.8823\n",
      "Epoch 3/10\n",
      "8250/8250 [==============================] - 1s 84us/sample - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.8460 - val_accuracy: 0.8806\n",
      "Epoch 4/10\n",
      "8250/8250 [==============================] - 1s 85us/sample - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.8240 - val_accuracy: 0.8857\n",
      "Epoch 5/10\n",
      "8250/8250 [==============================] - 1s 84us/sample - loss: 5.4934e-04 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.8897\n",
      "Epoch 6/10\n",
      "8250/8250 [==============================] - 1s 86us/sample - loss: 2.2059e-04 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.8937\n",
      "Epoch 7/10\n",
      "8250/8250 [==============================] - 1s 85us/sample - loss: 1.5636e-04 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.8949\n",
      "Epoch 8/10\n",
      "8250/8250 [==============================] - 1s 86us/sample - loss: 1.2990e-04 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.8937\n",
      "Epoch 9/10\n",
      "8250/8250 [==============================] - 1s 85us/sample - loss: 1.0968e-04 - accuracy: 1.0000 - val_loss: 0.8828 - val_accuracy: 0.8954\n",
      "Epoch 10/10\n",
      "8250/8250 [==============================] - 1s 86us/sample - loss: 9.5868e-05 - accuracy: 1.0000 - val_loss: 0.8876 - val_accuracy: 0.8937\n",
      "Train on 8500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 1s 131us/sample - loss: 0.0287 - accuracy: 0.9934 - val_loss: 0.8761 - val_accuracy: 0.8833\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 86us/sample - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.8294 - val_accuracy: 0.8813\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 86us/sample - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.7785 - val_accuracy: 0.8893\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 85us/sample - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.8070 - val_accuracy: 0.8847\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 87us/sample - loss: 4.0175e-04 - accuracy: 0.9999 - val_loss: 0.8094 - val_accuracy: 0.8867\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 84us/sample - loss: 2.5645e-04 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.8893\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 83us/sample - loss: 1.6626e-04 - accuracy: 1.0000 - val_loss: 0.8385 - val_accuracy: 0.8893\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 86us/sample - loss: 1.3733e-04 - accuracy: 1.0000 - val_loss: 0.8439 - val_accuracy: 0.8880\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 85us/sample - loss: 1.1121e-04 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.8913\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 84us/sample - loss: 9.7703e-05 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.8913\n",
      "Train on 8750 samples, validate on 1250 samples\n",
      "Epoch 1/10\n",
      "8750/8750 [==============================] - 1s 127us/sample - loss: 0.0286 - accuracy: 0.9954 - val_loss: 0.9049 - val_accuracy: 0.8816\n",
      "Epoch 2/10\n",
      "8750/8750 [==============================] - 1s 85us/sample - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.8896 - val_accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "8750/8750 [==============================] - 1s 83us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.9150 - val_accuracy: 0.8840\n",
      "Epoch 4/10\n",
      "8750/8750 [==============================] - 1s 83us/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.8795 - val_accuracy: 0.8848\n",
      "Epoch 5/10\n",
      "8750/8750 [==============================] - 1s 83us/sample - loss: 2.5368e-04 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.8880\n",
      "Epoch 6/10\n",
      "8750/8750 [==============================] - 1s 83us/sample - loss: 1.3315e-04 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.8888\n",
      "Epoch 7/10\n",
      "8750/8750 [==============================] - 1s 83us/sample - loss: 1.0734e-04 - accuracy: 1.0000 - val_loss: 0.8944 - val_accuracy: 0.8872\n",
      "Epoch 8/10\n",
      "8750/8750 [==============================] - 1s 84us/sample - loss: 9.0549e-05 - accuracy: 1.0000 - val_loss: 0.9032 - val_accuracy: 0.8888\n",
      "Epoch 9/10\n",
      "8750/8750 [==============================] - 1s 83us/sample - loss: 7.8267e-05 - accuracy: 1.0000 - val_loss: 0.9133 - val_accuracy: 0.8888\n",
      "Epoch 10/10\n",
      "8750/8750 [==============================] - 1s 84us/sample - loss: 6.7995e-05 - accuracy: 1.0000 - val_loss: 0.9195 - val_accuracy: 0.8904\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 1s 154us/sample - loss: 0.0325 - accuracy: 0.9929 - val_loss: 0.9069 - val_accuracy: 0.8790\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 82us/sample - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.9426 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 81us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.9010 - val_accuracy: 0.8910\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 81us/sample - loss: 4.0651e-04 - accuracy: 1.0000 - val_loss: 0.9069 - val_accuracy: 0.8860\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 81us/sample - loss: 1.9142e-04 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.8920\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 80us/sample - loss: 1.4903e-04 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.8900\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 79us/sample - loss: 1.2215e-04 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 0.8940\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 84us/sample - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.8930\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 90us/sample - loss: 8.6452e-05 - accuracy: 1.0000 - val_loss: 0.9571 - val_accuracy: 0.8940\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 80us/sample - loss: 7.3723e-05 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.8920\n",
      "Train on 9250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "9250/9250 [==============================] - 1s 120us/sample - loss: 0.0284 - accuracy: 0.9943 - val_loss: 1.1558 - val_accuracy: 0.8800\n",
      "Epoch 2/10\n",
      "9250/9250 [==============================] - 1s 80us/sample - loss: 0.0147 - accuracy: 0.9965 - val_loss: 1.1233 - val_accuracy: 0.8827\n",
      "Epoch 3/10\n",
      "9250/9250 [==============================] - 1s 78us/sample - loss: 0.0021 - accuracy: 0.9997 - val_loss: 1.1268 - val_accuracy: 0.8747\n",
      "Epoch 4/10\n",
      "9250/9250 [==============================] - 1s 80us/sample - loss: 7.2477e-04 - accuracy: 0.9999 - val_loss: 1.1416 - val_accuracy: 0.8813\n",
      "Epoch 5/10\n",
      "9250/9250 [==============================] - 1s 82us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 1.1367 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "9250/9250 [==============================] - 1s 80us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.1758 - val_accuracy: 0.8747\n",
      "Epoch 7/10\n",
      "9250/9250 [==============================] - 1s 82us/sample - loss: 0.0240 - accuracy: 0.9916 - val_loss: 1.1999 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "9250/9250 [==============================] - 1s 79us/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.1807 - val_accuracy: 0.8707\n",
      "Epoch 9/10\n",
      "9250/9250 [==============================] - 1s 78us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 1.1459 - val_accuracy: 0.8733\n",
      "Epoch 10/10\n",
      "9250/9250 [==============================] - 1s 80us/sample - loss: 1.8799e-04 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.8747\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 1s 116us/sample - loss: 0.0296 - accuracy: 0.9949 - val_loss: 1.1394 - val_accuracy: 0.8620\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 76us/sample - loss: 0.0085 - accuracy: 0.9978 - val_loss: 1.1817 - val_accuracy: 0.8700\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 78us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.1957 - val_accuracy: 0.8720\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500/9500 [==============================] - 1s 76us/sample - loss: 0.0036 - accuracy: 0.9995 - val_loss: 1.2554 - val_accuracy: 0.8720\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 77us/sample - loss: 0.0137 - accuracy: 0.9956 - val_loss: 1.2030 - val_accuracy: 0.8700\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 78us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.2774 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 77us/sample - loss: 8.7262e-04 - accuracy: 0.9999 - val_loss: 1.3230 - val_accuracy: 0.8740\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 75us/sample - loss: 0.0103 - accuracy: 0.9967 - val_loss: 1.2582 - val_accuracy: 0.8740\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 77us/sample - loss: 0.0180 - accuracy: 0.9956 - val_loss: 1.3349 - val_accuracy: 0.8540\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 77us/sample - loss: 0.0115 - accuracy: 0.9982 - val_loss: 1.4533 - val_accuracy: 0.8520\n",
      "Train on 9750 samples, validate on 250 samples\n",
      "Epoch 1/10\n",
      "9750/9750 [==============================] - 1s 113us/sample - loss: 0.0282 - accuracy: 0.9947 - val_loss: 1.3041 - val_accuracy: 0.8480\n",
      "Epoch 2/10\n",
      "9750/9750 [==============================] - 1s 76us/sample - loss: 0.0091 - accuracy: 0.9976 - val_loss: 1.2976 - val_accuracy: 0.8480\n",
      "Epoch 3/10\n",
      "9750/9750 [==============================] - 1s 75us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 1.3125 - val_accuracy: 0.8560\n",
      "Epoch 4/10\n",
      "9750/9750 [==============================] - 1s 75us/sample - loss: 3.8221e-04 - accuracy: 1.0000 - val_loss: 1.2647 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "9750/9750 [==============================] - 1s 76us/sample - loss: 1.4899e-04 - accuracy: 1.0000 - val_loss: 1.2858 - val_accuracy: 0.8680\n",
      "Epoch 6/10\n",
      "9750/9750 [==============================] - 1s 75us/sample - loss: 1.1215e-04 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "9750/9750 [==============================] - 1s 76us/sample - loss: 9.1786e-05 - accuracy: 1.0000 - val_loss: 1.3108 - val_accuracy: 0.8560\n",
      "Epoch 8/10\n",
      "9750/9750 [==============================] - 1s 74us/sample - loss: 7.4685e-05 - accuracy: 1.0000 - val_loss: 1.3263 - val_accuracy: 0.8560\n",
      "Epoch 9/10\n",
      "9750/9750 [==============================] - 1s 74us/sample - loss: 6.1915e-05 - accuracy: 1.0000 - val_loss: 1.3371 - val_accuracy: 0.8560\n",
      "Epoch 10/10\n",
      "9750/9750 [==============================] - 1s 75us/sample - loss: 5.2746e-05 - accuracy: 1.0000 - val_loss: 1.3552 - val_accuracy: 0.8560\n",
      "Train on 250 samples, validate on 9750 samples\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 4ms/sample - loss: 2.0823 - accuracy: 0.2920 - val_loss: 1.7531 - val_accuracy: 0.4421\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 1.3321 - accuracy: 0.5600 - val_loss: 1.1435 - val_accuracy: 0.5609\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.9168 - accuracy: 0.6120 - val_loss: 1.0246 - val_accuracy: 0.6605\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.8111 - accuracy: 0.6840 - val_loss: 0.9448 - val_accuracy: 0.6452\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.6181 - accuracy: 0.7840 - val_loss: 0.7684 - val_accuracy: 0.7178\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.5314 - accuracy: 0.8280 - val_loss: 0.7325 - val_accuracy: 0.7439\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.4955 - accuracy: 0.8360 - val_loss: 0.7397 - val_accuracy: 0.7496\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.4731 - accuracy: 0.8320 - val_loss: 0.9518 - val_accuracy: 0.6854\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.4908 - accuracy: 0.8200 - val_loss: 0.7096 - val_accuracy: 0.7441\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/sample - loss: 0.3608 - accuracy: 0.9000 - val_loss: 0.6905 - val_accuracy: 0.7597\n",
      "Train on 500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.7666 - accuracy: 0.7380 - val_loss: 0.7929 - val_accuracy: 0.7311\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5366 - accuracy: 0.8360 - val_loss: 0.6365 - val_accuracy: 0.7639\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4491 - accuracy: 0.8500 - val_loss: 0.6195 - val_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3908 - accuracy: 0.8600 - val_loss: 0.6142 - val_accuracy: 0.7788\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3714 - accuracy: 0.8800 - val_loss: 0.5711 - val_accuracy: 0.7988\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3727 - accuracy: 0.8720 - val_loss: 0.6410 - val_accuracy: 0.7659\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3155 - accuracy: 0.9120 - val_loss: 0.5948 - val_accuracy: 0.7885\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2623 - accuracy: 0.9180 - val_loss: 0.6259 - val_accuracy: 0.7679\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2154 - accuracy: 0.9220 - val_loss: 0.6051 - val_accuracy: 0.7837\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.1951 - accuracy: 0.9460 - val_loss: 0.6496 - val_accuracy: 0.7788\n",
      "Train on 750 samples, validate on 9250 samples\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 1s 2ms/sample - loss: 0.3985 - accuracy: 0.8600 - val_loss: 0.6280 - val_accuracy: 0.7734\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 1s 828us/sample - loss: 0.3157 - accuracy: 0.9013 - val_loss: 0.5892 - val_accuracy: 0.7933\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 1s 849us/sample - loss: 0.2479 - accuracy: 0.9173 - val_loss: 0.5544 - val_accuracy: 0.8070\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 1s 828us/sample - loss: 0.1837 - accuracy: 0.9467 - val_loss: 0.5780 - val_accuracy: 0.8035\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 1s 881us/sample - loss: 0.1587 - accuracy: 0.9453 - val_loss: 0.5734 - val_accuracy: 0.8154\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 1s 835us/sample - loss: 0.1782 - accuracy: 0.9373 - val_loss: 0.5655 - val_accuracy: 0.8160\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 1s 813us/sample - loss: 0.1277 - accuracy: 0.9680 - val_loss: 0.6533 - val_accuracy: 0.8063\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 1s 816us/sample - loss: 0.1039 - accuracy: 0.9693 - val_loss: 0.6349 - val_accuracy: 0.8161\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 1s 829us/sample - loss: 0.0851 - accuracy: 0.9773 - val_loss: 0.6223 - val_accuracy: 0.8200\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 1s 817us/sample - loss: 0.0555 - accuracy: 0.9893 - val_loss: 0.6575 - val_accuracy: 0.8208\n",
      "Train on 1000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2392 - accuracy: 0.9230 - val_loss: 0.7065 - val_accuracy: 0.7950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 626us/sample - loss: 0.1865 - accuracy: 0.9360 - val_loss: 0.7489 - val_accuracy: 0.7920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 635us/sample - loss: 0.1289 - accuracy: 0.9590 - val_loss: 0.6190 - val_accuracy: 0.8222\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 623us/sample - loss: 0.1232 - accuracy: 0.9600 - val_loss: 0.6058 - val_accuracy: 0.8180\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 626us/sample - loss: 0.1040 - accuracy: 0.9810 - val_loss: 0.6304 - val_accuracy: 0.8174\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 625us/sample - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.6851 - val_accuracy: 0.8180\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 635us/sample - loss: 0.0516 - accuracy: 0.9860 - val_loss: 0.6595 - val_accuracy: 0.8246\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 635us/sample - loss: 0.0387 - accuracy: 0.9910 - val_loss: 0.7319 - val_accuracy: 0.8164\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 627us/sample - loss: 0.0718 - accuracy: 0.9790 - val_loss: 0.7056 - val_accuracy: 0.8186\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 621us/sample - loss: 0.0309 - accuracy: 0.9960 - val_loss: 0.7578 - val_accuracy: 0.8247\n",
      "Train on 1250 samples, validate on 8750 samples\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 1s 871us/sample - loss: 0.1983 - accuracy: 0.9400 - val_loss: 0.6708 - val_accuracy: 0.8134\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 1s 505us/sample - loss: 0.1182 - accuracy: 0.9624 - val_loss: 0.6572 - val_accuracy: 0.8263\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 1s 513us/sample - loss: 0.0612 - accuracy: 0.9784 - val_loss: 0.6498 - val_accuracy: 0.8270\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 1s 518us/sample - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.7990 - val_accuracy: 0.8118\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 1s 507us/sample - loss: 0.0471 - accuracy: 0.9816 - val_loss: 0.7819 - val_accuracy: 0.8145\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 1s 511us/sample - loss: 0.0520 - accuracy: 0.9864 - val_loss: 0.6905 - val_accuracy: 0.8296\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 1s 506us/sample - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.8095 - val_accuracy: 0.8175\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1s 513us/sample - loss: 0.0177 - accuracy: 0.9976 - val_loss: 0.7860 - val_accuracy: 0.8232\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1s 506us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.8207\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1s 515us/sample - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.8170 - val_accuracy: 0.8263\n",
      "Train on 1500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 701us/sample - loss: 0.1847 - accuracy: 0.9473 - val_loss: 0.6190 - val_accuracy: 0.8265\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 437us/sample - loss: 0.0921 - accuracy: 0.9680 - val_loss: 0.6713 - val_accuracy: 0.8254\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 428us/sample - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.6530 - val_accuracy: 0.8332\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 431us/sample - loss: 0.0323 - accuracy: 0.9913 - val_loss: 0.7313 - val_accuracy: 0.8316\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 435us/sample - loss: 0.0389 - accuracy: 0.9880 - val_loss: 0.7326 - val_accuracy: 0.8195\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 431us/sample - loss: 0.0157 - accuracy: 0.9993 - val_loss: 0.7777 - val_accuracy: 0.8312\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 429us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.8298\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 427us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.8339\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 433us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.8286\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 430us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.8325\n",
      "Train on 1750 samples, validate on 8250 samples\n",
      "Epoch 1/10\n",
      "1750/1750 [==============================] - 1s 625us/sample - loss: 0.1523 - accuracy: 0.9606 - val_loss: 0.6522 - val_accuracy: 0.8354\n",
      "Epoch 2/10\n",
      "1750/1750 [==============================] - 1s 378us/sample - loss: 0.0583 - accuracy: 0.9834 - val_loss: 0.7178 - val_accuracy: 0.8252\n",
      "Epoch 3/10\n",
      "1750/1750 [==============================] - 1s 369us/sample - loss: 0.0362 - accuracy: 0.9914 - val_loss: 0.7052 - val_accuracy: 0.8345\n",
      "Epoch 4/10\n",
      "1750/1750 [==============================] - 1s 366us/sample - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.6948 - val_accuracy: 0.8410\n",
      "Epoch 5/10\n",
      "1750/1750 [==============================] - 1s 371us/sample - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.7289 - val_accuracy: 0.8321\n",
      "Epoch 6/10\n",
      "1750/1750 [==============================] - 1s 375us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.8429\n",
      "Epoch 7/10\n",
      "1750/1750 [==============================] - 1s 370us/sample - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.8681 - val_accuracy: 0.8376\n",
      "Epoch 8/10\n",
      "1750/1750 [==============================] - 1s 373us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9517 - val_accuracy: 0.8315\n",
      "Epoch 9/10\n",
      "1750/1750 [==============================] - 1s 370us/sample - loss: 0.0085 - accuracy: 0.9966 - val_loss: 0.7675 - val_accuracy: 0.8439\n",
      "Epoch 10/10\n",
      "1750/1750 [==============================] - 1s 367us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8390 - val_accuracy: 0.8418\n",
      "Train on 2000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 652us/sample - loss: 0.1473 - accuracy: 0.9595 - val_loss: 0.6359 - val_accuracy: 0.8364\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 295us/sample - loss: 0.0738 - accuracy: 0.9775 - val_loss: 0.6787 - val_accuracy: 0.8338\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 292us/sample - loss: 0.0825 - accuracy: 0.9745 - val_loss: 0.7368 - val_accuracy: 0.8285\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 298us/sample - loss: 0.0418 - accuracy: 0.9880 - val_loss: 0.6726 - val_accuracy: 0.8425\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 291us/sample - loss: 0.0198 - accuracy: 0.9955 - val_loss: 0.7516 - val_accuracy: 0.8338\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 295us/sample - loss: 0.0181 - accuracy: 0.9960 - val_loss: 0.7246 - val_accuracy: 0.8381\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 290us/sample - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.7770 - val_accuracy: 0.8391\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 291us/sample - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.7560 - val_accuracy: 0.8420\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 303us/sample - loss: 0.0378 - accuracy: 0.9910 - val_loss: 0.6511 - val_accuracy: 0.8380\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 298us/sample - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.7438 - val_accuracy: 0.8381\n",
      "Train on 2250 samples, validate on 7750 samples\n",
      "Epoch 1/10\n",
      "2250/2250 [==============================] - 1s 517us/sample - loss: 0.1196 - accuracy: 0.9742 - val_loss: 0.6852 - val_accuracy: 0.8272\n",
      "Epoch 2/10\n",
      "2250/2250 [==============================] - 1s 303us/sample - loss: 0.0563 - accuracy: 0.9858 - val_loss: 0.6160 - val_accuracy: 0.8421\n",
      "Epoch 3/10\n",
      "2250/2250 [==============================] - 1s 295us/sample - loss: 0.0367 - accuracy: 0.9916 - val_loss: 0.6613 - val_accuracy: 0.8410\n",
      "Epoch 4/10\n",
      "2250/2250 [==============================] - 1s 292us/sample - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.7421 - val_accuracy: 0.8382\n",
      "Epoch 5/10\n",
      "2250/2250 [==============================] - 1s 318us/sample - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.7171 - val_accuracy: 0.8440\n",
      "Epoch 6/10\n",
      "2250/2250 [==============================] - 1s 292us/sample - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.7668 - val_accuracy: 0.8457\n",
      "Epoch 7/10\n",
      "2250/2250 [==============================] - 1s 301us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8467\n",
      "Epoch 8/10\n",
      "2250/2250 [==============================] - 1s 292us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.8462\n",
      "Epoch 9/10\n",
      "2250/2250 [==============================] - 1s 294us/sample - loss: 9.9973e-04 - accuracy: 1.0000 - val_loss: 0.8316 - val_accuracy: 0.8476\n",
      "Epoch 10/10\n",
      "2250/2250 [==============================] - 1s 296us/sample - loss: 7.5658e-04 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.8499\n",
      "Train on 2500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 436us/sample - loss: 0.1112 - accuracy: 0.9740 - val_loss: 0.6738 - val_accuracy: 0.8389\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 268us/sample - loss: 0.0372 - accuracy: 0.9928 - val_loss: 0.6984 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 271us/sample - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.6861 - val_accuracy: 0.8480\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 274us/sample - loss: 0.0408 - accuracy: 0.9880 - val_loss: 0.7492 - val_accuracy: 0.8365\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 268us/sample - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.7728 - val_accuracy: 0.8445\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 296us/sample - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.7850 - val_accuracy: 0.8512\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 270us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.8525\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 269us/sample - loss: 9.4151e-04 - accuracy: 1.0000 - val_loss: 0.8266 - val_accuracy: 0.8503\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 268us/sample - loss: 7.0304e-04 - accuracy: 1.0000 - val_loss: 0.8496 - val_accuracy: 0.8516\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 268us/sample - loss: 6.0028e-04 - accuracy: 1.0000 - val_loss: 0.8618 - val_accuracy: 0.8516\n",
      "Train on 2750 samples, validate on 7250 samples\n",
      "Epoch 1/10\n",
      "2750/2750 [==============================] - 1s 424us/sample - loss: 0.0761 - accuracy: 0.9844 - val_loss: 0.7074 - val_accuracy: 0.8466\n",
      "Epoch 2/10\n",
      "2750/2750 [==============================] - 1s 246us/sample - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.7946 - val_accuracy: 0.8385\n",
      "Epoch 3/10\n",
      "2750/2750 [==============================] - 1s 247us/sample - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.7221 - val_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "2750/2750 [==============================] - 1s 248us/sample - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.8262 - val_accuracy: 0.8394\n",
      "Epoch 5/10\n",
      "2750/2750 [==============================] - 1s 244us/sample - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.8326 - val_accuracy: 0.8461\n",
      "Epoch 6/10\n",
      "2750/2750 [==============================] - 1s 245us/sample - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.8342 - val_accuracy: 0.8506\n",
      "Epoch 7/10\n",
      "2750/2750 [==============================] - 1s 245us/sample - loss: 7.7339e-04 - accuracy: 1.0000 - val_loss: 0.8642 - val_accuracy: 0.8490\n",
      "Epoch 8/10\n",
      "2750/2750 [==============================] - 1s 248us/sample - loss: 5.0370e-04 - accuracy: 1.0000 - val_loss: 0.8793 - val_accuracy: 0.8508\n",
      "Epoch 9/10\n",
      "2750/2750 [==============================] - 1s 245us/sample - loss: 4.0490e-04 - accuracy: 1.0000 - val_loss: 0.8983 - val_accuracy: 0.8519\n",
      "Epoch 10/10\n",
      "2750/2750 [==============================] - 1s 245us/sample - loss: 3.4470e-04 - accuracy: 1.0000 - val_loss: 0.9098 - val_accuracy: 0.8528\n",
      "Train on 3000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 372us/sample - loss: 0.0806 - accuracy: 0.9790 - val_loss: 0.7360 - val_accuracy: 0.8413\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 231us/sample - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.7729 - val_accuracy: 0.8463\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 229us/sample - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.7847 - val_accuracy: 0.8511\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 228us/sample - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.8357 - val_accuracy: 0.8501\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 234us/sample - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.8327 - val_accuracy: 0.8513\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 228us/sample - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.8394 - val_accuracy: 0.8479\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 227us/sample - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.8945 - val_accuracy: 0.8533\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 227us/sample - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.9237 - val_accuracy: 0.8319\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 254us/sample - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.9015 - val_accuracy: 0.8467\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 248us/sample - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.9756 - val_accuracy: 0.8417\n",
      "Train on 3250 samples, validate on 6750 samples\n",
      "Epoch 1/10\n",
      "3250/3250 [==============================] - 2s 589us/sample - loss: 0.0720 - accuracy: 0.9831 - val_loss: 0.7729 - val_accuracy: 0.8480\n",
      "Epoch 2/10\n",
      "3250/3250 [==============================] - 1s 246us/sample - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.8210 - val_accuracy: 0.8511\n",
      "Epoch 3/10\n",
      "3250/3250 [==============================] - 1s 231us/sample - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.8416 - val_accuracy: 0.8462\n",
      "Epoch 4/10\n",
      "3250/3250 [==============================] - 1s 226us/sample - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.8762 - val_accuracy: 0.8495\n",
      "Epoch 5/10\n",
      "3250/3250 [==============================] - 1s 222us/sample - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.9415 - val_accuracy: 0.8455\n",
      "Epoch 6/10\n",
      "3250/3250 [==============================] - 1s 222us/sample - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.8661 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "3250/3250 [==============================] - 1s 228us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9166 - val_accuracy: 0.8495\n",
      "Epoch 8/10\n",
      "3250/3250 [==============================] - 1s 216us/sample - loss: 6.7797e-04 - accuracy: 1.0000 - val_loss: 0.9328 - val_accuracy: 0.8544\n",
      "Epoch 9/10\n",
      "3250/3250 [==============================] - 1s 231us/sample - loss: 3.0970e-04 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.8538\n",
      "Epoch 10/10\n",
      "3250/3250 [==============================] - 1s 216us/sample - loss: 1.9920e-04 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.8553\n",
      "Train on 3500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 334us/sample - loss: 0.0661 - accuracy: 0.9834 - val_loss: 0.7705 - val_accuracy: 0.8503\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 214us/sample - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.8002 - val_accuracy: 0.8529\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 213us/sample - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.8168 - val_accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 210us/sample - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.8389 - val_accuracy: 0.8531\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 209us/sample - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.8408 - val_accuracy: 0.8503\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 210us/sample - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.8662 - val_accuracy: 0.8558\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 211us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.8572\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 209us/sample - loss: 3.8103e-04 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.8572\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 210us/sample - loss: 2.5675e-04 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.8578\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 207us/sample - loss: 2.0065e-04 - accuracy: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.8571\n",
      "Train on 3750 samples, validate on 6250 samples\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 1s 318us/sample - loss: 0.0711 - accuracy: 0.9853 - val_loss: 0.7668 - val_accuracy: 0.8470\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 1s 197us/sample - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.8383 - val_accuracy: 0.8546\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 1s 201us/sample - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.8623 - val_accuracy: 0.8558\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 1s 197us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 1s 196us/sample - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.8951 - val_accuracy: 0.8507\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 1s 198us/sample - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.8308 - val_accuracy: 0.8389\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 1s 196us/sample - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.9067 - val_accuracy: 0.8555\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 1s 197us/sample - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.9216 - val_accuracy: 0.8533\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 1s 197us/sample - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.9444 - val_accuracy: 0.8542\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 1s 195us/sample - loss: 3.2453e-04 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.8592\n",
      "Train on 4000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 276us/sample - loss: 0.0753 - accuracy: 0.9845 - val_loss: 0.7911 - val_accuracy: 0.8545\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 172us/sample - loss: 0.0198 - accuracy: 0.9958 - val_loss: 0.8072 - val_accuracy: 0.8527\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.7953 - val_accuracy: 0.8497\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 174us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.7950 - val_accuracy: 0.8570\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 175us/sample - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.9177 - val_accuracy: 0.8543\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.8676 - val_accuracy: 0.8563\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 174us/sample - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.7982 - val_accuracy: 0.8505\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 171us/sample - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.7989 - val_accuracy: 0.8490\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 174us/sample - loss: 0.0313 - accuracy: 0.9890 - val_loss: 0.9318 - val_accuracy: 0.8343\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 170us/sample - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.8750 - val_accuracy: 0.8515\n",
      "Train on 4250 samples, validate on 5750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 278us/sample - loss: 0.0582 - accuracy: 0.9852 - val_loss: 0.6950 - val_accuracy: 0.8558\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 179us/sample - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.8033 - val_accuracy: 0.8572\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 176us/sample - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.8181 - val_accuracy: 0.8558\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 176us/sample - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.9326 - val_accuracy: 0.8619\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 176us/sample - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.9690 - val_accuracy: 0.8551\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 177us/sample - loss: 0.0100 - accuracy: 0.9955 - val_loss: 0.8968 - val_accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 176us/sample - loss: 0.0153 - accuracy: 0.9962 - val_loss: 1.0572 - val_accuracy: 0.8419\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 176us/sample - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.9327 - val_accuracy: 0.8558\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 177us/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.9349 - val_accuracy: 0.8513\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.9727 - val_accuracy: 0.8536\n",
      "Train on 4500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 334us/sample - loss: 0.0426 - accuracy: 0.9918 - val_loss: 0.8157 - val_accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 171us/sample - loss: 0.0158 - accuracy: 0.9960 - val_loss: 1.0441 - val_accuracy: 0.8307\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 168us/sample - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.9323 - val_accuracy: 0.8564\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 169us/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.9658 - val_accuracy: 0.8555\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 170us/sample - loss: 4.1867e-04 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.8587\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 168us/sample - loss: 1.5288e-04 - accuracy: 1.0000 - val_loss: 1.0132 - val_accuracy: 0.8585\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 170us/sample - loss: 1.0882e-04 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.8605\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 169us/sample - loss: 8.5498e-05 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.8605\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 169us/sample - loss: 7.0894e-05 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.8607\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 170us/sample - loss: 6.0191e-05 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.8607\n",
      "Train on 4750 samples, validate on 5250 samples\n",
      "Epoch 1/10\n",
      "4750/4750 [==============================] - 1s 252us/sample - loss: 0.0633 - accuracy: 0.9878 - val_loss: 0.7930 - val_accuracy: 0.8474\n",
      "Epoch 2/10\n",
      "4750/4750 [==============================] - 1s 161us/sample - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.8393 - val_accuracy: 0.8541\n",
      "Epoch 3/10\n",
      "4750/4750 [==============================] - 1s 160us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.9175 - val_accuracy: 0.8520\n",
      "Epoch 4/10\n",
      "4750/4750 [==============================] - 1s 161us/sample - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.9116 - val_accuracy: 0.8608\n",
      "Epoch 5/10\n",
      "4750/4750 [==============================] - 1s 160us/sample - loss: 6.0583e-04 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.8623\n",
      "Epoch 6/10\n",
      "4750/4750 [==============================] - 1s 161us/sample - loss: 1.9549e-04 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.8630\n",
      "Epoch 7/10\n",
      "4750/4750 [==============================] - 1s 163us/sample - loss: 1.3721e-04 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.8630\n",
      "Epoch 8/10\n",
      "4750/4750 [==============================] - 1s 161us/sample - loss: 1.0902e-04 - accuracy: 1.0000 - val_loss: 0.9976 - val_accuracy: 0.8613\n",
      "Epoch 9/10\n",
      "4750/4750 [==============================] - 1s 162us/sample - loss: 9.2518e-05 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.8630\n",
      "Epoch 10/10\n",
      "4750/4750 [==============================] - 1s 161us/sample - loss: 7.9946e-05 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.8629\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 1s 243us/sample - loss: 0.0596 - accuracy: 0.9888 - val_loss: 0.7557 - val_accuracy: 0.8568\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 157us/sample - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.8580 - val_accuracy: 0.8526\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 156us/sample - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.8922 - val_accuracy: 0.8582\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 158us/sample - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.9203 - val_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 158us/sample - loss: 5.7533e-04 - accuracy: 1.0000 - val_loss: 0.9514 - val_accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 155us/sample - loss: 2.7796e-04 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.8604\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 155us/sample - loss: 1.3390e-04 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.8606\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 157us/sample - loss: 1.0362e-04 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.8610\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 155us/sample - loss: 8.4665e-05 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 155us/sample - loss: 7.1401e-05 - accuracy: 1.0000 - val_loss: 1.0298 - val_accuracy: 0.8592\n",
      "Train on 5250 samples, validate on 4750 samples\n",
      "Epoch 1/10\n",
      "5250/5250 [==============================] - 1s 232us/sample - loss: 0.0611 - accuracy: 0.9899 - val_loss: 0.8146 - val_accuracy: 0.8564\n",
      "Epoch 2/10\n",
      "5250/5250 [==============================] - 1s 149us/sample - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.8183 - val_accuracy: 0.8611\n",
      "Epoch 3/10\n",
      "5250/5250 [==============================] - 1s 150us/sample - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.8602 - val_accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "5250/5250 [==============================] - 1s 156us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8940 - val_accuracy: 0.8535\n",
      "Epoch 5/10\n",
      "5250/5250 [==============================] - 1s 148us/sample - loss: 4.4991e-04 - accuracy: 1.0000 - val_loss: 0.9595 - val_accuracy: 0.8579\n",
      "Epoch 6/10\n",
      "5250/5250 [==============================] - 1s 148us/sample - loss: 1.9009e-04 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.8606\n",
      "Epoch 7/10\n",
      "5250/5250 [==============================] - 1s 150us/sample - loss: 1.1960e-04 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.8611\n",
      "Epoch 8/10\n",
      "5250/5250 [==============================] - 1s 148us/sample - loss: 9.5155e-05 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.8613\n",
      "Epoch 9/10\n",
      "5250/5250 [==============================] - 1s 148us/sample - loss: 7.8284e-05 - accuracy: 1.0000 - val_loss: 1.0172 - val_accuracy: 0.8629\n",
      "Epoch 10/10\n",
      "5250/5250 [==============================] - 1s 149us/sample - loss: 6.6546e-05 - accuracy: 1.0000 - val_loss: 1.0297 - val_accuracy: 0.8625\n",
      "Train on 5500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 1s 222us/sample - loss: 0.0409 - accuracy: 0.9931 - val_loss: 0.9198 - val_accuracy: 0.8520\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 145us/sample - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.9085 - val_accuracy: 0.8553\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 144us/sample - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.9352 - val_accuracy: 0.8544\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 145us/sample - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.9055 - val_accuracy: 0.8460\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 143us/sample - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.9023 - val_accuracy: 0.8502\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 145us/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.9652 - val_accuracy: 0.8553\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 144us/sample - loss: 5.1173e-04 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.8587\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 142us/sample - loss: 1.4902e-04 - accuracy: 1.0000 - val_loss: 1.0094 - val_accuracy: 0.8602\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 146us/sample - loss: 1.0166e-04 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.8613\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 143us/sample - loss: 8.2286e-05 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.8620\n",
      "Train on 5750 samples, validate on 4250 samples\n",
      "Epoch 1/10\n",
      "5750/5750 [==============================] - 1s 213us/sample - loss: 0.0399 - accuracy: 0.9922 - val_loss: 0.8470 - val_accuracy: 0.8642\n",
      "Epoch 2/10\n",
      "5750/5750 [==============================] - 1s 137us/sample - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.8446 - val_accuracy: 0.8666\n",
      "Epoch 3/10\n",
      "5750/5750 [==============================] - 1s 138us/sample - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.8663 - val_accuracy: 0.8680\n",
      "Epoch 4/10\n",
      "5750/5750 [==============================] - 1s 137us/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.9152 - val_accuracy: 0.8652\n",
      "Epoch 5/10\n",
      "5750/5750 [==============================] - 1s 138us/sample - loss: 3.5616e-04 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.8628\n",
      "Epoch 6/10\n",
      "5750/5750 [==============================] - 1s 138us/sample - loss: 1.8245e-04 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.8661\n",
      "Epoch 7/10\n",
      "5750/5750 [==============================] - 1s 138us/sample - loss: 7.6267e-05 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.8671\n",
      "Epoch 8/10\n",
      "5750/5750 [==============================] - 1s 137us/sample - loss: 6.0895e-05 - accuracy: 1.0000 - val_loss: 1.0210 - val_accuracy: 0.8664\n",
      "Epoch 9/10\n",
      "5750/5750 [==============================] - 1s 139us/sample - loss: 5.0727e-05 - accuracy: 1.0000 - val_loss: 1.0317 - val_accuracy: 0.8673\n",
      "Epoch 10/10\n",
      "5750/5750 [==============================] - 1s 139us/sample - loss: 4.3189e-05 - accuracy: 1.0000 - val_loss: 1.0439 - val_accuracy: 0.8671\n",
      "Train on 6000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 1s 199us/sample - loss: 0.0430 - accuracy: 0.9913 - val_loss: 0.8210 - val_accuracy: 0.8540\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 129us/sample - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.8615 - val_accuracy: 0.8547\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 127us/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.9147 - val_accuracy: 0.8630\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 127us/sample - loss: 4.4505e-04 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.8650\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 130us/sample - loss: 1.2791e-04 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.8655\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 128us/sample - loss: 9.0364e-05 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.8670\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 128us/sample - loss: 7.0395e-05 - accuracy: 1.0000 - val_loss: 1.0294 - val_accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 130us/sample - loss: 5.6965e-05 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.8677\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 128us/sample - loss: 4.6902e-05 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 127us/sample - loss: 3.9881e-05 - accuracy: 1.0000 - val_loss: 1.0745 - val_accuracy: 0.8685\n",
      "Train on 6250 samples, validate on 3750 samples\n",
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 1s 204us/sample - loss: 0.0532 - accuracy: 0.9907 - val_loss: 0.8302 - val_accuracy: 0.8640\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 1s 131us/sample - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.7861 - val_accuracy: 0.8683\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 1s 130us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.8372 - val_accuracy: 0.8717\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 1s 132us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.9513 - val_accuracy: 0.8672\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 1s 130us/sample - loss: 0.0099 - accuracy: 0.9960 - val_loss: 1.1482 - val_accuracy: 0.8483\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 1s 130us/sample - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.8752 - val_accuracy: 0.8525\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 1s 130us/sample - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.8819 - val_accuracy: 0.8683\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 1s 132us/sample - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.9116 - val_accuracy: 0.8675\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 1s 130us/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.9409 - val_accuracy: 0.8723\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 1s 132us/sample - loss: 1.4529e-04 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.8733\n",
      "Train on 6500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 1s 192us/sample - loss: 0.0443 - accuracy: 0.9914 - val_loss: 0.8524 - val_accuracy: 0.8660\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 129us/sample - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.8519 - val_accuracy: 0.8706\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 126us/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.8069 - val_accuracy: 0.8737\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 126us/sample - loss: 4.5803e-04 - accuracy: 1.0000 - val_loss: 0.8870 - val_accuracy: 0.8769\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 128us/sample - loss: 1.5521e-04 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 128us/sample - loss: 8.7007e-05 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 131us/sample - loss: 6.2740e-05 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.8771\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 126us/sample - loss: 4.9886e-05 - accuracy: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.8774\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 128us/sample - loss: 4.0753e-05 - accuracy: 1.0000 - val_loss: 1.0041 - val_accuracy: 0.8780\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 128us/sample - loss: 3.4191e-05 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.8769\n",
      "Train on 6750 samples, validate on 3250 samples\n",
      "Epoch 1/10\n",
      "6750/6750 [==============================] - 1s 187us/sample - loss: 0.0311 - accuracy: 0.9935 - val_loss: 0.9022 - val_accuracy: 0.8612\n",
      "Epoch 2/10\n",
      "6750/6750 [==============================] - 1s 123us/sample - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.8663 - val_accuracy: 0.8738\n",
      "Epoch 3/10\n",
      "6750/6750 [==============================] - 1s 122us/sample - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.8448 - val_accuracy: 0.8677\n",
      "Epoch 4/10\n",
      "6750/6750 [==============================] - 1s 123us/sample - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.8967 - val_accuracy: 0.8757\n",
      "Epoch 5/10\n",
      "6750/6750 [==============================] - 1s 123us/sample - loss: 3.4342e-04 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.8782\n",
      "Epoch 6/10\n",
      "6750/6750 [==============================] - 1s 121us/sample - loss: 9.3138e-05 - accuracy: 1.0000 - val_loss: 0.9828 - val_accuracy: 0.8788\n",
      "Epoch 7/10\n",
      "6750/6750 [==============================] - 1s 122us/sample - loss: 5.6596e-05 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "6750/6750 [==============================] - 1s 124us/sample - loss: 4.3786e-05 - accuracy: 1.0000 - val_loss: 1.0144 - val_accuracy: 0.8791\n",
      "Epoch 9/10\n",
      "6750/6750 [==============================] - 1s 122us/sample - loss: 3.5753e-05 - accuracy: 1.0000 - val_loss: 1.0296 - val_accuracy: 0.8788\n",
      "Epoch 10/10\n",
      "6750/6750 [==============================] - 1s 123us/sample - loss: 2.9878e-05 - accuracy: 1.0000 - val_loss: 1.0431 - val_accuracy: 0.8794\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 1s 180us/sample - loss: 0.0244 - accuracy: 0.9959 - val_loss: 0.9336 - val_accuracy: 0.8690\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 123us/sample - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.8764 - val_accuracy: 0.8660\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 120us/sample - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.9819 - val_accuracy: 0.8573\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 120us/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.8990 - val_accuracy: 0.8737\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 121us/sample - loss: 0.0099 - accuracy: 0.9976 - val_loss: 1.0016 - val_accuracy: 0.8657\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 119us/sample - loss: 0.0163 - accuracy: 0.9941 - val_loss: 0.9409 - val_accuracy: 0.8630\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 122us/sample - loss: 0.0030 - accuracy: 0.9991 - val_loss: 1.0472 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 119us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.0203 - val_accuracy: 0.8687\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 120us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.9334 - val_accuracy: 0.8723\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 119us/sample - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.8995 - val_accuracy: 0.8493\n",
      "Train on 7250 samples, validate on 2750 samples\n",
      "Epoch 1/10\n",
      "7250/7250 [==============================] - 2s 220us/sample - loss: 0.0289 - accuracy: 0.9948 - val_loss: 0.9255 - val_accuracy: 0.8724\n",
      "Epoch 2/10\n",
      "7250/7250 [==============================] - 1s 118us/sample - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.9590 - val_accuracy: 0.8629\n",
      "Epoch 3/10\n",
      "7250/7250 [==============================] - 1s 120us/sample - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.9457 - val_accuracy: 0.8727\n",
      "Epoch 4/10\n",
      "7250/7250 [==============================] - 1s 118us/sample - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.0160 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "7250/7250 [==============================] - 1s 120us/sample - loss: 0.0078 - accuracy: 0.9971 - val_loss: 1.0648 - val_accuracy: 0.8578\n",
      "Epoch 6/10\n",
      "7250/7250 [==============================] - 1s 118us/sample - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.0622 - val_accuracy: 0.8727\n",
      "Epoch 7/10\n",
      "7250/7250 [==============================] - 1s 120us/sample - loss: 7.5154e-04 - accuracy: 0.9999 - val_loss: 1.0436 - val_accuracy: 0.8782\n",
      "Epoch 8/10\n",
      "7250/7250 [==============================] - 1s 118us/sample - loss: 0.0060 - accuracy: 0.9979 - val_loss: 1.0141 - val_accuracy: 0.8709\n",
      "Epoch 9/10\n",
      "7250/7250 [==============================] - 1s 118us/sample - loss: 0.0038 - accuracy: 0.9992 - val_loss: 1.2926 - val_accuracy: 0.8702\n",
      "Epoch 10/10\n",
      "7250/7250 [==============================] - 1s 120us/sample - loss: 0.0096 - accuracy: 0.9977 - val_loss: 1.1509 - val_accuracy: 0.8705\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 1s 173us/sample - loss: 0.0493 - accuracy: 0.9924 - val_loss: 0.9094 - val_accuracy: 0.8596\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 116us/sample - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.8651 - val_accuracy: 0.8696\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 115us/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.9967 - val_accuracy: 0.8732\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 115us/sample - loss: 1.0938e-04 - accuracy: 1.0000 - val_loss: 1.0304 - val_accuracy: 0.8752\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 115us/sample - loss: 6.4809e-05 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.8744\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 113us/sample - loss: 4.9070e-05 - accuracy: 1.0000 - val_loss: 1.0668 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 112us/sample - loss: 3.9035e-05 - accuracy: 1.0000 - val_loss: 1.0809 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 119us/sample - loss: 3.1849e-05 - accuracy: 1.0000 - val_loss: 1.0930 - val_accuracy: 0.8752\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 114us/sample - loss: 2.6412e-05 - accuracy: 1.0000 - val_loss: 1.1061 - val_accuracy: 0.8760\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 115us/sample - loss: 2.2173e-05 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.8764\n",
      "Train on 7750 samples, validate on 2250 samples\n",
      "Epoch 1/10\n",
      "7750/7750 [==============================] - 1s 168us/sample - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.8766 - val_accuracy: 0.8733\n",
      "Epoch 2/10\n",
      "7750/7750 [==============================] - 1s 113us/sample - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.8981 - val_accuracy: 0.8827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "7750/7750 [==============================] - 1s 113us/sample - loss: 6.3948e-04 - accuracy: 0.9999 - val_loss: 0.9258 - val_accuracy: 0.8804\n",
      "Epoch 4/10\n",
      "7750/7750 [==============================] - 1s 113us/sample - loss: 3.1502e-04 - accuracy: 0.9999 - val_loss: 0.9678 - val_accuracy: 0.8778\n",
      "Epoch 5/10\n",
      "7750/7750 [==============================] - 1s 111us/sample - loss: 0.0037 - accuracy: 0.9987 - val_loss: 1.0409 - val_accuracy: 0.8733\n",
      "Epoch 6/10\n",
      "7750/7750 [==============================] - 1s 110us/sample - loss: 0.0161 - accuracy: 0.9956 - val_loss: 1.0562 - val_accuracy: 0.8644\n",
      "Epoch 7/10\n",
      "7750/7750 [==============================] - 1s 111us/sample - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.0021 - val_accuracy: 0.8649\n",
      "Epoch 8/10\n",
      "7750/7750 [==============================] - 1s 111us/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 1.1358 - val_accuracy: 0.8667\n",
      "Epoch 9/10\n",
      "7750/7750 [==============================] - 1s 116us/sample - loss: 0.0063 - accuracy: 0.9977 - val_loss: 1.0218 - val_accuracy: 0.8769\n",
      "Epoch 10/10\n",
      "7750/7750 [==============================] - 1s 111us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.1097 - val_accuracy: 0.8662\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0407 - accuracy: 0.9931 - val_loss: 0.8683 - val_accuracy: 0.8740\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.9441 - val_accuracy: 0.8740\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.0789 - val_accuracy: 0.8805\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1.8050e-04 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.8825\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 5.5014e-05 - accuracy: 1.0000 - val_loss: 1.1313 - val_accuracy: 0.8810\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 3.5581e-05 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.8820\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 2.7455e-05 - accuracy: 1.0000 - val_loss: 1.1636 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 2.2154e-05 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 0.8820\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1.8226e-05 - accuracy: 1.0000 - val_loss: 1.1893 - val_accuracy: 0.8815\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 1.5192e-05 - accuracy: 1.0000 - val_loss: 1.2015 - val_accuracy: 0.8820\n",
      "Train on 8250 samples, validate on 1750 samples\n",
      "Epoch 1/10\n",
      "8250/8250 [==============================] - 1s 162us/sample - loss: 0.0440 - accuracy: 0.9942 - val_loss: 0.9842 - val_accuracy: 0.8697\n",
      "Epoch 2/10\n",
      "8250/8250 [==============================] - 1s 108us/sample - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.9955 - val_accuracy: 0.8669\n",
      "Epoch 3/10\n",
      "8250/8250 [==============================] - 1s 105us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.1144 - val_accuracy: 0.8709\n",
      "Epoch 4/10\n",
      "8250/8250 [==============================] - 1s 106us/sample - loss: 4.7483e-04 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.8731\n",
      "Epoch 5/10\n",
      "8250/8250 [==============================] - 1s 107us/sample - loss: 0.0068 - accuracy: 0.9972 - val_loss: 1.1013 - val_accuracy: 0.8611\n",
      "Epoch 6/10\n",
      "8250/8250 [==============================] - 1s 107us/sample - loss: 0.0190 - accuracy: 0.9937 - val_loss: 1.0532 - val_accuracy: 0.8606\n",
      "Epoch 7/10\n",
      "8250/8250 [==============================] - 1s 108us/sample - loss: 0.0102 - accuracy: 0.9966 - val_loss: 1.1143 - val_accuracy: 0.8731\n",
      "Epoch 8/10\n",
      "8250/8250 [==============================] - 1s 108us/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 1.1551 - val_accuracy: 0.8629\n",
      "Epoch 9/10\n",
      "8250/8250 [==============================] - 1s 107us/sample - loss: 8.2979e-04 - accuracy: 0.9998 - val_loss: 1.1408 - val_accuracy: 0.8640\n",
      "Epoch 10/10\n",
      "8250/8250 [==============================] - 1s 112us/sample - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.3492 - val_accuracy: 0.8526\n",
      "Train on 8500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 194us/sample - loss: 0.0317 - accuracy: 0.9940 - val_loss: 0.9749 - val_accuracy: 0.8673\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 105us/sample - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.9356 - val_accuracy: 0.8727\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 105us/sample - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.0552 - val_accuracy: 0.8720\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 104us/sample - loss: 7.9048e-04 - accuracy: 0.9998 - val_loss: 1.1087 - val_accuracy: 0.8720\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 104us/sample - loss: 1.2438e-04 - accuracy: 1.0000 - val_loss: 1.1507 - val_accuracy: 0.8747\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 105us/sample - loss: 3.7030e-05 - accuracy: 1.0000 - val_loss: 1.1656 - val_accuracy: 0.8753\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 104us/sample - loss: 2.6223e-05 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 104us/sample - loss: 2.0688e-05 - accuracy: 1.0000 - val_loss: 1.1958 - val_accuracy: 0.8760\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 105us/sample - loss: 1.6764e-05 - accuracy: 1.0000 - val_loss: 1.2122 - val_accuracy: 0.8767\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 103us/sample - loss: 1.3878e-05 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.8780\n",
      "Train on 8750 samples, validate on 1250 samples\n",
      "Epoch 1/10\n",
      "8750/8750 [==============================] - 1s 156us/sample - loss: 0.0189 - accuracy: 0.9961 - val_loss: 1.1505 - val_accuracy: 0.8664\n",
      "Epoch 2/10\n",
      "8750/8750 [==============================] - 1s 103us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 1.0633 - val_accuracy: 0.8792\n",
      "Epoch 3/10\n",
      "8750/8750 [==============================] - 1s 105us/sample - loss: 2.1314e-04 - accuracy: 1.0000 - val_loss: 1.1214 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "8750/8750 [==============================] - 1s 102us/sample - loss: 6.6940e-05 - accuracy: 1.0000 - val_loss: 1.1388 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "8750/8750 [==============================] - 1s 103us/sample - loss: 2.6546e-05 - accuracy: 1.0000 - val_loss: 1.1509 - val_accuracy: 0.8832\n",
      "Epoch 6/10\n",
      "8750/8750 [==============================] - 1s 102us/sample - loss: 1.8900e-05 - accuracy: 1.0000 - val_loss: 1.1686 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "8750/8750 [==============================] - 1s 103us/sample - loss: 1.4847e-05 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.8816\n",
      "Epoch 8/10\n",
      "8750/8750 [==============================] - 1s 102us/sample - loss: 1.1901e-05 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.8832\n",
      "Epoch 9/10\n",
      "8750/8750 [==============================] - 1s 102us/sample - loss: 9.8311e-06 - accuracy: 1.0000 - val_loss: 1.2079 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "8750/8750 [==============================] - 1s 102us/sample - loss: 8.1750e-06 - accuracy: 1.0000 - val_loss: 1.2210 - val_accuracy: 0.8816\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 1s 150us/sample - loss: 0.0303 - accuracy: 0.9942 - val_loss: 1.0566 - val_accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 101us/sample - loss: 0.0041 - accuracy: 0.9988 - val_loss: 1.0812 - val_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 101us/sample - loss: 0.0150 - accuracy: 0.9962 - val_loss: 1.1442 - val_accuracy: 0.8710\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 100us/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.1590 - val_accuracy: 0.8730\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 103us/sample - loss: 3.8072e-04 - accuracy: 0.9999 - val_loss: 1.2216 - val_accuracy: 0.8780\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 1s 101us/sample - loss: 4.7249e-05 - accuracy: 1.0000 - val_loss: 1.2372 - val_accuracy: 0.8800\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 100us/sample - loss: 2.8814e-05 - accuracy: 1.0000 - val_loss: 1.2521 - val_accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 102us/sample - loss: 2.2094e-05 - accuracy: 1.0000 - val_loss: 1.2661 - val_accuracy: 0.8780\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 100us/sample - loss: 1.7709e-05 - accuracy: 1.0000 - val_loss: 1.2793 - val_accuracy: 0.8770\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 101us/sample - loss: 1.4537e-05 - accuracy: 1.0000 - val_loss: 1.2905 - val_accuracy: 0.8770\n",
      "Train on 9250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "9250/9250 [==============================] - 1s 144us/sample - loss: 0.0353 - accuracy: 0.9963 - val_loss: 1.1185 - val_accuracy: 0.8533\n",
      "Epoch 2/10\n",
      "9250/9250 [==============================] - 1s 98us/sample - loss: 0.0092 - accuracy: 0.9972 - val_loss: 1.4228 - val_accuracy: 0.8613\n",
      "Epoch 3/10\n",
      "9250/9250 [==============================] - 1s 97us/sample - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.2025 - val_accuracy: 0.8707\n",
      "Epoch 4/10\n",
      "9250/9250 [==============================] - 1s 98us/sample - loss: 0.0015 - accuracy: 0.9998 - val_loss: 1.2719 - val_accuracy: 0.8667\n",
      "Epoch 5/10\n",
      "9250/9250 [==============================] - 1s 98us/sample - loss: 5.5232e-04 - accuracy: 0.9999 - val_loss: 1.4003 - val_accuracy: 0.8707\n",
      "Epoch 6/10\n",
      "9250/9250 [==============================] - 1s 97us/sample - loss: 4.7708e-05 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.8747\n",
      "Epoch 7/10\n",
      "9250/9250 [==============================] - 1s 98us/sample - loss: 2.6284e-05 - accuracy: 1.0000 - val_loss: 1.4303 - val_accuracy: 0.8747\n",
      "Epoch 8/10\n",
      "9250/9250 [==============================] - 1s 99us/sample - loss: 2.0390e-05 - accuracy: 1.0000 - val_loss: 1.4453 - val_accuracy: 0.8773\n",
      "Epoch 9/10\n",
      "9250/9250 [==============================] - 1s 99us/sample - loss: 1.6422e-05 - accuracy: 1.0000 - val_loss: 1.4601 - val_accuracy: 0.8773\n",
      "Epoch 10/10\n",
      "9250/9250 [==============================] - 1s 97us/sample - loss: 1.3423e-05 - accuracy: 1.0000 - val_loss: 1.4744 - val_accuracy: 0.8747\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 1s 140us/sample - loss: 0.0311 - accuracy: 0.9954 - val_loss: 1.2856 - val_accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 96us/sample - loss: 0.0100 - accuracy: 0.9976 - val_loss: 1.6252 - val_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 97us/sample - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.2899 - val_accuracy: 0.8540\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 98us/sample - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.3752 - val_accuracy: 0.8740\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 97us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.4613 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 96us/sample - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 1.4729 - val_accuracy: 0.8780\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 96us/sample - loss: 3.6204e-05 - accuracy: 1.0000 - val_loss: 1.5061 - val_accuracy: 0.8740\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 95us/sample - loss: 2.3876e-05 - accuracy: 1.0000 - val_loss: 1.5323 - val_accuracy: 0.8700\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 98us/sample - loss: 1.7999e-05 - accuracy: 1.0000 - val_loss: 1.5550 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 96us/sample - loss: 1.4340e-05 - accuracy: 1.0000 - val_loss: 1.5741 - val_accuracy: 0.8720\n",
      "Train on 9750 samples, validate on 250 samples\n",
      "Epoch 1/10\n",
      "9750/9750 [==============================] - 1s 137us/sample - loss: 0.0252 - accuracy: 0.9959 - val_loss: 1.3344 - val_accuracy: 0.8480\n",
      "Epoch 2/10\n",
      "9750/9750 [==============================] - 1s 95us/sample - loss: 0.0129 - accuracy: 0.9978 - val_loss: 1.1211 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "9750/9750 [==============================] - 1s 93us/sample - loss: 0.0041 - accuracy: 0.9989 - val_loss: 1.2043 - val_accuracy: 0.8840\n",
      "Epoch 4/10\n",
      "9750/9750 [==============================] - 1s 94us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 1.2125 - val_accuracy: 0.8760\n",
      "Epoch 5/10\n",
      "9750/9750 [==============================] - 1s 93us/sample - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.4531 - val_accuracy: 0.8720\n",
      "Epoch 6/10\n",
      "9750/9750 [==============================] - 1s 94us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 1.2075 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "9750/9750 [==============================] - 1s 94us/sample - loss: 0.0132 - accuracy: 0.9963 - val_loss: 1.5403 - val_accuracy: 0.8960\n",
      "Epoch 8/10\n",
      "9750/9750 [==============================] - 1s 95us/sample - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.4337 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "9750/9750 [==============================] - 1s 94us/sample - loss: 0.0132 - accuracy: 0.9964 - val_loss: 1.2592 - val_accuracy: 0.8840\n",
      "Epoch 10/10\n",
      "9750/9750 [==============================] - 1s 95us/sample - loss: 0.0032 - accuracy: 0.9991 - val_loss: 1.1295 - val_accuracy: 0.8920\n",
      "Train on 250 samples, validate on 9750 samples\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 7ms/sample - loss: 2.1920 - accuracy: 0.2000 - val_loss: 1.9401 - val_accuracy: 0.3407\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 1.5895 - accuracy: 0.4160 - val_loss: 1.3798 - val_accuracy: 0.4550\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 1.1445 - accuracy: 0.5520 - val_loss: 1.3359 - val_accuracy: 0.5333\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 1.0226 - accuracy: 0.5920 - val_loss: 1.0096 - val_accuracy: 0.5929\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.8800 - accuracy: 0.6760 - val_loss: 0.9577 - val_accuracy: 0.6367\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.7682 - accuracy: 0.6960 - val_loss: 0.9559 - val_accuracy: 0.6512\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.6728 - accuracy: 0.7480 - val_loss: 0.9230 - val_accuracy: 0.6593\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.6053 - accuracy: 0.7880 - val_loss: 0.8130 - val_accuracy: 0.7051\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.5204 - accuracy: 0.8360 - val_loss: 0.9228 - val_accuracy: 0.6957\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.5363 - accuracy: 0.8200 - val_loss: 0.7735 - val_accuracy: 0.7243\n",
      "Train on 500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 3ms/sample - loss: 0.7726 - accuracy: 0.7460 - val_loss: 0.8223 - val_accuracy: 0.7056\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5584 - accuracy: 0.8220 - val_loss: 0.7841 - val_accuracy: 0.7020\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4908 - accuracy: 0.8200 - val_loss: 0.7609 - val_accuracy: 0.7461\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4719 - accuracy: 0.8220 - val_loss: 0.6497 - val_accuracy: 0.7632\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3636 - accuracy: 0.8580 - val_loss: 0.6736 - val_accuracy: 0.7842\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3155 - accuracy: 0.8900 - val_loss: 0.6706 - val_accuracy: 0.7756\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2775 - accuracy: 0.9060 - val_loss: 0.6844 - val_accuracy: 0.7789\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2018 - accuracy: 0.9260 - val_loss: 0.7684 - val_accuracy: 0.7718\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.1713 - accuracy: 0.9500 - val_loss: 0.8295 - val_accuracy: 0.7767\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2260 - accuracy: 0.9340 - val_loss: 0.7651 - val_accuracy: 0.7773\n",
      "Train on 750 samples, validate on 9250 samples\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 1s 2ms/sample - loss: 0.3967 - accuracy: 0.8787 - val_loss: 0.6588 - val_accuracy: 0.7863\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 1s 940us/sample - loss: 0.2582 - accuracy: 0.9000 - val_loss: 0.6280 - val_accuracy: 0.8022\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 1s 919us/sample - loss: 0.1815 - accuracy: 0.9227 - val_loss: 0.6803 - val_accuracy: 0.8028\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 1s 936us/sample - loss: 0.1685 - accuracy: 0.9453 - val_loss: 0.7270 - val_accuracy: 0.7938\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 1s 927us/sample - loss: 0.1919 - accuracy: 0.9347 - val_loss: 0.6966 - val_accuracy: 0.8097\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 1s 925us/sample - loss: 0.1285 - accuracy: 0.9440 - val_loss: 0.6952 - val_accuracy: 0.8068\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 1s 927us/sample - loss: 0.1078 - accuracy: 0.9600 - val_loss: 0.8012 - val_accuracy: 0.7979\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 1s 929us/sample - loss: 0.0671 - accuracy: 0.9773 - val_loss: 0.8935 - val_accuracy: 0.8052\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 1s 919us/sample - loss: 0.0653 - accuracy: 0.9760 - val_loss: 0.8754 - val_accuracy: 0.7961\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 1s 935us/sample - loss: 0.0592 - accuracy: 0.9840 - val_loss: 0.9822 - val_accuracy: 0.8053\n",
      "Train on 1000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2804 - accuracy: 0.9260 - val_loss: 0.6900 - val_accuracy: 0.7988\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 735us/sample - loss: 0.1495 - accuracy: 0.9530 - val_loss: 0.7437 - val_accuracy: 0.8101\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 720us/sample - loss: 0.0893 - accuracy: 0.9690 - val_loss: 0.8304 - val_accuracy: 0.8146\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 704us/sample - loss: 0.0745 - accuracy: 0.9740 - val_loss: 0.9092 - val_accuracy: 0.8040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 708us/sample - loss: 0.0789 - accuracy: 0.9740 - val_loss: 0.8535 - val_accuracy: 0.8147\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 719us/sample - loss: 0.0396 - accuracy: 0.9880 - val_loss: 1.1223 - val_accuracy: 0.7989\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 700us/sample - loss: 0.0478 - accuracy: 0.9860 - val_loss: 1.1436 - val_accuracy: 0.7958\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 703us/sample - loss: 0.0937 - accuracy: 0.9640 - val_loss: 0.8924 - val_accuracy: 0.8188\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 703us/sample - loss: 0.0782 - accuracy: 0.9770 - val_loss: 0.9134 - val_accuracy: 0.7996\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 720us/sample - loss: 0.0766 - accuracy: 0.9750 - val_loss: 1.0442 - val_accuracy: 0.7996\n",
      "Train on 1250 samples, validate on 8750 samples\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 2s 1ms/sample - loss: 0.1963 - accuracy: 0.9448 - val_loss: 0.6433 - val_accuracy: 0.8072\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 1s 586us/sample - loss: 0.0972 - accuracy: 0.9664 - val_loss: 0.7662 - val_accuracy: 0.8221\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 1s 571us/sample - loss: 0.0702 - accuracy: 0.9792 - val_loss: 0.8684 - val_accuracy: 0.7966\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 1s 581us/sample - loss: 0.0602 - accuracy: 0.9808 - val_loss: 0.9773 - val_accuracy: 0.7935\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 1s 578us/sample - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.9038 - val_accuracy: 0.8251\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 1s 578us/sample - loss: 0.0200 - accuracy: 0.9920 - val_loss: 1.2389 - val_accuracy: 0.8077\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 1s 581us/sample - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.9300 - val_accuracy: 0.8177\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1s 577us/sample - loss: 0.0283 - accuracy: 0.9936 - val_loss: 1.0441 - val_accuracy: 0.8207\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1s 593us/sample - loss: 0.0319 - accuracy: 0.9856 - val_loss: 1.0144 - val_accuracy: 0.8215\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1s 590us/sample - loss: 0.0157 - accuracy: 0.9968 - val_loss: 1.0234 - val_accuracy: 0.8270\n",
      "Train on 1500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 901us/sample - loss: 0.2128 - accuracy: 0.9613 - val_loss: 0.5810 - val_accuracy: 0.8222\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 491us/sample - loss: 0.0883 - accuracy: 0.9760 - val_loss: 0.6576 - val_accuracy: 0.8264\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 485us/sample - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.7628 - val_accuracy: 0.8324\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 491us/sample - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.9006 - val_accuracy: 0.8308\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 492us/sample - loss: 0.0138 - accuracy: 0.9960 - val_loss: 1.0144 - val_accuracy: 0.8180\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 489us/sample - loss: 0.0265 - accuracy: 0.9893 - val_loss: 0.9655 - val_accuracy: 0.8300\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 491us/sample - loss: 0.0670 - accuracy: 0.9773 - val_loss: 0.8640 - val_accuracy: 0.8076\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 497us/sample - loss: 0.0529 - accuracy: 0.9887 - val_loss: 0.8295 - val_accuracy: 0.8102\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 489us/sample - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.9354 - val_accuracy: 0.8180\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 481us/sample - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.9894 - val_accuracy: 0.8100\n",
      "Train on 1750 samples, validate on 8250 samples\n",
      "Epoch 1/10\n",
      "1750/1750 [==============================] - 1s 786us/sample - loss: 0.1161 - accuracy: 0.9697 - val_loss: 0.7919 - val_accuracy: 0.8121\n",
      "Epoch 2/10\n",
      "1750/1750 [==============================] - 1s 434us/sample - loss: 0.0586 - accuracy: 0.9806 - val_loss: 0.7724 - val_accuracy: 0.8246\n",
      "Epoch 3/10\n",
      "1750/1750 [==============================] - 1s 433us/sample - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.8823 - val_accuracy: 0.8290\n",
      "Epoch 4/10\n",
      "1750/1750 [==============================] - 1s 421us/sample - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.9715 - val_accuracy: 0.8267\n",
      "Epoch 5/10\n",
      "1750/1750 [==============================] - 1s 425us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.8316\n",
      "Epoch 6/10\n",
      "1750/1750 [==============================] - 1s 426us/sample - loss: 3.9229e-04 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.8316\n",
      "Epoch 7/10\n",
      "1750/1750 [==============================] - 1s 430us/sample - loss: 2.4728e-04 - accuracy: 1.0000 - val_loss: 1.1421 - val_accuracy: 0.8316\n",
      "Epoch 8/10\n",
      "1750/1750 [==============================] - 1s 427us/sample - loss: 1.8558e-04 - accuracy: 1.0000 - val_loss: 1.1752 - val_accuracy: 0.8319\n",
      "Epoch 9/10\n",
      "1750/1750 [==============================] - 1s 429us/sample - loss: 1.4537e-04 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.8327\n",
      "Epoch 10/10\n",
      "1750/1750 [==============================] - 1s 435us/sample - loss: 1.1810e-04 - accuracy: 1.0000 - val_loss: 1.2245 - val_accuracy: 0.8332\n",
      "Train on 2000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 673us/sample - loss: 0.1790 - accuracy: 0.9565 - val_loss: 0.6178 - val_accuracy: 0.8353\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 347us/sample - loss: 0.0608 - accuracy: 0.9825 - val_loss: 0.7262 - val_accuracy: 0.8311\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 345us/sample - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.8661 - val_accuracy: 0.8291\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 344us/sample - loss: 0.0382 - accuracy: 0.9905 - val_loss: 0.9793 - val_accuracy: 0.8253\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 343us/sample - loss: 0.0269 - accuracy: 0.9910 - val_loss: 0.8843 - val_accuracy: 0.8311\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 344us/sample - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.9755 - val_accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 337us/sample - loss: 0.0033 - accuracy: 0.9995 - val_loss: 1.0944 - val_accuracy: 0.8372\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 350us/sample - loss: 6.6013e-04 - accuracy: 1.0000 - val_loss: 1.1752 - val_accuracy: 0.8363\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 342us/sample - loss: 2.1351e-04 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.8376\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 348us/sample - loss: 1.6247e-04 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.8380\n",
      "Train on 2250 samples, validate on 7750 samples\n",
      "Epoch 1/10\n",
      "2250/2250 [==============================] - 1s 654us/sample - loss: 0.1495 - accuracy: 0.9676 - val_loss: 0.6483 - val_accuracy: 0.8325\n",
      "Epoch 2/10\n",
      "2250/2250 [==============================] - 1s 344us/sample - loss: 0.0388 - accuracy: 0.9880 - val_loss: 0.8419 - val_accuracy: 0.8280\n",
      "Epoch 3/10\n",
      "2250/2250 [==============================] - 1s 346us/sample - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.9561 - val_accuracy: 0.8275\n",
      "Epoch 4/10\n",
      "2250/2250 [==============================] - 1s 340us/sample - loss: 0.0370 - accuracy: 0.9898 - val_loss: 0.9836 - val_accuracy: 0.8288\n",
      "Epoch 5/10\n",
      "2250/2250 [==============================] - 1s 340us/sample - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.8778 - val_accuracy: 0.8444\n",
      "Epoch 6/10\n",
      "2250/2250 [==============================] - 1s 348us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.9925 - val_accuracy: 0.8397\n",
      "Epoch 7/10\n",
      "2250/2250 [==============================] - 1s 346us/sample - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.9840 - val_accuracy: 0.8369\n",
      "Epoch 8/10\n",
      "2250/2250 [==============================] - 1s 338us/sample - loss: 0.0158 - accuracy: 0.9969 - val_loss: 1.1363 - val_accuracy: 0.8335\n",
      "Epoch 9/10\n",
      "2250/2250 [==============================] - 1s 340us/sample - loss: 0.0444 - accuracy: 0.9840 - val_loss: 0.8422 - val_accuracy: 0.8266\n",
      "Epoch 10/10\n",
      "2250/2250 [==============================] - 1s 346us/sample - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.9815 - val_accuracy: 0.8298\n",
      "Train on 2500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 693us/sample - loss: 0.1403 - accuracy: 0.9692 - val_loss: 0.5988 - val_accuracy: 0.8249\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 311us/sample - loss: 0.0378 - accuracy: 0.9896 - val_loss: 0.7285 - val_accuracy: 0.8372\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 311us/sample - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.8401 - val_accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.8387 - val_accuracy: 0.8433\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 315us/sample - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.9764 - val_accuracy: 0.8400\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 310us/sample - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.9843 - val_accuracy: 0.8437\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 313us/sample - loss: 0.0311 - accuracy: 0.9880 - val_loss: 0.8709 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 315us/sample - loss: 0.0289 - accuracy: 0.9904 - val_loss: 0.9654 - val_accuracy: 0.8403\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 310us/sample - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.9916 - val_accuracy: 0.8305\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 310us/sample - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.9450 - val_accuracy: 0.8227\n",
      "Train on 2750 samples, validate on 7250 samples\n",
      "Epoch 1/10\n",
      "2750/2750 [==============================] - 1s 543us/sample - loss: 0.0672 - accuracy: 0.9811 - val_loss: 0.8916 - val_accuracy: 0.8345\n",
      "Epoch 2/10\n",
      "2750/2750 [==============================] - 1s 291us/sample - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.9231 - val_accuracy: 0.8428\n",
      "Epoch 3/10\n",
      "2750/2750 [==============================] - 1s 288us/sample - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.9585 - val_accuracy: 0.8443\n",
      "Epoch 4/10\n",
      "2750/2750 [==============================] - 1s 292us/sample - loss: 0.0032 - accuracy: 0.9989 - val_loss: 1.0205 - val_accuracy: 0.8444\n",
      "Epoch 5/10\n",
      "2750/2750 [==============================] - 1s 287us/sample - loss: 9.4510e-04 - accuracy: 0.9996 - val_loss: 1.0805 - val_accuracy: 0.8454\n",
      "Epoch 6/10\n",
      "2750/2750 [==============================] - 1s 288us/sample - loss: 9.3403e-04 - accuracy: 0.9996 - val_loss: 1.1089 - val_accuracy: 0.8498\n",
      "Epoch 7/10\n",
      "2750/2750 [==============================] - 1s 290us/sample - loss: 1.2527e-04 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.8503\n",
      "Epoch 8/10\n",
      "2750/2750 [==============================] - 1s 284us/sample - loss: 4.7913e-05 - accuracy: 1.0000 - val_loss: 1.1793 - val_accuracy: 0.8492\n",
      "Epoch 9/10\n",
      "2750/2750 [==============================] - 1s 293us/sample - loss: 3.6363e-05 - accuracy: 1.0000 - val_loss: 1.1954 - val_accuracy: 0.8498\n",
      "Epoch 10/10\n",
      "2750/2750 [==============================] - 1s 288us/sample - loss: 2.9812e-05 - accuracy: 1.0000 - val_loss: 1.2095 - val_accuracy: 0.8503\n",
      "Train on 3000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 492us/sample - loss: 0.0834 - accuracy: 0.9830 - val_loss: 0.6752 - val_accuracy: 0.8316\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 268us/sample - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.8915 - val_accuracy: 0.8436\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 271us/sample - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.9521 - val_accuracy: 0.8491\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 269us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0974 - val_accuracy: 0.8454\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 269us/sample - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.1655 - val_accuracy: 0.8386\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 277us/sample - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.8222 - val_accuracy: 0.8383\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 271us/sample - loss: 0.0434 - accuracy: 0.9870 - val_loss: 0.9609 - val_accuracy: 0.8206\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 268us/sample - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.9090 - val_accuracy: 0.8416\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 269us/sample - loss: 0.0109 - accuracy: 0.9973 - val_loss: 1.0910 - val_accuracy: 0.8330\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 273us/sample - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.0116 - val_accuracy: 0.8453\n",
      "Train on 3250 samples, validate on 6750 samples\n",
      "Epoch 1/10\n",
      "3250/3250 [==============================] - 1s 447us/sample - loss: 0.0688 - accuracy: 0.9849 - val_loss: 0.9586 - val_accuracy: 0.8393\n",
      "Epoch 2/10\n",
      "3250/3250 [==============================] - 1s 251us/sample - loss: 0.0181 - accuracy: 0.9935 - val_loss: 0.9196 - val_accuracy: 0.8477\n",
      "Epoch 3/10\n",
      "3250/3250 [==============================] - 1s 253us/sample - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.9504 - val_accuracy: 0.8473\n",
      "Epoch 4/10\n",
      "3250/3250 [==============================] - 1s 256us/sample - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.0492 - val_accuracy: 0.8464\n",
      "Epoch 5/10\n",
      "3250/3250 [==============================] - 1s 256us/sample - loss: 0.0210 - accuracy: 0.9935 - val_loss: 1.0649 - val_accuracy: 0.8350\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250/3250 [==============================] - 1s 249us/sample - loss: 0.0220 - accuracy: 0.9932 - val_loss: 1.1536 - val_accuracy: 0.8324\n",
      "Epoch 7/10\n",
      "3250/3250 [==============================] - 1s 253us/sample - loss: 0.0347 - accuracy: 0.9877 - val_loss: 1.0448 - val_accuracy: 0.8302\n",
      "Epoch 8/10\n",
      "3250/3250 [==============================] - 1s 255us/sample - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.9710 - val_accuracy: 0.8419\n",
      "Epoch 9/10\n",
      "3250/3250 [==============================] - 1s 249us/sample - loss: 0.0022 - accuracy: 0.9997 - val_loss: 1.1505 - val_accuracy: 0.8446\n",
      "Epoch 10/10\n",
      "3250/3250 [==============================] - 1s 252us/sample - loss: 3.1237e-04 - accuracy: 1.0000 - val_loss: 1.1729 - val_accuracy: 0.8456\n",
      "Train on 3500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 396us/sample - loss: 0.0675 - accuracy: 0.9880 - val_loss: 0.9237 - val_accuracy: 0.8369\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 246us/sample - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.8864 - val_accuracy: 0.8489\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 237us/sample - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.9501 - val_accuracy: 0.8512\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 241us/sample - loss: 0.0025 - accuracy: 0.9997 - val_loss: 1.0448 - val_accuracy: 0.8502\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 237us/sample - loss: 1.4499e-04 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.8489\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 239us/sample - loss: 7.2739e-05 - accuracy: 1.0000 - val_loss: 1.1020 - val_accuracy: 0.8508\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 237us/sample - loss: 5.1704e-05 - accuracy: 1.0000 - val_loss: 1.1260 - val_accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 239us/sample - loss: 3.9664e-05 - accuracy: 1.0000 - val_loss: 1.1459 - val_accuracy: 0.8525\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 239us/sample - loss: 3.1895e-05 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.8531\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 237us/sample - loss: 2.6306e-05 - accuracy: 1.0000 - val_loss: 1.1805 - val_accuracy: 0.8528\n",
      "Train on 3750 samples, validate on 6250 samples\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 1s 394us/sample - loss: 0.0748 - accuracy: 0.9837 - val_loss: 0.7651 - val_accuracy: 0.8363\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 1s 230us/sample - loss: 0.0154 - accuracy: 0.9965 - val_loss: 0.8801 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 1s 226us/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.0023 - val_accuracy: 0.8462\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 1s 229us/sample - loss: 6.4293e-04 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.8507\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 1s 225us/sample - loss: 1.3982e-04 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 1s 226us/sample - loss: 7.5368e-05 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.8522\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 1s 228us/sample - loss: 5.5877e-05 - accuracy: 1.0000 - val_loss: 1.1374 - val_accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 1s 231us/sample - loss: 4.3887e-05 - accuracy: 1.0000 - val_loss: 1.1582 - val_accuracy: 0.8517\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 1s 225us/sample - loss: 3.5185e-05 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.8526\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 1s 226us/sample - loss: 2.9112e-05 - accuracy: 1.0000 - val_loss: 1.1933 - val_accuracy: 0.8533\n",
      "Train on 4000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 341us/sample - loss: 0.0787 - accuracy: 0.9858 - val_loss: 0.7347 - val_accuracy: 0.8485\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 201us/sample - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.7637 - val_accuracy: 0.8480\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 208us/sample - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.8358 - val_accuracy: 0.8430\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 203us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 1.0500 - val_accuracy: 0.8482\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 201us/sample - loss: 0.0197 - accuracy: 0.9940 - val_loss: 1.0283 - val_accuracy: 0.8473\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 201us/sample - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.9295 - val_accuracy: 0.8452\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 205us/sample - loss: 0.0333 - accuracy: 0.9883 - val_loss: 0.9683 - val_accuracy: 0.8272\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 201us/sample - loss: 0.0262 - accuracy: 0.9902 - val_loss: 0.9979 - val_accuracy: 0.8410\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 203us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.0402 - val_accuracy: 0.8463\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 203us/sample - loss: 0.0041 - accuracy: 0.9983 - val_loss: 1.1359 - val_accuracy: 0.8357\n",
      "Train on 4250 samples, validate on 5750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 343us/sample - loss: 0.0611 - accuracy: 0.9866 - val_loss: 0.7758 - val_accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.8453 - val_accuracy: 0.8496\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.9271 - val_accuracy: 0.8485\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.0087 - accuracy: 0.9976 - val_loss: 1.0534 - val_accuracy: 0.8374\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.0213 - accuracy: 0.9927 - val_loss: 1.0245 - val_accuracy: 0.8433\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.9368 - val_accuracy: 0.8410\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.0082 - accuracy: 0.9979 - val_loss: 1.1861 - val_accuracy: 0.8520\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.9924 - val_accuracy: 0.8403\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.0143 - accuracy: 0.9955 - val_loss: 1.2351 - val_accuracy: 0.8428\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.0153 - accuracy: 0.9955 - val_loss: 1.1206 - val_accuracy: 0.8435\n",
      "Train on 4500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 1s 319us/sample - loss: 0.0589 - accuracy: 0.9896 - val_loss: 0.7753 - val_accuracy: 0.8491\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 194us/sample - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.8259 - val_accuracy: 0.8489\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 195us/sample - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.9957 - val_accuracy: 0.8475\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 194us/sample - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.8605 - val_accuracy: 0.8545\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 196us/sample - loss: 0.0052 - accuracy: 0.9987 - val_loss: 1.1247 - val_accuracy: 0.8455\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 197us/sample - loss: 0.0126 - accuracy: 0.9964 - val_loss: 1.0295 - val_accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 199us/sample - loss: 0.0199 - accuracy: 0.9936 - val_loss: 1.0415 - val_accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 196us/sample - loss: 0.0119 - accuracy: 0.9958 - val_loss: 1.0878 - val_accuracy: 0.8551\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 1s 196us/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 1.1503 - val_accuracy: 0.8509\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 200us/sample - loss: 0.0160 - accuracy: 0.9951 - val_loss: 1.0692 - val_accuracy: 0.8438\n",
      "Train on 4750 samples, validate on 5250 samples\n",
      "Epoch 1/10\n",
      "4750/4750 [==============================] - 2s 371us/sample - loss: 0.0590 - accuracy: 0.9874 - val_loss: 0.6782 - val_accuracy: 0.8482\n",
      "Epoch 2/10\n",
      "4750/4750 [==============================] - 1s 187us/sample - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.8812 - val_accuracy: 0.8491\n",
      "Epoch 3/10\n",
      "4750/4750 [==============================] - 1s 191us/sample - loss: 0.0044 - accuracy: 0.9992 - val_loss: 1.0221 - val_accuracy: 0.8497\n",
      "Epoch 4/10\n",
      "4750/4750 [==============================] - 1s 189us/sample - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.9864 - val_accuracy: 0.8570\n",
      "Epoch 5/10\n",
      "4750/4750 [==============================] - 1s 191us/sample - loss: 2.7282e-04 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.8570\n",
      "Epoch 6/10\n",
      "4750/4750 [==============================] - 1s 187us/sample - loss: 7.4320e-05 - accuracy: 1.0000 - val_loss: 1.0908 - val_accuracy: 0.8583\n",
      "Epoch 7/10\n",
      "4750/4750 [==============================] - 1s 187us/sample - loss: 3.8964e-05 - accuracy: 1.0000 - val_loss: 1.1140 - val_accuracy: 0.8577\n",
      "Epoch 8/10\n",
      "4750/4750 [==============================] - 1s 190us/sample - loss: 2.9325e-05 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.8581\n",
      "Epoch 9/10\n",
      "4750/4750 [==============================] - 1s 188us/sample - loss: 2.3293e-05 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.8587\n",
      "Epoch 10/10\n",
      "4750/4750 [==============================] - 1s 188us/sample - loss: 1.9111e-05 - accuracy: 1.0000 - val_loss: 1.1685 - val_accuracy: 0.8596\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 1s 294us/sample - loss: 0.0513 - accuracy: 0.9894 - val_loss: 0.7961 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 181us/sample - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.9343 - val_accuracy: 0.8570\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 185us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.9783 - val_accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.0020 - accuracy: 0.9990 - val_loss: 0.9785 - val_accuracy: 0.8556\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 190us/sample - loss: 0.0053 - accuracy: 0.9986 - val_loss: 1.0434 - val_accuracy: 0.8504\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 179us/sample - loss: 0.0107 - accuracy: 0.9962 - val_loss: 1.0381 - val_accuracy: 0.8524\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.0134 - accuracy: 0.9946 - val_loss: 1.1706 - val_accuracy: 0.8456\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 184us/sample - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.9238 - val_accuracy: 0.8508\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 185us/sample - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.9313 - val_accuracy: 0.8444\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.0215 - accuracy: 0.9942 - val_loss: 1.1210 - val_accuracy: 0.8498\n",
      "Train on 5250 samples, validate on 4750 samples\n",
      "Epoch 1/10\n",
      "5250/5250 [==============================] - 1s 286us/sample - loss: 0.0722 - accuracy: 0.9888 - val_loss: 0.6124 - val_accuracy: 0.8520\n",
      "Epoch 2/10\n",
      "5250/5250 [==============================] - 1s 174us/sample - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.8388 - val_accuracy: 0.8564\n",
      "Epoch 3/10\n",
      "5250/5250 [==============================] - 1s 178us/sample - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.9377 - val_accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "5250/5250 [==============================] - 1s 177us/sample - loss: 4.2943e-04 - accuracy: 1.0000 - val_loss: 1.0021 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "5250/5250 [==============================] - 1s 176us/sample - loss: 7.6546e-05 - accuracy: 1.0000 - val_loss: 1.0434 - val_accuracy: 0.8581\n",
      "Epoch 6/10\n",
      "5250/5250 [==============================] - 1s 176us/sample - loss: 4.3216e-05 - accuracy: 1.0000 - val_loss: 1.0722 - val_accuracy: 0.8596\n",
      "Epoch 7/10\n",
      "5250/5250 [==============================] - 1s 176us/sample - loss: 3.1074e-05 - accuracy: 1.0000 - val_loss: 1.0963 - val_accuracy: 0.8587\n",
      "Epoch 8/10\n",
      "5250/5250 [==============================] - 1s 177us/sample - loss: 2.3602e-05 - accuracy: 1.0000 - val_loss: 1.1174 - val_accuracy: 0.8583\n",
      "Epoch 9/10\n",
      "5250/5250 [==============================] - 1s 177us/sample - loss: 1.8632e-05 - accuracy: 1.0000 - val_loss: 1.1366 - val_accuracy: 0.8587\n",
      "Epoch 10/10\n",
      "5250/5250 [==============================] - 1s 174us/sample - loss: 1.5042e-05 - accuracy: 1.0000 - val_loss: 1.1537 - val_accuracy: 0.8594\n",
      "Train on 5500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 273us/sample - loss: 0.0446 - accuracy: 0.9911 - val_loss: 0.7665 - val_accuracy: 0.8502\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 170us/sample - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.9163 - val_accuracy: 0.8593\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 170us/sample - loss: 4.6552e-04 - accuracy: 0.9998 - val_loss: 0.9692 - val_accuracy: 0.8589\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 169us/sample - loss: 1.6171e-04 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 170us/sample - loss: 4.6836e-05 - accuracy: 1.0000 - val_loss: 1.0560 - val_accuracy: 0.8596\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 168us/sample - loss: 3.2589e-05 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.8602\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 170us/sample - loss: 2.4479e-05 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.8596\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 168us/sample - loss: 1.9064e-05 - accuracy: 1.0000 - val_loss: 1.1265 - val_accuracy: 0.8616\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 171us/sample - loss: 1.5234e-05 - accuracy: 1.0000 - val_loss: 1.1442 - val_accuracy: 0.8618\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 168us/sample - loss: 1.2533e-05 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 0.8609\n",
      "Train on 5750 samples, validate on 4250 samples\n",
      "Epoch 1/10\n",
      "5750/5750 [==============================] - 1s 260us/sample - loss: 0.0469 - accuracy: 0.9901 - val_loss: 0.7199 - val_accuracy: 0.8574 loss: 0.0465 - accu\n",
      "Epoch 2/10\n",
      "5750/5750 [==============================] - 1s 165us/sample - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.8494 - val_accuracy: 0.8593\n",
      "Epoch 3/10\n",
      "5750/5750 [==============================] - 1s 164us/sample - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.9429 - val_accuracy: 0.8605\n",
      "Epoch 4/10\n",
      "5750/5750 [==============================] - 1s 165us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.9670 - val_accuracy: 0.8579\n",
      "Epoch 5/10\n",
      "5750/5750 [==============================] - 1s 164us/sample - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.8513 - val_accuracy: 0.8576\n",
      "Epoch 6/10\n",
      "5750/5750 [==============================] - 1s 162us/sample - loss: 0.0077 - accuracy: 0.9979 - val_loss: 1.0730 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "5750/5750 [==============================] - 1s 165us/sample - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.9855 - val_accuracy: 0.8539\n",
      "Epoch 8/10\n",
      "5750/5750 [==============================] - 1s 165us/sample - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.9896 - val_accuracy: 0.8584\n",
      "Epoch 9/10\n",
      "5750/5750 [==============================] - 1s 164us/sample - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.9135 - val_accuracy: 0.8645\n",
      "Epoch 10/10\n",
      "5750/5750 [==============================] - 1s 165us/sample - loss: 0.0019 - accuracy: 0.9993 - val_loss: 1.1076 - val_accuracy: 0.8666\n",
      "Train on 6000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 302us/sample - loss: 0.0554 - accuracy: 0.9898 - val_loss: 0.7550 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 154us/sample - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.8379 - val_accuracy: 0.8645\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 153us/sample - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.9292 - val_accuracy: 0.8650\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 155us/sample - loss: 2.5807e-04 - accuracy: 1.0000 - val_loss: 1.0319 - val_accuracy: 0.8670\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 156us/sample - loss: 6.5912e-05 - accuracy: 1.0000 - val_loss: 1.0644 - val_accuracy: 0.8685\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 158us/sample - loss: 3.9995e-05 - accuracy: 1.0000 - val_loss: 1.0896 - val_accuracy: 0.8685\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 154us/sample - loss: 2.9003e-05 - accuracy: 1.0000 - val_loss: 1.1125 - val_accuracy: 0.8687\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 156us/sample - loss: 2.1931e-05 - accuracy: 1.0000 - val_loss: 1.1324 - val_accuracy: 0.8687\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 152us/sample - loss: 1.7261e-05 - accuracy: 1.0000 - val_loss: 1.1507 - val_accuracy: 0.8692\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 154us/sample - loss: 1.3902e-05 - accuracy: 1.0000 - val_loss: 1.1677 - val_accuracy: 0.8695\n",
      "Train on 6250 samples, validate on 3750 samples\n",
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 2s 252us/sample - loss: 0.0500 - accuracy: 0.9917 - val_loss: 0.7303 - val_accuracy: 0.8621\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 1s 160us/sample - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.0382 - val_accuracy: 0.8664\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 1s 158us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.0383 - val_accuracy: 0.8600\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 1s 158us/sample - loss: 4.5414e-04 - accuracy: 0.9998 - val_loss: 1.1245 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 1s 157us/sample - loss: 4.3734e-05 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.8685\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 1s 163us/sample - loss: 2.6569e-05 - accuracy: 1.0000 - val_loss: 1.1795 - val_accuracy: 0.8680\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 1s 160us/sample - loss: 1.9829e-05 - accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.8677\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 1s 160us/sample - loss: 1.5474e-05 - accuracy: 1.0000 - val_loss: 1.2188 - val_accuracy: 0.8683\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 1s 160us/sample - loss: 1.2414e-05 - accuracy: 1.0000 - val_loss: 1.2364 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 1s 158us/sample - loss: 1.0119e-05 - accuracy: 1.0000 - val_loss: 1.2523 - val_accuracy: 0.8693\n",
      "Train on 6500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 246us/sample - loss: 0.0458 - accuracy: 0.9900 - val_loss: 0.7760 - val_accuracy: 0.8649\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 154us/sample - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.9981 - val_accuracy: 0.8637\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 154us/sample - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.9590 - val_accuracy: 0.8569\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 154us/sample - loss: 0.0030 - accuracy: 0.9989 - val_loss: 1.0538 - val_accuracy: 0.8723\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 163us/sample - loss: 3.6434e-04 - accuracy: 1.0000 - val_loss: 1.1038 - val_accuracy: 0.8746\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 153us/sample - loss: 4.6076e-05 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.8774\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 151us/sample - loss: 2.3477e-05 - accuracy: 1.0000 - val_loss: 1.1610 - val_accuracy: 0.8774\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 152us/sample - loss: 1.7399e-05 - accuracy: 1.0000 - val_loss: 1.1808 - val_accuracy: 0.8771\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 155us/sample - loss: 1.3627e-05 - accuracy: 1.0000 - val_loss: 1.1986 - val_accuracy: 0.8757\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 156us/sample - loss: 1.1051e-05 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.8760\n",
      "Train on 6750 samples, validate on 3250 samples\n",
      "Epoch 1/10\n",
      "6750/6750 [==============================] - 2s 235us/sample - loss: 0.0452 - accuracy: 0.9919 - val_loss: 0.7535 - val_accuracy: 0.8677\n",
      "Epoch 2/10\n",
      "6750/6750 [==============================] - 1s 149us/sample - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.7809 - val_accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "6750/6750 [==============================] - 1s 151us/sample - loss: 6.1650e-04 - accuracy: 0.9999 - val_loss: 0.9284 - val_accuracy: 0.8778\n",
      "Epoch 4/10\n",
      "6750/6750 [==============================] - 1s 149us/sample - loss: 5.3365e-05 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.8772\n",
      "Epoch 5/10\n",
      "6750/6750 [==============================] - 1s 149us/sample - loss: 3.4094e-05 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.8785\n",
      "Epoch 6/10\n",
      "6750/6750 [==============================] - 1s 150us/sample - loss: 2.4686e-05 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.8785\n",
      "Epoch 7/10\n",
      "6750/6750 [==============================] - 1s 148us/sample - loss: 1.8902e-05 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.8775\n",
      "Epoch 8/10\n",
      "6750/6750 [==============================] - 1s 149us/sample - loss: 1.4878e-05 - accuracy: 1.0000 - val_loss: 1.0507 - val_accuracy: 0.8775\n",
      "Epoch 9/10\n",
      "6750/6750 [==============================] - 1s 149us/sample - loss: 1.2014e-05 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.8772\n",
      "Epoch 10/10\n",
      "6750/6750 [==============================] - 1s 149us/sample - loss: 9.8596e-06 - accuracy: 1.0000 - val_loss: 1.0824 - val_accuracy: 0.8772\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 223us/sample - loss: 0.0344 - accuracy: 0.9933 - val_loss: 0.7624 - val_accuracy: 0.8737\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.8844 - val_accuracy: 0.8707\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.9540 - val_accuracy: 0.8703\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.8725 - val_accuracy: 0.8687\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 142us/sample - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.8150 - val_accuracy: 0.8667\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.9620 - val_accuracy: 0.8783\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 1.1501e-04 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.8747\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 144us/sample - loss: 4.6635e-05 - accuracy: 1.0000 - val_loss: 1.0520 - val_accuracy: 0.8733\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 3.2787e-05 - accuracy: 1.0000 - val_loss: 1.0771 - val_accuracy: 0.8737\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 144us/sample - loss: 2.4833e-05 - accuracy: 1.0000 - val_loss: 1.0979 - val_accuracy: 0.8733\n",
      "Train on 7250 samples, validate on 2750 samples\n",
      "Epoch 1/10\n",
      "7250/7250 [==============================] - 2s 265us/sample - loss: 0.0271 - accuracy: 0.9949 - val_loss: 0.9422 - val_accuracy: 0.8673\n",
      "Epoch 2/10\n",
      "7250/7250 [==============================] - 1s 141us/sample - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.9979 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "7250/7250 [==============================] - 1s 140us/sample - loss: 0.0103 - accuracy: 0.9961 - val_loss: 1.0386 - val_accuracy: 0.8676\n",
      "Epoch 4/10\n",
      "7250/7250 [==============================] - 1s 140us/sample - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.9520 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "7250/7250 [==============================] - 1s 142us/sample - loss: 0.0095 - accuracy: 0.9972 - val_loss: 1.6550 - val_accuracy: 0.8647\n",
      "Epoch 6/10\n",
      "7250/7250 [==============================] - 1s 140us/sample - loss: 0.0314 - accuracy: 0.9906 - val_loss: 1.0057 - val_accuracy: 0.8618\n",
      "Epoch 7/10\n",
      "7250/7250 [==============================] - 1s 141us/sample - loss: 0.0082 - accuracy: 0.9983 - val_loss: 1.1958 - val_accuracy: 0.8655\n",
      "Epoch 8/10\n",
      "7250/7250 [==============================] - 1s 141us/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.2232 - val_accuracy: 0.8644\n",
      "Epoch 9/10\n",
      "7250/7250 [==============================] - 1s 140us/sample - loss: 0.0055 - accuracy: 0.9990 - val_loss: 1.0587 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "7250/7250 [==============================] - 1s 139us/sample - loss: 4.9989e-04 - accuracy: 1.0000 - val_loss: 1.1920 - val_accuracy: 0.8705\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 215us/sample - loss: 0.0513 - accuracy: 0.9919 - val_loss: 0.7086 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 139us/sample - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.9584 - val_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 139us/sample - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.8685 - val_accuracy: 0.8576\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 140us/sample - loss: 0.0130 - accuracy: 0.9964 - val_loss: 1.1213 - val_accuracy: 0.8592\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 140us/sample - loss: 0.0076 - accuracy: 0.9988 - val_loss: 1.0292 - val_accuracy: 0.8604\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 177us/sample - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.9132 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 0.0139 - accuracy: 0.9955 - val_loss: 1.3027 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 154us/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.2371 - val_accuracy: 0.8684\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 163us/sample - loss: 0.0176 - accuracy: 0.9956 - val_loss: 1.4750 - val_accuracy: 0.8504\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 158us/sample - loss: 0.0262 - accuracy: 0.9939 - val_loss: 1.0256 - val_accuracy: 0.8572\n",
      "Train on 7750 samples, validate on 2250 samples\n",
      "Epoch 1/10\n",
      "7750/7750 [==============================] - 2s 254us/sample - loss: 0.0433 - accuracy: 0.9920 - val_loss: 0.8187 - val_accuracy: 0.8716\n",
      "Epoch 2/10\n",
      "7750/7750 [==============================] - 1s 159us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.9131 - val_accuracy: 0.8720\n",
      "Epoch 3/10\n",
      "7750/7750 [==============================] - 1s 151us/sample - loss: 8.7451e-04 - accuracy: 0.9997 - val_loss: 1.0874 - val_accuracy: 0.8760\n",
      "Epoch 4/10\n",
      "7750/7750 [==============================] - 1s 150us/sample - loss: 5.3745e-04 - accuracy: 0.9999 - val_loss: 1.0107 - val_accuracy: 0.8756\n",
      "Epoch 5/10\n",
      "7750/7750 [==============================] - 1s 157us/sample - loss: 0.0032 - accuracy: 0.9994 - val_loss: 1.0874 - val_accuracy: 0.8631\n",
      "Epoch 6/10\n",
      "7750/7750 [==============================] - 1s 167us/sample - loss: 0.0374 - accuracy: 0.9888 - val_loss: 0.8996 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "7750/7750 [==============================] - 1s 153us/sample - loss: 0.0150 - accuracy: 0.9950 - val_loss: 1.0176 - val_accuracy: 0.8689\n",
      "Epoch 8/10\n",
      "7750/7750 [==============================] - 1s 164us/sample - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.9510 - val_accuracy: 0.8738\n",
      "Epoch 9/10\n",
      "7750/7750 [==============================] - 1s 167us/sample - loss: 6.9652e-04 - accuracy: 0.9999 - val_loss: 1.0711 - val_accuracy: 0.8782\n",
      "Epoch 10/10\n",
      "7750/7750 [==============================] - 1s 191us/sample - loss: 9.1630e-05 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.8791\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 208us/sample - loss: 0.0385 - accuracy: 0.9934 - val_loss: 0.8849 - val_accuracy: 0.8695\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.9907 - val_accuracy: 0.8765\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 171us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.9559 - val_accuracy: 0.8725\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 151us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 1.3275 - val_accuracy: 0.8610\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 142us/sample - loss: 0.0323 - accuracy: 0.9900 - val_loss: 1.0500 - val_accuracy: 0.8645\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 160us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.2629 - val_accuracy: 0.8635\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 162us/sample - loss: 0.0120 - accuracy: 0.9965 - val_loss: 1.1125 - val_accuracy: 0.8755\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 160us/sample - loss: 0.0027 - accuracy: 0.9990 - val_loss: 1.3796 - val_accuracy: 0.8730\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 164us/sample - loss: 0.0057 - accuracy: 0.9986 - val_loss: 1.3331 - val_accuracy: 0.8725\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 159us/sample - loss: 0.0115 - accuracy: 0.9976 - val_loss: 1.3120 - val_accuracy: 0.8685\n",
      "Train on 8250 samples, validate on 1750 samples\n",
      "Epoch 1/10\n",
      "8250/8250 [==============================] - 2s 246us/sample - loss: 0.0435 - accuracy: 0.9916 - val_loss: 0.8343 - val_accuracy: 0.8560\n",
      "Epoch 2/10\n",
      "8250/8250 [==============================] - 1s 164us/sample - loss: 0.0042 - accuracy: 0.9990 - val_loss: 1.2142 - val_accuracy: 0.8737\n",
      "Epoch 3/10\n",
      "8250/8250 [==============================] - 1s 163us/sample - loss: 0.0049 - accuracy: 0.9989 - val_loss: 1.1611 - val_accuracy: 0.8611\n",
      "Epoch 4/10\n",
      "8250/8250 [==============================] - 1s 164us/sample - loss: 0.0184 - accuracy: 0.9942 - val_loss: 1.2971 - val_accuracy: 0.8669\n",
      "Epoch 5/10\n",
      "8250/8250 [==============================] - 1s 155us/sample - loss: 0.0099 - accuracy: 0.9970 - val_loss: 1.4518 - val_accuracy: 0.8629\n",
      "Epoch 6/10\n",
      "8250/8250 [==============================] - 1s 156us/sample - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.4897 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "8250/8250 [==============================] - 1s 155us/sample - loss: 0.0138 - accuracy: 0.9964 - val_loss: 1.4339 - val_accuracy: 0.8714\n",
      "Epoch 8/10\n",
      "8250/8250 [==============================] - 1s 152us/sample - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.1067 - val_accuracy: 0.8634\n",
      "Epoch 9/10\n",
      "8250/8250 [==============================] - 1s 157us/sample - loss: 0.0094 - accuracy: 0.9972 - val_loss: 1.2270 - val_accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "8250/8250 [==============================] - 1s 154us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 1.2345 - val_accuracy: 0.8737\n",
      "Train on 8500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 276us/sample - loss: 0.0331 - accuracy: 0.9926 - val_loss: 1.1804 - val_accuracy: 0.8687\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 156us/sample - loss: 0.0130 - accuracy: 0.9961 - val_loss: 1.2848 - val_accuracy: 0.8733\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 154us/sample - loss: 0.0075 - accuracy: 0.9984 - val_loss: 1.0308 - val_accuracy: 0.8727\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 161us/sample - loss: 0.0033 - accuracy: 0.9993 - val_loss: 1.2375 - val_accuracy: 0.8793\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 161us/sample - loss: 0.0130 - accuracy: 0.9967 - val_loss: 1.2821 - val_accuracy: 0.8740\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 156us/sample - loss: 0.0162 - accuracy: 0.9959 - val_loss: 1.1648 - val_accuracy: 0.8707\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 156us/sample - loss: 0.0165 - accuracy: 0.9956 - val_loss: 1.1392 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500/8500 [==============================] - 1s 158us/sample - loss: 0.0037 - accuracy: 0.9986 - val_loss: 1.2589 - val_accuracy: 0.8760\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 157us/sample - loss: 0.0078 - accuracy: 0.9979 - val_loss: 1.2818 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 159us/sample - loss: 0.0125 - accuracy: 0.9967 - val_loss: 1.2835 - val_accuracy: 0.8713\n",
      "Train on 8750 samples, validate on 1250 samples\n",
      "Epoch 1/10\n",
      "8750/8750 [==============================] - 2s 224us/sample - loss: 0.0292 - accuracy: 0.9943 - val_loss: 1.0590 - val_accuracy: 0.8744\n",
      "Epoch 2/10\n",
      "8750/8750 [==============================] - 1s 147us/sample - loss: 0.0067 - accuracy: 0.9976 - val_loss: 1.3559 - val_accuracy: 0.8752\n",
      "Epoch 3/10\n",
      "8750/8750 [==============================] - 1s 148us/sample - loss: 0.0041 - accuracy: 0.9991 - val_loss: 1.1905 - val_accuracy: 0.8792\n",
      "Epoch 4/10\n",
      "8750/8750 [==============================] - 1s 147us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 1.1826 - val_accuracy: 0.8752\n",
      "Epoch 5/10\n",
      "8750/8750 [==============================] - 1s 148us/sample - loss: 4.4648e-04 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.8896\n",
      "Epoch 6/10\n",
      "8750/8750 [==============================] - 1s 149us/sample - loss: 5.3539e-05 - accuracy: 1.0000 - val_loss: 1.3137 - val_accuracy: 0.8848\n",
      "Epoch 7/10\n",
      "8750/8750 [==============================] - 1s 148us/sample - loss: 1.1771e-05 - accuracy: 1.0000 - val_loss: 1.3385 - val_accuracy: 0.8856\n",
      "Epoch 8/10\n",
      "8750/8750 [==============================] - 1s 149us/sample - loss: 8.6379e-06 - accuracy: 1.0000 - val_loss: 1.3594 - val_accuracy: 0.8856\n",
      "Epoch 9/10\n",
      "8750/8750 [==============================] - 1s 151us/sample - loss: 6.6932e-06 - accuracy: 1.0000 - val_loss: 1.3782 - val_accuracy: 0.8864\n",
      "Epoch 10/10\n",
      "8750/8750 [==============================] - 1s 150us/sample - loss: 5.3533e-06 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.8856\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 221us/sample - loss: 0.0459 - accuracy: 0.9932 - val_loss: 1.0445 - val_accuracy: 0.8670\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 147us/sample - loss: 0.0066 - accuracy: 0.9986 - val_loss: 1.1032 - val_accuracy: 0.8720\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 148us/sample - loss: 0.0057 - accuracy: 0.9987 - val_loss: 1.1083 - val_accuracy: 0.8710\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0090 - accuracy: 0.9980 - val_loss: 1.2627 - val_accuracy: 0.8730\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 144us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 1.4033 - val_accuracy: 0.8650\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 150us/sample - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.5948 - val_accuracy: 0.8610\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 153us/sample - loss: 0.0342 - accuracy: 0.9916 - val_loss: 1.1762 - val_accuracy: 0.8610\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0095 - accuracy: 0.9970 - val_loss: 1.4586 - val_accuracy: 0.8730\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 149us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.3942 - val_accuracy: 0.8770\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0105 - accuracy: 0.9970 - val_loss: 1.1378 - val_accuracy: 0.8580\n",
      "Train on 9250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "9250/9250 [==============================] - 2s 220us/sample - loss: 0.0506 - accuracy: 0.9923 - val_loss: 0.7639 - val_accuracy: 0.8667\n",
      "Epoch 2/10\n",
      "9250/9250 [==============================] - 1s 152us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 1.1181 - val_accuracy: 0.8613\n",
      "Epoch 3/10\n",
      "9250/9250 [==============================] - 1s 147us/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.2313 - val_accuracy: 0.8627\n",
      "Epoch 4/10\n",
      "9250/9250 [==============================] - 1s 150us/sample - loss: 0.0032 - accuracy: 0.9994 - val_loss: 1.3483 - val_accuracy: 0.8747\n",
      "Epoch 5/10\n",
      "9250/9250 [==============================] - 1s 147us/sample - loss: 0.0219 - accuracy: 0.9939 - val_loss: 1.0522 - val_accuracy: 0.8587\n",
      "Epoch 6/10\n",
      "9250/9250 [==============================] - 1s 151us/sample - loss: 0.0113 - accuracy: 0.9969 - val_loss: 1.4393 - val_accuracy: 0.8693\n",
      "Epoch 7/10\n",
      "9250/9250 [==============================] - 1s 148us/sample - loss: 0.0053 - accuracy: 0.9986 - val_loss: 1.4452 - val_accuracy: 0.8600\n",
      "Epoch 8/10\n",
      "9250/9250 [==============================] - 1s 147us/sample - loss: 2.5267e-04 - accuracy: 1.0000 - val_loss: 1.3987 - val_accuracy: 0.8627\n",
      "Epoch 9/10\n",
      "9250/9250 [==============================] - 1s 150us/sample - loss: 1.4175e-04 - accuracy: 1.0000 - val_loss: 1.3584 - val_accuracy: 0.8613\n",
      "Epoch 10/10\n",
      "9250/9250 [==============================] - 2s 163us/sample - loss: 4.0255e-05 - accuracy: 1.0000 - val_loss: 1.4365 - val_accuracy: 0.8653\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 213us/sample - loss: 0.0301 - accuracy: 0.9956 - val_loss: 1.1935 - val_accuracy: 0.8620\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 149us/sample - loss: 0.0123 - accuracy: 0.9965 - val_loss: 1.4923 - val_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 143us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 1.5752 - val_accuracy: 0.8660\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 146us/sample - loss: 0.0108 - accuracy: 0.9969 - val_loss: 1.6057 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 146us/sample - loss: 0.0164 - accuracy: 0.9943 - val_loss: 1.6975 - val_accuracy: 0.8660\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 145us/sample - loss: 0.0152 - accuracy: 0.9956 - val_loss: 1.7725 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 146us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.8038 - val_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 147us/sample - loss: 0.0129 - accuracy: 0.9967 - val_loss: 1.6611 - val_accuracy: 0.8680\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 142us/sample - loss: 0.0194 - accuracy: 0.9951 - val_loss: 1.7640 - val_accuracy: 0.8620\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 140us/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.7439 - val_accuracy: 0.8700\n",
      "Train on 9750 samples, validate on 250 samples\n",
      "Epoch 1/10\n",
      "9750/9750 [==============================] - 2s 243us/sample - loss: 0.0323 - accuracy: 0.9965 - val_loss: 1.2298 - val_accuracy: 0.8720\n",
      "Epoch 2/10\n",
      "9750/9750 [==============================] - 1s 138us/sample - loss: 0.0050 - accuracy: 0.9990 - val_loss: 1.2151 - val_accuracy: 0.8920\n",
      "Epoch 3/10\n",
      "9750/9750 [==============================] - 1s 139us/sample - loss: 0.0018 - accuracy: 0.9993 - val_loss: 1.3012 - val_accuracy: 0.8680\n",
      "Epoch 4/10\n",
      "9750/9750 [==============================] - 1s 139us/sample - loss: 0.0067 - accuracy: 0.9977 - val_loss: 1.5259 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "9750/9750 [==============================] - 1s 139us/sample - loss: 0.0232 - accuracy: 0.9928 - val_loss: 2.1230 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "9750/9750 [==============================] - 1s 139us/sample - loss: 0.0168 - accuracy: 0.9949 - val_loss: 1.6604 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "9750/9750 [==============================] - 1s 137us/sample - loss: 0.0084 - accuracy: 0.9982 - val_loss: 1.7919 - val_accuracy: 0.8720\n",
      "Epoch 8/10\n",
      "9750/9750 [==============================] - 1s 140us/sample - loss: 0.0042 - accuracy: 0.9988 - val_loss: 1.5888 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "9750/9750 [==============================] - 1s 137us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 1.1790 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "9750/9750 [==============================] - 1s 138us/sample - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.2293 - val_accuracy: 0.8640\n",
      "Train on 250 samples, validate on 9750 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 2s 7ms/sample - loss: 2.2787 - accuracy: 0.1520 - val_loss: 2.2868 - val_accuracy: 0.0997\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 2.1259 - accuracy: 0.2160 - val_loss: 1.9346 - val_accuracy: 0.3520\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 4ms/sample - loss: 1.6297 - accuracy: 0.3880 - val_loss: 1.5650 - val_accuracy: 0.4644\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 1.2821 - accuracy: 0.5080 - val_loss: 1.2565 - val_accuracy: 0.5734\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 1.0683 - accuracy: 0.6000 - val_loss: 1.0663 - val_accuracy: 0.5680\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.8957 - accuracy: 0.6480 - val_loss: 1.1376 - val_accuracy: 0.6343\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.8378 - accuracy: 0.6720 - val_loss: 0.9078 - val_accuracy: 0.6642\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.7508 - accuracy: 0.7000 - val_loss: 0.9754 - val_accuracy: 0.6439\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.7171 - accuracy: 0.7200 - val_loss: 0.8131 - val_accuracy: 0.7066\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/sample - loss: 0.5955 - accuracy: 0.8080 - val_loss: 0.9115 - val_accuracy: 0.6973\n",
      "Train on 500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 0.9203 - accuracy: 0.6920 - val_loss: 0.9169 - val_accuracy: 0.6597\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.7187 - accuracy: 0.7400 - val_loss: 0.7773 - val_accuracy: 0.7162\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.6261 - accuracy: 0.8020 - val_loss: 0.7915 - val_accuracy: 0.7151\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.5915 - accuracy: 0.7960 - val_loss: 0.7306 - val_accuracy: 0.7236\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.4923 - accuracy: 0.8200 - val_loss: 0.7529 - val_accuracy: 0.7409\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.3906 - accuracy: 0.8600 - val_loss: 0.7573 - val_accuracy: 0.7573\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.4383 - accuracy: 0.8520 - val_loss: 0.7350 - val_accuracy: 0.7377\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.3495 - accuracy: 0.8860 - val_loss: 0.6865 - val_accuracy: 0.7765\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.2846 - accuracy: 0.8980 - val_loss: 0.8048 - val_accuracy: 0.7606\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.2932 - accuracy: 0.8960 - val_loss: 0.7705 - val_accuracy: 0.7647\n",
      "Train on 750 samples, validate on 9250 samples\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 2s 2ms/sample - loss: 0.4930 - accuracy: 0.8427 - val_loss: 0.7252 - val_accuracy: 0.7751\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.3641 - accuracy: 0.8760 - val_loss: 0.6895 - val_accuracy: 0.7761\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.2637 - accuracy: 0.8973 - val_loss: 0.9298 - val_accuracy: 0.7636\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.2718 - accuracy: 0.8920 - val_loss: 0.7274 - val_accuracy: 0.7766\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.2010 - accuracy: 0.9253 - val_loss: 0.8849 - val_accuracy: 0.7621\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 1s 2ms/sample - loss: 0.2174 - accuracy: 0.9173 - val_loss: 0.8186 - val_accuracy: 0.7841\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.1777 - accuracy: 0.9360 - val_loss: 0.9487 - val_accuracy: 0.7796\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.1847 - accuracy: 0.9347 - val_loss: 0.7774 - val_accuracy: 0.7862\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.1141 - accuracy: 0.9640 - val_loss: 1.1866 - val_accuracy: 0.7531\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 1s 1ms/sample - loss: 0.1636 - accuracy: 0.9387 - val_loss: 0.9297 - val_accuracy: 0.7790\n",
      "Train on 1000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.3602 - accuracy: 0.8710 - val_loss: 0.7792 - val_accuracy: 0.7677\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 980us/sample - loss: 0.2193 - accuracy: 0.9300 - val_loss: 0.7264 - val_accuracy: 0.7826\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 986us/sample - loss: 0.1533 - accuracy: 0.9460 - val_loss: 0.9472 - val_accuracy: 0.7851\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.1568 - accuracy: 0.9420 - val_loss: 0.8569 - val_accuracy: 0.7833\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 986us/sample - loss: 0.1409 - accuracy: 0.9490 - val_loss: 0.9333 - val_accuracy: 0.7866\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.1281 - accuracy: 0.9590 - val_loss: 0.8745 - val_accuracy: 0.7901\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 955us/sample - loss: 0.1197 - accuracy: 0.9600 - val_loss: 0.9352 - val_accuracy: 0.7828\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 956us/sample - loss: 0.1509 - accuracy: 0.9470 - val_loss: 0.8401 - val_accuracy: 0.7857\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 955us/sample - loss: 0.1011 - accuracy: 0.9670 - val_loss: 1.0565 - val_accuracy: 0.7802\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 959us/sample - loss: 0.1030 - accuracy: 0.9580 - val_loss: 1.1165 - val_accuracy: 0.7669\n",
      "Train on 1250 samples, validate on 8750 samples\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 2s 2ms/sample - loss: 0.2773 - accuracy: 0.9096 - val_loss: 0.7483 - val_accuracy: 0.7915\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 1s 893us/sample - loss: 0.1657 - accuracy: 0.9464 - val_loss: 0.8222 - val_accuracy: 0.7771\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 1s 874us/sample - loss: 0.1276 - accuracy: 0.9560 - val_loss: 0.9182 - val_accuracy: 0.7872\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 1s 841us/sample - loss: 0.0961 - accuracy: 0.9664 - val_loss: 1.5375 - val_accuracy: 0.7490\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 1s 869us/sample - loss: 0.1145 - accuracy: 0.9552 - val_loss: 1.0771 - val_accuracy: 0.7801\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 1s 832us/sample - loss: 0.0833 - accuracy: 0.9680 - val_loss: 1.1243 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 1s 830us/sample - loss: 0.0572 - accuracy: 0.9792 - val_loss: 1.5660 - val_accuracy: 0.7655\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1s 863us/sample - loss: 0.0880 - accuracy: 0.9728 - val_loss: 1.1569 - val_accuracy: 0.7864\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1s 869us/sample - loss: 0.0463 - accuracy: 0.9824 - val_loss: 1.2761 - val_accuracy: 0.7833\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1s 861us/sample - loss: 0.0368 - accuracy: 0.9880 - val_loss: 1.5079 - val_accuracy: 0.7594\n",
      "Train on 1500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.2805 - accuracy: 0.9273 - val_loss: 0.6606 - val_accuracy: 0.8052\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 728us/sample - loss: 0.1398 - accuracy: 0.9627 - val_loss: 0.6711 - val_accuracy: 0.7985\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 724us/sample - loss: 0.0736 - accuracy: 0.9767 - val_loss: 0.9732 - val_accuracy: 0.8086\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 725us/sample - loss: 0.0662 - accuracy: 0.9773 - val_loss: 0.9387 - val_accuracy: 0.7896\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 723us/sample - loss: 0.0858 - accuracy: 0.9713 - val_loss: 0.9517 - val_accuracy: 0.7842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 709us/sample - loss: 0.0782 - accuracy: 0.9720 - val_loss: 1.1226 - val_accuracy: 0.7924\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 717us/sample - loss: 0.0944 - accuracy: 0.9693 - val_loss: 0.8821 - val_accuracy: 0.7881\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 717us/sample - loss: 0.0678 - accuracy: 0.9760 - val_loss: 1.0062 - val_accuracy: 0.7908\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 716us/sample - loss: 0.0332 - accuracy: 0.9933 - val_loss: 1.0608 - val_accuracy: 0.8073\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 749us/sample - loss: 0.0058 - accuracy: 0.9993 - val_loss: 1.4722 - val_accuracy: 0.8066\n",
      "Train on 1750 samples, validate on 8250 samples\n",
      "Epoch 1/10\n",
      "1750/1750 [==============================] - 2s 1ms/sample - loss: 0.1703 - accuracy: 0.9583 - val_loss: 0.7854 - val_accuracy: 0.8062\n",
      "Epoch 2/10\n",
      "1750/1750 [==============================] - 1s 773us/sample - loss: 0.0726 - accuracy: 0.9823 - val_loss: 0.8568 - val_accuracy: 0.8088\n",
      "Epoch 3/10\n",
      "1750/1750 [==============================] - 1s 690us/sample - loss: 0.0438 - accuracy: 0.9857 - val_loss: 1.1933 - val_accuracy: 0.8022\n",
      "Epoch 4/10\n",
      "1750/1750 [==============================] - 1s 747us/sample - loss: 0.0572 - accuracy: 0.9800 - val_loss: 0.9712 - val_accuracy: 0.8044\n",
      "Epoch 5/10\n",
      "1750/1750 [==============================] - 1s 674us/sample - loss: 0.0646 - accuracy: 0.9789 - val_loss: 1.2437 - val_accuracy: 0.7898\n",
      "Epoch 6/10\n",
      "1750/1750 [==============================] - 1s 665us/sample - loss: 0.0658 - accuracy: 0.9743 - val_loss: 1.0894 - val_accuracy: 0.8074\n",
      "Epoch 7/10\n",
      "1750/1750 [==============================] - 1s 672us/sample - loss: 0.0612 - accuracy: 0.9817 - val_loss: 1.0742 - val_accuracy: 0.8002\n",
      "Epoch 8/10\n",
      "1750/1750 [==============================] - 1s 677us/sample - loss: 0.0574 - accuracy: 0.9811 - val_loss: 1.1317 - val_accuracy: 0.7966\n",
      "Epoch 9/10\n",
      "1750/1750 [==============================] - 1s 665us/sample - loss: 0.0346 - accuracy: 0.9897 - val_loss: 1.3170 - val_accuracy: 0.8048\n",
      "Epoch 10/10\n",
      "1750/1750 [==============================] - 1s 661us/sample - loss: 0.0533 - accuracy: 0.9886 - val_loss: 1.1255 - val_accuracy: 0.8012\n",
      "Train on 2000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 0.1968 - accuracy: 0.9525 - val_loss: 0.6754 - val_accuracy: 0.8050\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 529us/sample - loss: 0.0912 - accuracy: 0.9720 - val_loss: 0.7958 - val_accuracy: 0.8141\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 535us/sample - loss: 0.0618 - accuracy: 0.9775 - val_loss: 0.9526 - val_accuracy: 0.8043\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 539us/sample - loss: 0.0482 - accuracy: 0.9880 - val_loss: 1.1141 - val_accuracy: 0.8021\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 455us/sample - loss: 0.0291 - accuracy: 0.9885 - val_loss: 1.3398 - val_accuracy: 0.8079\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 483us/sample - loss: 0.0446 - accuracy: 0.9890 - val_loss: 1.1064 - val_accuracy: 0.8055\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 506us/sample - loss: 0.0948 - accuracy: 0.9690 - val_loss: 0.8782 - val_accuracy: 0.7865\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 510us/sample - loss: 0.0434 - accuracy: 0.9845 - val_loss: 1.2909 - val_accuracy: 0.8115\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 515us/sample - loss: 0.0233 - accuracy: 0.9955 - val_loss: 1.2614 - val_accuracy: 0.8139\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 547us/sample - loss: 0.0031 - accuracy: 0.9995 - val_loss: 1.4600 - val_accuracy: 0.8185\n",
      "Train on 2250 samples, validate on 7750 samples\n",
      "Epoch 1/10\n",
      "2250/2250 [==============================] - 2s 976us/sample - loss: 0.1427 - accuracy: 0.9613 - val_loss: 0.8007 - val_accuracy: 0.8102\n",
      "Epoch 2/10\n",
      "2250/2250 [==============================] - 1s 514us/sample - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.9652 - val_accuracy: 0.8145\n",
      "Epoch 3/10\n",
      "2250/2250 [==============================] - 1s 523us/sample - loss: 0.0337 - accuracy: 0.9876 - val_loss: 1.1111 - val_accuracy: 0.8068\n",
      "Epoch 4/10\n",
      "2250/2250 [==============================] - 1s 522us/sample - loss: 0.0523 - accuracy: 0.9809 - val_loss: 1.1066 - val_accuracy: 0.8130\n",
      "Epoch 5/10\n",
      "2250/2250 [==============================] - 1s 524us/sample - loss: 0.0436 - accuracy: 0.9871 - val_loss: 1.1177 - val_accuracy: 0.8074\n",
      "Epoch 6/10\n",
      "2250/2250 [==============================] - 1s 520us/sample - loss: 0.0604 - accuracy: 0.9840 - val_loss: 0.9747 - val_accuracy: 0.8092\n",
      "Epoch 7/10\n",
      "2250/2250 [==============================] - 1s 521us/sample - loss: 0.0521 - accuracy: 0.9809 - val_loss: 1.0480 - val_accuracy: 0.8084\n",
      "Epoch 8/10\n",
      "2250/2250 [==============================] - 1s 521us/sample - loss: 0.0420 - accuracy: 0.9871 - val_loss: 1.3625 - val_accuracy: 0.8028\n",
      "Epoch 9/10\n",
      "2250/2250 [==============================] - 1s 524us/sample - loss: 0.0323 - accuracy: 0.9911 - val_loss: 1.0618 - val_accuracy: 0.8152\n",
      "Epoch 10/10\n",
      "2250/2250 [==============================] - 1s 516us/sample - loss: 0.0102 - accuracy: 0.9969 - val_loss: 1.2737 - val_accuracy: 0.8092\n",
      "Train on 2500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 887us/sample - loss: 0.1151 - accuracy: 0.9732 - val_loss: 0.7282 - val_accuracy: 0.8244\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 475us/sample - loss: 0.0433 - accuracy: 0.9884 - val_loss: 0.9918 - val_accuracy: 0.8155\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 481us/sample - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.9833 - val_accuracy: 0.8163\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 516us/sample - loss: 0.0435 - accuracy: 0.9844 - val_loss: 1.0459 - val_accuracy: 0.8139\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 548us/sample - loss: 0.0355 - accuracy: 0.9892 - val_loss: 1.2620 - val_accuracy: 0.8081\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 541us/sample - loss: 0.0935 - accuracy: 0.9720 - val_loss: 1.1193 - val_accuracy: 0.8147\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 457us/sample - loss: 0.0344 - accuracy: 0.9900 - val_loss: 1.1463 - val_accuracy: 0.8040\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 458us/sample - loss: 0.0123 - accuracy: 0.9948 - val_loss: 1.4438 - val_accuracy: 0.8172\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 489us/sample - loss: 0.0022 - accuracy: 0.9996 - val_loss: 1.6533 - val_accuracy: 0.8225\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 502us/sample - loss: 4.3949e-04 - accuracy: 1.0000 - val_loss: 1.7262 - val_accuracy: 0.8224\n",
      "Train on 2750 samples, validate on 7250 samples\n",
      "Epoch 1/10\n",
      "2750/2750 [==============================] - 3s 987us/sample - loss: 0.1075 - accuracy: 0.9760 - val_loss: 0.8017 - val_accuracy: 0.8262\n",
      "Epoch 2/10\n",
      "2750/2750 [==============================] - 1s 460us/sample - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.9827 - val_accuracy: 0.8204\n",
      "Epoch 3/10\n",
      "2750/2750 [==============================] - 1s 454us/sample - loss: 0.0238 - accuracy: 0.9938 - val_loss: 1.1370 - val_accuracy: 0.8334\n",
      "Epoch 4/10\n",
      "2750/2750 [==============================] - 1s 453us/sample - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.9892 - val_accuracy: 0.8139\n",
      "Epoch 5/10\n",
      "2750/2750 [==============================] - 1s 455us/sample - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.9784 - val_accuracy: 0.8206\n",
      "Epoch 6/10\n",
      "2750/2750 [==============================] - 1s 445us/sample - loss: 0.0429 - accuracy: 0.9876 - val_loss: 1.0918 - val_accuracy: 0.8206\n",
      "Epoch 7/10\n",
      "2750/2750 [==============================] - 1s 457us/sample - loss: 0.0278 - accuracy: 0.9898 - val_loss: 1.1417 - val_accuracy: 0.8200\n",
      "Epoch 8/10\n",
      "2750/2750 [==============================] - 1s 453us/sample - loss: 0.0349 - accuracy: 0.9876 - val_loss: 1.2937 - val_accuracy: 0.8123\n",
      "Epoch 9/10\n",
      "2750/2750 [==============================] - 1s 474us/sample - loss: 0.0116 - accuracy: 0.9956 - val_loss: 1.1615 - val_accuracy: 0.8229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "2750/2750 [==============================] - 1s 440us/sample - loss: 0.0232 - accuracy: 0.9945 - val_loss: 1.2656 - val_accuracy: 0.8270\n",
      "Train on 3000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 775us/sample - loss: 0.0980 - accuracy: 0.9780 - val_loss: 0.7208 - val_accuracy: 0.8243\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 430us/sample - loss: 0.0267 - accuracy: 0.9930 - val_loss: 1.0625 - val_accuracy: 0.8300\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 419us/sample - loss: 0.0340 - accuracy: 0.9883 - val_loss: 1.1543 - val_accuracy: 0.8183\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 426us/sample - loss: 0.0314 - accuracy: 0.9897 - val_loss: 1.3571 - val_accuracy: 0.8199\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 427us/sample - loss: 0.0357 - accuracy: 0.9900 - val_loss: 1.2408 - val_accuracy: 0.8340\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 419us/sample - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.3612 - val_accuracy: 0.8297\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 416us/sample - loss: 0.0508 - accuracy: 0.9857 - val_loss: 0.9856 - val_accuracy: 0.8021\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 423us/sample - loss: 0.0680 - accuracy: 0.9813 - val_loss: 0.9799 - val_accuracy: 0.8116\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 425us/sample - loss: 0.0201 - accuracy: 0.9940 - val_loss: 1.2438 - val_accuracy: 0.8273\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 416us/sample - loss: 0.0161 - accuracy: 0.9940 - val_loss: 1.2691 - val_accuracy: 0.8170\n",
      "Train on 3250 samples, validate on 6750 samples\n",
      "Epoch 1/10\n",
      "3250/3250 [==============================] - 2s 720us/sample - loss: 0.0874 - accuracy: 0.9775 - val_loss: 0.6957 - val_accuracy: 0.8351\n",
      "Epoch 2/10\n",
      "3250/3250 [==============================] - 1s 408us/sample - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.8368 - val_accuracy: 0.8293\n",
      "Epoch 3/10\n",
      "3250/3250 [==============================] - 1s 410us/sample - loss: 0.0233 - accuracy: 0.9942 - val_loss: 1.0017 - val_accuracy: 0.8224\n",
      "Epoch 4/10\n",
      "3250/3250 [==============================] - 1s 417us/sample - loss: 0.0255 - accuracy: 0.9911 - val_loss: 1.1420 - val_accuracy: 0.8207\n",
      "Epoch 5/10\n",
      "3250/3250 [==============================] - 1s 406us/sample - loss: 0.0339 - accuracy: 0.9874 - val_loss: 1.1258 - val_accuracy: 0.8253\n",
      "Epoch 6/10\n",
      "3250/3250 [==============================] - 1s 407us/sample - loss: 0.0329 - accuracy: 0.9902 - val_loss: 1.2097 - val_accuracy: 0.8236\n",
      "Epoch 7/10\n",
      "3250/3250 [==============================] - 1s 405us/sample - loss: 0.0319 - accuracy: 0.9886 - val_loss: 1.2726 - val_accuracy: 0.8056\n",
      "Epoch 8/10\n",
      "3250/3250 [==============================] - 1s 407us/sample - loss: 0.0458 - accuracy: 0.9871 - val_loss: 0.9946 - val_accuracy: 0.8308\n",
      "Epoch 9/10\n",
      "3250/3250 [==============================] - 1s 407us/sample - loss: 0.0126 - accuracy: 0.9960 - val_loss: 1.1897 - val_accuracy: 0.8164\n",
      "Epoch 10/10\n",
      "3250/3250 [==============================] - 1s 400us/sample - loss: 0.0080 - accuracy: 0.9969 - val_loss: 1.4057 - val_accuracy: 0.8279\n",
      "Train on 3500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 660us/sample - loss: 0.0860 - accuracy: 0.9806 - val_loss: 0.9620 - val_accuracy: 0.8198\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 370us/sample - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.9732 - val_accuracy: 0.8249\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 367us/sample - loss: 0.0248 - accuracy: 0.9923 - val_loss: 1.1178 - val_accuracy: 0.8298\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 380us/sample - loss: 0.0148 - accuracy: 0.9963 - val_loss: 1.4148 - val_accuracy: 0.8248\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 380us/sample - loss: 5.6426e-04 - accuracy: 1.0000 - val_loss: 1.5378 - val_accuracy: 0.8305\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 365us/sample - loss: 1.0549e-04 - accuracy: 1.0000 - val_loss: 1.5771 - val_accuracy: 0.8314\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 374us/sample - loss: 5.4001e-05 - accuracy: 1.0000 - val_loss: 1.6164 - val_accuracy: 0.8298\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 370us/sample - loss: 3.7808e-05 - accuracy: 1.0000 - val_loss: 1.6490 - val_accuracy: 0.8297\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 370us/sample - loss: 2.9247e-05 - accuracy: 1.0000 - val_loss: 1.6776 - val_accuracy: 0.8298\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 373us/sample - loss: 2.3519e-05 - accuracy: 1.0000 - val_loss: 1.7042 - val_accuracy: 0.8292\n",
      "Train on 3750 samples, validate on 6250 samples\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 3s 738us/sample - loss: 0.0837 - accuracy: 0.9843 - val_loss: 0.8719 - val_accuracy: 0.8266\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 1s 349us/sample - loss: 0.0207 - accuracy: 0.9952 - val_loss: 1.0105 - val_accuracy: 0.8192\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 1s 347us/sample - loss: 0.0132 - accuracy: 0.9963 - val_loss: 1.3594 - val_accuracy: 0.8240\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 1s 349us/sample - loss: 0.0116 - accuracy: 0.9965 - val_loss: 1.2907 - val_accuracy: 0.8323\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 1s 347us/sample - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.9564 - val_accuracy: 0.8222\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 1s 351us/sample - loss: 0.0267 - accuracy: 0.9917 - val_loss: 1.2669 - val_accuracy: 0.8198\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 1s 333us/sample - loss: 0.0498 - accuracy: 0.9848 - val_loss: 1.0791 - val_accuracy: 0.8213\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 1s 338us/sample - loss: 0.0203 - accuracy: 0.9928 - val_loss: 1.1232 - val_accuracy: 0.8253\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 1s 333us/sample - loss: 0.0287 - accuracy: 0.9915 - val_loss: 1.0298 - val_accuracy: 0.8262\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 1s 343us/sample - loss: 0.0087 - accuracy: 0.9976 - val_loss: 1.3685 - val_accuracy: 0.8270\n",
      "Train on 4000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 517us/sample - loss: 0.0877 - accuracy: 0.9827 - val_loss: 0.7354 - val_accuracy: 0.8317\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 307us/sample - loss: 0.0176 - accuracy: 0.9942 - val_loss: 1.0957 - val_accuracy: 0.8258\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 309us/sample - loss: 0.0177 - accuracy: 0.9950 - val_loss: 1.3346 - val_accuracy: 0.8315\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 303us/sample - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.9132 - val_accuracy: 0.8273\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 306us/sample - loss: 0.0289 - accuracy: 0.9908 - val_loss: 1.0189 - val_accuracy: 0.8315\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 306us/sample - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.4093 - val_accuracy: 0.8222\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 307us/sample - loss: 0.0312 - accuracy: 0.9910 - val_loss: 1.0702 - val_accuracy: 0.8303\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 309us/sample - loss: 0.0114 - accuracy: 0.9967 - val_loss: 1.3824 - val_accuracy: 0.8222\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 303us/sample - loss: 0.0393 - accuracy: 0.9865 - val_loss: 1.2350 - val_accuracy: 0.8248\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 306us/sample - loss: 0.0331 - accuracy: 0.9898 - val_loss: 1.0316 - val_accuracy: 0.8242\n",
      "Train on 4250 samples, validate on 5750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 2s 512us/sample - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.7477 - val_accuracy: 0.8273\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 304us/sample - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.9671 - val_accuracy: 0.8397\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 312us/sample - loss: 0.0207 - accuracy: 0.9951 - val_loss: 0.9973 - val_accuracy: 0.8303\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 304us/sample - loss: 0.0180 - accuracy: 0.9946 - val_loss: 1.2109 - val_accuracy: 0.8270\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 304us/sample - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.9612 - val_accuracy: 0.8172\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 309us/sample - loss: 0.0322 - accuracy: 0.9908 - val_loss: 1.2159 - val_accuracy: 0.8195\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 306us/sample - loss: 0.0216 - accuracy: 0.9918 - val_loss: 1.3294 - val_accuracy: 0.8243\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 304us/sample - loss: 0.0250 - accuracy: 0.9913 - val_loss: 1.1016 - val_accuracy: 0.8252\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 306us/sample - loss: 0.0553 - accuracy: 0.9824 - val_loss: 1.1437 - val_accuracy: 0.8237\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 308us/sample - loss: 0.0251 - accuracy: 0.9908 - val_loss: 1.2035 - val_accuracy: 0.8310\n",
      "Train on 4500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 473us/sample - loss: 0.0667 - accuracy: 0.9838 - val_loss: 0.7736 - val_accuracy: 0.8355\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 290us/sample - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.9938 - val_accuracy: 0.8364\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 290us/sample - loss: 0.0121 - accuracy: 0.9967 - val_loss: 1.2562 - val_accuracy: 0.8287\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 292us/sample - loss: 0.0380 - accuracy: 0.9884 - val_loss: 1.1287 - val_accuracy: 0.8305\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 291us/sample - loss: 0.0286 - accuracy: 0.9916 - val_loss: 1.1320 - val_accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 289us/sample - loss: 0.0153 - accuracy: 0.9964 - val_loss: 1.2710 - val_accuracy: 0.8267\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 292us/sample - loss: 0.0248 - accuracy: 0.9933 - val_loss: 1.3442 - val_accuracy: 0.8155\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 290us/sample - loss: 0.0360 - accuracy: 0.9880 - val_loss: 1.1935 - val_accuracy: 0.8385\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 290us/sample - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3184 - val_accuracy: 0.8398\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 291us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4560 - val_accuracy: 0.8416\n",
      "Train on 4750 samples, validate on 5250 samples\n",
      "Epoch 1/10\n",
      "4750/4750 [==============================] - 3s 538us/sample - loss: 0.0655 - accuracy: 0.9853 - val_loss: 0.8598 - val_accuracy: 0.8377\n",
      "Epoch 2/10\n",
      "4750/4750 [==============================] - 1s 283us/sample - loss: 0.0152 - accuracy: 0.9960 - val_loss: 1.0214 - val_accuracy: 0.8324\n",
      "Epoch 3/10\n",
      "4750/4750 [==============================] - 1s 288us/sample - loss: 0.0078 - accuracy: 0.9968 - val_loss: 1.2388 - val_accuracy: 0.8381\n",
      "Epoch 4/10\n",
      "4750/4750 [==============================] - 1s 282us/sample - loss: 0.0232 - accuracy: 0.9924 - val_loss: 1.2803 - val_accuracy: 0.8251\n",
      "Epoch 5/10\n",
      "4750/4750 [==============================] - 1s 282us/sample - loss: 0.0430 - accuracy: 0.9859 - val_loss: 1.1803 - val_accuracy: 0.8301\n",
      "Epoch 6/10\n",
      "4750/4750 [==============================] - 1s 284us/sample - loss: 0.0227 - accuracy: 0.9926 - val_loss: 1.2123 - val_accuracy: 0.8282\n",
      "Epoch 7/10\n",
      "4750/4750 [==============================] - 1s 280us/sample - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.3767 - val_accuracy: 0.8324\n",
      "Epoch 8/10\n",
      "4750/4750 [==============================] - 1s 285us/sample - loss: 0.0084 - accuracy: 0.9962 - val_loss: 1.5254 - val_accuracy: 0.8337\n",
      "Epoch 9/10\n",
      "4750/4750 [==============================] - 1s 285us/sample - loss: 0.0431 - accuracy: 0.9863 - val_loss: 1.0705 - val_accuracy: 0.8375\n",
      "Epoch 10/10\n",
      "4750/4750 [==============================] - 1s 287us/sample - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.3095 - val_accuracy: 0.8282\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 456us/sample - loss: 0.0594 - accuracy: 0.9880 - val_loss: 0.8978 - val_accuracy: 0.8378\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 278us/sample - loss: 0.0140 - accuracy: 0.9958 - val_loss: 1.1022 - val_accuracy: 0.8368\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 2s 327us/sample - loss: 0.0146 - accuracy: 0.9954 - val_loss: 1.3815 - val_accuracy: 0.8342\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 293us/sample - loss: 0.0259 - accuracy: 0.9920 - val_loss: 1.3362 - val_accuracy: 0.8134\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 290us/sample - loss: 0.0267 - accuracy: 0.9914 - val_loss: 1.2628 - val_accuracy: 0.8292\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 289us/sample - loss: 0.0234 - accuracy: 0.9924 - val_loss: 1.3177 - val_accuracy: 0.8200\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 285us/sample - loss: 0.0165 - accuracy: 0.9942 - val_loss: 1.6760 - val_accuracy: 0.8250\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 284us/sample - loss: 0.0531 - accuracy: 0.9854 - val_loss: 1.1051 - val_accuracy: 0.8330\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 289us/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 1.4613 - val_accuracy: 0.8340\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 295us/sample - loss: 0.0137 - accuracy: 0.9968 - val_loss: 1.3292 - val_accuracy: 0.8304\n",
      "Train on 5250 samples, validate on 4750 samples\n",
      "Epoch 1/10\n",
      "5250/5250 [==============================] - 2s 450us/sample - loss: 0.0742 - accuracy: 0.9853 - val_loss: 0.9666 - val_accuracy: 0.8324\n",
      "Epoch 2/10\n",
      "5250/5250 [==============================] - 1s 275us/sample - loss: 0.0221 - accuracy: 0.9958 - val_loss: 0.8465 - val_accuracy: 0.8375\n",
      "Epoch 3/10\n",
      "5250/5250 [==============================] - 1s 272us/sample - loss: 0.0050 - accuracy: 0.9989 - val_loss: 1.1760 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "5250/5250 [==============================] - 1s 280us/sample - loss: 0.0030 - accuracy: 0.9994 - val_loss: 1.4405 - val_accuracy: 0.8309\n",
      "Epoch 5/10\n",
      "5250/5250 [==============================] - 1s 268us/sample - loss: 0.0484 - accuracy: 0.9838 - val_loss: 1.0129 - val_accuracy: 0.8261\n",
      "Epoch 6/10\n",
      "5250/5250 [==============================] - 1s 270us/sample - loss: 0.0354 - accuracy: 0.9891 - val_loss: 1.2134 - val_accuracy: 0.8202\n",
      "Epoch 7/10\n",
      "5250/5250 [==============================] - 1s 270us/sample - loss: 0.0270 - accuracy: 0.9916 - val_loss: 1.1668 - val_accuracy: 0.8276\n",
      "Epoch 8/10\n",
      "5250/5250 [==============================] - 1s 273us/sample - loss: 0.0475 - accuracy: 0.9842 - val_loss: 1.1080 - val_accuracy: 0.8360\n",
      "Epoch 9/10\n",
      "5250/5250 [==============================] - 1s 270us/sample - loss: 0.0072 - accuracy: 0.9983 - val_loss: 1.2889 - val_accuracy: 0.8415\n",
      "Epoch 10/10\n",
      "5250/5250 [==============================] - 1s 269us/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.4343 - val_accuracy: 0.8491\n",
      "Train on 5500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 434us/sample - loss: 0.0694 - accuracy: 0.9867 - val_loss: 0.8623 - val_accuracy: 0.8411\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 261us/sample - loss: 0.0115 - accuracy: 0.9969 - val_loss: 1.2006 - val_accuracy: 0.8431\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 260us/sample - loss: 0.0047 - accuracy: 0.9991 - val_loss: 1.3429 - val_accuracy: 0.8413\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 2s 273us/sample - loss: 0.0135 - accuracy: 0.9958 - val_loss: 1.2799 - val_accuracy: 0.8202\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 269us/sample - loss: 0.0336 - accuracy: 0.9902 - val_loss: 1.0384 - val_accuracy: 0.8322\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 2s 273us/sample - loss: 0.0299 - accuracy: 0.9898 - val_loss: 1.1497 - val_accuracy: 0.8293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 265us/sample - loss: 0.0214 - accuracy: 0.9936 - val_loss: 1.2427 - val_accuracy: 0.8289\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 268us/sample - loss: 0.0210 - accuracy: 0.9951 - val_loss: 1.2454 - val_accuracy: 0.8376\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 266us/sample - loss: 0.0064 - accuracy: 0.9971 - val_loss: 1.6620 - val_accuracy: 0.8369\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 266us/sample - loss: 0.0224 - accuracy: 0.9931 - val_loss: 1.1396 - val_accuracy: 0.8289\n",
      "Train on 5750 samples, validate on 4250 samples\n",
      "Epoch 1/10\n",
      "5750/5750 [==============================] - 2s 421us/sample - loss: 0.0432 - accuracy: 0.9911 - val_loss: 1.0802 - val_accuracy: 0.8421\n",
      "Epoch 2/10\n",
      "5750/5750 [==============================] - 1s 251us/sample - loss: 0.0120 - accuracy: 0.9969 - val_loss: 1.1942 - val_accuracy: 0.8327\n",
      "Epoch 3/10\n",
      "5750/5750 [==============================] - 1s 249us/sample - loss: 0.0127 - accuracy: 0.9953 - val_loss: 1.3451 - val_accuracy: 0.8313\n",
      "Epoch 4/10\n",
      "5750/5750 [==============================] - 1s 254us/sample - loss: 0.0283 - accuracy: 0.9917 - val_loss: 1.4948 - val_accuracy: 0.8376\n",
      "Epoch 5/10\n",
      "5750/5750 [==============================] - 1s 253us/sample - loss: 0.0314 - accuracy: 0.9892 - val_loss: 1.1468 - val_accuracy: 0.8329\n",
      "Epoch 6/10\n",
      "5750/5750 [==============================] - 1s 255us/sample - loss: 0.0166 - accuracy: 0.9960 - val_loss: 1.1443 - val_accuracy: 0.8405\n",
      "Epoch 7/10\n",
      "5750/5750 [==============================] - 1s 253us/sample - loss: 0.0133 - accuracy: 0.9958 - val_loss: 1.2895 - val_accuracy: 0.8407\n",
      "Epoch 8/10\n",
      "5750/5750 [==============================] - 1s 255us/sample - loss: 0.0081 - accuracy: 0.9969 - val_loss: 1.5854 - val_accuracy: 0.8332\n",
      "Epoch 9/10\n",
      "5750/5750 [==============================] - 1s 250us/sample - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.5611 - val_accuracy: 0.8402\n",
      "Epoch 10/10\n",
      "5750/5750 [==============================] - 1s 260us/sample - loss: 0.0203 - accuracy: 0.9934 - val_loss: 1.2511 - val_accuracy: 0.8259\n",
      "Train on 6000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 404us/sample - loss: 0.0396 - accuracy: 0.9902 - val_loss: 1.0921 - val_accuracy: 0.8370\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 245us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 1.3340 - val_accuracy: 0.8450\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 248us/sample - loss: 6.7603e-04 - accuracy: 0.9998 - val_loss: 1.4004 - val_accuracy: 0.8435\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 247us/sample - loss: 0.0098 - accuracy: 0.9977 - val_loss: 1.4900 - val_accuracy: 0.8338\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 242us/sample - loss: 0.0490 - accuracy: 0.9853 - val_loss: 1.3235 - val_accuracy: 0.8217\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 244us/sample - loss: 0.0392 - accuracy: 0.9883 - val_loss: 1.1235 - val_accuracy: 0.8380\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 243us/sample - loss: 0.0214 - accuracy: 0.9935 - val_loss: 1.4606 - val_accuracy: 0.8332\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 244us/sample - loss: 0.0226 - accuracy: 0.9940 - val_loss: 1.2339 - val_accuracy: 0.8418\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 245us/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.3349 - val_accuracy: 0.8457\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 245us/sample - loss: 5.7076e-04 - accuracy: 1.0000 - val_loss: 1.3684 - val_accuracy: 0.8457\n",
      "Train on 6250 samples, validate on 3750 samples\n",
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 3s 403us/sample - loss: 0.0545 - accuracy: 0.9891 - val_loss: 0.9424 - val_accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 2s 247us/sample - loss: 0.0090 - accuracy: 0.9966 - val_loss: 1.1603 - val_accuracy: 0.8445\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 2s 245us/sample - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.2732 - val_accuracy: 0.8477\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 2s 245us/sample - loss: 0.0234 - accuracy: 0.9944 - val_loss: 1.3906 - val_accuracy: 0.8267\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 2s 246us/sample - loss: 0.0339 - accuracy: 0.9896 - val_loss: 1.3105 - val_accuracy: 0.8408\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 2s 242us/sample - loss: 0.0325 - accuracy: 0.9910 - val_loss: 1.3413 - val_accuracy: 0.8344\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 2s 247us/sample - loss: 0.0229 - accuracy: 0.9949 - val_loss: 1.3266 - val_accuracy: 0.8459\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 2s 245us/sample - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.4366 - val_accuracy: 0.8437\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 2s 246us/sample - loss: 0.0108 - accuracy: 0.9960 - val_loss: 1.2911 - val_accuracy: 0.8405\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 2s 246us/sample - loss: 0.0182 - accuracy: 0.9947 - val_loss: 1.3564 - val_accuracy: 0.8483\n",
      "Train on 6500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 3s 386us/sample - loss: 0.0514 - accuracy: 0.9900 - val_loss: 1.0240 - val_accuracy: 0.8429\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 2s 240us/sample - loss: 0.0133 - accuracy: 0.9963 - val_loss: 1.2948 - val_accuracy: 0.8454\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 2s 243us/sample - loss: 0.0039 - accuracy: 0.9988 - val_loss: 1.3263 - val_accuracy: 0.8426\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 2s 242us/sample - loss: 0.0304 - accuracy: 0.9909 - val_loss: 1.7290 - val_accuracy: 0.8277\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 2s 240us/sample - loss: 0.0410 - accuracy: 0.9865 - val_loss: 1.1775 - val_accuracy: 0.8449\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 2s 242us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 1.4516 - val_accuracy: 0.8511\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 2s 245us/sample - loss: 0.0239 - accuracy: 0.9935 - val_loss: 1.1390 - val_accuracy: 0.8423\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 2s 243us/sample - loss: 0.0110 - accuracy: 0.9968 - val_loss: 1.3429 - val_accuracy: 0.8489\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 2s 243us/sample - loss: 0.0054 - accuracy: 0.9978 - val_loss: 1.4841 - val_accuracy: 0.8517\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 2s 238us/sample - loss: 0.0148 - accuracy: 0.9948 - val_loss: 1.3908 - val_accuracy: 0.8394\n",
      "Train on 6750 samples, validate on 3250 samples\n",
      "Epoch 1/10\n",
      "6750/6750 [==============================] - 2s 368us/sample - loss: 0.0491 - accuracy: 0.9879 - val_loss: 1.2113 - val_accuracy: 0.8486\n",
      "Epoch 2/10\n",
      "6750/6750 [==============================] - 2s 239us/sample - loss: 0.0143 - accuracy: 0.9969 - val_loss: 1.2070 - val_accuracy: 0.8378\n",
      "Epoch 3/10\n",
      "6750/6750 [==============================] - 2s 237us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.3787 - val_accuracy: 0.8486\n",
      "Epoch 4/10\n",
      "6750/6750 [==============================] - 2s 235us/sample - loss: 0.0270 - accuracy: 0.9916 - val_loss: 1.3801 - val_accuracy: 0.8274\n",
      "Epoch 5/10\n",
      "6750/6750 [==============================] - 2s 231us/sample - loss: 0.0312 - accuracy: 0.9902 - val_loss: 1.3180 - val_accuracy: 0.8440\n",
      "Epoch 6/10\n",
      "6750/6750 [==============================] - 2s 236us/sample - loss: 0.0256 - accuracy: 0.9929 - val_loss: 1.2729 - val_accuracy: 0.8369\n",
      "Epoch 7/10\n",
      "6750/6750 [==============================] - 2s 232us/sample - loss: 0.0219 - accuracy: 0.9923 - val_loss: 1.4794 - val_accuracy: 0.8483\n",
      "Epoch 8/10\n",
      "6750/6750 [==============================] - 2s 239us/sample - loss: 0.0282 - accuracy: 0.9921 - val_loss: 1.1976 - val_accuracy: 0.8483\n",
      "Epoch 9/10\n",
      "6750/6750 [==============================] - 2s 238us/sample - loss: 0.0118 - accuracy: 0.9963 - val_loss: 1.5730 - val_accuracy: 0.8443\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750/6750 [==============================] - 2s 234us/sample - loss: 0.0105 - accuracy: 0.9979 - val_loss: 1.3958 - val_accuracy: 0.8397\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 3s 364us/sample - loss: 0.0437 - accuracy: 0.9903 - val_loss: 1.1465 - val_accuracy: 0.8363\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 223us/sample - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.4466 - val_accuracy: 0.8487\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 241us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.5341 - val_accuracy: 0.8530\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0272 - accuracy: 0.9927 - val_loss: 1.2703 - val_accuracy: 0.8323\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 228us/sample - loss: 0.0334 - accuracy: 0.9900 - val_loss: 1.3942 - val_accuracy: 0.8347\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 221us/sample - loss: 0.0227 - accuracy: 0.9934 - val_loss: 1.4219 - val_accuracy: 0.8437\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 221us/sample - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.4438 - val_accuracy: 0.8437\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 221us/sample - loss: 0.0069 - accuracy: 0.9976 - val_loss: 1.7411 - val_accuracy: 0.8443\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 220us/sample - loss: 0.0199 - accuracy: 0.9947 - val_loss: 1.5263 - val_accuracy: 0.8397\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 218us/sample - loss: 0.0304 - accuracy: 0.9939 - val_loss: 1.2558 - val_accuracy: 0.8460\n",
      "Train on 7250 samples, validate on 2750 samples\n",
      "Epoch 1/10\n",
      "7250/7250 [==============================] - 2s 342us/sample - loss: 0.0438 - accuracy: 0.9890 - val_loss: 1.0068 - val_accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "7250/7250 [==============================] - 2s 223us/sample - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.3602 - val_accuracy: 0.8458\n",
      "Epoch 3/10\n",
      "7250/7250 [==============================] - 2s 220us/sample - loss: 0.0113 - accuracy: 0.9971 - val_loss: 1.4929 - val_accuracy: 0.8498\n",
      "Epoch 4/10\n",
      "7250/7250 [==============================] - 2s 221us/sample - loss: 0.0110 - accuracy: 0.9972 - val_loss: 1.7673 - val_accuracy: 0.8462\n",
      "Epoch 5/10\n",
      "7250/7250 [==============================] - 2s 228us/sample - loss: 0.0257 - accuracy: 0.9916 - val_loss: 1.4504 - val_accuracy: 0.8396\n",
      "Epoch 6/10\n",
      "7250/7250 [==============================] - 2s 223us/sample - loss: 0.0542 - accuracy: 0.9844 - val_loss: 1.2151 - val_accuracy: 0.8418\n",
      "Epoch 7/10\n",
      "7250/7250 [==============================] - 2s 224us/sample - loss: 0.0074 - accuracy: 0.9979 - val_loss: 1.4540 - val_accuracy: 0.8451\n",
      "Epoch 8/10\n",
      "7250/7250 [==============================] - 2s 231us/sample - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.6870 - val_accuracy: 0.8447\n",
      "Epoch 9/10\n",
      "7250/7250 [==============================] - 2s 221us/sample - loss: 2.7201e-04 - accuracy: 1.0000 - val_loss: 1.7833 - val_accuracy: 0.8429\n",
      "Epoch 10/10\n",
      "7250/7250 [==============================] - 2s 222us/sample - loss: 5.8131e-05 - accuracy: 1.0000 - val_loss: 1.8247 - val_accuracy: 0.8436\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 3s 342us/sample - loss: 0.0534 - accuracy: 0.9923 - val_loss: 1.0082 - val_accuracy: 0.8400\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 2s 217us/sample - loss: 0.0192 - accuracy: 0.9953 - val_loss: 1.1933 - val_accuracy: 0.8420\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 2s 217us/sample - loss: 0.0100 - accuracy: 0.9976 - val_loss: 1.5142 - val_accuracy: 0.8392\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 2s 216us/sample - loss: 0.0357 - accuracy: 0.9901 - val_loss: 1.2525 - val_accuracy: 0.8392\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 2s 218us/sample - loss: 0.0080 - accuracy: 0.9979 - val_loss: 1.3384 - val_accuracy: 0.8464\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 2s 218us/sample - loss: 0.0088 - accuracy: 0.9975 - val_loss: 1.5485 - val_accuracy: 0.8424\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 2s 220us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.4464 - val_accuracy: 0.8480\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 2s 218us/sample - loss: 0.0138 - accuracy: 0.9960 - val_loss: 1.9403 - val_accuracy: 0.8416\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 2s 216us/sample - loss: 0.0473 - accuracy: 0.9864 - val_loss: 1.2913 - val_accuracy: 0.8448\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 2s 215us/sample - loss: 0.0336 - accuracy: 0.9896 - val_loss: 1.4121 - val_accuracy: 0.8464\n",
      "Train on 7750 samples, validate on 2250 samples\n",
      "Epoch 1/10\n",
      "7750/7750 [==============================] - 3s 327us/sample - loss: 0.0566 - accuracy: 0.9883 - val_loss: 1.1247 - val_accuracy: 0.8484\n",
      "Epoch 2/10\n",
      "7750/7750 [==============================] - 2s 209us/sample - loss: 0.0128 - accuracy: 0.9965 - val_loss: 1.0967 - val_accuracy: 0.8538\n",
      "Epoch 3/10\n",
      "7750/7750 [==============================] - 2s 210us/sample - loss: 0.0076 - accuracy: 0.9982 - val_loss: 1.2699 - val_accuracy: 0.8480\n",
      "Epoch 4/10\n",
      "7750/7750 [==============================] - 2s 209us/sample - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.7234 - val_accuracy: 0.8471\n",
      "Epoch 5/10\n",
      "7750/7750 [==============================] - 2s 208us/sample - loss: 0.0488 - accuracy: 0.9852 - val_loss: 1.0302 - val_accuracy: 0.8391\n",
      "Epoch 6/10\n",
      "7750/7750 [==============================] - 2s 211us/sample - loss: 0.0204 - accuracy: 0.9945 - val_loss: 1.2957 - val_accuracy: 0.8502\n",
      "Epoch 7/10\n",
      "7750/7750 [==============================] - 2s 212us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.5786 - val_accuracy: 0.8511\n",
      "Epoch 8/10\n",
      "7750/7750 [==============================] - 2s 208us/sample - loss: 1.6379e-04 - accuracy: 1.0000 - val_loss: 1.6361 - val_accuracy: 0.8480\n",
      "Epoch 9/10\n",
      "7750/7750 [==============================] - 2s 209us/sample - loss: 4.9013e-05 - accuracy: 1.0000 - val_loss: 1.6702 - val_accuracy: 0.8484\n",
      "Epoch 10/10\n",
      "7750/7750 [==============================] - 2s 212us/sample - loss: 3.5083e-05 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.8489\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 305us/sample - loss: 0.0509 - accuracy: 0.9911 - val_loss: 1.0048 - val_accuracy: 0.8485\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 196us/sample - loss: 0.0158 - accuracy: 0.9959 - val_loss: 1.2928 - val_accuracy: 0.8475\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 192us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 1.4691 - val_accuracy: 0.8380\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 193us/sample - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.5152 - val_accuracy: 0.8450\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 192us/sample - loss: 2.2656e-04 - accuracy: 1.0000 - val_loss: 1.6238 - val_accuracy: 0.8495\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 192us/sample - loss: 5.6243e-05 - accuracy: 1.0000 - val_loss: 1.6746 - val_accuracy: 0.8505\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 192us/sample - loss: 3.5320e-05 - accuracy: 1.0000 - val_loss: 1.7166 - val_accuracy: 0.8510\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 195us/sample - loss: 2.5037e-05 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.8510\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 193us/sample - loss: 1.8719e-05 - accuracy: 1.0000 - val_loss: 1.7879 - val_accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2s 195us/sample - loss: 1.4444e-05 - accuracy: 1.0000 - val_loss: 1.8185 - val_accuracy: 0.8495\n",
      "Train on 8250 samples, validate on 1750 samples\n",
      "Epoch 1/10\n",
      "8250/8250 [==============================] - 3s 316us/sample - loss: 0.0366 - accuracy: 0.9936 - val_loss: 1.0454 - val_accuracy: 0.8326\n",
      "Epoch 2/10\n",
      "8250/8250 [==============================] - 2s 204us/sample - loss: 0.0103 - accuracy: 0.9970 - val_loss: 1.3862 - val_accuracy: 0.8474\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8250/8250 [==============================] - 2s 200us/sample - loss: 0.0272 - accuracy: 0.9914 - val_loss: 1.2635 - val_accuracy: 0.8383\n",
      "Epoch 4/10\n",
      "8250/8250 [==============================] - 2s 201us/sample - loss: 0.0221 - accuracy: 0.9936 - val_loss: 1.4035 - val_accuracy: 0.8406\n",
      "Epoch 5/10\n",
      "8250/8250 [==============================] - 2s 202us/sample - loss: 0.0207 - accuracy: 0.9938 - val_loss: 1.2532 - val_accuracy: 0.8394\n",
      "Epoch 6/10\n",
      "8250/8250 [==============================] - 2s 202us/sample - loss: 0.0068 - accuracy: 0.9973 - val_loss: 1.3872 - val_accuracy: 0.8463\n",
      "Epoch 7/10\n",
      "8250/8250 [==============================] - 2s 205us/sample - loss: 0.0372 - accuracy: 0.9909 - val_loss: 1.2304 - val_accuracy: 0.8463\n",
      "Epoch 8/10\n",
      "8250/8250 [==============================] - 2s 202us/sample - loss: 0.0117 - accuracy: 0.9962 - val_loss: 1.5214 - val_accuracy: 0.8451\n",
      "Epoch 9/10\n",
      "8250/8250 [==============================] - 2s 205us/sample - loss: 0.0088 - accuracy: 0.9973 - val_loss: 1.4662 - val_accuracy: 0.8411\n",
      "Epoch 10/10\n",
      "8250/8250 [==============================] - 2s 205us/sample - loss: 0.0027 - accuracy: 0.9993 - val_loss: 1.7661 - val_accuracy: 0.8480\n",
      "Train on 8500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 3s 311us/sample - loss: 0.0458 - accuracy: 0.9912 - val_loss: 1.0577 - val_accuracy: 0.8473\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 208us/sample - loss: 0.0131 - accuracy: 0.9966 - val_loss: 1.3104 - val_accuracy: 0.8407\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 212us/sample - loss: 0.0252 - accuracy: 0.9922 - val_loss: 1.2699 - val_accuracy: 0.8433\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 208us/sample - loss: 0.0351 - accuracy: 0.9895 - val_loss: 1.2436 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 207us/sample - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.2900 - val_accuracy: 0.8587\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 209us/sample - loss: 0.0162 - accuracy: 0.9956 - val_loss: 1.3115 - val_accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 211us/sample - loss: 0.0124 - accuracy: 0.9962 - val_loss: 1.6375 - val_accuracy: 0.8467\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 207us/sample - loss: 0.0268 - accuracy: 0.9929 - val_loss: 1.4046 - val_accuracy: 0.8527\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 210us/sample - loss: 0.0262 - accuracy: 0.9919 - val_loss: 1.2432 - val_accuracy: 0.8440\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 207us/sample - loss: 0.0423 - accuracy: 0.9872 - val_loss: 1.2427 - val_accuracy: 0.8580\n",
      "Train on 8750 samples, validate on 1250 samples\n",
      "Epoch 1/10\n",
      "8750/8750 [==============================] - 3s 303us/sample - loss: 0.0355 - accuracy: 0.9904 - val_loss: 1.3329 - val_accuracy: 0.8432\n",
      "Epoch 2/10\n",
      "8750/8750 [==============================] - 2s 207us/sample - loss: 0.0144 - accuracy: 0.9955 - val_loss: 1.4386 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "8750/8750 [==============================] - 2s 208us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.6923 - val_accuracy: 0.8544\n",
      "Epoch 4/10\n",
      "8750/8750 [==============================] - 2s 204us/sample - loss: 0.0080 - accuracy: 0.9978 - val_loss: 1.5368 - val_accuracy: 0.8360\n",
      "Epoch 5/10\n",
      "8750/8750 [==============================] - 2s 204us/sample - loss: 0.0335 - accuracy: 0.9886 - val_loss: 1.5790 - val_accuracy: 0.8416\n",
      "Epoch 6/10\n",
      "8750/8750 [==============================] - 2s 201us/sample - loss: 0.0383 - accuracy: 0.9893 - val_loss: 1.3612 - val_accuracy: 0.8440\n",
      "Epoch 7/10\n",
      "8750/8750 [==============================] - 2s 202us/sample - loss: 0.0272 - accuracy: 0.9912 - val_loss: 1.6031 - val_accuracy: 0.8496\n",
      "Epoch 8/10\n",
      "8750/8750 [==============================] - 2s 200us/sample - loss: 0.0197 - accuracy: 0.9949 - val_loss: 1.4035 - val_accuracy: 0.8520\n",
      "Epoch 9/10\n",
      "8750/8750 [==============================] - 2s 199us/sample - loss: 0.0124 - accuracy: 0.9965 - val_loss: 1.5185 - val_accuracy: 0.8632\n",
      "Epoch 10/10\n",
      "8750/8750 [==============================] - 2s 203us/sample - loss: 0.0258 - accuracy: 0.9923 - val_loss: 1.6186 - val_accuracy: 0.8368\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 376us/sample - loss: 0.0490 - accuracy: 0.9900 - val_loss: 1.2544 - val_accuracy: 0.8480\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 222us/sample - loss: 0.0150 - accuracy: 0.9953 - val_loss: 1.3180 - val_accuracy: 0.8390\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 222us/sample - loss: 0.0248 - accuracy: 0.9928 - val_loss: 1.3365 - val_accuracy: 0.8390\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 232us/sample - loss: 0.0168 - accuracy: 0.9943 - val_loss: 1.2910 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 252us/sample - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.1425 - val_accuracy: 0.8290\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 250us/sample - loss: 0.0340 - accuracy: 0.9913 - val_loss: 1.0564 - val_accuracy: 0.8540\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 201us/sample - loss: 0.0286 - accuracy: 0.9909 - val_loss: 1.2847 - val_accuracy: 0.8510\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 246us/sample - loss: 0.0056 - accuracy: 0.9983 - val_loss: 1.4308 - val_accuracy: 0.8610\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 4s 429us/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.6290 - val_accuracy: 0.8610\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 6s 635us/sample - loss: 0.0157 - accuracy: 0.9947 - val_loss: 1.5668 - val_accuracy: 0.8570\n",
      "Train on 9250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "9250/9250 [==============================] - 5s 542us/sample - loss: 0.0547 - accuracy: 0.9891 - val_loss: 1.1062 - val_accuracy: 0.8467\n",
      "Epoch 2/10\n",
      "9250/9250 [==============================] - 3s 356us/sample - loss: 0.0132 - accuracy: 0.9955 - val_loss: 1.3426 - val_accuracy: 0.8547\n",
      "Epoch 3/10\n",
      "9250/9250 [==============================] - 4s 457us/sample - loss: 0.0100 - accuracy: 0.9973 - val_loss: 1.5369 - val_accuracy: 0.8533\n",
      "Epoch 4/10\n",
      "9250/9250 [==============================] - 3s 354us/sample - loss: 0.0028 - accuracy: 0.9990 - val_loss: 1.5602 - val_accuracy: 0.8587\n",
      "Epoch 5/10\n",
      "9250/9250 [==============================] - 4s 458us/sample - loss: 0.0171 - accuracy: 0.9955 - val_loss: 1.5487 - val_accuracy: 0.8507\n",
      "Epoch 6/10\n",
      "9250/9250 [==============================] - 3s 334us/sample - loss: 0.0365 - accuracy: 0.9896 - val_loss: 1.1528 - val_accuracy: 0.8533\n",
      "Epoch 7/10\n",
      "9250/9250 [==============================] - 3s 319us/sample - loss: 0.0472 - accuracy: 0.9862 - val_loss: 1.4290 - val_accuracy: 0.8413\n",
      "Epoch 8/10\n",
      "9250/9250 [==============================] - 4s 402us/sample - loss: 0.0166 - accuracy: 0.9951 - val_loss: 1.3873 - val_accuracy: 0.8453\n",
      "Epoch 9/10\n",
      "9250/9250 [==============================] - 4s 434us/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.7654 - val_accuracy: 0.8587\n",
      "Epoch 10/10\n",
      "9250/9250 [==============================] - 3s 331us/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 1.8281 - val_accuracy: 0.8520\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 8s 804us/sample - loss: 0.0397 - accuracy: 0.9923 - val_loss: 1.3176 - val_accuracy: 0.8580\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 7s 789us/sample - loss: 0.0245 - accuracy: 0.9928 - val_loss: 1.5010 - val_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 4s 390us/sample - loss: 0.0137 - accuracy: 0.9968 - val_loss: 1.3015 - val_accuracy: 0.8680\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 3s 313us/sample - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.6330 - val_accuracy: 0.8660\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 3s 311us/sample - loss: 0.0200 - accuracy: 0.9946 - val_loss: 2.0247 - val_accuracy: 0.8640\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 4s 395us/sample - loss: 0.0271 - accuracy: 0.9936 - val_loss: 1.3106 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 3s 298us/sample - loss: 0.0249 - accuracy: 0.9937 - val_loss: 1.4849 - val_accuracy: 0.8460\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 3s 351us/sample - loss: 0.0221 - accuracy: 0.9940 - val_loss: 1.6357 - val_accuracy: 0.8700\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 3s 293us/sample - loss: 0.0111 - accuracy: 0.9966 - val_loss: 1.7545 - val_accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 3s 298us/sample - loss: 0.0268 - accuracy: 0.9921 - val_loss: 1.6980 - val_accuracy: 0.8560\n",
      "Train on 9750 samples, validate on 250 samples\n",
      "Epoch 1/10\n",
      "9750/9750 [==============================] - 4s 453us/sample - loss: 0.0376 - accuracy: 0.9923 - val_loss: 1.1963 - val_accuracy: 0.8720\n",
      "Epoch 2/10\n",
      "9750/9750 [==============================] - 4s 367us/sample - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.4981 - val_accuracy: 0.8760\n",
      "Epoch 3/10\n",
      "9750/9750 [==============================] - 4s 401us/sample - loss: 0.0122 - accuracy: 0.9961 - val_loss: 1.7370 - val_accuracy: 0.8600\n",
      "Epoch 4/10\n",
      "9750/9750 [==============================] - 5s 504us/sample - loss: 0.0356 - accuracy: 0.9909 - val_loss: 1.4281 - val_accuracy: 0.8520\n",
      "Epoch 5/10\n",
      "9750/9750 [==============================] - 4s 372us/sample - loss: 0.0116 - accuracy: 0.9965 - val_loss: 1.3129 - val_accuracy: 0.8480\n",
      "Epoch 6/10\n",
      "9750/9750 [==============================] - 5s 506us/sample - loss: 0.0132 - accuracy: 0.9962 - val_loss: 1.6561 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "9750/9750 [==============================] - 3s 326us/sample - loss: 0.0070 - accuracy: 0.9972 - val_loss: 1.8440 - val_accuracy: 0.8480\n",
      "Epoch 8/10\n",
      "9750/9750 [==============================] - 2s 193us/sample - loss: 0.0288 - accuracy: 0.9920 - val_loss: 1.4616 - val_accuracy: 0.8600\n",
      "Epoch 9/10\n",
      "9750/9750 [==============================] - 2s 175us/sample - loss: 0.0155 - accuracy: 0.9953 - val_loss: 1.4848 - val_accuracy: 0.8800\n",
      "Epoch 10/10\n",
      "9750/9750 [==============================] - 2s 195us/sample - loss: 0.0021 - accuracy: 0.9991 - val_loss: 1.6383 - val_accuracy: 0.8720\n"
     ]
    }
   ],
   "source": [
    "def number_of_params(layers):\n",
    "    Sequential(layers).summary()\n",
    "    return Sequential(layers).count_params()\n",
    "\n",
    "def evaluate_cnn(layers, ratio, epochs):\n",
    "    train_samples = int(10000 * ratio)\n",
    "    test_samples = 10000 - train_samples\n",
    "    X_train, y_train = resample(X_train_org, y_train_org, random_state=0, n_samples=train_samples)\n",
    "    X_test, y_test = resample(X_test_org, y_test_org, random_state=0, n_samples=test_samples)\n",
    "\n",
    "    clear_session()\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "    return accuracy\n",
    "\n",
    "def gen_3a_cnn(layers, name):\n",
    "    for ratio in np.arange(0.025, 1.0, 0.025):\n",
    "        accuracy = evaluate_cnn(layers, ratio, 10)\n",
    "        yield ratio, accuracy, name\n",
    "\n",
    "\n",
    "model1 = [\n",
    "    Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "model2 = [\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "model5 = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "model10 = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "results_3a_1  = pd.DataFrame(gen_3a_cnn(model1,  'CNN 1'))\n",
    "results_3a_2  = pd.DataFrame(gen_3a_cnn(model2,  'CNN 2'))\n",
    "results_3a_5  = pd.DataFrame(gen_3a_cnn(model5,  'CNN 5'))\n",
    "results_3a_10 = pd.DataFrame(gen_3a_cnn(model10, 'CNN 10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 427.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 427.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAFgCAYAAACL5B9mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABkEElEQVR4nO3deXhU9b348fc5Z/bsmcliCGvYIYgQQCGUIhFtURqXWrWt19pbaa2/trbXX7H1sfpYe63acrXVW9sfhdreVu31li7eKkaRVWXRyKpsgkBC9j2Z9ZzfHyeZZMg2gWQywOf1PD4wZ5vPRJ1PvtvnqxiGYSCEEELEiDrcAQghhLi4SOIRQggRU5J4hBBCxJQkHiGEEDEliUcIIURMWYY7gOFQVlbW4/H09HRqa2tjHI3EEM9xSAzxFUc8xNBXHDk5OcMQzflHWjxdqOrw/zgkhk7xEIfE0Cke4oiHGCB+4jhfyU9PCCFETEniEUIIEVOSeIQQQsSUJB4hhBAxJYlHCCFETEniEUIIEVOSeIQQQsSUJB4hhBAxJYlHCCFETEniEUIIEVOSeIQQQsSUJB4hhBAxJYlHCCFETEniEUIIEVOSeIQQQsSUJB4hhBAxFbMdSEtLS1mzZg26rrNkyRKKi4sjzjc3N/Of//mfVFRUYLVa+cY3vsGoUaP6vLe5uZlVq1ZRVVVFRkYG9957L4mJibH6SEIIIc5CTFo8uq6zevVqfvCDH7Bq1Sq2bt3KyZMnI675y1/+wpgxY3jyySe55557WLt2bb/3rlu3jvz8fJ5++mny8/NZt25dLD6OEEKIcxCTxHP48GGys7PJysrCYrEwf/58duzYEXHNyZMnyc/PB2DEiBFUVVVRX1/f5707duxg0aJFACxatKjbM4UQQsSfmHS11dbW4na7w6/dbjeHDh2KuGb06NG8++67TJ48mcOHD1NVVUVtbW2f9zY0NJCWlgZAWloajY2NPb5/SUkJJSUlADz22GN4PJ4er7NYLL2eixWJIb7ikBjiK454iCGe4jhfxSTxGIbR7ZiiKBGvi4uLWbt2Lffddx+jRo1i7NixqKoa1b39KSoqoqioKPy6urq6x+s8Hk+v52JFYoivOCSG+IojHmLoK46cnJxhiOb8E5PE43a7qampCb+uqakJt1Q6uFwu7r77bsBMVPfccw+ZmZn4/f5e701JSaGuro60tDTq6upITk6OwacRQghxLmIyxpOXl0d5eTmVlZUEg0G2bdtGQUFBxDUtLS0Eg0EA3njjDaZMmYLL5erz3oKCAjZu3AjAxo0bmTNnTiw+jhBCRPAGdSqbA8MdxnkjJi0eTdO48847efTRR9F1ncWLFzNy5EjWr18PwNKlSzl16hS//OUvUVWV3Nxcvv71r/d5L5jdc6tWreLNN9/E4/Hw3e9+NxYfRwghAPCHdBp9IXzB7kMConeK0dMgygWurKysx+Px0H8sMcRXHBJDfMURDzEAJKWmc6ysAu8ZCWfO5DHDE9B5JmYLSIUQ4nzX0cJp1Xzdko6IniQeIYToRyBk0OgLhpONa5jjOd9J4hFCiF6EdIMmf4hWv460bwaPJB4hhDiDYRg0+3Wa/SF0yTiDThKPEEK0MwyDloBOsy9ESBLOkJHEI4S46BmGQWvAbOEE9eGO5sIniUcIcVFrDYRo8knCiSVJPEKIi1JbQKfRF5SEMwwk8QghLireoE6TL4RfBnGGjSQeIcRFQcrbxA9JPEKIC9qZiz/F8JPEI4S4IAVC5uLPtoAM4sQbSTxCiAtKUDdo8oVolYQTtyTxCCEuCCHdoNkfouUsy9vsq2jh9SMNVLcG8bgsXJWXwrSshEGPU8RoIzghhBgqhmHQ7AtR2RKg+RySzgt7a6j3hnBZFeq9IV7YW8O+ipZBj1dI4hFCnMe8QZ3KlgANvnOrqfb6kQY0RcFuUVDa/9QUhdePNAxesCJMEo8Q4rzjC+pUtQSoaR2cBaDVrUFsWuQxm2Yej0Z5k5+X9g7/BnXnCxnjEUKcN/xBnZrWwKBPjfa4LNR7Q9i7fCP6Q+bx3gRCBqWnW9h8rJHDtd5BjedCJ4lHCBH3OqZGD9XOn1flpfDC3hp8QbOl4w9ByDC4Ki+l27VVLQH+efQkGw5V0ezvbG55HNKBFC1JPEKIuHXm1GjHEL3PtKwEboFeZ7WFdIM9Fa1sPt7Igaq28H2qAjPcVgozNCalSOKJliQeIUTc6Ug4bYHY7fw5LSuh2/Tp2rYg2z5pZOsnTTR4Q+Hj6U4L8zM0rshQSbVJwhkoSTxCiLgRD1tN64bB/so2Nh9vZG9FazgOBZjqtlGYoTB/ZBrNzU3DFOH5TxKPEGLY6e1bTbcM41bTDd4gb59oYsvxJmrbOmezJdlUrsiyUehRcLeP42iqMjxBXiAk8Qghho1uGLT4dd450cT6w/UxrxpgGAYHa7xsPtZI6emWiKQ3Mc3GwkyVGakqFkk0g0oSjxBiWDT7zZ0/95w2qwZoihJRNeAWGLLk0+wP8e6JJjYfb6KyJRA+nmBVuTzbxgK3QpZTxm6GiiQeIURM+UM69W0hAu3Ni65VAwDsFvAFzeODmXgMw+BonY/Nxxt5r6yFYJfmTV6qlcIsK5elglVaN0NOEo8QF7Fdp5r5y4FaKpoDZCVauX5KOrNHJA7Je4V0g8YeqkZXtwZxWSO/7AdSNaA/bQGd7aea2HysibImf/i4w6IwN8tBYYbCCKckm1iSxCPERWrXqWae21mBRVVItKnUtgV5bmcFK2BQk49umFOje6safTZVA6LxSb3Zutlxqjlim+tRyVYKs63MTgWHJglnOEjiEeIC1leL5i8HarGoCg6LOZbhsCh4gzp/OVA7KInHaJ840NTPTLWBVA3ojy+os7Osmc3HmvikwRc+btMUCrIdFGZojHb2HIzx8SHYtQUa6yA5DWYXooydMOAYRP9ilnhKS0tZs2YNuq6zZMkSiouLI863trby9NNPU1NTQygU4rrrrmPx4sWUlZWxatWq8HWVlZXcfPPNLFu2jJdeeok33niD5ORkAG699VZmzZoVq48kRFzrr0VT0Rwg8YzFj3ZNoaI50PMDB6A1YE4ciKaAZ39VA6JR1uhn8/FG3j3ZFFFSJyfJSmGOnbmp4FQN6GV1kPHxIdjwCmga2F3Q0gwbXsFgWdTJx1JVFnW8F7uYJB5d11m9ejUPPPAAbreb+++/n4KCAnJzc8PXvPrqq+Tm5rJy5UoaGxv59re/zcKFC8nJyeGJJ54IP2fFihXMnTs3fN+yZctYvnx5LD6GEOeV/lo0WYlWatuCOCyd3U2+kEFWovWs39MX1Gn0hSK6tqLRU9WA/gRCOu+Xm0U6j9R1tm4sqsJl2U4KMy3kOYIoShSx7NpiJh2rzXxttQF+83gfiUerq8K5fxeO/TuxVpfD9dcP6DNcrGKSeA4fPkx2djZZWVkAzJ8/nx07dkQkHkVR8Hq9GIaB1+slMTERVY38bWzPnj1kZ2eTkZERi7CFOK/116K5fko6z+2swBvUsWsKvpBBUDe4fkr6gN8rEDJo9AWHpIDnmSqbA2w+3sg7J5po6TJRIcWuYVMNAiGdhmYvvmQLirMzifbZldZYZ7Z0urJYzeNnUJvqsezehvu9LdjKjw/JZ7zQxSTx1NbW4na7w6/dbjeHDh2KuOaaa67h8ccfZ8WKFbS1tXHvvfd2Szxbt25lwYIFEcdee+01Nm3axLhx47j99ttJTOzeN11SUkJJSQkAjz32GB6Pp8c4LRZLr+diRWKIrzjO5xhy08qpafHjsHRuNOMNhMhNc+DxeLja4yE5JZk/7jpFeaOXS5Kd3DZ7BFeMiUw8bx+rbb/mGJck2yOuCekGjd4Abb4QThs4z+2j9iqoG+w6Uc8bOw+xp7wxfFxToGBkKmOSLLxxpBarqpBgsdAcMvjz8SAuVwIzMxz4Dx2gbeM/zVaNKwnaWmHjP3G6XNgmTKEpPQO9qRHFZg8/2/D7UNMzSEpOhtZmtL07sHzwNurHH6IYnQlWT0pFnzEPy6z5Q/TpLzwxSTyG0f23IEWJnE3ywQcfMHr0aB588EEqKip45JFHmDx5Mi6X+VtIMBhk165d3HbbbeF7li5dyk033QTAiy++yPPPP8/dd9/d7b2KioooKioKv66u7nnDJo/H0+u5WJEY4iuO8zmGa8cn8dzOCoKhUESL5trx7vDzJiTCjxZd0uUuPeK9uo4TJdmtVDS28cQbh7hrdiaTMlw0D3GJm5rWAFs/aWLbJ000+iKLdC4YmcAVHpUUw89T+xpR0dFQCOmgAUHD4G+HGxhr92NsXg+KApoFdD38Z+vm9bRljcC49HJzTEfXzZZOMIASCGDLTUVd/VPsRw+g6J3vbzgT8E6aiZ5fgG3sBOxWrYfoRW9iknjcbjc1NTXh1zU1NaSlpUVcs2HDBoqLi1EUhezsbDIzMykrK2P8+PEAvP/++4wdO5bU1NTwPV3/vmTJEn76058O6ecQ4nwye0QiK+Cc1ul0HSdSFPPP1kCIl/bW8O359v4fcBZ0w2BfZSubjzWxrzKySOdluSnMy9CYmqijBgPhuQLVXp0zZ1/bVPM40G9XmjJ2AgbLYMcmHNVlOEM+7G1NqFVHOuOy2ghMnIExvQDP3AVorc2D/+EvEjFJPHl5eZSXl1NZWUl6ejrbtm3jW9/6VsQ1Ho+HPXv2MGXKFOrr6ykrKyMzMzN8vqdutrq6unAC2759OyNHjhz6DyPEeWT2iMRzmhrdMU5kGAYh3Rw/0RSoGqTFnV3Ve4Ns+6SJrccbqeuyBUGKXeOKkYksyLYyLtlBfV0dnPH2HodKvV/H3qXh4de7bM6WnMY+I5mS9EupsSTiDjZTVPsB0+yNoOvYjh/EuX8njlMHUL2d++0YmoXQ+KmQX4Blcj5Ou7kjkN1upbV10H8EF42YJB5N07jzzjt59NFH0XWdxYsXM3LkSNavXw+YXWY33ngjzz77LN/73vcA+OIXvxieJu3z+di9ezd33XVXxHP/8Ic/cOzYMRRFISMjo9t5IcS5yUywUNMWxKoqaIqBQffFnfsqWs56KrRuGHxU3cbmY43srmiN6LabkuGkcKSL/CTQAl4IBTFCPc+4K8qx8OJRPz4MbKqZdEK6eRxg3/QlvFRhQTNCuAwfDaqNnc6RTGrZy4hf/gCtpXOLA0NR0MdMQp1RgDrtMjSnq8f3FGdPMXoagLnAlZX1PN/+fO7Pv9BiiJc4LtYYQrpBS0Dn3RNN/GlPtVnA02ah1R8kZBjcMt3NtKwE9lV0Fvjsuviz43xvmnwh3jnRxJbjjRGtp0SbyhUjk1iQ4yBD8UPAH3FfSnIyDY2NZz4OgH11AUrKglR7dTwOlaIcC9PSzET11L426pvaGFv7MbMq9zKr9iPcvoaI+43csaiXzoHps1ESk/v8+aSlpVFX133G24hZc/q8T5ikcoEQcaqj6kB128d4nFqP4zODXWvNaN8Xp2PSwNRMF7dMd/P6kQbqvEHSHFpEi2YgBT4Nw+BIrZfNx5t4v7w5YnHp+HQHhaMSmZmuYvV7ITjw8ZNpadZwoulKq6ti3v63ufx0KZc0V0ScO5F4CaOumAf5Bahp7m73iqEhiUeIOHTmbLLatkC3OmqDXWutt2oDHYs7e/otP5oCn62BEO+eaGbz8UZOd6mK4LSozBuZSGFuApdYg+Btg7aeO2A6WjO1/jbSbUS0ZnqiNtXjPPAejv07sZUfp+uyzmqXm9IRl/Fu9kz8nkt4ZJZ0pcWaJB4h4lBPs8nOrKM2WLXWzrbaAPRe4NPt1DhW52Xz8UZ2nmoJb4EAMCbVzsLRyczKsGDzeyHQ2G2yQFf76gK8eNSPpkKi1UK9P8iLR/18YRwRyUdpbcbxUSnO/TuxfXIYpUt5HH9CCps8M3h/xGVUpOXiMxSCOtw16uyrNIRZrWCzm/+IqEjiESIORVNH7VxrrQVCZsI5l2oDZxb49AYN2oI6umHw+JbOsVS7pjAnN5HCkYmMdOhm66YlumlhJWVBNNV8hqIo5pokDErKgkxPCGE/uBvn/l3YP96PondprjkTYNplKDPmYB89HndtiOZPAjS36WQ5VYpHWZntOYvEo2korgRzKrfNjqLKGp6BksQjxDDpa3wmmjpqZ1trLaib2xScuS/O2ego8PmPj+o43RwgoBvoBrT4zWePSLaxcHQyBVl2nCEv+BqhZWDvceYaHS0UZHblAWaeKiXrfw+gBLskWpsdJl+KMqMA8qagWDpvnO1Rzy7RqApY21s0djuKxYqW5kY5ixaiMEniEWIY9Dc+07WOWoJm4A3q3eqoDbTWWiBk0OI3E85gfGX6QzrvlbWw+Xgjxxs6Z59ZVYXZOQkUjk5ijMtA8Xmhpa2PJ/XN41Bp9AaYXn+UgvIPyC/fjTPo7bxAs8DEaeDJhk+OwCeHMZrqQVFRJk4b+Bsqilkk1GYzk43VFq60ou/Zhf7a/1BVV42e5kG5+gbU/Nln/dkuVpJ4hBgG/Y3PdK06UN0WxOO0dJuxFm1lAl/QnKU2WAU8Tzf52fJJE++caIpoNWUlWlk4Opl5I5y4dD+0NUPzObSqDAPrqY/55tHtpBx8n2R/50w3HYXmURNJmT0XpszEOPEx/OMFsxabMwGaGuAfL6Bfewtqf8lHUSLHabokmq70Pbsw/vgcWCzmdOuGOow/Pod+24pw8tl2tJr544a/zmG8k8QjxDCIZnymIwH1tY6nr8oEbQEz4ZzNpIEzBXWDtz+u5Z/7yzlU09na0BSYeUkCC0cnMz5FRfF6oan7+paoGQaWylM49+/EdWAXakNtxOkjSbkcSB/PqPwpzJw3o/O2LevNpNMxwG+zg98HW9abraEzdU00NnuPiaZbaK/9D1gsYHeY19sdgNc8nj+bXaeaWf1+NevuksTTH0k8QgyDodgLB8y1Mq3tCSeaTdj6U90aYMvxJt7+pIkmf2cZG7fLwsLRyVyem0gSAXOyQMPZbyCn1Vbi2r8L54GdaNWnI0+mecDbCg4XExKs5LUcgK170dO0ztZMXbXZ0unKajOPgzlOY3OYycJ+lhMCqisgISnymM1uHsdseVo1tYcbxZkk8QgxDAZzLxwwS880+3VaBqFadEg32FPRypbjjRyoaguPB6kK5Ge5WDg6mUnpFlSfD1pq4SyLn2hN9SR+uAv7/p1oZZ9EnkzPgBlzUPILMP7xAjRpnS2TnlozaR6ze63rlOZgANxZkO7ptftsQDxZ0FDX3tJp5/eZxzFbsekJMqU6GpJ4hBgGg1E5GgY34dS3BdnySSPbPmmivkuRzlSHxoJRyXwmfwRKUw14vVDf1MeTeqe2NpN08H0c+3ehfHI4Yl8bNM2sGO3OhCuvQ500HQCjv9YMQOFSc4wnEAC73fzTAGXZzRF77JwL5eobzDEevBhaAvi8EAyiXH0DYLZiG5ukYnU0JPEIMUzOpXJ0IKTTEtBpC+jnlHB0w+BAVRtbjjeyp0uRTgWYmulk4ehkprrtaAEvKW31NDT1XCetL4rfS8Lh3bj27UQ9eiByrY0rAUaMgfKTZsLoaM288iK6ophdaT21ZgJ+87imgcOJOm8Remo6rP+L2fXlyRr0GWdq/mz021ZgvPY/ZjI8Y1bb55y1/OaEt5+nCJDEI8R5wzDMxZktfv2cJww0+UK8faKJzccbqelS3ibJpjF/VBLzRyXisbQv9Gxo/y3eEv24iBIMkHh0H44Du9AO7UEJnLHWZsqlKDPmQN4UjN89DQ5H7xMDOlozfh+GQzOTjm7AZ29GycgOP1abUQAzCs7p59IfNX825M/uccLHrLf/zAojFbhhSGO4EEjiEWKIDFYBz5Bu0OgL0eoPcS75xjAMDtWYZWxKy1sinjXR7aBwdDKXZtqx+H3ga4C2gc1OsBohXJ8cxLF/J+qHH5hJq4PFAhOmmws7J+aj2GydcfXTlaZOzke32WDjqxgNtZCeEZ/rZ6orKEg9+wkWFxNJPEIMgcEo4OkLtnenNXhp6rLt80C1+EO8e7KZzccaqWjp/GJ0WVUuz02kcHQyWbaO1s3Aygqohk7i6Y9x7t+Fuu896LKvDaoK4yah5M+BqTNRHM6eH9LbxABPFrgzUKw2tMxL4PJPx8U2Fb3yZGG0nN3Y18VGEo+4KJ1ra6S/+8+lgGdrIESzTw8X1nT0eXXPDMPg4zofm/Z8wvsNCgGls5tsbJpZpPOyLAe2kA/aGsAXfetGMQwSqk/i3L8Ly75dcMZaG0blmS2babP63dcGOGNigMPsSjNA+ezNKFZb//fHCeXqG+Cl/zfcYZwXJPGIi865tkaiuX+gBTw7xm962pagL/rBvbB5PdTVQJqbtvlL2eUcxebjjZxq9AMWUMChB5jTdITCugOMGHclSrILGmv7fX5E/LUVeHa8hXXvjvDalTCb3WzheLJh0WeiK1VjNUvSqJcvwkhzmwsxh2hiQCyo+bNJc5/ddPiLjSQecdE51+0Eork/2gWiQd2g1R+i5Sxmp+kH98LfXwDNwomUEWyxj2PHQSt+tbMrKtdXQ2HLUQpaj+MI+cHvhc2vwU1fieo9bE11JH70HrZ9O1HKPiFieoE7E0aMhmOHwqVm8Lb2WKpGP7gPtrwO9TXgyYSrb0S7tHO3TqV90D7e9bc5n7NgwTBGd/6QxCMuOue6nUA09/e3QHQw6qf5N7/BrtRJbEmZzHF75+6ZViNIwahUCrf8F6NoMdfKdKyXsVihse+SNnZvMwkfvW8mm0+ORC4QTU6F/AKU/ALIGYWx5j8i96I5c0aa1YZ+9CP43z+bZWqSUqCpEV74Dbqqnletmmg25xPRkcQjLjrnWq4mmvt7WiBaPDmNKZlOqloC5zQduqzJz5bjjbzrXkqb1jkgnx1oYGHzYeZU7SPhqv+L8a4fmr1mS6RDMADJad2eaQ+0kXBot5lsjn4IEWttEmH6LJLnL6YpLRNF7Uy6Pc5IszmgvhYyslE0Ddb8B++l5rHOM4dKSxKZwSaKq3cwq73G2fkims35RHQk8YiLzrmWq4n2/tkjEpmVk4AvZNZP8wZ06tqin53WMX5T21iHP9nNB5dezRZfCodr2xcpanYsRojLWk9Q2HyEcb5KcwuChARzdtmsBbDhFcBvtnSCAQiFYHYhAJZQgIS31+PYtRm19YzZWHZHeK2NEQrBtjdoev5ZjJQ0jMKlnd1oHTPS7E6zpo6imi2ezEvMpAO853Xym9wrsRghEnUfdZqL32RfyddOrmcO549zbSmLTpJ4xEXnXMvV9He/YRh4gwYte0rxblyP0T7wz8KlqBOnh59z5sSAruc7xm+q7Klsy7qCt11jaC63A2bSyXBZWJDQyry3/5skfKBZzdlgXRKLMnYCBstg1xazey05DS6bT4oSwPm/v0fdv8ucSdaV1QZXXIny6c+gWG3m2Mz//rl9181EjI7tBq67BXX6bFh6A/z3GggFQWvvZutSRgZgXc4CLKEADsVsRTmMIF5dZ13OgvMq8QxVYdeLkSQecVE6l3I1vd3vC5olbNqCOsGPOgf+cSWY4xp/b//Cnjg9YmLAmeeN8dMo3b6XrbnX8KErJ/x81dCZ4SuncNFsJiUrqH4vhuXTsLNLYpldiDJ2QvgeZewEGJOH49RREg/swvLKb1FazqgnZneA0wUOl9kqOnG0cxpzl+0GFFUxWzYBP7zzFsrCpWgF89Ht9j5npFUmZpHYWAmGYs5803XshKhMyjrrn/9wiGZzPhEdSTxC9EDfswsjip0muyabiFlpm9ebSSVi0L39+MTpPZ6v1RPY9t4Jth1LojFlbvhRaaFW5jcf4YrmI6Q2VqEsmRzeYE0ZMwHGTKAbw8BScZLEAzvNgpxnTigYnQeV5ZCUalYV6HBm8c26GnMrAFU1u+uUkJmIairDl6j9zEjLSk+kVjVwNNWbic1ixZeUSlbq+TUuEs3mfCI6kniEOEN/O02GdIOWgN53CZu6GrMl05XNZh7vcl5HYb8jmy2JeexzXIKhqOALoRgGU1tPUdh6lHx/BQR84PdDckrkwP8ZtJoKXPt34jywC63mjLU2l4w0F3ZOL0BJTUf/7SpzfKbr10DAb25JkJRstoSycsytACyOzm0FumwFEA2zpRDA67lkULaAGE7RbM4n+ieJR8TUYNUv60tHa6WvxYh9XdPTTpMhfHjX/x1/3gx8QaPP8RnAPNbUGFkGxu83jwON7hy2KdlsS5lIraUzQSWHvCyYnM0VvpOkr38VVBXF7sDwR47fdKU21uE8sAvX/p1YTp+IPOnODO9r07WgJhBRfBObHYJBs2LAtbegtG941t9WANEYrC0gxIVDMYyz3MXpPFZWVtbj8Xj4LeZ8j6GvxNJ1HUTX33xXFGT1+CV0NnF0ba2E15QEgyjtrZVorgmt/FdISEJXFAJWJ026il/RoLUF9d8ejRyfsdnMhBIKQvv4DdDjNXooyKErb2NLyM0H5c3odA5ST2oto7DuQ2bMn4ll5BgIhTA+PmRODGhqNFsgXcZv1NYmHB++j3P/TmwnjkT+EJLTIH+2Wf35kpG9b4BmsaAfPQgb/xdqqvpN0mo/3Y6xEA//f/QVR05OTg9XizNJi0cMmv5KyZxrxYBodG2tAO1/es3jPbRozrwmNG0WLRm5+Jpb8NoT0DQLISNkJqf21kq/4zdgTiC47hbYvJ7mxmbeyZrF1vSpVJ1UgRZAIUEzmNd4mMLy98h0aTB7PkrOSLNlQ/vEgLETSElOpqGxEcXXhmP3Ozj278R+7CMUo0uXW0KiWRstv8CslaZGTvsNa9+/BofTLL7pyYK5C/v8mfa1FYAQZ0MSjxg0/SWWmKyDqK4wB8O7stkja4t1uUYH/IoFnyMFX0MbenMAfdFys7Xi92Nompl0QkFYuNS8v7/xG8wp1Ufd49l8WSbvlzeb9dfaP+a4NDsLc51clqpgDc0EY2bvnyfgR9u7g9Sdm3Ac3osS6tw7B7vDrPqcP8esAq31sl9Oe3chThdK122bhRgmknguIkM9vtJfYhmsdRB9juF4sszB8K5fsGcMhoc82XibmvE6EvApFkAxr0nPRCWytWJ0TFPuOobTx/hNW0Dn3ZNNbDneSFlTZ0J1WBTm5bgozNTIsYaAAHTJIRFCIezHPsSxfxeOgx+g+rvsammxmPvZzCiAidN7r96sKGZ8Dqc5VtVbC0iIYRCzxFNaWsqaNWvQdZ0lS5ZQXFwccb61tZWnn36ampoaQqEQ1113HYsXLwbgm9/8Jg6HA1VV0TSNxx57DIDm5mZWrVpFVVUVGRkZ3HvvvSQmyoBlTwZjf5j+9JdYzrViAJwxPpOQ1G3GWdfB8K7jN8bSG2gNhMypz5++AePvL0BABxvdWzTAgZSxvD7lFuq8IdIcGlelpBAueblwaXuLiPD4zXFLClsmLGPX68cjyuGMTrFSeImd2SkGdhWgl8oFho715FGc+3bi+PB9tLYua21UFfImmy2bKZf2vq8NdCYbh1OSjYhbMUk8uq6zevVqHnjgAdxuN/fffz8FBQXk5uaGr3n11VfJzc1l5cqVNDY28u1vf5uFCxdiaV9j8KMf/Yjk5Mi9PdatW0d+fj7FxcWsW7eOdevW8aUvfSkWH+m8E4vxlf4Sy2DMbupvDEfNn41+2wpzvKa6El/GCHyLl+MfMx2jvVyNMnE6RnuLpqdZafsqWnhhbw2aopBgs1DvDfLC3hpuAaZlJYRbRL7Nb7BLT2Vz9nROWNOgAcDApikUZNpYmKEyKkEFepm/YxhYKk7g3L8T54H30M5Ya2OMHo86Yw6p8xfTEOyj1I7VBs6OZBP99tRCDJeYJJ7Dhw+TnZ1NVpbZ3TF//nx27NgRkXgURcHr9ZrlRrxeEhMTUfv5jW3Hjh089NBDACxatIiHHnpIEk8vYjG+Ek1iOdeKAf2N4YR0g7ZJM/HmzcAfNHr7yjeTTNfpz128fqQBTVGwWxSU9j99QfP4tKwETjX62eLL5t2c5RHVpXMSVBZmWpjjseC09DKTDHOtjXP/Tpz7d2KprYw4F7pkFNoMs/qzmmIW81STkqHujAWgmhauNqBYpMdcnF9i8l9sbW0tbndn2Xa3282hQ4cirrnmmmt4/PHHWbFiBW1tbdx7770RiefRRx8F4KqrrqKoqAiAhoYG0tLM/znT0tJobGzs8f1LSkooKSkB4LHHHsPj8fR4ncVi6fVcrAxVDLlp5dS0+HFYOn8j9gZC5KY5ur3fucRwtcfD1ZeOOZdQ+4yj9pJc9LqaiO4mv9eHP2ccdlsi/pCBagUX5j9no857ggSbBUVRUBSwaBYURae8KcBT71TwUVXn9tBWFeZlO7ky18WEVGuvU5eV+mq03e9i+eBt1LLjEeeMjEuwzppP4twFaFndp+NqFs3871xVUZwuVGcCit3e7bqhdiH//3G+xnG+ikni6Wmp0Jn/g37wwQeMHj2aBx98kIqKCh555BEmT56My+XikUceIT09nYaGBn784x+Tk5PD1KlTo37/oqKicLICep0SGg/TRYcqhmvHJ/HczgqCoVBEN9i1493d3i8efg69xaFfeR36H5/Dpyv47An4QjpBww7zr0GtHtiOmr1Jc2jUe4PYLQoGKvVtflr8OgaEk06mQ6Ewy8q8DAuJVgXw0tjkjXiO2tqE40D7WpuTkWttQslpBKbORrt0DrYRI9EVhUbo3rJRFNIvyaEu0AYWO0pQh6Ym858Yi4f/LuIhhr7ikHU80YlJ4nG73dTUdE41rampCbdUOmzYsIHi4mIURSE7O5vMzEzKysoYP3486enmGEFKSgpz5szh8OHDTJ06lZSUFOrq6khLS6Ourq7bGJDodL6vHg/qZlFGX94M2m78OkZfVQPO0ZVjk/nD7mrq2gwCXQqwqcBMt0ZhlpWJyWqPrRvF14bjow96XGsTciXinTwLps/GMTYPl6WP8Ri7IzwjTUv3oOjD/2UrxGCJSeLJy8ujvLycyspK0tPT2bZtG9/61rcirvF4POzZs4cpU6ZQX19PWVkZmZmZ4XEfp9OJ1+tl9+7d3HTTTQAUFBSwceNGiouL2bhxI3PmnE9F1mPvnMdXYiioG7T4gtS1BfGHdHMdTDtl4nSUQUw0HWpaA2w5Vs+2Ey00+zvf0KLALLdG8WgbKbYexh0DfhxH9prTn89Ya6PbHXgnzsQ/rQDr+Em4bBpab5UEOsZtnAm9r8kR4gIQk8SjaRp33nknjz76KLqus3jxYkaOHMn69esBWLp0KTfeeCPPPvss3/ve9wD44he/SHJyMhUVFTz55JMAhEIhCgsLmTlzJgDFxcWsWrWKN998E4/Hw3e/+91YfJwLVn/7yXe9ZrBbTYZh4A+ZrRqz3Dz4rQFaA70XxBwMwZDOvvJGthxvYn9tIDwZQQGmp2lcMzaZUTYf6pnJIrzWZieOg7sj1toYFive8dPxTi0gNH4aiU4baVr37mXzjWRxp7j4SK22LuKh/3i4Yui6zifBbqXFF+hWR22gtdai0dO2Ah0FOJXGOowzF28OAkMPUd/YxrZPmtha7qXe3/m/QIpVYX6WhQWZFtLsarhcTfuN2E4cwbF/J84P30dt65xkYKgqvjGT8U4twDtxBnank0Sr+XPqkdXaPiut/ynQ8fDfZbzEEQ8x9BWHjPFER+ZhCiC6/eQHYy2QYRj4QgbenvawIbK4prnjZeQGatHYV9HC60caqG4N4nFZuCovhanpVnS/j48qW9lc5mVPbYiubakpKRqFWRby0zQ0tUuyMAys5cfNZHPgPbSm+s5TKPhH5uGdWkDb5MswXIk4VPBYFWw9JRxVNcdtnAkoVtm1Uly8JPEIILp1Pme7FiikG/hCZsvGHzK6JZsIXQpwKh1lX84owNlTYpmWlRA+Zy7+BJcG9a1+/lhaweQUjUONOtW+zjdPtMAVmVYWZFnIcER+Lkv1abMb7cP3cJ2xr40/exTeqbNpmzIbPdmcJOPUIMmqYFV7SDg2O7hcYHf2XilaiIuIJB4BRFdHLZpr9D270F/7H/w1Nfg8Ofg/fS3BCZ0tlX73semnAGfXqgIuq0K9N8QLe2v4gmEwLc3C6wdr0YwQNgx8IWgJQGsI3q7qXPk/PkllYbaVS9O1iEShNdTg2L8L5/6dWCtPRYQQcGebLZupswmlZwLmOFCCBgk9JRxVMbeSdiWgWKR1I0RXkngEEN1+8tdPSee5bZ/gbWnEHvDiszoIJiRz/axRZsWA3e/R9vIf8FkdGCnZ0OKFv70Q3qcmYo8aV4JZaPPMbrR+NlDrWlUAw8CuGviCOiUfVTNtmpPKFnOCQG0QuhQVQAE+nW2hMMtKtquzdaO2NOH48L32tTZHI34mwZR0jJnzqc/LJ5g5wpwIgDmtOsECCRYlslsOzCTpTJDCnEL0QRKPAKLbT/6y2o/42sFXWZcxl0pbCh5/A58p30TuuCJOJ01H3/A6WJ2971MTxT42XQtwGpozooCnYRhUt/hxabRXdjYzixWD063w+8M+GgKRldFsKthVyHIq3DTWfF/F24bjYCnO/buwdVtrk4R3yizaphYQGDGWlJQUgu2TCzQFEi0KLguRs9xU1Uw2TilfI0Q05P8SEdbffvKB1/7CJH8z36nZiE+xYKBAwId/03rUCdP736cmin1sum1JkJQKl38aJWsE1FTisUG93yxCqhsGrUFoCpitm3eqOtfPODRIbu/hCulwTZaB44DZsrEf2dfjWpu2qQX4x0yEM2aZWRRz/MZ55pRoGbsR4qxI4hG90rusrfEFdfyNPnClAl2/fLskjn66yfo9jznrTRk7EUaMIdVpp762vQxOwA9AUY6F/zrspylg4A1Ftm5GuFQWZltI1Aw2VYSoaw1wedMhrqn9gKy39qL6fZ3v077Wpm1qAb68adDDOIxNBY9TIzHYpctMVdsXebpk7EaIsySJR0QIhAwavUGqWwPdqzv3lzh62KcmYp+b3s4vKMLwtpndagFfOJsY1s6Whz9k8F5NkC0VQRq6bKCmAJNSVK4daWNMooqCge3EERad2InzwPuo3jPW2oydinfqbLwTZmD0smDToZotHJum4LSoeMHcesCVYK67kdaNEOdEEo/A114toG3fbgKb+li42U9i6dpN1tOstfD5Ta+Z51PToKAQxZMFzT1XFj/dqrOlIsA7VUHaumxJk+VUWNhepNOlgfX0Jzi297LWZtR42qYW4J00E8PV+3qjblOiVQU1IRFUq6y7EWIQSeKJE9GUqxksPS3ijGbhZn+JpeOanva5MYIBCPjNsZrrv9Tr3mgAAd3gg9oQb39Yw4d1/vBxTYGZ6RoLs6yMT1ax1lTg2LoD54FdWOqqIp7hzx6Fd1qBudYmKbXPn4dDhWRbl4TTMTPN4URNTUcJDv9KeSEuJJJ44kDXUjRJdiu1bYFB35a6YxGnN2hOP+62iDOKhZvQ9wZqXRmhoNkiCrT/E0VlpmqvzpaKIG9XBmju0p3mtisUZlm4ItNKakvtgNba9MWuQnJHlQEZuxEiZiTxxIFoytWcDX+XROMP9fPFH8WMs74YoQD4zVYNwQDo0RX3DBkGe+tCbD4d5EBDZ1+aCszKtHO5G6ZYWnF9uB3nGzuxnfo44v5gSnp7sikgmJETXmvTF1t7wrFrnQU6sTtk7EaIGJHEEwcGa1vqfls1fYlixllXZqLpaNEEomrRdFXn09laGWRbRZCGQOe9qTazdTM/JcDY8j3wzy3Yjn+E0uX5oYQkvJM719pEk2zAnBadbFVw2jRZdyPEMJL/6+JANKVoehMI6bRF26rpSx8LN8Gs6BzuNvP7o27RdKUbBgfqQ2yuCLK3LhSxBcGUVI1CNxRU7UPfvJ30Tw5g0TtbQLrdiXdS+1qb0RO6rbXpiwIkWhWSXDaUhERZdyPEMJPEEweiKVfTQTc61tWYyWYguaavOmk9LtycvwRlxBiM+lqz++wsNfoN3q4KsLUiSE2XIp1JVrjCo7HY+zGjDr6L/ZUPUAOdkwn8qpUPMqfybvZMpszJZ6rHOaD3VYEEm0JCogstIUlmpgkRJyTxxIH+ytUEumyQFggZfU0I61U0ddKUcZNg5FhSXS7qqyvNmWdd9pwZCMMwONSos7kiQGltKKLbb2KyymKtiss/3krS5si1NiFFZZ9nEqUjLuNAzgxaFQ1fyOBkBUz1RPfemgKJDguu5ERUZ4LUTBMizkjiiRNdy9VUVlXhDxnUtwXxDrBV06se66QZsPFVjOzciJlnhqb2Od25Ly0Bg3ergmypCFDh7XxIggXmu1opOr2DcTu3oDU3hM8ZKPhHT6BtagE/8k7EcLpQFAWLZoFQEJtqznjrj6oqJCU4SUhJRO06ViWEiCuSeGKkvy2jA6H2CQFNPk43Bc72e793dTXm7C1DN//RDVBUqKsyx3POgWEYfNxsToXeVR2MqAqd5wiypPkjPvXBq7jqztjX5pLR5sLOKbPCa22c+9raa7F1uU4Hj6P3VotqtZCYlEBCUgKaFv3YjxBieEjiiYGu63QSbSq1bUGe21nBnSGdKZmu9jEd81o1qA9a0jEMo3NCQFIyNDeZpV86BAPQvpHZ2WgLGuyoDrK5IkBZa2fUDtVgfqica468yfiTuyPuCXja19pM6XmtTVGOhReP+vFhoKnmQteQbh4/k+pwkJicSGKCI7JatBAirkniiYGOdTp2TcEALKpCUDd4eX8t30ntuV7Y2dAP7jXL0dRWQ0oazJ6PMmaCeXLWAtjwCuA3C2IGAxAKwezCAb/PJ80htlQE2VEdxN+lB2w0LVx9egeLDpXgDHVOEgimuM0dO6cWmPva9GFampUvjIOSsiC1fp10m0pRjoVpae0TA1QVxeEkITmBJIet+344Qoi4J4lniAVCOuVNflxWlUCXEXarCtWtwT7ujE5HKRrjo72wfh1omrkosrkR3nwFY/EylLETUMZOwGAZ7NoCjXVmS2d2IcrYCVG9jy9ksKsmyJbTQY63dGYbGyEWNB3mmoOvMaHpZPh4KCEJ7xQz2QRyxkS91gbM5DMtzUpKcjIN7XvhYLWiOJy4ElwkOyyScIQ4j0niGWQdizi7TndOd1qo94bMXTPb+UPgcQ38x9/rws13NphJp6MrzWoD/GaiaU8uytgJ4b9Hq6y9SOf2M4p05gbqufr4Jj59eicJQS8AusOJd9JltE2djX/URLMMzblQVbMatMOJy2knya5hkYQjxHlPEs856ii46WtfWxPooVzAVXkpvLC3Bl8QbJqZdEKGwVV5Kf0/P2Qu3Nx3uomS421Ue0N4HGd0P4HZirG7Im+2WM3jA+QPGWxvn5l2pKmzdWMxQlxRtYerT21jSsMxFEC32mibMpu2aQX4xk7pcV+bAbNYwO5A82SS0NIkCUeIC4wknrPQMQPNG9K771nTg2lZCdwCvH6kgerWIB6XhavyUpiWldDtWiMUwvC1RVQI2FcX4MWjfjQVXBZzB84Xj/r5wjg6k09yGrQ0n9Pkgco2c2bau9UVNHcpY5PdVsPSsre58vROkgOtGKqGb3y+uYnahOkYtkEap7I7wOlEsdhwWVVyUpzU622D82whRNyQxBOF8DYC7TtxBgdeLYZpWQk9JxpdNxNE++wz3d9mLu7soqQsiBb0Y/c2QyiIXbPgcyRSUqZ2Jp7ZhWc1eSCkG3xQF2JLRYCPGjo/mKaHmFu9j6vL3mF6/REUwD96AvUd+9o4u3+Ws6Jp4HCaZWxUFadVJcmmYdUULJos/BTiQhR14nnyySf51Kc+xaxZs7BcBIUVQ3pntQBfFK2aaJlTnDsTTTSlaKqb/bhaGsyiY6oKeghbSwPVqIBZRmagkwdqfDrbKoJsqwzS2KV14/HWsbTsXa48vYN0fxP+nDE0FdxorrVJ7L9rMGo2u1mks72F5rAoJNs1rJJshLjgRZ1BJk2axMsvv8yvfvUrrrjiCj71qU8xadKkoYwt5nxBnUZvEO8ZYzX7Klqi6ibrjRHsKK7ZnnAGyN1aQ4Nqxd6R/hQFv6Lgbq0BOpNBf5MHdMNgX32ILaeD7KsPYmCOm6iGzqyaD1la/i6X1XyIkjWC5is+TeWU2YTSMgYcb68UpX0LAidK+0JPe3vCsUnCEeKiEXXiue6667juuus4ceIEmzdv5qmnnkLTNBYtWkRhYSHZ2dlDGeeQ6DoDzRvUadV8NPkj+9H2VbTwwt4aNEXBZVWo94Z4YW8Nt0CvySdy5pn/rMvPdCiq3MlL2Z/CRwibEcKvaITQKKp4GxjX7/0Nfp1tlUG2nvZTF+gYpFdI9TVSdHoHV5W9S5pTwzu1gNqpN5CQN5mWxsY+nzkgFgs4Ive8sWlmwrFbJOEIcbEZcJ/ZyJEjue2227jsssv47W9/y5///Gf+/ve/M378eL785S8zZsyYIQhzcDX5Qnij3Ebg9SMNaIoSngptt4AvaB7vSDzh3TY7xmrOYsuAvkzTWri5cisl6ZdSY0nEHWymqPYDpmm9F/DUDYOPGnS2lnn5oMFAR4H2Fs6M2oNcU/YOl3lPEpx8GW0L/5WqAa61iUqXyQIdJOEIIQaUeMrKyti0aRNbt27FYrGwcOFCvv/975OcnMz69et54okneOaZZ3q8t7S0lDVr1qDrOkuWLKG4uDjifGtrK08//TQ1NTWEQiGuu+46Fi9eTHV1Nc888wz19fUoikJRURGf/exnAXjppZd44403SE5OBuDWW29l1qxZ/X6ORl+o32s6VLcGcVkjv5BtGlS3+DGaG6Lem8b4+NBZL95kdiHTNrzCtNayyIkDi5d1u7QpYPBuuZet5V4q9Y4vfIVkfzNXnt7JkprdpI0ZRdtVV1I7asK5r7U5U3iygAOly545FhWS7Bouq9RSE+JiF3XiWblyJVVVVVxxxRV861vfYsKEyC/Na6+9ln/+85893qvrOqtXr+aBBx7A7XZz//33U1BQQG5ubviaV199ldzcXFauXEljYyPf/va3WbhwIZqm8eUvf5lx48bR1tbGypUrmTFjRvjeZcuWsXz58rP57FHxuCzUe4Nm0UrdAEPHH9Lx2FTweqN6hvHxIXPGmaaZa21ammHDKxgsCyefjsRU39Ro1lXrkpj6mzhgGAZH6v1s+7iOXV4XQUUDzKQztf4oSyt2MjNNJThrFr5xV9OgDcHkEJsNnAnhyQIdVAWSbBoJNlU2XxNCAANIPMXFxRQUFPQ5o6231s7hw4fJzs4mKysLgPnz57Njx46IxKMoCl6vF8Mw8Hq9JCYmoqoqaWlppKWZa1GcTicjRoygtrY24t7B1nXmWVG2youHg/hCYFPNSsm9Fa3s1a4tfVYV6JqYFKcLo4fE1NPEgVZ/iF2Hytlcp3FKSwaSQAFXsI1FFe+z2FKNe+IEfEtuo2WotgmwO8DlQtG6LxxNsKok2TUpbyOEiBD1t6fT6aSyspKcnJzwsbKyMqqrq5kxY0af99bW1uJ2u8Ov3W43hw4dirjmmmuu4fHHH2fFihW0tbVx7733op7RDVRZWcnHH3/M+PHjw8dee+01Nm3axLhx47j99ttJTEzkTCUlJZSUlADw2GOPhRNZh45Eo7S1kIJuzkLDAKvG/NwUXHY7r3zcTFVbiAynxrKxiczMiH7RZH1TI0r7HjPh91QdGE2NpCQn0/TBO+hWK4rNjqKA4XBi+H2oH7xD0qWzI2PVdY4dOsabR2rZqmTiV9OgvfdqfOMJrgp+wry8DCxXXgPta20GmnJUTSOlvfuy5wtU8/M4XSg9tJ6cVpUUhxXbOY7jWCwWPJ4od38bIhJDfMURDzHEUxznq6gTz+rVq3n44YcjjjkcDlavXs1TTz3V572G0X0Q/8xulw8++IDRo0fz4IMPUlFRwSOPPMLkyZNxucwyMF6vl5/97Gfccccd4WNLly7lpptuAuDFF1/k+eef5+677+72XkVFRRQVFYVf19bWdlm02TnFOaIoZRdj7XDP5K5dSH4aGgcwLTopGaOlGaNrN1T7VgUNjY0YtVVgd2GEQqiahh4KgaoRqq0KxxM8fYrSQ+W85U/jY1c2aGaVZ0fIx/ymIyx06zRMH8//1o/mxRYdT2kzRTneyLI6Uert54DFao7fWG0ogRAEmiJOW1WFFIeGElJpjK4Xsk8ej4fq6upzf5DEcMHEEQ8x9BVH11/MRe+iTjwNDQ3dWgppaWnU19f3e6/b7aampib8uqamptuzNmzYQHFxMYqikJ2dTWZmJmVlZYwfP55gMMjPfvYzFi5cyLx588L3pKamhv++ZMkSfvrTn0b3YWoqo7tusPRXVaCXcjeaw0n11k1sqrOwJWUSbZYp4X9jo7zVLLLXM2vKCGzuOV3K6ui9l9U5Gwpgd5rFOnupw2bTFJLsGg6ZqSaEiELUiScrK4u9e/cyffr08LF9+/aRmdl9M68z5eXlUV5eTmVlJenp6Wzbto1vfetbEdd4PB727NnDlClTqK+vp6ysjMzMTAzD4Fe/+hUjRozg2muvjbinrq4unMC2b9/OyJEjo/04MdVvVYEuiUnRNayNdXzgyuWN9AI+UsdAey+lVQ8y16hiwagkRo0chaKMDr9HSVkQTQW71j7tWwMfBiVlwbNLPB2tmy5rb85ktygk2WRqtBBiYKJOPJ///Od58sknufLKK8nKyqKiooINGzb02LV1Jk3TuPPOO3n00UfRdZ3FixczcuRI1q9fD5hdZjfeeCPPPvss3/ve9wD44he/SHJyMh9++CGbNm1i1KhR3HfffUDntOk//OEPHDt2DEVRyMjI4K677jqbn0FM9FVVQM3OwTFqFHWHj7AhfTpvTf88zdbOStPZejML3TAnL4MEa89la6q9ZkunK5tqHh8Qmx013YNi632NkCQcIcS5UIyeBmB6cfjwYd58801qampwu91ceeWVEQP954vtW97t8XivYxtDQPF7sR/ag3X/e5Q2qqy/ZC570zp/lpqhM8vpZf7YVCakWPqdivzUvjbq/Xq4xQPm5m2pNpVvT3P2EwxmZQGHC0XTSEtLo66u+3YKDovZpRar8jbx0J8vMcRXHPEQQ19xyBhPdAa0oGP8+PHnZaI5V+e0+LOrYAD70f049++i4ZMTvJI5izcu+RwNuUnhSzK0IPMvsXN5lotkW1IfD4tUlGPhxaN+fBjRT/tWVXA6we5C6WMhaawTjhDiwjagxHPs2DEOHDhAU1NTxEy1L3zhC4MeWLwYyOLPHhOTrmM7fhDn/p1YD+7m/YTRvJZzOaUFn8dQzC9yBYP8FJXCS2xcPiqbpqam3sLp1bQ0K18YZ471VHv1njeL62BtH7+x9T5+A52z1KRLTQgxmKJOPCUlJfzud79jxowZlJaWMnPmTHbv3k1BQcFQxjf8BrD4M5yY3vwHlhmzcNVV4PjwPeoDCv+4ZC6vz/w2NY7U8KNTrDA/y8qCTAtpdvPLXT2H1f3T0qx9TySw2cGV0OvstA6aqpDq0EiwSXkbIcTgizrx/PWvf+UHP/gBU6ZM4Stf+Qr33Xcf77//Plu3bh3K+IZff1tKdyQmixVLwIuzpR5nSz1qyRE+SJvAa2OuZ6dnCrpifokrGExOsbAw28L0NA1tqMvInDF+0xdVgUSbRk6ynZqAJB0hxNCIOvE0NjYyZcoUwFz8qes6l112GU8//fSQBRcX+tlSWqutxBn04WytxxrwUW9N4G85C3g9Zx4Vzs5qDYkWmJ9pZUGWBY8jBl1Xqtq5900UhUC7lreRmmpCiKEUdeJJT0+nsrKSzMxMLrnkEnbu3ElSUtKFvxtpD4s/Vb8PZ1YmzrWPY6v5BAPYnzKO13Iu5+2M6YTUzp/JhGSVhVlWLk3XsMSiZpnVBg5Hv+M3HWyaOY4jEweEELESddb43Oc+x6lTp8jMzOSmm27i5z//OcFgkK985StDGd+w61j8qWx/C2fVKZxBL7a2JpTqj2myOHktt5D1OZdzytW5kNYV8jIvKUjhxAyynTH4Qu+oLuB09lissyeqAsl2GccRQsReVInHMAymTJkSLop32WWXsWbNGoLBIA5H9MUyzzeKz4vj0G4c+3dhP7YfRdcxgIPJo3htZCFbPfkElM4v7jGtFSz0HuOyKSOxjzuL6dYDFd77JrrutA4Oi0KqwyJVo4UQwyKqxKMoCv/2b//G7373u84bLZYLs5stvNZmJ45De1CCAQDaNDtvjSzgtdGL+MSSGr7crsLcDAuFWRZyE8YRzVbU58xiAacLxd7PwtAzb1MhxWGRmmpCiGEVdeYYM2YM5eXljBgxYijjGR56CNvxg9gO7SZr7w5UX1v41NHkkfxz0jVsSRiHj87WTa5LZWG2hQKPBYcWo5aDzW7OTrPZ+r+2C00xd/+UbjUhRDyIOvFMmzaNn/zkJyxatKjbPhRXXnnloAc25Awd66ljZsvmwHtorZ2LNr2ajU1TlrI+czZH9YTwcasKs91m62ZMYox21AxXF3BGbCUdDQVIsJmz1c5lfZAQYngdO3aMz3zmMxQWFrJt2zZGjBjBX//6V/7whz/w61//Gr/fz/jx4/n973+Py+XijjvuwOl08uGHH3L8+HHWrFnD7373O95++23mzZvH2rVrAVi/fj0/+tGP8Pl85OXlsWbNmh73NBtsUSeejz76iMzMTA4cONDt3PmWeJI2rMOxfyeWxsh6ZMfGz+V/Ry1kq5JJW0iB9vqa2U6Fwiwr8zIsuCyxat3YwJEw4NZNB7tFIcVuwRqr1pgQYkgdOnSIP/3pT/zmN7/h5ptv5uWXX+aGG27ga1/7GgAPPPAAq1ev5v/8n/8DmNX733zzTf72t79x3XXXsXXrVv7f//t/zJkzh9LSUnJzc/nxj39MSUkJCQkJ/PSnP+XnP/85Dz744JB/lqgTz49+9KOhjCOmEt95Pfz31uzRbMm9nDcsuRxyZIWTjUWBmW6Nwiwr45Ni17pREpNBs/W72LM3mgLJDg2XVbrVhLiQjB07lpkzZwIwe/Zsjh07xt69e3nggQeor6+nubmZq6++Onz9ddddh6Io5Ofnk5WVRX5+PmD2Xh07doyTJ0+yf/9+FixYAIDf7+eKK66IyWeJOvHoeu/l9c/cojreBdMyOTZ1ASWZs9hWb6HZ6PyS9vgbKaw7wLz80STn5cUmIJutfezGjpqQiOIPDPgR0q0mxIXNbu/cxF7TNNra2rjjjjtYt24dl156KWvXruWtt97qdr2qqhH3qqpKMBhE0zSuuuoq/vSnP8XsM3SIOvHceuutvZ578cUXByWYWPnRp/4vBxp0aO9pUw2d/NaTLGw5wsSWU6gBP7x/HKJMPPvqAtEV5+xKVTunQp9l66aDw6KQ4rDEZoGqECJuNDU1cckllxAIBPiv//qvAU3+uvzyy/nmN7/J4cOHGT9+PK2trZw8eZKJEycOYcSmqBPPL3/5y4jXdXV1rFu37rwsEnqgwWy9pdkU5p/azhWtx0nVvaiaZva0da3F1o/OLaeJbstpq629MrT9nLvvbJpCsl2qRwtxsXrkkUeYN28eo0ePJj8/f0CV7TMyMli7di233norPp8PgB//+McxSTwD2gjuTK2trdx///089dRTgxnTkLvjNxtZmG1hWqqG8vLacC02VdPQQyEI+CEhEeWm/qsyRLUB2wAqC/S2CVtXNs3cH2eo1uPE+2ZbEsPFG0c8xNBXHLIRXHTOaQVoa2srjTHasXMw3T2ls9qC0aUWm6E6zKQTCpk12qLQ55bTFouZcOyOAVUW6I1MHBBCXAiiTjy/+MUvIrqGfD4fBw4cYOHChUMSWKx01GJj1xaMpkZISh7QDqMeh9re4uk85jdUPAkWlFR37zcOJEZk4oAQ4sIRdeLJzs6OeG2327nqqquYMWPGoAcVa8rYCTB2AinJyTQMsAUX3nJaAZuq4kchpMBVE9IGJTabZm7KZpXq0UKIC0TUiefzn//8UMZx3pqWmcAXXAmUHG+jujWIx2XhqrwUpmUl9H9zH6RbTQhxoYo68fz2t79lwYIFTJo0KXzso48+4u233+aOO+4Yitjim91hFuq0WJmeAtNHDE4LRwGSbCqJ0q0mhLhARd1/s3XrVvLOWNcybtw4tmzZMuhBDbV9dQNfoBnmcEKaGyUpBcUS3d430UqwqlyS4iDZYZGkI4S4YEWdeDq2u+5K13XOYTb2sCkpCw7sBkUBVwKke1ASk1G0wd0OwmFRyEywkuqURaBCiMHx6KOPMm3aNGbMmMHMmTP5zGc+w/333x9xTWlpKVOmTAHMHQjOnCw2c+ZMpk+fPuixRZ14Jk+ezAsvvBBOPrqu8+c//5nJkycPelBDrbrZH92FqgoJiZCegeJKHHB16P7YNAWPy4LbZZVinkKIQfP222/zj3/8g/fee4/du3dTUlLCypUru1WZeeGFF7jtttvCr5uamjhx4gRAjwWhB0vUiecrX/kKe/bsYcWKFdx///2sWLGC3bt3c+eddw5ZcEPF3VrT9wUWCyQmQ5oHxZkw6AVCLSqkOTUyEqxSdUAIQdvOrVTe/3XK7lxO5f1fp23n1nN6Xnl5OR6PJ1yjzePxsGjRIlJTU3n33XfD17300kvccsst4dc333xzODn96U9/6rNU2rmI+lvP7Xbz05/+lPvuu4/ly5dz33338dhjj+F2D85alVgqqtzZ43HFZoPkVJRUN4rDOegJR1Ugxa6RmWCV2WpCCMBMOnX/+TjB2mqUxGSCtdXU/efj55R8li5dyokTJ5g4cSJ33303GzduBMyamy+88AIA77zzDm63mwkTOtcs3nTTTfzP//wPAH//+9+57rrrzuGT9S7qxHPs2DFqa2uZOHEiV1xxBRMnTqS2tpZjx44NSWBDaZrWEnnAZoOUNNQ0D4rN3vNN56BjplpWopVEuxabLRaEEOeFppd/DxYravsvu6rDCRarefwsJSYmsmvXLn7961+TkZHBF77wBdauXcstt9zCf//3f6PrOi+88EK3Fk16ejppaWm88MILTJkyBZfLda4fr0dRJ55f/OIXhEKhiGPBYLBb8dDzQkc5HLsD0tJRktNQrGe34VpfFMyZalmJVpmpJoToUbCiDMXuiDim2B0EK8rO6bmapvHpT3+ahx9+mF/+8pe8/PLLjBw5kjFjxrBx40Zefvllbr755m73feELX+Cb3/zmkHWzwQDW8VRXV5OVlRVxLDs7m6qqqqjuLy0tZc2aNei6zpIlSyguLo4439raytNPP01NTQ2hUIjrrruOxYsX93lvc3Mzq1atoqqqioyMDO69996otm1Vpl5q7n9zjtsR9MVpVUm2azJLTQjRJ0tWjtnN5nCGjxk+L5assy84+tFHH6GqargbrbS0lNGjRwNmd9u9995LXl4eubm53e69/vrrKS8v5+qrr6as7NySX2+ibvGkp6dz9OjRiGNHjx4lLa3/hZO6rrN69Wp+8IMfsGrVKrZu3crJkycjrnn11VfJzc3liSee4KGHHuL5558nGAz2ee+6devIz8/n6aefJj8/n3Xr1kX1WZSEpIiks6+ihf/YVsa3Xt7Nf2wrY19FSx93981lVclMsJIuU6OFEFFIuvHLEAyge9swDAPd2wbBgHn8LDU3N/Mv//IvTJ06lRkzZrB//34eeughwKxCs2/fvohJBRHxJCXx/e9/H5tt8HuBOkTd4lm2bBlPPPEEy5cvJysri4qKCv7+979zww039Hvv4cOHyc7ODreY5s+fz44dOyKyraIoeL1eDMPA6/WSmJiIqqp93rtjx47wD3PRokU89NBDfOlLXxrI52dfRQsv7K1BUxQSbBbqvUFe2FvDLTCgsjcuq0qiTZNp0UKIAXEWLIBv/F+aXv49wYoyLFk5JN34ZfP4WZo9ezbbtm3r8VxGRgaBQPdF9D2N148ZM4a9e/eedRy9iTrxFBUVkZCQwJtvvklNTQ0ej4fbb7+dyy+/vN97a2trI2a/ud1uDh06FHHNNddcw+OPP86KFStoa2vj3nvvRVXVPu9taGgIt7jS0tLOaouG1480oCkKdouC0v6nL2gejybxSMIRQpwrZ8GCc0o055sBLcGfMmUKVqs1/AXf2trKm2++yZVXXtnnfT1VNzhzZtcHH3zA6NGjefDBB6moqOCRRx5h8uTJUd3bn5KSEkpKSgB47LHHIroH67wnSLBZUBQFRQGLZkFTDeq8wV67ERXAZdPM7aYHuWq0xWLB4/EM6jPPxxjiJQ6JIb7iiIcY4imO81XUiWf79u388pe/JDs7mxMnTjBy5EhOnDjB5MmT+008brebmprORZs1NTXdvtQ3bNhAcXExiqKQnZ1NZmYmZWVlfd6bkpJCXV1deNfO5OTkHt+/qKiIoqKi8OuuO3ymOTTqvUHsFgWLZiEYCuILGqQ5tG47gSq0t3DsGkZIob6t75/Z2YiHHRbjIYZ4iUNiiK844iGGvuKQHUijE/Wv6y+++CLf+MY3ePzxx3E4HDz++OPcddddjB07tt978/LyKC8vp7KykmAwyLZt2ygoKIi4xuPxsGfPHgDq6+spKysjMzOzz3sLCgrCC6M2btzInDlzov7gHa7KSyFkGPiCBkb7nyHD4Kq8lPA1HdOiMxOlnpoQQpyrAU2nvuKKKyKOLVq0iLvuuovbb7+9z3s1TePOO+/k0UcfRdd1Fi9ezMiRI1m/fj1grrK98cYbefbZZ/ne974HwBe/+MVwC6anewGKi4tZtWoVb775Jh6Ph+9+97vRf/J207ISuAVzTKfOGyTNoUXsp+Oymjt/SrIRQojBEXXiSU5Opr6+ntTUVDIyMjh48CBJSUndKlb3ZtasWcyaNSvi2NKlS8N/T09P54EHHoj6XjCn/T344IPRfoReTctKYFpWQrjLDsx1OEkyaUAIIQZd1F1tS5Ys4cMPPwTMqdUPP/ww9913X0TyuBDYNIWMBAvpToskHSHEeev06dPccsst5OXlMXXqVD772c9y8OBBjh07hqIo/OIXvwhfe88997B27VoA7rjjDkaMGIHP5wPM3q4xY8b0+B5jxowhPz+fmTNndhs+6UvULZ6ulQYWLVrEtGnT8Hq9Pa58PR9pCrhdVlyhwd3cTQghYs0wDK6//nr+5V/+JVwUtLS0lIqKCkaOHElmZiZPPfUUK1as6HGhqKZp/Pa3v+Ub3/hGv++1YcOGAc/wO+u5wB6P54JIOgqQZNfISrSSYB/cDd6EECIa245W840X3uNzz23jGy+8x7aj5zZzb8OGDVitVr7+9a+Hj82cOTO80VtGRgZLlizhd7/7XY/3f+c732HVqlUEgwPcNDNKF/VmMM6OAp5SMVoIMUy2Ha3m8ZKDVLf4SXZYqG7x83jJwXNKPnv37mX27Nl9XrNy5Up+9rOfdSv+DDBq1CgKCwv5/e/7rpCtKApLly5l9uzZ/PrXv446vovyV3ybppDi0LAN8uJPIYQYqN9v/wSrpuJs36Or48/fb/+E+eOGbpHq2LFjmTt3Ln/84x97PP+DH/yA5cuXs2zZsl6fsXXrVnJycqisrOSqq65i8uTJfOpTn+r3vS/Kb96MBKskHSFEXChr8OI4Yydih0WlrNF71s+cNm0au3bt6ve6H/zgB/z0pz/tcXby+PHjmTlzJi+99FKv93csmM3MzOT6669n+/btUcUn375CCDGMclIceIORX/zeoE5OsqOXO/p35ZVX4vP5+M1vfhM+tmPHjvCC+w6TJ09m6tSp/OMf/+jxOT/84Q958sknezzX0tJCU1NT+O/r169n+vTpUcUniUcIIYbRl+eOIhDSaQuEMAyDtkCIQEjny3NHnfUzFUXhL3/5C6+//jp5eXlMmzaNhx56qMeSPj/84Q+7bVPTYdq0aT2uoQSoqKigsLCQSy+9lLlz57Js2TKuueaa6OIzeqrCeYHrbXOjeKgDJTHEVxwSQ3zFEQ8x9BXH2dZq23a0mt9v/4SyRi85yQ6+PHfUkI7vDLeLcnKBEELEk/njPBd0ojmTdLUJIYSIKUk8QgghYkoSjxBCiJiSxCOEECKmJPEIIYSIKUk8QgghYkoSjxBCiJiSxCOEECKmJPEIIYSIKUk8QgghYkoSjxBCiJiSxCOEECKmJPEIIYSIKUk8QgghYkoSjxBCiJiSxCOEECKmJPEIIYSIKUk8QgghYkoSjxBCiJiSxCOEECKmLLF6o9LSUtasWYOu6yxZsoTi4uKI83/729/YvHkzALquc/LkSVavXk1jYyOrVq0KX1dZWcnNN9/MsmXLeOmll3jjjTdITk4G4NZbb2XWrFmx+khCCCHOQkwSj67rrF69mgceeAC32839999PQUEBubm54WuWL1/O8uXLAdi5cyevvPIKiYmJJCYm8sQTT4Sfs2LFCubOnRu+b9myZeH7hBBCxL+YdLUdPnyY7OxssrKysFgszJ8/nx07dvR6/datW1mwYEG343v27CE7O5uMjIyhDFcIIcQQikmLp7a2FrfbHX7tdrs5dOhQj9f6fD5KS0v56le/2u1cTwnptddeY9OmTYwbN47bb7+dxMTEbveVlJRQUlICwGOPPYbH4+nxvS0WS6/nYkViiK84JIb4iiMeYoinOM5XMUk8hmF0O6YoSo/X7tq1i0mTJnVLIMFgkF27dnHbbbeFjy1dupSbbroJgBdffJHnn3+eu+++u9szi4qKKCoqCr+urq7u8b09Hk+v52JFYoivOCSG+IojHmLoK46cnJxhiOb8E5OuNrfbTU1NTfh1TU0NaWlpPV67detWCgsLux1///33GTt2LKmpqeFjqampqKqKqqosWbKEI0eODHrsQgghBldMEk9eXh7l5eVUVlYSDAbZtm0bBQUF3a5rbW1l//79PZ7rqZutrq4u/Pft27czcuTIwQ9eCCHEoIpJV5umadx55508+uij6LrO4sWLGTlyJOvXrwfMLjMwk8ell16Kw+GIuN/n87F7927uuuuuiON/+MMfOHbsGIqikJGR0e28EEKI+KMYPQ3AXODKysp6PB4P/ccSQ3zFITHEVxzxEENfccgYT3SkcoEQQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYssTqjUpLS1mzZg26rrNkyRKKi4sjzv/tb39j8+bNAOi6zsmTJ1m9ejWJiYl885vfxOFwoKoqmqbx2GOPAdDc3MyqVauoqqoiIyODe++9l8TExFh9JCGEEGchJolH13VWr17NAw88gNvt5v7776egoIDc3NzwNcuXL2f58uUA7Ny5k1deeSUiifzoRz8iOTk54rnr1q0jPz+f4uJi1q1bx7p16/jSl74Ui48khBDiLMWkq+3w4cNkZ2eTlZWFxWJh/vz57Nixo9frt27dyoIFC/p97o4dO1i0aBEAixYt6vOZQggh4kNMWjy1tbW43e7wa7fbzaFDh3q81ufzUVpayle/+tWI448++igAV111FUVFRQA0NDSQlpYGQFpaGo2NjT0+s6SkhJKSEgAee+wxPB5Pj9dZLJZez8WKxBBfcUgM8RVHPMQQT3Gcr2KSeAzD6HZMUZQer921axeTJk2K6GZ75JFHSE9Pp6GhgR//+Mfk5OQwderUqN+/qKgonKwAqqure7zO4/H0ei5WJIb4ikNiiK844iGGvuLIyckZhmjOPzHpanO73dTU1IRf19TUhFsqZ9q6dSuFhYURx9LT0wFISUlhzpw5HD58OPy6rq4OgLq6um5jQEIIIeJPTBJPXl4e5eXlVFZWEgwG2bZtGwUFBd2ua21tZf/+/RHnvF4vbW1t4b/v3r2bUaNGAVBQUMDGjRsB2LhxI3PmzInBpxFCCHEuYtLVpmkad955J48++ii6rrN48WJGjhzJ+vXrAVi6dCkA27dv59JLL8XhcITvbWho4MknnwQgFApRWFjIzJkzASguLmbVqlW8+eabeDwevvvd78bi4wghhDgHitHTAMwFrqysrMfj8dB/LDHEVxwSQ3zFEQ8x9BWHjPFERyoXCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEIIIWLKEqs3Ki0tZc2aNei6zpIlSyguLo44/7e//Y3NmzcDoOs6J0+eZPXq1Xi9Xp555hnq6+tRFIWioiI++9nPAvDSSy/xxhtvkJycDMCtt97KrFmzYvWRhBBCnIWYJB5d11m9ejUPPPAAbreb+++/n4KCAnJzc8PXLF++nOXLlwOwc+dOXnnlFRITEwkEAnz5y19m3LhxtLW1sXLlSmbMmBG+d9myZeH7hBBCxL+YdLUdPnyY7OxssrKysFgszJ8/nx07dvR6/datW1mwYAEAaWlpjBs3DgCn08mIESOora2NRdhCCCGGQExaPLW1tbjd7vBrt9vNoUOHerzW5/NRWlrKV7/61W7nKisr+fjjjxk/fnz42GuvvcamTZsYN24ct99+O4mJid3uKykpoaSkBIDHHnsMj8fT43tbLJZez8WKxBBfcUgM8RVHPMQQT3Gcr2KSeAzD6HZMUZQer921axeTJk3qlkC8Xi8/+9nPuOOOO3C5XAAsXbqUm266CYAXX3yR559/nrvvvrvbM4uKiigqKgq/rq6u7vG9PR5Pr+diRWKIrzgkhviKIx5i6CuOnJycYYjm/BOTrja3201NTU34dU1NDWlpaT1eu3XrVgoLCyOOBYNBfvazn7Fw4ULmzZsXPp6amoqqqqiqypIlSzhy5MjQfAAhhBCDJiaJJy8vj/LyciorKwkGg2zbto2CgoJu17W2trJ///6Ic4Zh8Ktf/YoRI0Zw7bXXRlxfV1cX/vv27dsZOXLk0H0IIYQQgyImXW2apnHnnXfy6KOPous6ixcvZuTIkaxfvx4wu8zATB6XXnopDocjfO9HH33Epk2bGDVqFPfddx/QOW36D3/4A8eOHUNRFDIyMrjrrrti8XGEEEKcA8XoaQDmAldWVtbj8XjoP5YY4isOiSG+4oiHGPqKQ8Z4oiOVC4QQQsSUJB4hhBAxJYlHCCFETEniEUIIEVOSeIQQQsSUJB4hhBAxJYlHCCFETEniEUIIEVOSeIQQQsTURVm5QAghxPCRFk8XK1euHO4QJIYu4iEOiaFTPMQRDzFA/MRxvpLEI4QQIqYk8QghhIgpSTxddN2lVGIYfvEQh8TQKR7iiIcYIH7iOF/J5AIhhBAxJS0eIYQQMSWJRwghREzFZOvreFJaWsqaNWvQdZ0lS5ZQXFwccf7UqVM8++yzfPzxx9xyyy0sX758WOLYvHkzf/3rXwFwOBz867/+K2PGjIlpDDt27ODFF19EURQ0TeOOO+5g8uTJMY2hw+HDh/nhD3/Ivffey+WXXz6oMUQTx759+3j88cfJzMwEYN68edx0000xjaEjjrVr1xIKhUhKSuLhhx+OaQx/+9vf2Lx5MwC6rnPy5ElWr15NYmJiTONobW3l6aefpqamhlAoxHXXXcfixYtjGkNzczP/+Z//SUVFBVarlW984xuMGjVqUGO4YBkXkVAoZNxzzz3G6dOnjUAgYPzbv/2bceLEiYhr6uvrjUOHDhl//OMfjb/+9a/DFseHH35oNDU1GYZhGO+9955x//33xzyGtrY2Q9d1wzAM49ixY8a3v/3tmMfQcd1DDz1k/OQnPzHefvvtQY0h2jj27t1r/Pu///ugv/dAYmhubja+853vGFVVVYZhmP+txjqGrnbs2GE89NBDgxpDtHG8/PLLxu9//3vDMAyjoaHBuOOOO4xAIBDTGJ5//nnjpZdeMgzDME6ePGk8/PDDg/b+F7qLqqvt8OHDZGdnk5WVhcViYf78+ezYsSPimpSUFMaPH4+macMax6RJk8K/RU6YMIGampqYx+BwOFAUBQCfzxf+eyxjAPjnP//JvHnzSE5OHtT3H2gcQymaGLZs2cK8efPweDyA+d9qrGPoauvWrSxYsGBQY4g2DkVR8Hq9GIaB1+slMTERVR28r7NoYjh58iT5+fkAjBgxgqqqKurr6wcthgvZRZV4amtrcbvd4ddut5va2tq4j+PNN9/ksssuG5YYtm/fzne+8x3+/d//nW984xsxj6G2tpbt27ezdOnSQX3vgcYBcPDgQe677z5+8pOfcOLEiZjHUF5eTnNzMw899BDf//732bhxY8xj6ODz+SgtLR2Sbs9o4rjmmms4deoUK1as4Hvf+x5f+cpXBjXxRBPD6NGjeffddwEzUVVVVQ3L98n56KJKPEYPM8cH+7f4wY5j7969bNiwgS9+8YvDEsPcuXP5j//4D+677z5efPHFmMewdu1avvjFLw7ql8rZxDF27FieffZZnnjiCa655hqeeOKJmMcQCoX4+OOPWblyJT/84Q95+eWXKSsri2kMHXbt2hXRKh9M0cTxwQcfMHr0aJ577jmeeOIJVq9eTWtra0xjKC4upqWlhfvuu49//vOfjB07dkj/O72QXFSTC9xud0SXVU1NDWlpaXEbx/Hjx3nuuee4//77SUpKGpYYOkydOpVnnnmGxsbGQevyiiaGI0eO8NRTTwHQ2NjI+++/j6qqzJ07d1BiiDYOl8sV/vusWbNYvXp1zH8WbrebpKQkHA4HDoeDKVOmcPz4cXJycmIWQ4etW7dSWFg4KO97NnFs2LCB4uJiFEUhOzubzMxMysrKGD9+fMxicLlc3H333YCZqO65557w5BPRt4sqPefl5VFeXk5lZSXBYJBt27ZRUFAQl3FUV1fz5JNPcs899wzaF8tAYzh9+nT4N7+jR48SDAYHNQFGE8MzzzwT/ufyyy/nX//1Xwc16UQbR319ffhncfjwYXRdj/nPoqCggA8//JBQKITP5+Pw4cOMGDEipjGAOaNs//79Q/b/TjRxeDwe9uzZA5j/bsrKygb1Sz+aGFpaWggGgwC88cYbTJkyJeIXFNG7i65ywXvvvcfvfvc7dF1n8eLF3HDDDaxfvx6ApUuXUl9fz8qVK2lra0NRFBwOBz//+c8H/T+o/uL41a9+xbvvvhseSNY0jcceeyymMaxbt45NmzahaRo2m40vf/nLgz6dur8YunrmmWeYPXv2kIwr9BfHq6++yvr168M/i9tvv51JkybFNAYwpzNv2LABVVW58sorWbZsWcxjeOuttygtLeU73/nOoL73QOKora3l2Wefpa6uDoDPfe5zfOpTn4ppDAcPHuSXv/wlqqqSm5vL17/+9SHperwQXXSJRwghxPC6qLrahBBCDD9JPEIIIWJKEo8QQoiYksQjhBAipiTxCCGEiClJPEJE6de//jX//d//PdxhCHHek+nUQvTgrbfe4o033uCRRx4Z7lCEuOBIi0dclEKh0HCHIMRFS1o84qLxzW9+k6uuuootW7ZQVlbGjTfeyFtvvUVDQwNut5tbb72VuXPncvLkSb7//e8TDAax2WxomsbatWt55plncLvd3HLLLQCUlJTw17/+lebmZiZPnszXvvY10tPTh/lTChH/pMUjLipbt25l5cqVrF27lpycHB5++GHWrl3L5z//eX7xi19QV1dHbm4uX/va15g4cSK///3vWbt2bbfn7N27lz/96U/ce++9/PrXvyYjIyNczFQI0TdJPOKi8pnPfAaPx4PNZuOKK64gPT0dVVWZP38+2dnZHD58OKrnbN68mcWLFzNu3DisViu33XYbBw8epLKycog/gRDnv4tqWwQhOoquAmzcuJF//OMfVFVVAeD1emlqaorqOXV1dYwdOzb82uFwkJiYSG1trZTGF6IfknjERamqqornnnuOBx98kIkTJ6KqKvfdd1+PG4D1JC0tjerq6vBrr9dLc3OzjPEIEQXpahMXJZ/Ph6Io4Y3cNmzYELGddWpqKrW1teH9Vs5UWFjIhg0bOHbsGIFAgD/96U+MHz9eWjtCREFaPOKilJuby7XXXssPf/hDVFXlU5/6VMT+OtOnTw9PMlBVldWrV0fcn5+fzxe+8AV+9rOf0dzczKRJk4Z0fxohLiQynVoIIURMSVebEEKImJLEI4QQIqYk8QghhIgpSTxCCCFiShKPEEKImJLEI4QQIqYk8QghhIgpSTxCCCFi6v8D/ph7ArpWj0oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 427.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 433.75x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_3a_1.columns = results_3a_2.columns = results_3a_5.columns = results_3a_10.columns = ['ratio', 'accuracy', 'name']\n",
    "\n",
    "concat_1  = pd.concat((results_3a_svm, results_3a_1))\n",
    "concat_2  = pd.concat((results_3a_svm, results_3a_2))\n",
    "concat_5  = pd.concat((results_3a_svm, results_3a_5))\n",
    "concat_10 = pd.concat((results_3a_svm, results_3a_10))\n",
    "\n",
    "def plot(data, filename):\n",
    "    ax = sns.lmplot(x='ratio', y='accuracy', hue='name', data=data)\n",
    "    ax.set(xlim=(0.08, 0.92))\n",
    "    ax.savefig(filename)\n",
    "    \n",
    "plot(concat_1,  'cnn_1.svg')\n",
    "plot(concat_2,  'cnn_2.svg')\n",
    "plot(concat_5,  'cnn_5.svg')\n",
    "plot(concat_10, 'cnn_10.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3a_svm.to_csv('svm.csv')\n",
    "results_3a_1.to_csv('cnn_1.csv')\n",
    "results_3a_2.to_csv('cnn_2.csv')\n",
    "results_3a_5.to_csv('cnn_5.csv')\n",
    "results_3a_10.to_csv('cnn_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "25952/60000 [===========>..................] - ETA: 3s - loss: 0.4932 - accuracy: 0.8219"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e77ea0b72bfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2), strides=2),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print({'accuracy': accuracy, 'loss': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
