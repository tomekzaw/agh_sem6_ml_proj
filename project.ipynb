{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import backend as K\n",
    "import scikitplot as skplt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layers_1_s = [\n",
    "    Conv2D(4, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_2_s = [\n",
    "    Conv2D(4, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_5_s = [\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(6, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_10_s = [\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(4, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_1_l = [\n",
    "    Conv2D(4, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_2_l = [\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_5_l = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_10_l = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(12, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns = {\n",
    "    'CNN 1 S': layers_1_s,\n",
    "    'CNN 2 S': layers_2_s,\n",
    "    'CNN 5 S': layers_5_s,\n",
    "    'CNN 10 S': layers_10_s,\n",
    "    'CNN 1 L': layers_1_l,\n",
    "    'CNN 2 L': layers_2_l,\n",
    "    'CNN 5 L': layers_5_l,\n",
    "    'CNN 10 L': layers_10_l,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_org, y_train_org), (X_test_org, y_test_org) = fashion_mnist.load_data()\n",
    "\n",
    "X_train_org = X_train_org.reshape(-1, 28, 28, 1)\n",
    "X_test_org = X_test_org.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_org = X_train_org.astype('float32')\n",
    "X_test_org = X_test_org.astype('float32')\n",
    "X_train_org /= 255\n",
    "X_test_org /= 255\n",
    "\n",
    "X_train_org, y_train_org = resample(X_train_org, y_train_org, random_state=0)\n",
    "X_test_org, y_test_org = resample(X_test_org, y_test_org, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(train_samples, test_samples):\n",
    "    X_train = X_train_org[:train_samples]\n",
    "    y_train = y_train_org[:train_samples]\n",
    "    X_test = X_test_org[:test_samples]\n",
    "    y_test = y_test_org[:test_samples]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_test_samples(total_samples, ratio):\n",
    "    train_samples = int(total_samples * ratio)\n",
    "    test_samples = total_samples - train_samples\n",
    "    return train_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_roc(y_test, y_pred, figsize=(8, 5))\n",
    "    ax.set(xlim=(-0.04, 1.04), ylim=(-0.04, 1.04))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_confusion_matrix(y_test, y_pred.argmax(axis=1), normalize=True, figsize=(7, 7))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_precision_recall(y_test, y_pred, figsize=(8, 6))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "    \n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_m(y_true, y_pred):  \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm(train_samples, test_samples):\n",
    "    X_train, y_train, X_test, y_test = get_train_test_data(train_samples, test_samples)\n",
    "    \n",
    "    X_train = X_train.reshape(-1, 784)\n",
    "    X_test = X_test.reshape(-1, 784)\n",
    "    \n",
    "    svc = SVC(C=5.0, kernel='rbf', probability=True)\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = svc.predict(X_test)\n",
    "    y_pred_proba = svc.predict_proba(X_test)\n",
    "    \n",
    "    accuracy = cross_val_score(svc, X_train, y_train, cv=5).mean()\n",
    "    val_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    roc = plot_roc(y_test, y_pred_proba)\n",
    "    pr = plot_pr(y_test, y_pred_proba)\n",
    "    cm = plot_cm(y_test, y_pred_proba)\n",
    "    \n",
    "    return accuracy, val_accuracy, roc, pr, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn(layers, train_samples, test_samples, epochs):\n",
    "    X_train, y_train, X_test, y_test = get_train_test_data(train_samples, test_samples)    \n",
    "    \n",
    "    clear_session()\n",
    "    np.random.seed(0x859)\n",
    "    tf.random.set_seed(0x859)\n",
    "    \n",
    "    model = Sequential(layers)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy', f1_m])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=True)\n",
    "    \n",
    "    loss = history.history['loss'][-1]\n",
    "    accuracy = history.history['accuracy'][-1]\n",
    "    f1 = history.history['f1_m'][-1]\n",
    "    \n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    val_f1 = history.history['val_f1_m'][-1]\n",
    "       \n",
    "    y_pred_proba = model.predict(X_test, verbose=False)\n",
    "    \n",
    "    roc = plot_roc(y_test, y_pred_proba)\n",
    "    pr = plot_pr(y_test, y_pred_proba)\n",
    "    cm = plot_cm(y_test, y_pred_proba)\n",
    "    \n",
    "    return loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_size(results_df, size):\n",
    "    return results_df[results_df['model'].str.endswith(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3a(data):\n",
    "    ax = sns.lmplot(x='ratio', y='val_accuracy', hue='model', data=data)\n",
    "    ax.set(xlim=(0.08, 0.92))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3b(data):\n",
    "    ax = sns.lmplot(x='epochs', y='val_accuracy', hue='model', data=data)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>ratio</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.779400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1000</td>\n",
       "      <td>19000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.809500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1500</td>\n",
       "      <td>18500</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.835333</td>\n",
       "      <td>0.815900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2000</td>\n",
       "      <td>18000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.822400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2500</td>\n",
       "      <td>17500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.840400</td>\n",
       "      <td>0.830500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3000</td>\n",
       "      <td>17000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.839600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3500</td>\n",
       "      <td>16500</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4000</td>\n",
       "      <td>16000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.850500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4500</td>\n",
       "      <td>15500</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.854800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>5000</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.859800</td>\n",
       "      <td>0.854600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>5500</td>\n",
       "      <td>14500</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.857300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>6000</td>\n",
       "      <td>14000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.863500</td>\n",
       "      <td>0.853500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>6500</td>\n",
       "      <td>13500</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.865077</td>\n",
       "      <td>0.857300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM</td>\n",
       "      <td>7000</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.868714</td>\n",
       "      <td>0.856800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM</td>\n",
       "      <td>7500</td>\n",
       "      <td>12500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.860600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8000</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.870625</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8500</td>\n",
       "      <td>11500</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.873294</td>\n",
       "      <td>0.865100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>9000</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.866700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM</td>\n",
       "      <td>9500</td>\n",
       "      <td>10500</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.877263</td>\n",
       "      <td>0.866300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.882600</td>\n",
       "      <td>0.866900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVM</td>\n",
       "      <td>10500</td>\n",
       "      <td>9500</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.868632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVM</td>\n",
       "      <td>11000</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.884727</td>\n",
       "      <td>0.868444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVM</td>\n",
       "      <td>11500</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.886696</td>\n",
       "      <td>0.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>12000</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.885583</td>\n",
       "      <td>0.870625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM</td>\n",
       "      <td>12500</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.887760</td>\n",
       "      <td>0.868267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVM</td>\n",
       "      <td>13000</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.889692</td>\n",
       "      <td>0.871714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVM</td>\n",
       "      <td>13500</td>\n",
       "      <td>6500</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.890593</td>\n",
       "      <td>0.872769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVM</td>\n",
       "      <td>14000</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.890500</td>\n",
       "      <td>0.871833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVM</td>\n",
       "      <td>14500</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.890828</td>\n",
       "      <td>0.872909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>15000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.892067</td>\n",
       "      <td>0.871400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVM</td>\n",
       "      <td>15500</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.893935</td>\n",
       "      <td>0.867556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM</td>\n",
       "      <td>16000</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.893062</td>\n",
       "      <td>0.871250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVM</td>\n",
       "      <td>16500</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.892303</td>\n",
       "      <td>0.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM</td>\n",
       "      <td>17000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.893353</td>\n",
       "      <td>0.872667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVM</td>\n",
       "      <td>17500</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.894057</td>\n",
       "      <td>0.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>18000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVM</td>\n",
       "      <td>18500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.897676</td>\n",
       "      <td>0.886000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SVM</td>\n",
       "      <td>19000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.899684</td>\n",
       "      <td>0.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVM</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.872000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  train_samples  test_samples  ratio  accuracy  val_accuracy\n",
       "0    SVM            500         19500  0.025  0.780000      0.779400\n",
       "1    SVM           1000         19000  0.050  0.833000      0.809500\n",
       "2    SVM           1500         18500  0.075  0.835333      0.815900\n",
       "3    SVM           2000         18000  0.100  0.840500      0.822400\n",
       "4    SVM           2500         17500  0.125  0.840400      0.830500\n",
       "5    SVM           3000         17000  0.150  0.846667      0.839600\n",
       "6    SVM           3500         16500  0.175  0.851429      0.845000\n",
       "7    SVM           4000         16000  0.200  0.848000      0.850500\n",
       "8    SVM           4500         15500  0.225  0.854444      0.854800\n",
       "9    SVM           5000         15000  0.250  0.859800      0.854600\n",
       "10   SVM           5500         14500  0.275  0.860000      0.857300\n",
       "11   SVM           6000         14000  0.300  0.863500      0.853500\n",
       "12   SVM           6500         13500  0.325  0.865077      0.857300\n",
       "13   SVM           7000         13000  0.350  0.868714      0.856800\n",
       "14   SVM           7500         12500  0.375  0.869333      0.860600\n",
       "15   SVM           8000         12000  0.400  0.870625      0.863300\n",
       "16   SVM           8500         11500  0.425  0.873294      0.865100\n",
       "17   SVM           9000         11000  0.450  0.874222      0.866700\n",
       "18   SVM           9500         10500  0.475  0.877263      0.866300\n",
       "19   SVM          10000         10000  0.500  0.882600      0.866900\n",
       "20   SVM          10500          9500  0.525  0.886000      0.868632\n",
       "21   SVM          11000          9000  0.550  0.884727      0.868444\n",
       "22   SVM          11500          8500  0.575  0.886696      0.872000\n",
       "23   SVM          12000          8000  0.600  0.885583      0.870625\n",
       "24   SVM          12500          7500  0.625  0.887760      0.868267\n",
       "25   SVM          13000          7000  0.650  0.889692      0.871714\n",
       "26   SVM          13500          6500  0.675  0.890593      0.872769\n",
       "27   SVM          14000          6000  0.700  0.890500      0.871833\n",
       "28   SVM          14500          5500  0.725  0.890828      0.872909\n",
       "29   SVM          15000          5000  0.750  0.892067      0.871400\n",
       "30   SVM          15500          4500  0.775  0.893935      0.867556\n",
       "31   SVM          16000          4000  0.800  0.893062      0.871250\n",
       "32   SVM          16500          3500  0.825  0.892303      0.874000\n",
       "33   SVM          17000          3000  0.850  0.893353      0.872667\n",
       "34   SVM          17500          2500  0.875  0.894057      0.871600\n",
       "35   SVM          18000          2000  0.900  0.894000      0.881000\n",
       "36   SVM          18500          1500  0.925  0.897676      0.886000\n",
       "37   SVM          19000          1000  0.950  0.899684      0.883000\n",
       "38   SVM          19500           500  0.975  0.900667      0.872000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_3a_svm():\n",
    "    total_samples = 20000\n",
    "    ratios = np.arange(0.025, 1.0, 0.025)\n",
    "    \n",
    "#     total_samples = 300\n",
    "#     ratios = [0.2, 0.8]\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        train_samples, test_samples = calc_train_test_samples(total_samples, ratio)               \n",
    "        accuracy, val_accuracy, roc, pr, cm = evaluate_svm(train_samples, test_samples)\n",
    "        \n",
    "        yield 'SVM', train_samples, test_samples, ratio, accuracy, val_accuracy        \n",
    "        roc.savefig(f'plots/3a/svm_{ratio}_roc.svg')\n",
    "        pr.savefig(f'plots/3a/svm_{ratio}_pr.svg')\n",
    "        cm.savefig(f'plots/3a/svm_{ratio}_cm.svg')          \n",
    "        plt.close('all')\n",
    "        \n",
    "        \n",
    "results_3a_svm = pd.DataFrame(gen_3a_svm(), columns=[\n",
    "    'model', 'train_samples', 'test_samples', 'ratio', 'accuracy', 'val_accuracy'\n",
    "])\n",
    "results_3a_svm.to_csv('results/3a_svm.csv')\n",
    "results_3a_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 2.1395 - accuracy: 0.2700 - f1_m: 8.6953 - val_loss: 2.0113 - val_accuracy: 0.3435 - val_f1_m: 7.9065\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.8027 - accuracy: 0.4500 - f1_m: 6.4183 - val_loss: 1.7398 - val_accuracy: 0.4417 - val_f1_m: 5.5431\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.5164 - accuracy: 0.5260 - f1_m: 4.4678 - val_loss: 1.4761 - val_accuracy: 0.5302 - val_f1_m: 4.7109\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.2884 - accuracy: 0.5820 - f1_m: 4.0485 - val_loss: 1.2918 - val_accuracy: 0.5867 - val_f1_m: 3.9834\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.1618 - accuracy: 0.6420 - f1_m: 3.5330 - val_loss: 1.1974 - val_accuracy: 0.5717 - val_f1_m: 3.4574\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.0252 - accuracy: 0.6340 - f1_m: 3.1513 - val_loss: 1.1451 - val_accuracy: 0.6008 - val_f1_m: 3.1288\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.9339 - accuracy: 0.6940 - f1_m: 2.9436 - val_loss: 1.0280 - val_accuracy: 0.6320 - val_f1_m: 2.8482\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8740 - accuracy: 0.7100 - f1_m: 2.6309 - val_loss: 1.0064 - val_accuracy: 0.6231 - val_f1_m: 2.5775\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8413 - accuracy: 0.7140 - f1_m: 2.4636 - val_loss: 0.9253 - val_accuracy: 0.6704 - val_f1_m: 2.6158\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7466 - accuracy: 0.7360 - f1_m: 2.2869 - val_loss: 0.8742 - val_accuracy: 0.6861 - val_f1_m: 2.3851\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 2.2125 - accuracy: 0.2740 - f1_m: 9.2867 - val_loss: 2.0507 - val_accuracy: 0.3991 - val_f1_m: 8.8944\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.8467 - accuracy: 0.4780 - f1_m: 7.4383 - val_loss: 1.6305 - val_accuracy: 0.4565 - val_f1_m: 5.9875\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.3798 - accuracy: 0.5360 - f1_m: 4.1691 - val_loss: 1.2318 - val_accuracy: 0.5483 - val_f1_m: 3.9374\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.0524 - accuracy: 0.6040 - f1_m: 3.2324 - val_loss: 1.0336 - val_accuracy: 0.6003 - val_f1_m: 3.0398\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.9482 - accuracy: 0.6480 - f1_m: 2.6653 - val_loss: 0.9277 - val_accuracy: 0.6185 - val_f1_m: 2.6470\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8527 - accuracy: 0.6740 - f1_m: 2.5002 - val_loss: 0.8912 - val_accuracy: 0.6363 - val_f1_m: 2.4494\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7844 - accuracy: 0.7140 - f1_m: 2.2807 - val_loss: 0.8557 - val_accuracy: 0.6678 - val_f1_m: 2.2583\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7531 - accuracy: 0.7340 - f1_m: 2.1433 - val_loss: 0.8275 - val_accuracy: 0.6787 - val_f1_m: 2.2480\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7233 - accuracy: 0.7340 - f1_m: 2.0427 - val_loss: 0.7939 - val_accuracy: 0.6897 - val_f1_m: 2.1958\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6676 - accuracy: 0.7440 - f1_m: 2.0033 - val_loss: 0.7599 - val_accuracy: 0.7256 - val_f1_m: 2.0854\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 5ms/sample - loss: 2.2256 - accuracy: 0.2020 - f1_m: 9.5372 - val_loss: 2.1121 - val_accuracy: 0.2434 - val_f1_m: 9.4111\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.8144 - accuracy: 0.3220 - f1_m: 7.4569 - val_loss: 1.6180 - val_accuracy: 0.3417 - val_f1_m: 5.8108\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.3111 - accuracy: 0.5260 - f1_m: 3.6362 - val_loss: 1.2259 - val_accuracy: 0.5200 - val_f1_m: 3.1505\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.1039 - accuracy: 0.5760 - f1_m: 2.7396 - val_loss: 1.1037 - val_accuracy: 0.5377 - val_f1_m: 2.7743\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.0087 - accuracy: 0.5980 - f1_m: 2.5378 - val_loss: 1.0945 - val_accuracy: 0.5650 - val_f1_m: 2.4800\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.0063 - accuracy: 0.6120 - f1_m: 2.2762 - val_loss: 1.0337 - val_accuracy: 0.5804 - val_f1_m: 2.6205\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8972 - accuracy: 0.6560 - f1_m: 2.4690 - val_loss: 0.9573 - val_accuracy: 0.6228 - val_f1_m: 2.4733\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8413 - accuracy: 0.6700 - f1_m: 2.1504 - val_loss: 1.0359 - val_accuracy: 0.6305 - val_f1_m: 2.0280\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8601 - accuracy: 0.7020 - f1_m: 2.0800 - val_loss: 1.0995 - val_accuracy: 0.6094 - val_f1_m: 1.8995\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7896 - accuracy: 0.7060 - f1_m: 2.1030 - val_loss: 0.8786 - val_accuracy: 0.6742 - val_f1_m: 2.1806\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 2.2883 - accuracy: 0.2160 - f1_m: 9.7766 - val_loss: 2.2295 - val_accuracy: 0.2690 - val_f1_m: 9.5180\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 2.0585 - accuracy: 0.2680 - f1_m: 7.3191 - val_loss: 1.9004 - val_accuracy: 0.3366 - val_f1_m: 6.6767\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.5024 - accuracy: 0.4640 - f1_m: 4.0319 - val_loss: 1.5169 - val_accuracy: 0.4535 - val_f1_m: 2.8210\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.2603 - accuracy: 0.5420 - f1_m: 3.1372 - val_loss: 1.2198 - val_accuracy: 0.5089 - val_f1_m: 3.3239\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 1.0800 - accuracy: 0.6080 - f1_m: 2.6927 - val_loss: 1.0487 - val_accuracy: 0.6085 - val_f1_m: 2.5220\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.9690 - accuracy: 0.6560 - f1_m: 2.0314 - val_loss: 0.9993 - val_accuracy: 0.6320 - val_f1_m: 2.5266\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.8621 - accuracy: 0.7040 - f1_m: 2.2502 - val_loss: 0.9875 - val_accuracy: 0.6514 - val_f1_m: 2.0120\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8506 - accuracy: 0.7180 - f1_m: 1.9978 - val_loss: 0.8954 - val_accuracy: 0.6861 - val_f1_m: 2.1278\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.8329 - accuracy: 0.7000 - f1_m: 2.0803 - val_loss: 0.9769 - val_accuracy: 0.6468 - val_f1_m: 1.9360\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7532 - accuracy: 0.7380 - f1_m: 1.8870 - val_loss: 0.9089 - val_accuracy: 0.6930 - val_f1_m: 1.8135\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 1.8342 - accuracy: 0.3420 - f1_m: 7.2535 - val_loss: 1.4197 - val_accuracy: 0.5395 - val_f1_m: 5.1191\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.1594 - accuracy: 0.6160 - f1_m: 3.7860 - val_loss: 1.1411 - val_accuracy: 0.5950 - val_f1_m: 3.0323\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.9406 - accuracy: 0.6680 - f1_m: 2.7022 - val_loss: 0.9424 - val_accuracy: 0.6478 - val_f1_m: 2.6028\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7743 - accuracy: 0.7200 - f1_m: 2.3789 - val_loss: 0.9011 - val_accuracy: 0.6489 - val_f1_m: 2.2416\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7374 - accuracy: 0.7360 - f1_m: 2.0571 - val_loss: 0.8869 - val_accuracy: 0.6368 - val_f1_m: 2.2196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6793 - accuracy: 0.7440 - f1_m: 2.0236 - val_loss: 0.8119 - val_accuracy: 0.6843 - val_f1_m: 2.1356\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6064 - accuracy: 0.7920 - f1_m: 1.9512 - val_loss: 0.7519 - val_accuracy: 0.7163 - val_f1_m: 1.9866\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5710 - accuracy: 0.7960 - f1_m: 1.8086 - val_loss: 0.8059 - val_accuracy: 0.7025 - val_f1_m: 1.8593\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5708 - accuracy: 0.7980 - f1_m: 1.7698 - val_loss: 0.8193 - val_accuracy: 0.6851 - val_f1_m: 1.8503\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4940 - accuracy: 0.8340 - f1_m: 1.7167 - val_loss: 0.6928 - val_accuracy: 0.7567 - val_f1_m: 1.8749\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 2.0235 - accuracy: 0.3360 - f1_m: 8.7651 - val_loss: 1.6509 - val_accuracy: 0.4694 - val_f1_m: 6.6193\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.2934 - accuracy: 0.5600 - f1_m: 4.0658 - val_loss: 1.3010 - val_accuracy: 0.4520 - val_f1_m: 3.0863\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.9684 - accuracy: 0.6260 - f1_m: 2.5482 - val_loss: 0.8813 - val_accuracy: 0.6741 - val_f1_m: 2.4707\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8023 - accuracy: 0.7120 - f1_m: 2.2030 - val_loss: 0.8061 - val_accuracy: 0.7158 - val_f1_m: 2.2568\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7428 - accuracy: 0.7620 - f1_m: 1.9493 - val_loss: 0.9041 - val_accuracy: 0.6473 - val_f1_m: 2.0723\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7212 - accuracy: 0.7280 - f1_m: 1.8618 - val_loss: 0.8134 - val_accuracy: 0.7093 - val_f1_m: 1.8518\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6153 - accuracy: 0.7940 - f1_m: 1.8674 - val_loss: 0.7105 - val_accuracy: 0.7435 - val_f1_m: 1.9769\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5740 - accuracy: 0.7960 - f1_m: 1.7295 - val_loss: 0.7935 - val_accuracy: 0.7084 - val_f1_m: 1.6411\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5809 - accuracy: 0.7920 - f1_m: 1.6426 - val_loss: 0.7449 - val_accuracy: 0.7133 - val_f1_m: 1.6427\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4930 - accuracy: 0.8100 - f1_m: 1.6498 - val_loss: 0.6637 - val_accuracy: 0.7551 - val_f1_m: 1.6729\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 2.1360 - accuracy: 0.2640 - f1_m: 9.2548 - val_loss: 1.7194 - val_accuracy: 0.4030 - val_f1_m: 7.2178\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.3790 - accuracy: 0.5140 - f1_m: 3.5894 - val_loss: 1.2346 - val_accuracy: 0.5264 - val_f1_m: 3.3760\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.0586 - accuracy: 0.6120 - f1_m: 2.6957 - val_loss: 0.9854 - val_accuracy: 0.6264 - val_f1_m: 2.3686\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8926 - accuracy: 0.6600 - f1_m: 2.1593 - val_loss: 0.9062 - val_accuracy: 0.6612 - val_f1_m: 2.2793\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7892 - accuracy: 0.7280 - f1_m: 2.1192 - val_loss: 0.9017 - val_accuracy: 0.6724 - val_f1_m: 2.0329\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7507 - accuracy: 0.7340 - f1_m: 1.9384 - val_loss: 0.8257 - val_accuracy: 0.7061 - val_f1_m: 1.9670\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.7560 - f1_m: 1.8892 - val_loss: 0.7849 - val_accuracy: 0.7058 - val_f1_m: 1.7635\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5946 - accuracy: 0.7920 - f1_m: 1.6447 - val_loss: 0.7641 - val_accuracy: 0.7335 - val_f1_m: 1.6313\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5723 - accuracy: 0.8000 - f1_m: 1.6876 - val_loss: 0.7861 - val_accuracy: 0.7121 - val_f1_m: 1.6464\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4889 - accuracy: 0.8320 - f1_m: 1.6217 - val_loss: 0.7521 - val_accuracy: 0.7360 - val_f1_m: 1.5106\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 2.2321 - accuracy: 0.1580 - f1_m: 9.6695 - val_loss: 1.9031 - val_accuracy: 0.3578 - val_f1_m: 8.1830\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 1.4651 - accuracy: 0.4880 - f1_m: 3.9824 - val_loss: 1.2830 - val_accuracy: 0.4843 - val_f1_m: 3.4376\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 1.0899 - accuracy: 0.6020 - f1_m: 2.5102 - val_loss: 1.1000 - val_accuracy: 0.5973 - val_f1_m: 2.0117\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 1.0166 - accuracy: 0.6180 - f1_m: 2.3152 - val_loss: 1.0462 - val_accuracy: 0.5904 - val_f1_m: 2.6991\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.9221 - accuracy: 0.6680 - f1_m: 2.1481 - val_loss: 1.0000 - val_accuracy: 0.5868 - val_f1_m: 2.3267\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.8287 - accuracy: 0.6720 - f1_m: 1.9637 - val_loss: 0.8412 - val_accuracy: 0.7114 - val_f1_m: 1.9525\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.7670 - accuracy: 0.7140 - f1_m: 1.9443 - val_loss: 0.8680 - val_accuracy: 0.6834 - val_f1_m: 1.8763\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.6977 - accuracy: 0.7660 - f1_m: 1.7167 - val_loss: 0.8687 - val_accuracy: 0.6987 - val_f1_m: 1.8746\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.7283 - accuracy: 0.7180 - f1_m: 1.8370 - val_loss: 0.8082 - val_accuracy: 0.6981 - val_f1_m: 1.7088\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.5869 - accuracy: 0.7860 - f1_m: 1.5934 - val_loss: 0.7677 - val_accuracy: 0.7368 - val_f1_m: 1.7176\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.7993 - accuracy: 0.7060 - f1_m: 2.2775 - val_loss: 0.8787 - val_accuracy: 0.6878 - val_f1_m: 2.0217\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.7171 - accuracy: 0.7510 - f1_m: 2.0444 - val_loss: 0.8378 - val_accuracy: 0.6954 - val_f1_m: 2.2690\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.6713 - accuracy: 0.7560 - f1_m: 2.0188 - val_loss: 0.7737 - val_accuracy: 0.7334 - val_f1_m: 2.0814\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.6481 - accuracy: 0.7690 - f1_m: 1.8465 - val_loss: 0.7623 - val_accuracy: 0.7312 - val_f1_m: 1.9956\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 610us/sample - loss: 0.6538 - accuracy: 0.7630 - f1_m: 1.8337 - val_loss: 0.7905 - val_accuracy: 0.7220 - val_f1_m: 1.9211\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.6001 - accuracy: 0.7840 - f1_m: 1.7984 - val_loss: 0.7949 - val_accuracy: 0.7159 - val_f1_m: 2.0049\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 610us/sample - loss: 0.5747 - accuracy: 0.7920 - f1_m: 1.7477 - val_loss: 0.7325 - val_accuracy: 0.7511 - val_f1_m: 1.8200\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 610us/sample - loss: 0.5342 - accuracy: 0.8150 - f1_m: 1.7025 - val_loss: 0.7644 - val_accuracy: 0.7330 - val_f1_m: 1.6616\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.5289 - accuracy: 0.8120 - f1_m: 1.6351 - val_loss: 0.8063 - val_accuracy: 0.7165 - val_f1_m: 1.7382\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 610us/sample - loss: 0.5080 - accuracy: 0.8340 - f1_m: 1.6405 - val_loss: 0.7103 - val_accuracy: 0.7617 - val_f1_m: 1.7693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6945 - accuracy: 0.7300 - f1_m: 1.9496 - val_loss: 0.7620 - val_accuracy: 0.7173 - val_f1_m: 1.8585\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 635us/sample - loss: 0.6550 - accuracy: 0.7550 - f1_m: 1.8176 - val_loss: 0.7261 - val_accuracy: 0.7280 - val_f1_m: 1.9936\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 640us/sample - loss: 0.6145 - accuracy: 0.7700 - f1_m: 1.8710 - val_loss: 0.7069 - val_accuracy: 0.7360 - val_f1_m: 1.8566\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 640us/sample - loss: 0.5980 - accuracy: 0.7880 - f1_m: 1.7161 - val_loss: 0.7222 - val_accuracy: 0.7300 - val_f1_m: 1.8195\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 645us/sample - loss: 0.6033 - accuracy: 0.7850 - f1_m: 1.6997 - val_loss: 0.6863 - val_accuracy: 0.7578 - val_f1_m: 1.7506\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 641us/sample - loss: 0.5430 - accuracy: 0.8090 - f1_m: 1.6904 - val_loss: 0.6600 - val_accuracy: 0.7572 - val_f1_m: 1.8075\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 633us/sample - loss: 0.5137 - accuracy: 0.8160 - f1_m: 1.6509 - val_loss: 0.6438 - val_accuracy: 0.7662 - val_f1_m: 1.6966\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 640us/sample - loss: 0.5003 - accuracy: 0.8180 - f1_m: 1.6035 - val_loss: 0.6561 - val_accuracy: 0.7622 - val_f1_m: 1.6220\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 640us/sample - loss: 0.4908 - accuracy: 0.8200 - f1_m: 1.5654 - val_loss: 0.6886 - val_accuracy: 0.7411 - val_f1_m: 1.6173\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 645us/sample - loss: 0.4653 - accuracy: 0.8280 - f1_m: 1.5551 - val_loss: 0.6312 - val_accuracy: 0.7715 - val_f1_m: 1.6933\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.8437 - accuracy: 0.6800 - f1_m: 2.0860 - val_loss: 0.9213 - val_accuracy: 0.6697 - val_f1_m: 1.9633\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 713us/sample - loss: 0.7368 - accuracy: 0.7420 - f1_m: 1.9428 - val_loss: 0.8548 - val_accuracy: 0.6814 - val_f1_m: 1.9641\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 711us/sample - loss: 0.7248 - accuracy: 0.7400 - f1_m: 1.8987 - val_loss: 0.7883 - val_accuracy: 0.7160 - val_f1_m: 1.9586\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 721us/sample - loss: 0.6910 - accuracy: 0.7630 - f1_m: 1.7587 - val_loss: 0.7613 - val_accuracy: 0.7396 - val_f1_m: 2.0440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 712us/sample - loss: 0.6355 - accuracy: 0.7780 - f1_m: 1.7455 - val_loss: 0.8133 - val_accuracy: 0.7131 - val_f1_m: 1.7510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 707us/sample - loss: 0.6060 - accuracy: 0.7860 - f1_m: 1.6987 - val_loss: 0.7695 - val_accuracy: 0.7273 - val_f1_m: 1.8092\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 704us/sample - loss: 0.5899 - accuracy: 0.7810 - f1_m: 1.6311 - val_loss: 0.7417 - val_accuracy: 0.7308 - val_f1_m: 1.7206\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 720us/sample - loss: 0.5537 - accuracy: 0.7970 - f1_m: 1.6156 - val_loss: 0.7350 - val_accuracy: 0.7422 - val_f1_m: 1.5480\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 710us/sample - loss: 0.5166 - accuracy: 0.8060 - f1_m: 1.5593 - val_loss: 0.7086 - val_accuracy: 0.7439 - val_f1_m: 1.6145\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 717us/sample - loss: 0.4959 - accuracy: 0.8140 - f1_m: 1.4906 - val_loss: 0.6564 - val_accuracy: 0.7661 - val_f1_m: 1.7142\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.8403 - accuracy: 0.7100 - f1_m: 2.0177 - val_loss: 0.8879 - val_accuracy: 0.7092 - val_f1_m: 1.8447\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 828us/sample - loss: 0.7646 - accuracy: 0.7270 - f1_m: 1.8182 - val_loss: 0.9011 - val_accuracy: 0.6691 - val_f1_m: 1.8140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 824us/sample - loss: 0.7787 - accuracy: 0.7160 - f1_m: 1.8989 - val_loss: 0.8117 - val_accuracy: 0.7093 - val_f1_m: 2.0928\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 825us/sample - loss: 0.7644 - accuracy: 0.7380 - f1_m: 1.7894 - val_loss: 0.8996 - val_accuracy: 0.6777 - val_f1_m: 1.8005\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 828us/sample - loss: 0.7380 - accuracy: 0.7400 - f1_m: 1.8192 - val_loss: 0.7939 - val_accuracy: 0.7275 - val_f1_m: 1.8724\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.6761 - accuracy: 0.7760 - f1_m: 1.7345 - val_loss: 0.7990 - val_accuracy: 0.7158 - val_f1_m: 1.7531\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 825us/sample - loss: 0.6412 - accuracy: 0.7770 - f1_m: 1.7380 - val_loss: 0.7556 - val_accuracy: 0.7407 - val_f1_m: 1.6452\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 821us/sample - loss: 0.6284 - accuracy: 0.7690 - f1_m: 1.6355 - val_loss: 0.7608 - val_accuracy: 0.7372 - val_f1_m: 1.6588\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.5983 - accuracy: 0.7890 - f1_m: 1.5885 - val_loss: 0.8297 - val_accuracy: 0.7132 - val_f1_m: 1.7418\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 830us/sample - loss: 0.5607 - accuracy: 0.7990 - f1_m: 1.5816 - val_loss: 0.7419 - val_accuracy: 0.7428 - val_f1_m: 1.7036\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6310 - accuracy: 0.7680 - f1_m: 1.7578 - val_loss: 0.7416 - val_accuracy: 0.7466 - val_f1_m: 1.6994\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 620us/sample - loss: 0.5292 - accuracy: 0.8100 - f1_m: 1.6702 - val_loss: 0.7389 - val_accuracy: 0.7354 - val_f1_m: 1.8081\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 610us/sample - loss: 0.5202 - accuracy: 0.8060 - f1_m: 1.6449 - val_loss: 0.7045 - val_accuracy: 0.7472 - val_f1_m: 1.6286\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 620us/sample - loss: 0.5259 - accuracy: 0.8080 - f1_m: 1.4864 - val_loss: 0.7065 - val_accuracy: 0.7480 - val_f1_m: 1.6454\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 605us/sample - loss: 0.5125 - accuracy: 0.8110 - f1_m: 1.5588 - val_loss: 0.8047 - val_accuracy: 0.7229 - val_f1_m: 1.5937\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.4812 - accuracy: 0.8280 - f1_m: 1.5229 - val_loss: 0.6834 - val_accuracy: 0.7599 - val_f1_m: 1.6998\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 613us/sample - loss: 0.4201 - accuracy: 0.8470 - f1_m: 1.5031 - val_loss: 0.6495 - val_accuracy: 0.7771 - val_f1_m: 1.4959\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 607us/sample - loss: 0.3820 - accuracy: 0.8580 - f1_m: 1.4465 - val_loss: 0.6929 - val_accuracy: 0.7623 - val_f1_m: 1.4445\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.3704 - accuracy: 0.8680 - f1_m: 1.4237 - val_loss: 0.7008 - val_accuracy: 0.7595 - val_f1_m: 1.5263\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 615us/sample - loss: 0.3700 - accuracy: 0.8710 - f1_m: 1.3800 - val_loss: 0.6239 - val_accuracy: 0.7865 - val_f1_m: 1.5093\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5698 - accuracy: 0.7830 - f1_m: 1.6802 - val_loss: 0.6516 - val_accuracy: 0.7619 - val_f1_m: 1.6275\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 665us/sample - loss: 0.4986 - accuracy: 0.8070 - f1_m: 1.5993 - val_loss: 0.7221 - val_accuracy: 0.7371 - val_f1_m: 1.6206\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 665us/sample - loss: 0.4792 - accuracy: 0.8100 - f1_m: 1.5820 - val_loss: 0.6379 - val_accuracy: 0.7654 - val_f1_m: 1.6450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 680us/sample - loss: 0.4554 - accuracy: 0.8210 - f1_m: 1.4462 - val_loss: 0.6374 - val_accuracy: 0.7606 - val_f1_m: 1.5859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 675us/sample - loss: 0.4187 - accuracy: 0.8380 - f1_m: 1.4528 - val_loss: 0.6638 - val_accuracy: 0.7474 - val_f1_m: 1.5664\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 670us/sample - loss: 0.3881 - accuracy: 0.8640 - f1_m: 1.4641 - val_loss: 0.5780 - val_accuracy: 0.7903 - val_f1_m: 1.5351\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 665us/sample - loss: 0.3352 - accuracy: 0.8800 - f1_m: 1.3843 - val_loss: 0.6093 - val_accuracy: 0.7908 - val_f1_m: 1.3710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 675us/sample - loss: 0.3326 - accuracy: 0.8730 - f1_m: 1.3652 - val_loss: 0.6484 - val_accuracy: 0.7740 - val_f1_m: 1.3708\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 670us/sample - loss: 0.3003 - accuracy: 0.8870 - f1_m: 1.3129 - val_loss: 0.5760 - val_accuracy: 0.7910 - val_f1_m: 1.4519\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 665us/sample - loss: 0.2685 - accuracy: 0.9130 - f1_m: 1.2632 - val_loss: 0.5490 - val_accuracy: 0.8126 - val_f1_m: 1.3917\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6258 - accuracy: 0.7740 - f1_m: 1.6681 - val_loss: 0.7105 - val_accuracy: 0.7534 - val_f1_m: 1.6455\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 760us/sample - loss: 0.5014 - accuracy: 0.8270 - f1_m: 1.5284 - val_loss: 0.7338 - val_accuracy: 0.7320 - val_f1_m: 1.5085\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 750us/sample - loss: 0.4959 - accuracy: 0.8260 - f1_m: 1.5371 - val_loss: 0.6413 - val_accuracy: 0.7748 - val_f1_m: 1.5967\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 754us/sample - loss: 0.4640 - accuracy: 0.8300 - f1_m: 1.4567 - val_loss: 0.6258 - val_accuracy: 0.7790 - val_f1_m: 1.5052\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 750us/sample - loss: 0.4150 - accuracy: 0.8610 - f1_m: 1.3830 - val_loss: 0.6309 - val_accuracy: 0.7780 - val_f1_m: 1.4801\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 744us/sample - loss: 0.3627 - accuracy: 0.8660 - f1_m: 1.3629 - val_loss: 0.6465 - val_accuracy: 0.7712 - val_f1_m: 1.4115\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 750us/sample - loss: 0.3162 - accuracy: 0.8940 - f1_m: 1.2950 - val_loss: 0.5896 - val_accuracy: 0.8032 - val_f1_m: 1.3765\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 740us/sample - loss: 0.3092 - accuracy: 0.8760 - f1_m: 1.2858 - val_loss: 0.6423 - val_accuracy: 0.7821 - val_f1_m: 1.3787\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 738us/sample - loss: 0.2640 - accuracy: 0.9050 - f1_m: 1.2613 - val_loss: 0.6145 - val_accuracy: 0.8042 - val_f1_m: 1.2988\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 757us/sample - loss: 0.2436 - accuracy: 0.9210 - f1_m: 1.1959 - val_loss: 0.6161 - val_accuracy: 0.7945 - val_f1_m: 1.3248\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.7890 - accuracy: 0.7260 - f1_m: 1.8958 - val_loss: 0.7423 - val_accuracy: 0.7420 - val_f1_m: 1.6385\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 879us/sample - loss: 0.6486 - accuracy: 0.7750 - f1_m: 1.6182 - val_loss: 0.8045 - val_accuracy: 0.6914 - val_f1_m: 1.7046\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 880us/sample - loss: 0.6492 - accuracy: 0.7600 - f1_m: 1.7359 - val_loss: 0.7457 - val_accuracy: 0.7470 - val_f1_m: 1.6092\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 890us/sample - loss: 0.6140 - accuracy: 0.7780 - f1_m: 1.5953 - val_loss: 0.6860 - val_accuracy: 0.7547 - val_f1_m: 1.5850\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 890us/sample - loss: 0.5376 - accuracy: 0.8130 - f1_m: 1.5524 - val_loss: 0.6527 - val_accuracy: 0.7724 - val_f1_m: 1.5949\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 880us/sample - loss: 0.4807 - accuracy: 0.8240 - f1_m: 1.4731 - val_loss: 0.6352 - val_accuracy: 0.7679 - val_f1_m: 1.5806\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 880us/sample - loss: 0.4438 - accuracy: 0.8380 - f1_m: 1.4158 - val_loss: 0.6669 - val_accuracy: 0.7797 - val_f1_m: 1.4917\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 870us/sample - loss: 0.4253 - accuracy: 0.8410 - f1_m: 1.3929 - val_loss: 0.7717 - val_accuracy: 0.7532 - val_f1_m: 1.3592\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 885us/sample - loss: 0.3949 - accuracy: 0.8630 - f1_m: 1.3534 - val_loss: 0.7503 - val_accuracy: 0.7576 - val_f1_m: 1.3818\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 875us/sample - loss: 0.3602 - accuracy: 0.8670 - f1_m: 1.3012 - val_loss: 0.6514 - val_accuracy: 0.7537 - val_f1_m: 1.5228\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 753us/sample - loss: 0.5846 - accuracy: 0.8047 - f1_m: 1.6340 - val_loss: 0.6974 - val_accuracy: 0.7549 - val_f1_m: 1.6620\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 427us/sample - loss: 0.5564 - accuracy: 0.8033 - f1_m: 1.6233 - val_loss: 0.6841 - val_accuracy: 0.7568 - val_f1_m: 1.6647\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 430us/sample - loss: 0.5616 - accuracy: 0.8033 - f1_m: 1.6088 - val_loss: 0.6572 - val_accuracy: 0.7753 - val_f1_m: 1.7091\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 423us/sample - loss: 0.5287 - accuracy: 0.8173 - f1_m: 1.5708 - val_loss: 0.6329 - val_accuracy: 0.7811 - val_f1_m: 1.6356\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 430us/sample - loss: 0.5168 - accuracy: 0.8233 - f1_m: 1.5720 - val_loss: 0.6439 - val_accuracy: 0.7771 - val_f1_m: 1.6482\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 433us/sample - loss: 0.4944 - accuracy: 0.8220 - f1_m: 1.5591 - val_loss: 0.6223 - val_accuracy: 0.7814 - val_f1_m: 1.5846\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 430us/sample - loss: 0.4783 - accuracy: 0.8307 - f1_m: 1.5211 - val_loss: 0.6675 - val_accuracy: 0.7612 - val_f1_m: 1.5304\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 427us/sample - loss: 0.4831 - accuracy: 0.8267 - f1_m: 1.5263 - val_loss: 0.6393 - val_accuracy: 0.7868 - val_f1_m: 1.5570\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 433us/sample - loss: 0.4780 - accuracy: 0.8320 - f1_m: 1.4940 - val_loss: 0.6507 - val_accuracy: 0.7783 - val_f1_m: 1.6071\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 433us/sample - loss: 0.4631 - accuracy: 0.8413 - f1_m: 1.4928 - val_loss: 0.6491 - val_accuracy: 0.7857 - val_f1_m: 1.5158\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 813us/sample - loss: 0.5539 - accuracy: 0.8067 - f1_m: 1.6400 - val_loss: 0.6368 - val_accuracy: 0.7676 - val_f1_m: 1.6606\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 453us/sample - loss: 0.5113 - accuracy: 0.8207 - f1_m: 1.6418 - val_loss: 0.5849 - val_accuracy: 0.7932 - val_f1_m: 1.6340\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 456us/sample - loss: 0.5188 - accuracy: 0.8100 - f1_m: 1.5702 - val_loss: 0.5748 - val_accuracy: 0.7874 - val_f1_m: 1.6913\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 450us/sample - loss: 0.4868 - accuracy: 0.8193 - f1_m: 1.5389 - val_loss: 0.5679 - val_accuracy: 0.7962 - val_f1_m: 1.5564\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 454us/sample - loss: 0.4610 - accuracy: 0.8293 - f1_m: 1.5174 - val_loss: 0.5970 - val_accuracy: 0.7720 - val_f1_m: 1.5969\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 456us/sample - loss: 0.4730 - accuracy: 0.8233 - f1_m: 1.5049 - val_loss: 0.5452 - val_accuracy: 0.8007 - val_f1_m: 1.5519\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 454us/sample - loss: 0.4287 - accuracy: 0.8407 - f1_m: 1.4924 - val_loss: 0.5825 - val_accuracy: 0.7816 - val_f1_m: 1.4964\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 453us/sample - loss: 0.4373 - accuracy: 0.8473 - f1_m: 1.4727 - val_loss: 0.5505 - val_accuracy: 0.8002 - val_f1_m: 1.5378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 457us/sample - loss: 0.4098 - accuracy: 0.8480 - f1_m: 1.4644 - val_loss: 0.5485 - val_accuracy: 0.7966 - val_f1_m: 1.5402\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 450us/sample - loss: 0.3994 - accuracy: 0.8573 - f1_m: 1.4346 - val_loss: 0.5664 - val_accuracy: 0.7997 - val_f1_m: 1.4474\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.5846 - accuracy: 0.7907 - f1_m: 1.5661 - val_loss: 0.6530 - val_accuracy: 0.7646 - val_f1_m: 1.6910\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 504us/sample - loss: 0.5291 - accuracy: 0.8140 - f1_m: 1.5524 - val_loss: 0.6202 - val_accuracy: 0.7747 - val_f1_m: 1.5965\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 516us/sample - loss: 0.5342 - accuracy: 0.8087 - f1_m: 1.5513 - val_loss: 0.5924 - val_accuracy: 0.7910 - val_f1_m: 1.6450\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 513us/sample - loss: 0.4928 - accuracy: 0.8173 - f1_m: 1.5242 - val_loss: 0.6095 - val_accuracy: 0.7805 - val_f1_m: 1.6760\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 513us/sample - loss: 0.4690 - accuracy: 0.8333 - f1_m: 1.5157 - val_loss: 0.6131 - val_accuracy: 0.7710 - val_f1_m: 1.5312\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 506us/sample - loss: 0.4543 - accuracy: 0.8367 - f1_m: 1.4761 - val_loss: 0.5899 - val_accuracy: 0.7959 - val_f1_m: 1.5617\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 510us/sample - loss: 0.4237 - accuracy: 0.8507 - f1_m: 1.4084 - val_loss: 0.6324 - val_accuracy: 0.7642 - val_f1_m: 1.4693\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 507us/sample - loss: 0.4172 - accuracy: 0.8427 - f1_m: 1.3970 - val_loss: 0.6010 - val_accuracy: 0.7848 - val_f1_m: 1.5267\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 517us/sample - loss: 0.4014 - accuracy: 0.8633 - f1_m: 1.4056 - val_loss: 0.5761 - val_accuracy: 0.7992 - val_f1_m: 1.4694\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 510us/sample - loss: 0.3790 - accuracy: 0.8600 - f1_m: 1.3778 - val_loss: 0.6042 - val_accuracy: 0.7912 - val_f1_m: 1.4109\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.6580 - accuracy: 0.7707 - f1_m: 1.6544 - val_loss: 0.7389 - val_accuracy: 0.7360 - val_f1_m: 1.9224\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 590us/sample - loss: 0.5920 - accuracy: 0.7853 - f1_m: 1.6482 - val_loss: 0.6571 - val_accuracy: 0.7621 - val_f1_m: 1.6700\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 597us/sample - loss: 0.5722 - accuracy: 0.7913 - f1_m: 1.6156 - val_loss: 0.6501 - val_accuracy: 0.7619 - val_f1_m: 1.6712\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 593us/sample - loss: 0.5397 - accuracy: 0.8033 - f1_m: 1.5820 - val_loss: 0.7199 - val_accuracy: 0.7552 - val_f1_m: 1.4584\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 600us/sample - loss: 0.5211 - accuracy: 0.7987 - f1_m: 1.5171 - val_loss: 0.6697 - val_accuracy: 0.7507 - val_f1_m: 1.6661\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 597us/sample - loss: 0.4934 - accuracy: 0.8300 - f1_m: 1.5538 - val_loss: 0.6368 - val_accuracy: 0.7727 - val_f1_m: 1.5457\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 593us/sample - loss: 0.4688 - accuracy: 0.8320 - f1_m: 1.4590 - val_loss: 0.6668 - val_accuracy: 0.7541 - val_f1_m: 1.4714\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 597us/sample - loss: 0.4521 - accuracy: 0.8313 - f1_m: 1.4354 - val_loss: 0.6263 - val_accuracy: 0.7803 - val_f1_m: 1.5929\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 593us/sample - loss: 0.4526 - accuracy: 0.8413 - f1_m: 1.4207 - val_loss: 0.6540 - val_accuracy: 0.7706 - val_f1_m: 1.5320\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 593us/sample - loss: 0.4403 - accuracy: 0.8467 - f1_m: 1.4359 - val_loss: 0.6366 - val_accuracy: 0.7802 - val_f1_m: 1.4412\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 744us/sample - loss: 0.4626 - accuracy: 0.8333 - f1_m: 1.4283 - val_loss: 0.6054 - val_accuracy: 0.7957 - val_f1_m: 1.5103\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 437us/sample - loss: 0.4239 - accuracy: 0.8507 - f1_m: 1.4455 - val_loss: 0.5776 - val_accuracy: 0.7992 - val_f1_m: 1.4777\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 433us/sample - loss: 0.4299 - accuracy: 0.8500 - f1_m: 1.4397 - val_loss: 0.5612 - val_accuracy: 0.7996 - val_f1_m: 1.4952\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 430us/sample - loss: 0.3787 - accuracy: 0.8760 - f1_m: 1.3818 - val_loss: 0.6033 - val_accuracy: 0.7887 - val_f1_m: 1.4567\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 430us/sample - loss: 0.3961 - accuracy: 0.8533 - f1_m: 1.3668 - val_loss: 0.5788 - val_accuracy: 0.7931 - val_f1_m: 1.4633\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 433us/sample - loss: 0.3564 - accuracy: 0.8773 - f1_m: 1.3839 - val_loss: 0.5619 - val_accuracy: 0.8081 - val_f1_m: 1.4695\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 430us/sample - loss: 0.3392 - accuracy: 0.8780 - f1_m: 1.3385 - val_loss: 0.5692 - val_accuracy: 0.7979 - val_f1_m: 1.4030\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 464us/sample - loss: 0.3434 - accuracy: 0.8813 - f1_m: 1.3180 - val_loss: 0.6233 - val_accuracy: 0.7926 - val_f1_m: 1.4012\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 440us/sample - loss: 0.3338 - accuracy: 0.8847 - f1_m: 1.3307 - val_loss: 0.5603 - val_accuracy: 0.8085 - val_f1_m: 1.4107\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 453us/sample - loss: 0.3036 - accuracy: 0.8980 - f1_m: 1.3122 - val_loss: 0.6161 - val_accuracy: 0.7995 - val_f1_m: 1.3578\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 843us/sample - loss: 0.3769 - accuracy: 0.8700 - f1_m: 1.3442 - val_loss: 0.5260 - val_accuracy: 0.8145 - val_f1_m: 1.3979\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 480us/sample - loss: 0.3383 - accuracy: 0.8853 - f1_m: 1.3175 - val_loss: 0.5260 - val_accuracy: 0.8169 - val_f1_m: 1.4644\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 480us/sample - loss: 0.3281 - accuracy: 0.8787 - f1_m: 1.3285 - val_loss: 0.5109 - val_accuracy: 0.8180 - val_f1_m: 1.4621\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 473us/sample - loss: 0.2960 - accuracy: 0.8987 - f1_m: 1.2929 - val_loss: 0.4894 - val_accuracy: 0.8284 - val_f1_m: 1.3439\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 480us/sample - loss: 0.2592 - accuracy: 0.9093 - f1_m: 1.2502 - val_loss: 0.4968 - val_accuracy: 0.8250 - val_f1_m: 1.3387\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 483us/sample - loss: 0.2414 - accuracy: 0.9167 - f1_m: 1.2274 - val_loss: 0.4969 - val_accuracy: 0.8245 - val_f1_m: 1.3365\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 477us/sample - loss: 0.2130 - accuracy: 0.9253 - f1_m: 1.2007 - val_loss: 0.5276 - val_accuracy: 0.8278 - val_f1_m: 1.2842\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 477us/sample - loss: 0.2251 - accuracy: 0.9240 - f1_m: 1.2027 - val_loss: 0.5095 - val_accuracy: 0.8258 - val_f1_m: 1.2983\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 483us/sample - loss: 0.1934 - accuracy: 0.9327 - f1_m: 1.1887 - val_loss: 0.5527 - val_accuracy: 0.8217 - val_f1_m: 1.2680\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 477us/sample - loss: 0.1682 - accuracy: 0.9427 - f1_m: 1.1466 - val_loss: 0.5409 - val_accuracy: 0.8309 - val_f1_m: 1.2638\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.3927 - accuracy: 0.8647 - f1_m: 1.3156 - val_loss: 0.5624 - val_accuracy: 0.7998 - val_f1_m: 1.3577\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 547us/sample - loss: 0.3159 - accuracy: 0.8913 - f1_m: 1.2978 - val_loss: 0.5163 - val_accuracy: 0.8233 - val_f1_m: 1.3774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 537us/sample - loss: 0.3008 - accuracy: 0.8847 - f1_m: 1.2643 - val_loss: 0.5086 - val_accuracy: 0.8216 - val_f1_m: 1.3636\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 543us/sample - loss: 0.2866 - accuracy: 0.8960 - f1_m: 1.2397 - val_loss: 0.6221 - val_accuracy: 0.7964 - val_f1_m: 1.3321\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 544us/sample - loss: 0.2228 - accuracy: 0.9193 - f1_m: 1.1813 - val_loss: 0.5637 - val_accuracy: 0.8089 - val_f1_m: 1.2968\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 537us/sample - loss: 0.2000 - accuracy: 0.9273 - f1_m: 1.1660 - val_loss: 0.6845 - val_accuracy: 0.8089 - val_f1_m: 1.2072\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 540us/sample - loss: 0.2038 - accuracy: 0.9227 - f1_m: 1.1604 - val_loss: 0.5634 - val_accuracy: 0.8217 - val_f1_m: 1.2268\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 527us/sample - loss: 0.1635 - accuracy: 0.9453 - f1_m: 1.1175 - val_loss: 0.5875 - val_accuracy: 0.8177 - val_f1_m: 1.2203\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 529us/sample - loss: 0.1610 - accuracy: 0.9440 - f1_m: 1.0994 - val_loss: 0.6501 - val_accuracy: 0.8140 - val_f1_m: 1.2155\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 540us/sample - loss: 0.1467 - accuracy: 0.9440 - f1_m: 1.1085 - val_loss: 0.6629 - val_accuracy: 0.8169 - val_f1_m: 1.1931\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.5126 - accuracy: 0.8093 - f1_m: 1.4748 - val_loss: 0.6390 - val_accuracy: 0.7731 - val_f1_m: 1.6304\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 640us/sample - loss: 0.4072 - accuracy: 0.8520 - f1_m: 1.3785 - val_loss: 0.5903 - val_accuracy: 0.7939 - val_f1_m: 1.4172\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 636us/sample - loss: 0.4076 - accuracy: 0.8420 - f1_m: 1.3850 - val_loss: 0.5565 - val_accuracy: 0.7991 - val_f1_m: 1.4589\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 640us/sample - loss: 0.3544 - accuracy: 0.8687 - f1_m: 1.3138 - val_loss: 0.6693 - val_accuracy: 0.7789 - val_f1_m: 1.3858\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 634us/sample - loss: 0.3267 - accuracy: 0.8720 - f1_m: 1.2714 - val_loss: 0.6237 - val_accuracy: 0.7885 - val_f1_m: 1.3313\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 639us/sample - loss: 0.2879 - accuracy: 0.9000 - f1_m: 1.2246 - val_loss: 0.6445 - val_accuracy: 0.7987 - val_f1_m: 1.2696\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 634us/sample - loss: 0.2607 - accuracy: 0.9107 - f1_m: 1.1858 - val_loss: 0.6343 - val_accuracy: 0.7968 - val_f1_m: 1.2849\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 640us/sample - loss: 0.2326 - accuracy: 0.9167 - f1_m: 1.1819 - val_loss: 0.6963 - val_accuracy: 0.7951 - val_f1_m: 1.2872\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 637us/sample - loss: 0.2362 - accuracy: 0.9107 - f1_m: 1.1525 - val_loss: 0.6016 - val_accuracy: 0.8018 - val_f1_m: 1.3370\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 640us/sample - loss: 0.2109 - accuracy: 0.9273 - f1_m: 1.1480 - val_loss: 0.7740 - val_accuracy: 0.7902 - val_f1_m: 1.2038\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 745us/sample - loss: 0.5143 - accuracy: 0.8200 - f1_m: 1.4959 - val_loss: 0.6130 - val_accuracy: 0.7986 - val_f1_m: 1.5846\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 343us/sample - loss: 0.5013 - accuracy: 0.8215 - f1_m: 1.5226 - val_loss: 0.5976 - val_accuracy: 0.7968 - val_f1_m: 1.5333\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 337us/sample - loss: 0.5231 - accuracy: 0.8050 - f1_m: 1.4963 - val_loss: 0.6423 - val_accuracy: 0.7743 - val_f1_m: 1.5737\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 343us/sample - loss: 0.4868 - accuracy: 0.8175 - f1_m: 1.4954 - val_loss: 0.5840 - val_accuracy: 0.7999 - val_f1_m: 1.5269\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 344us/sample - loss: 0.4624 - accuracy: 0.8305 - f1_m: 1.4808 - val_loss: 0.5838 - val_accuracy: 0.7974 - val_f1_m: 1.5297\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 342us/sample - loss: 0.4477 - accuracy: 0.8410 - f1_m: 1.4736 - val_loss: 0.5765 - val_accuracy: 0.7998 - val_f1_m: 1.5012\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 345us/sample - loss: 0.4299 - accuracy: 0.8500 - f1_m: 1.4768 - val_loss: 0.5680 - val_accuracy: 0.8039 - val_f1_m: 1.4996\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 340us/sample - loss: 0.4585 - accuracy: 0.8335 - f1_m: 1.4698 - val_loss: 0.5945 - val_accuracy: 0.7978 - val_f1_m: 1.4762\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 340us/sample - loss: 0.4211 - accuracy: 0.8460 - f1_m: 1.4240 - val_loss: 0.6093 - val_accuracy: 0.7941 - val_f1_m: 1.5202\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 343us/sample - loss: 0.4311 - accuracy: 0.8370 - f1_m: 1.4182 - val_loss: 0.5914 - val_accuracy: 0.7854 - val_f1_m: 1.5019\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 642us/sample - loss: 0.4358 - accuracy: 0.8375 - f1_m: 1.4456 - val_loss: 0.5292 - val_accuracy: 0.8068 - val_f1_m: 1.5009\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 360us/sample - loss: 0.4126 - accuracy: 0.8510 - f1_m: 1.4385 - val_loss: 0.5369 - val_accuracy: 0.8047 - val_f1_m: 1.4802\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 358us/sample - loss: 0.4100 - accuracy: 0.8500 - f1_m: 1.4138 - val_loss: 0.5928 - val_accuracy: 0.7798 - val_f1_m: 1.4419\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 362us/sample - loss: 0.3984 - accuracy: 0.8520 - f1_m: 1.4223 - val_loss: 0.5024 - val_accuracy: 0.8217 - val_f1_m: 1.4489\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 367us/sample - loss: 0.3801 - accuracy: 0.8680 - f1_m: 1.3987 - val_loss: 0.5197 - val_accuracy: 0.8168 - val_f1_m: 1.4560\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 363us/sample - loss: 0.3640 - accuracy: 0.8600 - f1_m: 1.3716 - val_loss: 0.4903 - val_accuracy: 0.8226 - val_f1_m: 1.4304\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 362us/sample - loss: 0.3504 - accuracy: 0.8700 - f1_m: 1.3593 - val_loss: 0.5314 - val_accuracy: 0.8095 - val_f1_m: 1.4190\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 363us/sample - loss: 0.3628 - accuracy: 0.8600 - f1_m: 1.3558 - val_loss: 0.5060 - val_accuracy: 0.8215 - val_f1_m: 1.3742\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 365us/sample - loss: 0.3416 - accuracy: 0.8700 - f1_m: 1.3318 - val_loss: 0.5140 - val_accuracy: 0.8133 - val_f1_m: 1.4260\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 360us/sample - loss: 0.3348 - accuracy: 0.8740 - f1_m: 1.3387 - val_loss: 0.5074 - val_accuracy: 0.8164 - val_f1_m: 1.3891\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 745us/sample - loss: 0.4449 - accuracy: 0.8415 - f1_m: 1.4094 - val_loss: 0.5477 - val_accuracy: 0.8077 - val_f1_m: 1.4113\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 403us/sample - loss: 0.4236 - accuracy: 0.8480 - f1_m: 1.3965 - val_loss: 0.5735 - val_accuracy: 0.7942 - val_f1_m: 1.4473\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 405us/sample - loss: 0.4143 - accuracy: 0.8520 - f1_m: 1.3732 - val_loss: 0.5744 - val_accuracy: 0.7900 - val_f1_m: 1.4687\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 408us/sample - loss: 0.3827 - accuracy: 0.8620 - f1_m: 1.3615 - val_loss: 0.5422 - val_accuracy: 0.8090 - val_f1_m: 1.4310\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 418us/sample - loss: 0.3681 - accuracy: 0.8615 - f1_m: 1.3386 - val_loss: 0.5326 - val_accuracy: 0.8153 - val_f1_m: 1.3854\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 405us/sample - loss: 0.3591 - accuracy: 0.8605 - f1_m: 1.3304 - val_loss: 0.5563 - val_accuracy: 0.8021 - val_f1_m: 1.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 407us/sample - loss: 0.3376 - accuracy: 0.8725 - f1_m: 1.3104 - val_loss: 0.5494 - val_accuracy: 0.8157 - val_f1_m: 1.3555\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 403us/sample - loss: 0.3463 - accuracy: 0.8715 - f1_m: 1.2964 - val_loss: 0.5891 - val_accuracy: 0.7932 - val_f1_m: 1.3679\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 405us/sample - loss: 0.3343 - accuracy: 0.8685 - f1_m: 1.2913 - val_loss: 0.5392 - val_accuracy: 0.8137 - val_f1_m: 1.3684\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 405us/sample - loss: 0.3004 - accuracy: 0.8810 - f1_m: 1.2570 - val_loss: 0.5778 - val_accuracy: 0.8047 - val_f1_m: 1.3546\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 912us/sample - loss: 0.4770 - accuracy: 0.8230 - f1_m: 1.4202 - val_loss: 0.6140 - val_accuracy: 0.7795 - val_f1_m: 1.5729\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 480us/sample - loss: 0.4507 - accuracy: 0.8420 - f1_m: 1.4438 - val_loss: 0.6072 - val_accuracy: 0.7897 - val_f1_m: 1.5135\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 480us/sample - loss: 0.4240 - accuracy: 0.8455 - f1_m: 1.3819 - val_loss: 0.6563 - val_accuracy: 0.7686 - val_f1_m: 1.4250\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 477us/sample - loss: 0.4037 - accuracy: 0.8510 - f1_m: 1.3721 - val_loss: 0.5659 - val_accuracy: 0.8023 - val_f1_m: 1.3712\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 480us/sample - loss: 0.3882 - accuracy: 0.8520 - f1_m: 1.3670 - val_loss: 0.5698 - val_accuracy: 0.8061 - val_f1_m: 1.4009\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 483us/sample - loss: 0.4040 - accuracy: 0.8425 - f1_m: 1.3729 - val_loss: 0.5753 - val_accuracy: 0.8006 - val_f1_m: 1.3936\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 483us/sample - loss: 0.3566 - accuracy: 0.8625 - f1_m: 1.3130 - val_loss: 0.5851 - val_accuracy: 0.8027 - val_f1_m: 1.3531\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 480us/sample - loss: 0.3548 - accuracy: 0.8675 - f1_m: 1.3046 - val_loss: 0.5942 - val_accuracy: 0.7836 - val_f1_m: 1.4771\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 477us/sample - loss: 0.3387 - accuracy: 0.8640 - f1_m: 1.2973 - val_loss: 0.5939 - val_accuracy: 0.7991 - val_f1_m: 1.4081\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 480us/sample - loss: 0.3295 - accuracy: 0.8715 - f1_m: 1.2864 - val_loss: 0.6324 - val_accuracy: 0.7976 - val_f1_m: 1.2989\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 572us/sample - loss: 0.3832 - accuracy: 0.8630 - f1_m: 1.3547 - val_loss: 0.5721 - val_accuracy: 0.8056 - val_f1_m: 1.4291\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 338us/sample - loss: 0.3726 - accuracy: 0.8720 - f1_m: 1.3462 - val_loss: 0.5480 - val_accuracy: 0.8155 - val_f1_m: 1.3857\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 335us/sample - loss: 0.3793 - accuracy: 0.8675 - f1_m: 1.3191 - val_loss: 0.6215 - val_accuracy: 0.7855 - val_f1_m: 1.3861\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 342us/sample - loss: 0.3186 - accuracy: 0.8910 - f1_m: 1.3334 - val_loss: 0.5301 - val_accuracy: 0.8247 - val_f1_m: 1.3455\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 343us/sample - loss: 0.3204 - accuracy: 0.8880 - f1_m: 1.3066 - val_loss: 0.5332 - val_accuracy: 0.8198 - val_f1_m: 1.3710\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 342us/sample - loss: 0.3050 - accuracy: 0.8930 - f1_m: 1.2988 - val_loss: 0.5144 - val_accuracy: 0.8268 - val_f1_m: 1.3368\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 343us/sample - loss: 0.2834 - accuracy: 0.8995 - f1_m: 1.2956 - val_loss: 0.5114 - val_accuracy: 0.8303 - val_f1_m: 1.3097\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 342us/sample - loss: 0.2804 - accuracy: 0.9010 - f1_m: 1.2721 - val_loss: 0.5391 - val_accuracy: 0.8210 - val_f1_m: 1.3088\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 343us/sample - loss: 0.2722 - accuracy: 0.8940 - f1_m: 1.2444 - val_loss: 0.5403 - val_accuracy: 0.8222 - val_f1_m: 1.3265\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 339us/sample - loss: 0.2588 - accuracy: 0.9055 - f1_m: 1.2397 - val_loss: 0.5541 - val_accuracy: 0.8114 - val_f1_m: 1.3129\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 647us/sample - loss: 0.2619 - accuracy: 0.9130 - f1_m: 1.1958 - val_loss: 0.5121 - val_accuracy: 0.8273 - val_f1_m: 1.2903\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 385us/sample - loss: 0.2249 - accuracy: 0.9240 - f1_m: 1.1802 - val_loss: 0.5553 - val_accuracy: 0.8271 - val_f1_m: 1.2377\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 380us/sample - loss: 0.2216 - accuracy: 0.9190 - f1_m: 1.1635 - val_loss: 0.5868 - val_accuracy: 0.8162 - val_f1_m: 1.2714\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 385us/sample - loss: 0.1911 - accuracy: 0.9345 - f1_m: 1.1529 - val_loss: 0.5086 - val_accuracy: 0.8439 - val_f1_m: 1.2105\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 377us/sample - loss: 0.1709 - accuracy: 0.9400 - f1_m: 1.1226 - val_loss: 0.5377 - val_accuracy: 0.8275 - val_f1_m: 1.2046\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 383us/sample - loss: 0.1776 - accuracy: 0.9355 - f1_m: 1.1359 - val_loss: 0.5296 - val_accuracy: 0.8359 - val_f1_m: 1.1996\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 377us/sample - loss: 0.1466 - accuracy: 0.9540 - f1_m: 1.1041 - val_loss: 0.5293 - val_accuracy: 0.8346 - val_f1_m: 1.1859\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 383us/sample - loss: 0.1536 - accuracy: 0.9450 - f1_m: 1.1137 - val_loss: 0.5401 - val_accuracy: 0.8385 - val_f1_m: 1.1702\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 378us/sample - loss: 0.1321 - accuracy: 0.9515 - f1_m: 1.0984 - val_loss: 0.6032 - val_accuracy: 0.8290 - val_f1_m: 1.1932\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 380us/sample - loss: 0.1067 - accuracy: 0.9625 - f1_m: 1.0657 - val_loss: 0.5885 - val_accuracy: 0.8307 - val_f1_m: 1.1488\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 780us/sample - loss: 0.2608 - accuracy: 0.9155 - f1_m: 1.1626 - val_loss: 0.5833 - val_accuracy: 0.8273 - val_f1_m: 1.2216\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 441us/sample - loss: 0.2135 - accuracy: 0.9300 - f1_m: 1.1589 - val_loss: 0.5845 - val_accuracy: 0.8158 - val_f1_m: 1.2248\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 426us/sample - loss: 0.1815 - accuracy: 0.9340 - f1_m: 1.1191 - val_loss: 0.5711 - val_accuracy: 0.8149 - val_f1_m: 1.2384\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 432us/sample - loss: 0.1548 - accuracy: 0.9495 - f1_m: 1.0997 - val_loss: 0.5752 - val_accuracy: 0.8321 - val_f1_m: 1.1839\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 435us/sample - loss: 0.1278 - accuracy: 0.9550 - f1_m: 1.0776 - val_loss: 0.6033 - val_accuracy: 0.8338 - val_f1_m: 1.1433\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 425us/sample - loss: 0.1249 - accuracy: 0.9530 - f1_m: 1.0688 - val_loss: 0.5475 - val_accuracy: 0.8354 - val_f1_m: 1.1888\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 432us/sample - loss: 0.1032 - accuracy: 0.9635 - f1_m: 1.0573 - val_loss: 0.6106 - val_accuracy: 0.8341 - val_f1_m: 1.1306\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 432us/sample - loss: 0.0877 - accuracy: 0.9675 - f1_m: 1.0386 - val_loss: 0.6280 - val_accuracy: 0.8298 - val_f1_m: 1.1389\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 433us/sample - loss: 0.0772 - accuracy: 0.9735 - f1_m: 1.0198 - val_loss: 0.7012 - val_accuracy: 0.8289 - val_f1_m: 1.1194\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 430us/sample - loss: 0.0709 - accuracy: 0.9720 - f1_m: 1.0268 - val_loss: 0.7383 - val_accuracy: 0.8280 - val_f1_m: 1.1030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 943us/sample - loss: 0.3408 - accuracy: 0.8745 - f1_m: 1.2389 - val_loss: 0.6157 - val_accuracy: 0.7967 - val_f1_m: 1.3032\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 515us/sample - loss: 0.2873 - accuracy: 0.9000 - f1_m: 1.2090 - val_loss: 0.5744 - val_accuracy: 0.8055 - val_f1_m: 1.3491\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 515us/sample - loss: 0.2491 - accuracy: 0.9075 - f1_m: 1.1572 - val_loss: 0.6396 - val_accuracy: 0.8017 - val_f1_m: 1.2526\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 515us/sample - loss: 0.2049 - accuracy: 0.9205 - f1_m: 1.1453 - val_loss: 0.6380 - val_accuracy: 0.8148 - val_f1_m: 1.2211\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 515us/sample - loss: 0.2289 - accuracy: 0.9145 - f1_m: 1.1488 - val_loss: 0.7010 - val_accuracy: 0.8088 - val_f1_m: 1.2181\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 515us/sample - loss: 0.2077 - accuracy: 0.9250 - f1_m: 1.1120 - val_loss: 0.6199 - val_accuracy: 0.8121 - val_f1_m: 1.1938\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 522us/sample - loss: 0.1831 - accuracy: 0.9305 - f1_m: 1.1160 - val_loss: 0.7280 - val_accuracy: 0.8040 - val_f1_m: 1.1720\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 516us/sample - loss: 0.1680 - accuracy: 0.9315 - f1_m: 1.0922 - val_loss: 0.6649 - val_accuracy: 0.8111 - val_f1_m: 1.1994\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 515us/sample - loss: 0.1640 - accuracy: 0.9380 - f1_m: 1.0767 - val_loss: 0.6217 - val_accuracy: 0.8110 - val_f1_m: 1.2314\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 519us/sample - loss: 0.1472 - accuracy: 0.9490 - f1_m: 1.0716 - val_loss: 0.7680 - val_accuracy: 0.7942 - val_f1_m: 1.1860\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 478us/sample - loss: 0.4723 - accuracy: 0.8336 - f1_m: 1.4493 - val_loss: 0.5698 - val_accuracy: 0.8021 - val_f1_m: 1.4530\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 292us/sample - loss: 0.4463 - accuracy: 0.8500 - f1_m: 1.4278 - val_loss: 0.5691 - val_accuracy: 0.8061 - val_f1_m: 1.4753\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 292us/sample - loss: 0.4258 - accuracy: 0.8508 - f1_m: 1.4297 - val_loss: 0.6595 - val_accuracy: 0.7863 - val_f1_m: 1.4682\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.4417 - accuracy: 0.8364 - f1_m: 1.4333 - val_loss: 0.6007 - val_accuracy: 0.7878 - val_f1_m: 1.4775\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.4530 - accuracy: 0.8420 - f1_m: 1.4315 - val_loss: 0.5665 - val_accuracy: 0.8040 - val_f1_m: 1.4596\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.4046 - accuracy: 0.8612 - f1_m: 1.4203 - val_loss: 0.5844 - val_accuracy: 0.7937 - val_f1_m: 1.5125\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.4277 - accuracy: 0.8420 - f1_m: 1.4077 - val_loss: 0.6210 - val_accuracy: 0.7755 - val_f1_m: 1.4880\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.3955 - accuracy: 0.8564 - f1_m: 1.3977 - val_loss: 0.5812 - val_accuracy: 0.7982 - val_f1_m: 1.4439\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.4175 - accuracy: 0.8492 - f1_m: 1.3749 - val_loss: 0.5713 - val_accuracy: 0.8039 - val_f1_m: 1.4706\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.3859 - accuracy: 0.8684 - f1_m: 1.3728 - val_loss: 0.5929 - val_accuracy: 0.7952 - val_f1_m: 1.4533\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 512us/sample - loss: 0.3722 - accuracy: 0.8660 - f1_m: 1.3513 - val_loss: 0.4927 - val_accuracy: 0.8246 - val_f1_m: 1.3703\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 308us/sample - loss: 0.3547 - accuracy: 0.8692 - f1_m: 1.3311 - val_loss: 0.4786 - val_accuracy: 0.8302 - val_f1_m: 1.3862\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 304us/sample - loss: 0.3366 - accuracy: 0.8716 - f1_m: 1.3332 - val_loss: 0.4862 - val_accuracy: 0.8269 - val_f1_m: 1.3547\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 300us/sample - loss: 0.3366 - accuracy: 0.8768 - f1_m: 1.3266 - val_loss: 0.5123 - val_accuracy: 0.8104 - val_f1_m: 1.3997\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 308us/sample - loss: 0.3288 - accuracy: 0.8744 - f1_m: 1.3290 - val_loss: 0.4905 - val_accuracy: 0.8256 - val_f1_m: 1.3614\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 304us/sample - loss: 0.3098 - accuracy: 0.8836 - f1_m: 1.3089 - val_loss: 0.4958 - val_accuracy: 0.8219 - val_f1_m: 1.3679\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 308us/sample - loss: 0.3246 - accuracy: 0.8824 - f1_m: 1.3188 - val_loss: 0.4874 - val_accuracy: 0.8285 - val_f1_m: 1.3735\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 304us/sample - loss: 0.2976 - accuracy: 0.8888 - f1_m: 1.2894 - val_loss: 0.5107 - val_accuracy: 0.8198 - val_f1_m: 1.3585\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 304us/sample - loss: 0.3117 - accuracy: 0.8852 - f1_m: 1.2857 - val_loss: 0.4980 - val_accuracy: 0.8250 - val_f1_m: 1.3470\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 304us/sample - loss: 0.2859 - accuracy: 0.8912 - f1_m: 1.2692 - val_loss: 0.4832 - val_accuracy: 0.8306 - val_f1_m: 1.3224\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 636us/sample - loss: 0.3659 - accuracy: 0.8712 - f1_m: 1.3229 - val_loss: 0.5309 - val_accuracy: 0.8115 - val_f1_m: 1.3225\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 349us/sample - loss: 0.3394 - accuracy: 0.8768 - f1_m: 1.2908 - val_loss: 0.5198 - val_accuracy: 0.8149 - val_f1_m: 1.3255\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 347us/sample - loss: 0.3230 - accuracy: 0.8768 - f1_m: 1.2837 - val_loss: 0.5929 - val_accuracy: 0.8038 - val_f1_m: 1.3259\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 343us/sample - loss: 0.3277 - accuracy: 0.8824 - f1_m: 1.2797 - val_loss: 0.5649 - val_accuracy: 0.8054 - val_f1_m: 1.3386\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 352us/sample - loss: 0.3291 - accuracy: 0.8708 - f1_m: 1.2884 - val_loss: 0.5663 - val_accuracy: 0.8094 - val_f1_m: 1.3685\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 345us/sample - loss: 0.2875 - accuracy: 0.8948 - f1_m: 1.2689 - val_loss: 0.5368 - val_accuracy: 0.8205 - val_f1_m: 1.2794\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 344us/sample - loss: 0.2895 - accuracy: 0.8936 - f1_m: 1.2402 - val_loss: 0.5430 - val_accuracy: 0.8120 - val_f1_m: 1.3250\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 345us/sample - loss: 0.2687 - accuracy: 0.9024 - f1_m: 1.2242 - val_loss: 0.5547 - val_accuracy: 0.8109 - val_f1_m: 1.2788\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 346us/sample - loss: 0.2632 - accuracy: 0.9104 - f1_m: 1.2329 - val_loss: 0.5572 - val_accuracy: 0.8125 - val_f1_m: 1.2611\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 349us/sample - loss: 0.2530 - accuracy: 0.9092 - f1_m: 1.2120 - val_loss: 0.5552 - val_accuracy: 0.8140 - val_f1_m: 1.2534\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 762us/sample - loss: 0.3775 - accuracy: 0.8640 - f1_m: 1.3327 - val_loss: 0.5538 - val_accuracy: 0.8145 - val_f1_m: 1.3227\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 412us/sample - loss: 0.3549 - accuracy: 0.8684 - f1_m: 1.2799 - val_loss: 0.5748 - val_accuracy: 0.8096 - val_f1_m: 1.3398\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 412us/sample - loss: 0.3450 - accuracy: 0.8720 - f1_m: 1.3201 - val_loss: 0.6131 - val_accuracy: 0.8035 - val_f1_m: 1.2848\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 420us/sample - loss: 0.3322 - accuracy: 0.8800 - f1_m: 1.2776 - val_loss: 0.5807 - val_accuracy: 0.7948 - val_f1_m: 1.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 416us/sample - loss: 0.3542 - accuracy: 0.8636 - f1_m: 1.3029 - val_loss: 0.5836 - val_accuracy: 0.7964 - val_f1_m: 1.3459\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 408us/sample - loss: 0.3119 - accuracy: 0.8872 - f1_m: 1.2668 - val_loss: 0.5789 - val_accuracy: 0.8137 - val_f1_m: 1.2818\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 415us/sample - loss: 0.3043 - accuracy: 0.8836 - f1_m: 1.2443 - val_loss: 0.6198 - val_accuracy: 0.8040 - val_f1_m: 1.2879\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 408us/sample - loss: 0.3123 - accuracy: 0.8852 - f1_m: 1.2509 - val_loss: 0.6325 - val_accuracy: 0.7955 - val_f1_m: 1.2812\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 416us/sample - loss: 0.2919 - accuracy: 0.8912 - f1_m: 1.2239 - val_loss: 0.6028 - val_accuracy: 0.8092 - val_f1_m: 1.2981\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 415us/sample - loss: 0.2688 - accuracy: 0.8932 - f1_m: 1.2021 - val_loss: 0.6603 - val_accuracy: 0.8055 - val_f1_m: 1.2507\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 471us/sample - loss: 0.3313 - accuracy: 0.8876 - f1_m: 1.2848 - val_loss: 0.5122 - val_accuracy: 0.8288 - val_f1_m: 1.3047\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 290us/sample - loss: 0.2981 - accuracy: 0.8940 - f1_m: 1.2545 - val_loss: 0.5265 - val_accuracy: 0.8260 - val_f1_m: 1.3213\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 290us/sample - loss: 0.2872 - accuracy: 0.9060 - f1_m: 1.2489 - val_loss: 0.5448 - val_accuracy: 0.8199 - val_f1_m: 1.2941\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.2856 - accuracy: 0.8976 - f1_m: 1.2631 - val_loss: 0.5260 - val_accuracy: 0.8193 - val_f1_m: 1.3398\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 292us/sample - loss: 0.2875 - accuracy: 0.8904 - f1_m: 1.2617 - val_loss: 0.5056 - val_accuracy: 0.8262 - val_f1_m: 1.3389\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.2363 - accuracy: 0.9224 - f1_m: 1.2290 - val_loss: 0.4938 - val_accuracy: 0.8291 - val_f1_m: 1.3186\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 285us/sample - loss: 0.2466 - accuracy: 0.9112 - f1_m: 1.2221 - val_loss: 0.5187 - val_accuracy: 0.8236 - val_f1_m: 1.3116\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 292us/sample - loss: 0.2142 - accuracy: 0.9300 - f1_m: 1.2143 - val_loss: 0.5641 - val_accuracy: 0.8150 - val_f1_m: 1.2807\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 288us/sample - loss: 0.2209 - accuracy: 0.9264 - f1_m: 1.1823 - val_loss: 0.5176 - val_accuracy: 0.8243 - val_f1_m: 1.2805\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 283us/sample - loss: 0.2126 - accuracy: 0.9268 - f1_m: 1.1823 - val_loss: 0.4954 - val_accuracy: 0.8284 - val_f1_m: 1.3042\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 544us/sample - loss: 0.2194 - accuracy: 0.9292 - f1_m: 1.1201 - val_loss: 0.5347 - val_accuracy: 0.8326 - val_f1_m: 1.1898\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.1876 - accuracy: 0.9368 - f1_m: 1.1103 - val_loss: 0.5050 - val_accuracy: 0.8407 - val_f1_m: 1.1800\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.1585 - accuracy: 0.9452 - f1_m: 1.1160 - val_loss: 0.5208 - val_accuracy: 0.8452 - val_f1_m: 1.1742\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.1500 - accuracy: 0.9468 - f1_m: 1.1070 - val_loss: 0.5431 - val_accuracy: 0.8305 - val_f1_m: 1.2086\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.1292 - accuracy: 0.9552 - f1_m: 1.0943 - val_loss: 0.5714 - val_accuracy: 0.8333 - val_f1_m: 1.1732\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.1159 - accuracy: 0.9560 - f1_m: 1.0732 - val_loss: 0.6000 - val_accuracy: 0.8370 - val_f1_m: 1.1690\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.1162 - accuracy: 0.9568 - f1_m: 1.0722 - val_loss: 0.5923 - val_accuracy: 0.8391 - val_f1_m: 1.1454\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.1131 - accuracy: 0.9636 - f1_m: 1.0589 - val_loss: 0.5884 - val_accuracy: 0.8310 - val_f1_m: 1.1615\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.0782 - accuracy: 0.9756 - f1_m: 1.0422 - val_loss: 0.5972 - val_accuracy: 0.8409 - val_f1_m: 1.1196\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 328us/sample - loss: 0.0789 - accuracy: 0.9708 - f1_m: 1.0337 - val_loss: 0.5958 - val_accuracy: 0.8434 - val_f1_m: 1.1199\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 656us/sample - loss: 0.2022 - accuracy: 0.9352 - f1_m: 1.0965 - val_loss: 0.5945 - val_accuracy: 0.8358 - val_f1_m: 1.1495\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 364us/sample - loss: 0.1324 - accuracy: 0.9572 - f1_m: 1.0598 - val_loss: 0.5598 - val_accuracy: 0.8357 - val_f1_m: 1.1746\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 367us/sample - loss: 0.1020 - accuracy: 0.9660 - f1_m: 1.0479 - val_loss: 0.7395 - val_accuracy: 0.8247 - val_f1_m: 1.1152\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 372us/sample - loss: 0.1333 - accuracy: 0.9516 - f1_m: 1.0791 - val_loss: 0.6149 - val_accuracy: 0.8338 - val_f1_m: 1.1404\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 364us/sample - loss: 0.0922 - accuracy: 0.9676 - f1_m: 1.0369 - val_loss: 0.6754 - val_accuracy: 0.8319 - val_f1_m: 1.1314\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 368us/sample - loss: 0.0700 - accuracy: 0.9760 - f1_m: 1.0216 - val_loss: 0.7141 - val_accuracy: 0.8395 - val_f1_m: 1.0987\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 360us/sample - loss: 0.0684 - accuracy: 0.9792 - f1_m: 1.0010 - val_loss: 0.6850 - val_accuracy: 0.8388 - val_f1_m: 1.1183\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 368us/sample - loss: 0.1114 - accuracy: 0.9684 - f1_m: 1.0470 - val_loss: 0.7010 - val_accuracy: 0.8332 - val_f1_m: 1.1046\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 360us/sample - loss: 0.0318 - accuracy: 0.9900 - f1_m: 0.9771 - val_loss: 0.7830 - val_accuracy: 0.8372 - val_f1_m: 1.0767\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 364us/sample - loss: 0.0216 - accuracy: 0.9940 - f1_m: 0.9748 - val_loss: 0.8380 - val_accuracy: 0.8418 - val_f1_m: 1.0562\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 784us/sample - loss: 0.2773 - accuracy: 0.9112 - f1_m: 1.1654 - val_loss: 0.6070 - val_accuracy: 0.8176 - val_f1_m: 1.1956\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 444us/sample - loss: 0.2056 - accuracy: 0.9236 - f1_m: 1.1168 - val_loss: 0.6127 - val_accuracy: 0.8133 - val_f1_m: 1.2389\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.1859 - accuracy: 0.9272 - f1_m: 1.1238 - val_loss: 0.7053 - val_accuracy: 0.8191 - val_f1_m: 1.1536\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.2131 - accuracy: 0.9204 - f1_m: 1.1394 - val_loss: 0.6534 - val_accuracy: 0.8250 - val_f1_m: 1.1588\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 444us/sample - loss: 0.1883 - accuracy: 0.9252 - f1_m: 1.1121 - val_loss: 0.6791 - val_accuracy: 0.8046 - val_f1_m: 1.1962\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.1530 - accuracy: 0.9404 - f1_m: 1.0859 - val_loss: 0.7550 - val_accuracy: 0.8020 - val_f1_m: 1.1622\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.1444 - accuracy: 0.9476 - f1_m: 1.0649 - val_loss: 0.7417 - val_accuracy: 0.8134 - val_f1_m: 1.1449\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.1330 - accuracy: 0.9544 - f1_m: 1.0704 - val_loss: 0.8575 - val_accuracy: 0.8128 - val_f1_m: 1.1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.1374 - accuracy: 0.9492 - f1_m: 1.0600 - val_loss: 0.8901 - val_accuracy: 0.8055 - val_f1_m: 1.0996\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.1100 - accuracy: 0.9588 - f1_m: 1.0367 - val_loss: 0.9384 - val_accuracy: 0.8152 - val_f1_m: 1.0967\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 412us/sample - loss: 0.4210 - accuracy: 0.8513 - f1_m: 1.4048 - val_loss: 0.5410 - val_accuracy: 0.8139 - val_f1_m: 1.4250\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.3986 - accuracy: 0.8557 - f1_m: 1.3776 - val_loss: 0.5367 - val_accuracy: 0.8105 - val_f1_m: 1.4170\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.3839 - accuracy: 0.8573 - f1_m: 1.3778 - val_loss: 0.6245 - val_accuracy: 0.7753 - val_f1_m: 1.4148\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 247us/sample - loss: 0.3696 - accuracy: 0.8680 - f1_m: 1.3735 - val_loss: 0.5434 - val_accuracy: 0.8120 - val_f1_m: 1.4099\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.3711 - accuracy: 0.8637 - f1_m: 1.3766 - val_loss: 0.5268 - val_accuracy: 0.8198 - val_f1_m: 1.3676\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.3765 - accuracy: 0.8650 - f1_m: 1.3461 - val_loss: 0.5842 - val_accuracy: 0.8006 - val_f1_m: 1.3928\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.3570 - accuracy: 0.8733 - f1_m: 1.3410 - val_loss: 0.5348 - val_accuracy: 0.8164 - val_f1_m: 1.3727\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 253us/sample - loss: 0.3453 - accuracy: 0.8747 - f1_m: 1.3489 - val_loss: 0.5318 - val_accuracy: 0.8206 - val_f1_m: 1.3743\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 247us/sample - loss: 0.3493 - accuracy: 0.8743 - f1_m: 1.3232 - val_loss: 0.5585 - val_accuracy: 0.8069 - val_f1_m: 1.3745\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.3324 - accuracy: 0.8817 - f1_m: 1.3207 - val_loss: 0.5248 - val_accuracy: 0.8215 - val_f1_m: 1.3678\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 446us/sample - loss: 0.3185 - accuracy: 0.8823 - f1_m: 1.2722 - val_loss: 0.4848 - val_accuracy: 0.8286 - val_f1_m: 1.3276\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 270us/sample - loss: 0.3097 - accuracy: 0.8817 - f1_m: 1.2735 - val_loss: 0.4740 - val_accuracy: 0.8352 - val_f1_m: 1.3116\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 263us/sample - loss: 0.2887 - accuracy: 0.8937 - f1_m: 1.2710 - val_loss: 0.4810 - val_accuracy: 0.8320 - val_f1_m: 1.3305\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 267us/sample - loss: 0.2878 - accuracy: 0.8993 - f1_m: 1.2605 - val_loss: 0.5008 - val_accuracy: 0.8241 - val_f1_m: 1.3024\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 267us/sample - loss: 0.2806 - accuracy: 0.8977 - f1_m: 1.2601 - val_loss: 0.4899 - val_accuracy: 0.8279 - val_f1_m: 1.2986\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 267us/sample - loss: 0.2811 - accuracy: 0.8967 - f1_m: 1.2526 - val_loss: 0.4764 - val_accuracy: 0.8345 - val_f1_m: 1.3085\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 267us/sample - loss: 0.2761 - accuracy: 0.8983 - f1_m: 1.2433 - val_loss: 0.4755 - val_accuracy: 0.8340 - val_f1_m: 1.3049\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 270us/sample - loss: 0.2597 - accuracy: 0.9017 - f1_m: 1.2421 - val_loss: 0.4773 - val_accuracy: 0.8371 - val_f1_m: 1.2794\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 267us/sample - loss: 0.2613 - accuracy: 0.9040 - f1_m: 1.2237 - val_loss: 0.4905 - val_accuracy: 0.8352 - val_f1_m: 1.2894\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 267us/sample - loss: 0.2490 - accuracy: 0.9047 - f1_m: 1.2202 - val_loss: 0.4990 - val_accuracy: 0.8309 - val_f1_m: 1.2466\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 550us/sample - loss: 0.2949 - accuracy: 0.8960 - f1_m: 1.2321 - val_loss: 0.5472 - val_accuracy: 0.8176 - val_f1_m: 1.2733\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 307us/sample - loss: 0.2763 - accuracy: 0.8963 - f1_m: 1.2147 - val_loss: 0.5279 - val_accuracy: 0.8197 - val_f1_m: 1.2997\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 303us/sample - loss: 0.2533 - accuracy: 0.9060 - f1_m: 1.2060 - val_loss: 0.5531 - val_accuracy: 0.8086 - val_f1_m: 1.2729\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 303us/sample - loss: 0.2400 - accuracy: 0.9107 - f1_m: 1.2079 - val_loss: 0.5523 - val_accuracy: 0.8179 - val_f1_m: 1.2436\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 310us/sample - loss: 0.2258 - accuracy: 0.9147 - f1_m: 1.1935 - val_loss: 0.5484 - val_accuracy: 0.8269 - val_f1_m: 1.2189\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 310us/sample - loss: 0.2306 - accuracy: 0.9150 - f1_m: 1.1853 - val_loss: 0.5704 - val_accuracy: 0.8165 - val_f1_m: 1.2241\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 303us/sample - loss: 0.2047 - accuracy: 0.9247 - f1_m: 1.1519 - val_loss: 0.5685 - val_accuracy: 0.8190 - val_f1_m: 1.2277\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 303us/sample - loss: 0.1895 - accuracy: 0.9327 - f1_m: 1.1624 - val_loss: 0.5953 - val_accuracy: 0.8264 - val_f1_m: 1.1778\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 307us/sample - loss: 0.1940 - accuracy: 0.9260 - f1_m: 1.1558 - val_loss: 0.6093 - val_accuracy: 0.8249 - val_f1_m: 1.1998\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 303us/sample - loss: 0.1732 - accuracy: 0.9350 - f1_m: 1.1415 - val_loss: 0.6244 - val_accuracy: 0.8227 - val_f1_m: 1.1969\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 667us/sample - loss: 0.3192 - accuracy: 0.8797 - f1_m: 1.2488 - val_loss: 0.5918 - val_accuracy: 0.8086 - val_f1_m: 1.2836\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 363us/sample - loss: 0.2853 - accuracy: 0.8930 - f1_m: 1.2305 - val_loss: 0.5921 - val_accuracy: 0.8086 - val_f1_m: 1.3005\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 367us/sample - loss: 0.2891 - accuracy: 0.8940 - f1_m: 1.2257 - val_loss: 0.5798 - val_accuracy: 0.8074 - val_f1_m: 1.3090\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 366us/sample - loss: 0.2793 - accuracy: 0.8960 - f1_m: 1.2186 - val_loss: 0.5887 - val_accuracy: 0.8141 - val_f1_m: 1.2534\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 368us/sample - loss: 0.2589 - accuracy: 0.9027 - f1_m: 1.1909 - val_loss: 0.5907 - val_accuracy: 0.8203 - val_f1_m: 1.2660\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 363us/sample - loss: 0.2596 - accuracy: 0.8973 - f1_m: 1.2076 - val_loss: 0.6231 - val_accuracy: 0.8106 - val_f1_m: 1.2378\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 365us/sample - loss: 0.2636 - accuracy: 0.9043 - f1_m: 1.2016 - val_loss: 0.5782 - val_accuracy: 0.8092 - val_f1_m: 1.3262\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 365us/sample - loss: 0.2315 - accuracy: 0.9160 - f1_m: 1.1851 - val_loss: 0.6407 - val_accuracy: 0.8165 - val_f1_m: 1.2009\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 365us/sample - loss: 0.2394 - accuracy: 0.9063 - f1_m: 1.1734 - val_loss: 0.6224 - val_accuracy: 0.8044 - val_f1_m: 1.2804\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 367us/sample - loss: 0.2336 - accuracy: 0.9137 - f1_m: 1.1711 - val_loss: 0.6408 - val_accuracy: 0.8090 - val_f1_m: 1.2107\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 408us/sample - loss: 0.2588 - accuracy: 0.9053 - f1_m: 1.2002 - val_loss: 0.4756 - val_accuracy: 0.8371 - val_f1_m: 1.2840\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 252us/sample - loss: 0.2342 - accuracy: 0.9193 - f1_m: 1.1941 - val_loss: 0.4981 - val_accuracy: 0.8345 - val_f1_m: 1.2746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 249us/sample - loss: 0.2141 - accuracy: 0.9270 - f1_m: 1.1900 - val_loss: 0.5404 - val_accuracy: 0.8251 - val_f1_m: 1.2850\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.1996 - accuracy: 0.9367 - f1_m: 1.1769 - val_loss: 0.5057 - val_accuracy: 0.8375 - val_f1_m: 1.2402\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.1925 - accuracy: 0.9370 - f1_m: 1.1853 - val_loss: 0.4982 - val_accuracy: 0.8363 - val_f1_m: 1.2377\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 248us/sample - loss: 0.1933 - accuracy: 0.9310 - f1_m: 1.1710 - val_loss: 0.5288 - val_accuracy: 0.8279 - val_f1_m: 1.2516\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 252us/sample - loss: 0.2022 - accuracy: 0.9310 - f1_m: 1.1644 - val_loss: 0.5031 - val_accuracy: 0.8335 - val_f1_m: 1.2514\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.1624 - accuracy: 0.9477 - f1_m: 1.1399 - val_loss: 0.4927 - val_accuracy: 0.8385 - val_f1_m: 1.2219\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 248us/sample - loss: 0.1623 - accuracy: 0.9477 - f1_m: 1.1390 - val_loss: 0.5458 - val_accuracy: 0.8306 - val_f1_m: 1.2427\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 250us/sample - loss: 0.1532 - accuracy: 0.9483 - f1_m: 1.1439 - val_loss: 0.5553 - val_accuracy: 0.8328 - val_f1_m: 1.2090\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 472us/sample - loss: 0.1797 - accuracy: 0.9413 - f1_m: 1.0823 - val_loss: 0.5900 - val_accuracy: 0.8361 - val_f1_m: 1.1509\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 280us/sample - loss: 0.1305 - accuracy: 0.9570 - f1_m: 1.0665 - val_loss: 0.5905 - val_accuracy: 0.8398 - val_f1_m: 1.1290\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 278us/sample - loss: 0.1132 - accuracy: 0.9670 - f1_m: 1.0511 - val_loss: 0.5877 - val_accuracy: 0.8441 - val_f1_m: 1.1182\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.0948 - accuracy: 0.9713 - f1_m: 1.0528 - val_loss: 0.6308 - val_accuracy: 0.8414 - val_f1_m: 1.1215\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 280us/sample - loss: 0.0913 - accuracy: 0.9707 - f1_m: 1.0388 - val_loss: 0.6173 - val_accuracy: 0.8363 - val_f1_m: 1.1302\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 280us/sample - loss: 0.0748 - accuracy: 0.9757 - f1_m: 1.0319 - val_loss: 0.6226 - val_accuracy: 0.8407 - val_f1_m: 1.1116\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 277us/sample - loss: 0.0663 - accuracy: 0.9793 - f1_m: 1.0251 - val_loss: 0.6469 - val_accuracy: 0.8400 - val_f1_m: 1.1118\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 283us/sample - loss: 0.0625 - accuracy: 0.9813 - f1_m: 1.0174 - val_loss: 0.6587 - val_accuracy: 0.8437 - val_f1_m: 1.1211\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.0555 - accuracy: 0.9827 - f1_m: 1.0170 - val_loss: 0.6890 - val_accuracy: 0.8434 - val_f1_m: 1.0982\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 279us/sample - loss: 0.0429 - accuracy: 0.9887 - f1_m: 0.9957 - val_loss: 0.7046 - val_accuracy: 0.8479 - val_f1_m: 1.0743\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 570us/sample - loss: 0.1567 - accuracy: 0.9553 - f1_m: 1.0463 - val_loss: 0.6018 - val_accuracy: 0.8422 - val_f1_m: 1.1143\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 323us/sample - loss: 0.1061 - accuracy: 0.9680 - f1_m: 1.0288 - val_loss: 0.5902 - val_accuracy: 0.8447 - val_f1_m: 1.1257\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 321us/sample - loss: 0.0732 - accuracy: 0.9767 - f1_m: 1.0110 - val_loss: 0.6551 - val_accuracy: 0.8434 - val_f1_m: 1.0958\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 322us/sample - loss: 0.0637 - accuracy: 0.9770 - f1_m: 1.0020 - val_loss: 0.6754 - val_accuracy: 0.8444 - val_f1_m: 1.0980\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 322us/sample - loss: 0.0533 - accuracy: 0.9847 - f1_m: 1.0003 - val_loss: 0.7564 - val_accuracy: 0.8399 - val_f1_m: 1.0786\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 320us/sample - loss: 0.0555 - accuracy: 0.9787 - f1_m: 0.9918 - val_loss: 0.6719 - val_accuracy: 0.8477 - val_f1_m: 1.1041\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 328us/sample - loss: 0.0395 - accuracy: 0.9877 - f1_m: 0.9872 - val_loss: 0.8103 - val_accuracy: 0.8401 - val_f1_m: 1.0687\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 322us/sample - loss: 0.0460 - accuracy: 0.9853 - f1_m: 0.9802 - val_loss: 0.7792 - val_accuracy: 0.8399 - val_f1_m: 1.0703\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 325us/sample - loss: 0.0206 - accuracy: 0.9940 - f1_m: 0.9620 - val_loss: 0.8853 - val_accuracy: 0.8512 - val_f1_m: 1.0575\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 323us/sample - loss: 0.0385 - accuracy: 0.9877 - f1_m: 0.9783 - val_loss: 0.8796 - val_accuracy: 0.8449 - val_f1_m: 1.0559\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 697us/sample - loss: 0.2106 - accuracy: 0.9327 - f1_m: 1.1193 - val_loss: 0.7008 - val_accuracy: 0.8178 - val_f1_m: 1.1666\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 428us/sample - loss: 0.1548 - accuracy: 0.9480 - f1_m: 1.0726 - val_loss: 0.6803 - val_accuracy: 0.8151 - val_f1_m: 1.1786\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 392us/sample - loss: 0.1201 - accuracy: 0.9607 - f1_m: 1.0477 - val_loss: 0.6642 - val_accuracy: 0.8144 - val_f1_m: 1.1635\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 395us/sample - loss: 0.1129 - accuracy: 0.9610 - f1_m: 1.0446 - val_loss: 0.7485 - val_accuracy: 0.8171 - val_f1_m: 1.1385\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 393us/sample - loss: 0.0934 - accuracy: 0.9687 - f1_m: 1.0261 - val_loss: 0.7791 - val_accuracy: 0.8240 - val_f1_m: 1.1138\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 392us/sample - loss: 0.1080 - accuracy: 0.9637 - f1_m: 1.0296 - val_loss: 0.7983 - val_accuracy: 0.8169 - val_f1_m: 1.1194\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 395us/sample - loss: 0.1003 - accuracy: 0.9673 - f1_m: 1.0283 - val_loss: 0.8354 - val_accuracy: 0.8176 - val_f1_m: 1.1105\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 397us/sample - loss: 0.0885 - accuracy: 0.9673 - f1_m: 1.0198 - val_loss: 0.8321 - val_accuracy: 0.8232 - val_f1_m: 1.0963\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 395us/sample - loss: 0.0664 - accuracy: 0.9770 - f1_m: 1.0006 - val_loss: 0.9362 - val_accuracy: 0.8175 - val_f1_m: 1.0911\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 395us/sample - loss: 0.0797 - accuracy: 0.9727 - f1_m: 1.0106 - val_loss: 0.7243 - val_accuracy: 0.8166 - val_f1_m: 1.1563\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 367us/sample - loss: 0.3649 - accuracy: 0.8709 - f1_m: 1.3303 - val_loss: 0.5420 - val_accuracy: 0.8170 - val_f1_m: 1.3562\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 227us/sample - loss: 0.3443 - accuracy: 0.8814 - f1_m: 1.3173 - val_loss: 0.5337 - val_accuracy: 0.8177 - val_f1_m: 1.3684\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 227us/sample - loss: 0.3463 - accuracy: 0.8734 - f1_m: 1.3124 - val_loss: 0.5428 - val_accuracy: 0.8191 - val_f1_m: 1.3467\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 227us/sample - loss: 0.3356 - accuracy: 0.8823 - f1_m: 1.3249 - val_loss: 0.5817 - val_accuracy: 0.8083 - val_f1_m: 1.3324\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 227us/sample - loss: 0.3327 - accuracy: 0.8834 - f1_m: 1.3018 - val_loss: 0.5968 - val_accuracy: 0.8033 - val_f1_m: 1.3530\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 227us/sample - loss: 0.3338 - accuracy: 0.8803 - f1_m: 1.3159 - val_loss: 0.5178 - val_accuracy: 0.8274 - val_f1_m: 1.3303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 224us/sample - loss: 0.3282 - accuracy: 0.8851 - f1_m: 1.3036 - val_loss: 0.5704 - val_accuracy: 0.8063 - val_f1_m: 1.3575\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 226us/sample - loss: 0.3169 - accuracy: 0.8874 - f1_m: 1.2980 - val_loss: 0.5346 - val_accuracy: 0.8230 - val_f1_m: 1.3172\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 224us/sample - loss: 0.3087 - accuracy: 0.8883 - f1_m: 1.2961 - val_loss: 0.5112 - val_accuracy: 0.8271 - val_f1_m: 1.3391\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 224us/sample - loss: 0.3004 - accuracy: 0.8951 - f1_m: 1.2940 - val_loss: 0.5158 - val_accuracy: 0.8265 - val_f1_m: 1.3019\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 393us/sample - loss: 0.2879 - accuracy: 0.8989 - f1_m: 1.2367 - val_loss: 0.4767 - val_accuracy: 0.8363 - val_f1_m: 1.2683\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 240us/sample - loss: 0.2748 - accuracy: 0.8980 - f1_m: 1.2167 - val_loss: 0.4994 - val_accuracy: 0.8264 - val_f1_m: 1.2827\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 246us/sample - loss: 0.2713 - accuracy: 0.8980 - f1_m: 1.2320 - val_loss: 0.4894 - val_accuracy: 0.8325 - val_f1_m: 1.2619\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 242us/sample - loss: 0.2543 - accuracy: 0.9111 - f1_m: 1.2274 - val_loss: 0.5110 - val_accuracy: 0.8312 - val_f1_m: 1.2490\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 241us/sample - loss: 0.2455 - accuracy: 0.9106 - f1_m: 1.2125 - val_loss: 0.4986 - val_accuracy: 0.8333 - val_f1_m: 1.2762\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 242us/sample - loss: 0.2495 - accuracy: 0.9069 - f1_m: 1.2198 - val_loss: 0.5037 - val_accuracy: 0.8365 - val_f1_m: 1.2508\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 243us/sample - loss: 0.2431 - accuracy: 0.9054 - f1_m: 1.2052 - val_loss: 0.4931 - val_accuracy: 0.8424 - val_f1_m: 1.2679\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 240us/sample - loss: 0.2360 - accuracy: 0.9086 - f1_m: 1.1969 - val_loss: 0.4851 - val_accuracy: 0.8428 - val_f1_m: 1.2290\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 244us/sample - loss: 0.2248 - accuracy: 0.9157 - f1_m: 1.1824 - val_loss: 0.4867 - val_accuracy: 0.8415 - val_f1_m: 1.2640\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 241us/sample - loss: 0.2232 - accuracy: 0.9237 - f1_m: 1.1962 - val_loss: 0.4839 - val_accuracy: 0.8460 - val_f1_m: 1.2185\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 483us/sample - loss: 0.2447 - accuracy: 0.9149 - f1_m: 1.1626 - val_loss: 0.5503 - val_accuracy: 0.8301 - val_f1_m: 1.2014\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 279us/sample - loss: 0.2113 - accuracy: 0.9237 - f1_m: 1.1573 - val_loss: 0.5826 - val_accuracy: 0.8264 - val_f1_m: 1.1918\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 276us/sample - loss: 0.2074 - accuracy: 0.9237 - f1_m: 1.1580 - val_loss: 0.5600 - val_accuracy: 0.8347 - val_f1_m: 1.1760\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 279us/sample - loss: 0.1820 - accuracy: 0.9351 - f1_m: 1.1333 - val_loss: 0.6244 - val_accuracy: 0.8294 - val_f1_m: 1.1693\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 277us/sample - loss: 0.1709 - accuracy: 0.9386 - f1_m: 1.1235 - val_loss: 0.6454 - val_accuracy: 0.8157 - val_f1_m: 1.1953\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 273us/sample - loss: 0.1726 - accuracy: 0.9337 - f1_m: 1.1330 - val_loss: 0.5941 - val_accuracy: 0.8280 - val_f1_m: 1.1918\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 276us/sample - loss: 0.1610 - accuracy: 0.9386 - f1_m: 1.1046 - val_loss: 0.6436 - val_accuracy: 0.8265 - val_f1_m: 1.1601\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 280us/sample - loss: 0.1563 - accuracy: 0.9443 - f1_m: 1.1078 - val_loss: 0.6370 - val_accuracy: 0.8325 - val_f1_m: 1.1325\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 279us/sample - loss: 0.1338 - accuracy: 0.9526 - f1_m: 1.0749 - val_loss: 0.6889 - val_accuracy: 0.8220 - val_f1_m: 1.1528\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 275us/sample - loss: 0.1545 - accuracy: 0.9426 - f1_m: 1.1014 - val_loss: 0.6429 - val_accuracy: 0.8255 - val_f1_m: 1.1686\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 589us/sample - loss: 0.2958 - accuracy: 0.8957 - f1_m: 1.2028 - val_loss: 0.5631 - val_accuracy: 0.8247 - val_f1_m: 1.2614\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 333us/sample - loss: 0.2679 - accuracy: 0.9034 - f1_m: 1.1978 - val_loss: 0.5973 - val_accuracy: 0.8134 - val_f1_m: 1.2490\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 333us/sample - loss: 0.2650 - accuracy: 0.9083 - f1_m: 1.1942 - val_loss: 0.5946 - val_accuracy: 0.8162 - val_f1_m: 1.2285\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 340us/sample - loss: 0.2395 - accuracy: 0.9120 - f1_m: 1.1954 - val_loss: 0.6541 - val_accuracy: 0.8106 - val_f1_m: 1.2033\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 335us/sample - loss: 0.2261 - accuracy: 0.9191 - f1_m: 1.1757 - val_loss: 0.6883 - val_accuracy: 0.8005 - val_f1_m: 1.2539\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 334us/sample - loss: 0.2307 - accuracy: 0.9149 - f1_m: 1.1635 - val_loss: 0.6000 - val_accuracy: 0.8237 - val_f1_m: 1.2181\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 341us/sample - loss: 0.2105 - accuracy: 0.9226 - f1_m: 1.1436 - val_loss: 0.6550 - val_accuracy: 0.8186 - val_f1_m: 1.2145\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 336us/sample - loss: 0.2112 - accuracy: 0.9246 - f1_m: 1.1465 - val_loss: 0.6250 - val_accuracy: 0.8218 - val_f1_m: 1.2155\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 334us/sample - loss: 0.1839 - accuracy: 0.9271 - f1_m: 1.1336 - val_loss: 0.6265 - val_accuracy: 0.8285 - val_f1_m: 1.1934\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 331us/sample - loss: 0.1980 - accuracy: 0.9231 - f1_m: 1.1314 - val_loss: 0.6328 - val_accuracy: 0.8132 - val_f1_m: 1.2182\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 420us/sample - loss: 0.2080 - accuracy: 0.9374 - f1_m: 1.1467 - val_loss: 0.5091 - val_accuracy: 0.8415 - val_f1_m: 1.2306\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 231us/sample - loss: 0.1841 - accuracy: 0.9366 - f1_m: 1.1438 - val_loss: 0.5256 - val_accuracy: 0.8287 - val_f1_m: 1.2484\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 229us/sample - loss: 0.1686 - accuracy: 0.9423 - f1_m: 1.1408 - val_loss: 0.5062 - val_accuracy: 0.8434 - val_f1_m: 1.1973\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 230us/sample - loss: 0.1621 - accuracy: 0.9440 - f1_m: 1.1326 - val_loss: 0.5967 - val_accuracy: 0.8241 - val_f1_m: 1.1969\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 228us/sample - loss: 0.1544 - accuracy: 0.9483 - f1_m: 1.1201 - val_loss: 0.5873 - val_accuracy: 0.8275 - val_f1_m: 1.2219\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 233us/sample - loss: 0.1468 - accuracy: 0.9497 - f1_m: 1.1107 - val_loss: 0.5218 - val_accuracy: 0.8377 - val_f1_m: 1.1996\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 227us/sample - loss: 0.1290 - accuracy: 0.9611 - f1_m: 1.1160 - val_loss: 0.5257 - val_accuracy: 0.8449 - val_f1_m: 1.2061\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 233us/sample - loss: 0.1303 - accuracy: 0.9543 - f1_m: 1.1026 - val_loss: 0.5339 - val_accuracy: 0.8385 - val_f1_m: 1.1915\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 229us/sample - loss: 0.1103 - accuracy: 0.9654 - f1_m: 1.0857 - val_loss: 0.5218 - val_accuracy: 0.8457 - val_f1_m: 1.1829\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 229us/sample - loss: 0.1096 - accuracy: 0.9683 - f1_m: 1.0919 - val_loss: 0.5312 - val_accuracy: 0.8411 - val_f1_m: 1.1658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 425us/sample - loss: 0.1457 - accuracy: 0.9566 - f1_m: 1.0442 - val_loss: 0.6734 - val_accuracy: 0.8386 - val_f1_m: 1.1043\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 273us/sample - loss: 0.1064 - accuracy: 0.9643 - f1_m: 1.0408 - val_loss: 0.5992 - val_accuracy: 0.8442 - val_f1_m: 1.1299\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 256us/sample - loss: 0.0910 - accuracy: 0.9734 - f1_m: 1.0305 - val_loss: 0.6542 - val_accuracy: 0.8442 - val_f1_m: 1.1086\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 256us/sample - loss: 0.0735 - accuracy: 0.9774 - f1_m: 1.0255 - val_loss: 0.6671 - val_accuracy: 0.8492 - val_f1_m: 1.0946\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 257us/sample - loss: 0.0581 - accuracy: 0.9829 - f1_m: 1.0050 - val_loss: 0.7506 - val_accuracy: 0.8341 - val_f1_m: 1.1159\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 257us/sample - loss: 0.0600 - accuracy: 0.9794 - f1_m: 1.0202 - val_loss: 0.6819 - val_accuracy: 0.8398 - val_f1_m: 1.1033\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 260us/sample - loss: 0.0505 - accuracy: 0.9854 - f1_m: 1.0008 - val_loss: 0.7578 - val_accuracy: 0.8491 - val_f1_m: 1.0820\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 256us/sample - loss: 0.0488 - accuracy: 0.9854 - f1_m: 0.9980 - val_loss: 0.7043 - val_accuracy: 0.8418 - val_f1_m: 1.0810\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 259us/sample - loss: 0.0272 - accuracy: 0.9940 - f1_m: 0.9811 - val_loss: 0.7232 - val_accuracy: 0.8423 - val_f1_m: 1.0765\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 256us/sample - loss: 0.0303 - accuracy: 0.9903 - f1_m: 0.9849 - val_loss: 0.7283 - val_accuracy: 0.8504 - val_f1_m: 1.0655\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 500us/sample - loss: 0.1316 - accuracy: 0.9629 - f1_m: 1.0134 - val_loss: 0.7081 - val_accuracy: 0.8417 - val_f1_m: 1.0934\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 291us/sample - loss: 0.0815 - accuracy: 0.9743 - f1_m: 1.0096 - val_loss: 0.6314 - val_accuracy: 0.8426 - val_f1_m: 1.1111\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 295us/sample - loss: 0.0569 - accuracy: 0.9811 - f1_m: 0.9955 - val_loss: 0.6580 - val_accuracy: 0.8474 - val_f1_m: 1.0956\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 291us/sample - loss: 0.0452 - accuracy: 0.9866 - f1_m: 0.9868 - val_loss: 0.7091 - val_accuracy: 0.8441 - val_f1_m: 1.0769\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 294us/sample - loss: 0.0303 - accuracy: 0.9889 - f1_m: 0.9721 - val_loss: 0.8480 - val_accuracy: 0.8369 - val_f1_m: 1.0683\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 300us/sample - loss: 0.0474 - accuracy: 0.9857 - f1_m: 0.9949 - val_loss: 0.7883 - val_accuracy: 0.8536 - val_f1_m: 1.0521\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 297us/sample - loss: 0.0284 - accuracy: 0.9909 - f1_m: 0.9682 - val_loss: 0.8316 - val_accuracy: 0.8521 - val_f1_m: 1.0489\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 294us/sample - loss: 0.0328 - accuracy: 0.9889 - f1_m: 0.9751 - val_loss: 0.8430 - val_accuracy: 0.8450 - val_f1_m: 1.0425\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 297us/sample - loss: 0.0262 - accuracy: 0.9929 - f1_m: 0.9617 - val_loss: 0.8277 - val_accuracy: 0.8508 - val_f1_m: 1.0595\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 297us/sample - loss: 0.0177 - accuracy: 0.9937 - f1_m: 0.9630 - val_loss: 0.8611 - val_accuracy: 0.8474 - val_f1_m: 1.0618\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 608us/sample - loss: 0.1679 - accuracy: 0.9517 - f1_m: 1.0732 - val_loss: 0.6304 - val_accuracy: 0.8274 - val_f1_m: 1.1710\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 361us/sample - loss: 0.1162 - accuracy: 0.9611 - f1_m: 1.0422 - val_loss: 0.6255 - val_accuracy: 0.8245 - val_f1_m: 1.1702\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 359us/sample - loss: 0.0927 - accuracy: 0.9663 - f1_m: 1.0189 - val_loss: 0.8151 - val_accuracy: 0.8280 - val_f1_m: 1.0918\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 360us/sample - loss: 0.0802 - accuracy: 0.9740 - f1_m: 1.0185 - val_loss: 0.8961 - val_accuracy: 0.8278 - val_f1_m: 1.0738\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 363us/sample - loss: 0.0684 - accuracy: 0.9734 - f1_m: 1.0046 - val_loss: 0.8527 - val_accuracy: 0.8174 - val_f1_m: 1.1054\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 360us/sample - loss: 0.0682 - accuracy: 0.9766 - f1_m: 1.0033 - val_loss: 0.9671 - val_accuracy: 0.8253 - val_f1_m: 1.0644\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 363us/sample - loss: 0.0839 - accuracy: 0.9720 - f1_m: 1.0103 - val_loss: 0.8245 - val_accuracy: 0.8196 - val_f1_m: 1.1129\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 360us/sample - loss: 0.0493 - accuracy: 0.9851 - f1_m: 0.9855 - val_loss: 1.1141 - val_accuracy: 0.8123 - val_f1_m: 1.0675\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 360us/sample - loss: 0.0611 - accuracy: 0.9780 - f1_m: 0.9971 - val_loss: 0.9577 - val_accuracy: 0.8254 - val_f1_m: 1.0745\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 360us/sample - loss: 0.0367 - accuracy: 0.9883 - f1_m: 0.9759 - val_loss: 1.0357 - val_accuracy: 0.8260 - val_f1_m: 1.0559\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 318us/sample - loss: 0.3339 - accuracy: 0.8835 - f1_m: 1.2928 - val_loss: 0.5827 - val_accuracy: 0.8055 - val_f1_m: 1.3410\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.3342 - accuracy: 0.8865 - f1_m: 1.2948 - val_loss: 0.5294 - val_accuracy: 0.8241 - val_f1_m: 1.3100\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 202us/sample - loss: 0.3201 - accuracy: 0.8930 - f1_m: 1.2892 - val_loss: 0.5154 - val_accuracy: 0.8244 - val_f1_m: 1.3137\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.3154 - accuracy: 0.8907 - f1_m: 1.2913 - val_loss: 0.5191 - val_accuracy: 0.8284 - val_f1_m: 1.3060\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.3095 - accuracy: 0.8945 - f1_m: 1.2819 - val_loss: 0.4976 - val_accuracy: 0.8376 - val_f1_m: 1.3029\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.3034 - accuracy: 0.8920 - f1_m: 1.2771 - val_loss: 0.5118 - val_accuracy: 0.8252 - val_f1_m: 1.3142\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 197us/sample - loss: 0.3111 - accuracy: 0.8920 - f1_m: 1.2831 - val_loss: 0.5466 - val_accuracy: 0.8151 - val_f1_m: 1.3343\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.3001 - accuracy: 0.8985 - f1_m: 1.2644 - val_loss: 0.5092 - val_accuracy: 0.8320 - val_f1_m: 1.2941\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.2838 - accuracy: 0.8992 - f1_m: 1.2647 - val_loss: 0.5177 - val_accuracy: 0.8253 - val_f1_m: 1.3355\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 202us/sample - loss: 0.2846 - accuracy: 0.9015 - f1_m: 1.2704 - val_loss: 0.4961 - val_accuracy: 0.8356 - val_f1_m: 1.2986\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 345us/sample - loss: 0.2526 - accuracy: 0.9103 - f1_m: 1.1924 - val_loss: 0.4951 - val_accuracy: 0.8405 - val_f1_m: 1.2407\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.2521 - accuracy: 0.9103 - f1_m: 1.2010 - val_loss: 0.4944 - val_accuracy: 0.8344 - val_f1_m: 1.2244\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 220us/sample - loss: 0.2377 - accuracy: 0.9135 - f1_m: 1.1855 - val_loss: 0.4772 - val_accuracy: 0.8461 - val_f1_m: 1.2204\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.2256 - accuracy: 0.9202 - f1_m: 1.1847 - val_loss: 0.4868 - val_accuracy: 0.8374 - val_f1_m: 1.2240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 217us/sample - loss: 0.2254 - accuracy: 0.9205 - f1_m: 1.1818 - val_loss: 0.5246 - val_accuracy: 0.8365 - val_f1_m: 1.2157\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.2176 - accuracy: 0.9225 - f1_m: 1.1757 - val_loss: 0.4911 - val_accuracy: 0.8442 - val_f1_m: 1.1970\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.2172 - accuracy: 0.9235 - f1_m: 1.1700 - val_loss: 0.5064 - val_accuracy: 0.8438 - val_f1_m: 1.2056\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 219us/sample - loss: 0.2168 - accuracy: 0.9220 - f1_m: 1.1667 - val_loss: 0.4978 - val_accuracy: 0.8399 - val_f1_m: 1.2247\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.1993 - accuracy: 0.9315 - f1_m: 1.1578 - val_loss: 0.5145 - val_accuracy: 0.8409 - val_f1_m: 1.2122\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.2001 - accuracy: 0.9285 - f1_m: 1.1644 - val_loss: 0.4963 - val_accuracy: 0.8486 - val_f1_m: 1.2015\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 410us/sample - loss: 0.1981 - accuracy: 0.9317 - f1_m: 1.1248 - val_loss: 0.6302 - val_accuracy: 0.8302 - val_f1_m: 1.1712\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 250us/sample - loss: 0.1848 - accuracy: 0.9337 - f1_m: 1.1223 - val_loss: 0.6140 - val_accuracy: 0.8288 - val_f1_m: 1.1580\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 250us/sample - loss: 0.1733 - accuracy: 0.9370 - f1_m: 1.1137 - val_loss: 0.6155 - val_accuracy: 0.8347 - val_f1_m: 1.1494\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 253us/sample - loss: 0.1508 - accuracy: 0.9465 - f1_m: 1.1101 - val_loss: 0.6507 - val_accuracy: 0.8326 - val_f1_m: 1.1473\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 250us/sample - loss: 0.1540 - accuracy: 0.9460 - f1_m: 1.0946 - val_loss: 0.6258 - val_accuracy: 0.8329 - val_f1_m: 1.1488\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 248us/sample - loss: 0.1483 - accuracy: 0.9445 - f1_m: 1.0936 - val_loss: 0.6444 - val_accuracy: 0.8330 - val_f1_m: 1.1630\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 250us/sample - loss: 0.1356 - accuracy: 0.9500 - f1_m: 1.0875 - val_loss: 0.6537 - val_accuracy: 0.8299 - val_f1_m: 1.1514\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 253us/sample - loss: 0.1478 - accuracy: 0.9488 - f1_m: 1.0867 - val_loss: 0.6694 - val_accuracy: 0.8321 - val_f1_m: 1.1418\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 253us/sample - loss: 0.1173 - accuracy: 0.9592 - f1_m: 1.0768 - val_loss: 0.7667 - val_accuracy: 0.8230 - val_f1_m: 1.1295\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 252us/sample - loss: 0.1235 - accuracy: 0.9548 - f1_m: 1.0699 - val_loss: 0.6797 - val_accuracy: 0.8299 - val_f1_m: 1.1324\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 513us/sample - loss: 0.2394 - accuracy: 0.9183 - f1_m: 1.1572 - val_loss: 0.6087 - val_accuracy: 0.8185 - val_f1_m: 1.2142\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 300us/sample - loss: 0.2333 - accuracy: 0.9160 - f1_m: 1.1662 - val_loss: 0.6068 - val_accuracy: 0.8169 - val_f1_m: 1.2120\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 305us/sample - loss: 0.2177 - accuracy: 0.9205 - f1_m: 1.1585 - val_loss: 0.6063 - val_accuracy: 0.8271 - val_f1_m: 1.1947\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 305us/sample - loss: 0.2097 - accuracy: 0.9225 - f1_m: 1.1391 - val_loss: 0.6494 - val_accuracy: 0.8237 - val_f1_m: 1.1667\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 303us/sample - loss: 0.1972 - accuracy: 0.9268 - f1_m: 1.1399 - val_loss: 0.6328 - val_accuracy: 0.8299 - val_f1_m: 1.1710\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 302us/sample - loss: 0.1854 - accuracy: 0.9348 - f1_m: 1.1151 - val_loss: 0.5933 - val_accuracy: 0.8198 - val_f1_m: 1.2570\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 300us/sample - loss: 0.2050 - accuracy: 0.9260 - f1_m: 1.1380 - val_loss: 0.6180 - val_accuracy: 0.8223 - val_f1_m: 1.2041\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 305us/sample - loss: 0.1930 - accuracy: 0.9300 - f1_m: 1.1339 - val_loss: 0.6233 - val_accuracy: 0.8190 - val_f1_m: 1.1899\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 305us/sample - loss: 0.1682 - accuracy: 0.9342 - f1_m: 1.1139 - val_loss: 0.6728 - val_accuracy: 0.8204 - val_f1_m: 1.1579\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 302us/sample - loss: 0.1684 - accuracy: 0.9370 - f1_m: 1.1128 - val_loss: 0.6635 - val_accuracy: 0.8150 - val_f1_m: 1.1768\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 319us/sample - loss: 0.1742 - accuracy: 0.9492 - f1_m: 1.1079 - val_loss: 0.5286 - val_accuracy: 0.8466 - val_f1_m: 1.1931\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.1545 - accuracy: 0.9492 - f1_m: 1.1027 - val_loss: 0.5272 - val_accuracy: 0.8426 - val_f1_m: 1.1816\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.1400 - accuracy: 0.9575 - f1_m: 1.0878 - val_loss: 0.5046 - val_accuracy: 0.8466 - val_f1_m: 1.1745\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 203us/sample - loss: 0.1278 - accuracy: 0.9582 - f1_m: 1.0907 - val_loss: 0.6082 - val_accuracy: 0.8332 - val_f1_m: 1.1660\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.1309 - accuracy: 0.9578 - f1_m: 1.0945 - val_loss: 0.5114 - val_accuracy: 0.8525 - val_f1_m: 1.1771\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.1120 - accuracy: 0.9682 - f1_m: 1.0759 - val_loss: 0.5126 - val_accuracy: 0.8488 - val_f1_m: 1.1772\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 197us/sample - loss: 0.1108 - accuracy: 0.9653 - f1_m: 1.0772 - val_loss: 0.5245 - val_accuracy: 0.8436 - val_f1_m: 1.1833\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.1067 - accuracy: 0.9688 - f1_m: 1.0668 - val_loss: 0.5259 - val_accuracy: 0.8481 - val_f1_m: 1.1630\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 202us/sample - loss: 0.0888 - accuracy: 0.9730 - f1_m: 1.0580 - val_loss: 0.5611 - val_accuracy: 0.8446 - val_f1_m: 1.1544\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 200us/sample - loss: 0.0978 - accuracy: 0.9670 - f1_m: 1.0686 - val_loss: 0.5541 - val_accuracy: 0.8507 - val_f1_m: 1.1503\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 351us/sample - loss: 0.1369 - accuracy: 0.9657 - f1_m: 1.0219 - val_loss: 0.6690 - val_accuracy: 0.8437 - val_f1_m: 1.1079\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 223us/sample - loss: 0.1027 - accuracy: 0.9700 - f1_m: 1.0183 - val_loss: 0.6414 - val_accuracy: 0.8473 - val_f1_m: 1.0925\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 225us/sample - loss: 0.0677 - accuracy: 0.9778 - f1_m: 1.0121 - val_loss: 0.6477 - val_accuracy: 0.8500 - val_f1_m: 1.0859\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 225us/sample - loss: 0.0702 - accuracy: 0.9762 - f1_m: 1.0111 - val_loss: 0.6950 - val_accuracy: 0.8383 - val_f1_m: 1.1061\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 225us/sample - loss: 0.0549 - accuracy: 0.9845 - f1_m: 1.0159 - val_loss: 0.6983 - val_accuracy: 0.8489 - val_f1_m: 1.0670\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 225us/sample - loss: 0.0455 - accuracy: 0.9858 - f1_m: 0.9962 - val_loss: 0.6875 - val_accuracy: 0.8542 - val_f1_m: 1.0615\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 223us/sample - loss: 0.0416 - accuracy: 0.9872 - f1_m: 0.9942 - val_loss: 0.7164 - val_accuracy: 0.8446 - val_f1_m: 1.0861\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 223us/sample - loss: 0.0335 - accuracy: 0.9887 - f1_m: 0.9868 - val_loss: 0.7597 - val_accuracy: 0.8440 - val_f1_m: 1.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 223us/sample - loss: 0.0442 - accuracy: 0.9850 - f1_m: 0.9949 - val_loss: 0.7795 - val_accuracy: 0.8440 - val_f1_m: 1.0758\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 223us/sample - loss: 0.0338 - accuracy: 0.9893 - f1_m: 0.9875 - val_loss: 0.7420 - val_accuracy: 0.8530 - val_f1_m: 1.0624\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 417us/sample - loss: 0.1227 - accuracy: 0.9690 - f1_m: 1.0051 - val_loss: 0.5731 - val_accuracy: 0.8554 - val_f1_m: 1.1001\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 265us/sample - loss: 0.0569 - accuracy: 0.9862 - f1_m: 0.9894 - val_loss: 0.6504 - val_accuracy: 0.8426 - val_f1_m: 1.0845\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 263us/sample - loss: 0.0343 - accuracy: 0.9895 - f1_m: 0.9786 - val_loss: 0.7505 - val_accuracy: 0.8513 - val_f1_m: 1.0630\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 262us/sample - loss: 0.0263 - accuracy: 0.9925 - f1_m: 0.9753 - val_loss: 0.7780 - val_accuracy: 0.8515 - val_f1_m: 1.0478\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 263us/sample - loss: 0.0319 - accuracy: 0.9887 - f1_m: 0.9723 - val_loss: 0.8392 - val_accuracy: 0.8460 - val_f1_m: 1.0622\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 260us/sample - loss: 0.0550 - accuracy: 0.9795 - f1_m: 0.9848 - val_loss: 0.7512 - val_accuracy: 0.8505 - val_f1_m: 1.0643\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 268us/sample - loss: 0.0264 - accuracy: 0.9920 - f1_m: 0.9699 - val_loss: 0.9500 - val_accuracy: 0.8442 - val_f1_m: 1.0535\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 264us/sample - loss: 0.0319 - accuracy: 0.9893 - f1_m: 0.9704 - val_loss: 0.8358 - val_accuracy: 0.8532 - val_f1_m: 1.0473\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 262us/sample - loss: 0.0080 - accuracy: 0.9987 - f1_m: 0.9558 - val_loss: 0.9148 - val_accuracy: 0.8558 - val_f1_m: 1.0318\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 263us/sample - loss: 0.0011 - accuracy: 1.0000 - f1_m: 0.9437 - val_loss: 0.9860 - val_accuracy: 0.8603 - val_f1_m: 1.0209\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 3s 714us/sample - loss: 0.1508 - accuracy: 0.9580 - f1_m: 1.0440 - val_loss: 0.6620 - val_accuracy: 0.8314 - val_f1_m: 1.1258\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.0876 - accuracy: 0.9718 - f1_m: 1.0110 - val_loss: 0.7044 - val_accuracy: 0.8232 - val_f1_m: 1.1309\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 327us/sample - loss: 0.0854 - accuracy: 0.9712 - f1_m: 1.0120 - val_loss: 0.7215 - val_accuracy: 0.8301 - val_f1_m: 1.1072\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 328us/sample - loss: 0.0628 - accuracy: 0.9805 - f1_m: 1.0037 - val_loss: 0.8978 - val_accuracy: 0.8208 - val_f1_m: 1.0873\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.0747 - accuracy: 0.9765 - f1_m: 1.0052 - val_loss: 0.9642 - val_accuracy: 0.8251 - val_f1_m: 1.0881\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 328us/sample - loss: 0.0493 - accuracy: 0.9845 - f1_m: 0.9822 - val_loss: 0.9782 - val_accuracy: 0.8281 - val_f1_m: 1.0702\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 327us/sample - loss: 0.0528 - accuracy: 0.9825 - f1_m: 0.9902 - val_loss: 0.9365 - val_accuracy: 0.8240 - val_f1_m: 1.0797\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 326us/sample - loss: 0.0677 - accuracy: 0.9778 - f1_m: 0.9969 - val_loss: 1.1407 - val_accuracy: 0.8161 - val_f1_m: 1.0731\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.0469 - accuracy: 0.9855 - f1_m: 0.9858 - val_loss: 1.0789 - val_accuracy: 0.8221 - val_f1_m: 1.0675\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.0582 - accuracy: 0.9803 - f1_m: 0.9868 - val_loss: 0.9181 - val_accuracy: 0.8210 - val_f1_m: 1.0956\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 1s 298us/sample - loss: 0.3134 - accuracy: 0.8916 - f1_m: 1.2626 - val_loss: 0.5500 - val_accuracy: 0.8204 - val_f1_m: 1.3089\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 194us/sample - loss: 0.3030 - accuracy: 0.8967 - f1_m: 1.2696 - val_loss: 0.5159 - val_accuracy: 0.8257 - val_f1_m: 1.3116\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 195us/sample - loss: 0.2985 - accuracy: 0.8936 - f1_m: 1.2662 - val_loss: 0.4935 - val_accuracy: 0.8387 - val_f1_m: 1.2935\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 195us/sample - loss: 0.2874 - accuracy: 0.9029 - f1_m: 1.2649 - val_loss: 0.4922 - val_accuracy: 0.8347 - val_f1_m: 1.2933\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 192us/sample - loss: 0.2734 - accuracy: 0.9024 - f1_m: 1.2493 - val_loss: 0.5322 - val_accuracy: 0.8211 - val_f1_m: 1.3012\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 193us/sample - loss: 0.2798 - accuracy: 0.9044 - f1_m: 1.2464 - val_loss: 0.4829 - val_accuracy: 0.8392 - val_f1_m: 1.2888\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 196us/sample - loss: 0.2692 - accuracy: 0.9107 - f1_m: 1.2483 - val_loss: 0.4878 - val_accuracy: 0.8332 - val_f1_m: 1.2840\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 193us/sample - loss: 0.2692 - accuracy: 0.9073 - f1_m: 1.2439 - val_loss: 0.5209 - val_accuracy: 0.8297 - val_f1_m: 1.3064\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 193us/sample - loss: 0.2596 - accuracy: 0.9107 - f1_m: 1.2434 - val_loss: 0.4983 - val_accuracy: 0.8370 - val_f1_m: 1.2873\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 191us/sample - loss: 0.2685 - accuracy: 0.9002 - f1_m: 1.2369 - val_loss: 0.4820 - val_accuracy: 0.8371 - val_f1_m: 1.2744\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 1s 324us/sample - loss: 0.2229 - accuracy: 0.9184 - f1_m: 1.1608 - val_loss: 0.5294 - val_accuracy: 0.8395 - val_f1_m: 1.1843\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 209us/sample - loss: 0.2204 - accuracy: 0.9209 - f1_m: 1.1652 - val_loss: 0.4848 - val_accuracy: 0.8521 - val_f1_m: 1.2002\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 204us/sample - loss: 0.2027 - accuracy: 0.9291 - f1_m: 1.1596 - val_loss: 0.4798 - val_accuracy: 0.8486 - val_f1_m: 1.1873\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 207us/sample - loss: 0.1979 - accuracy: 0.9287 - f1_m: 1.1571 - val_loss: 0.5006 - val_accuracy: 0.8398 - val_f1_m: 1.2245\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 206us/sample - loss: 0.1928 - accuracy: 0.9304 - f1_m: 1.1509 - val_loss: 0.4982 - val_accuracy: 0.8431 - val_f1_m: 1.1880\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 207us/sample - loss: 0.1852 - accuracy: 0.9356 - f1_m: 1.1431 - val_loss: 0.5014 - val_accuracy: 0.8522 - val_f1_m: 1.1815\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 207us/sample - loss: 0.1827 - accuracy: 0.9324 - f1_m: 1.1396 - val_loss: 0.4915 - val_accuracy: 0.8483 - val_f1_m: 1.1972\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 207us/sample - loss: 0.1700 - accuracy: 0.9409 - f1_m: 1.1374 - val_loss: 0.5137 - val_accuracy: 0.8500 - val_f1_m: 1.1700\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 204us/sample - loss: 0.1676 - accuracy: 0.9391 - f1_m: 1.1314 - val_loss: 0.5093 - val_accuracy: 0.8490 - val_f1_m: 1.1691\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 207us/sample - loss: 0.1747 - accuracy: 0.9373 - f1_m: 1.1379 - val_loss: 0.5023 - val_accuracy: 0.8526 - val_f1_m: 1.1668\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 382us/sample - loss: 0.1767 - accuracy: 0.9447 - f1_m: 1.0947 - val_loss: 0.6857 - val_accuracy: 0.8334 - val_f1_m: 1.1206\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 240us/sample - loss: 0.1486 - accuracy: 0.9487 - f1_m: 1.0882 - val_loss: 0.7003 - val_accuracy: 0.8258 - val_f1_m: 1.1318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 238us/sample - loss: 0.1331 - accuracy: 0.9549 - f1_m: 1.0796 - val_loss: 0.6833 - val_accuracy: 0.8293 - val_f1_m: 1.1260\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 242us/sample - loss: 0.1219 - accuracy: 0.9578 - f1_m: 1.0673 - val_loss: 0.6727 - val_accuracy: 0.8197 - val_f1_m: 1.1786\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 240us/sample - loss: 0.1294 - accuracy: 0.9493 - f1_m: 1.0794 - val_loss: 0.7289 - val_accuracy: 0.8234 - val_f1_m: 1.1265\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 238us/sample - loss: 0.1156 - accuracy: 0.9604 - f1_m: 1.0687 - val_loss: 0.6998 - val_accuracy: 0.8364 - val_f1_m: 1.1169\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 238us/sample - loss: 0.1120 - accuracy: 0.9556 - f1_m: 1.0591 - val_loss: 0.7299 - val_accuracy: 0.8392 - val_f1_m: 1.1202\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 238us/sample - loss: 0.1017 - accuracy: 0.9604 - f1_m: 1.0532 - val_loss: 0.7758 - val_accuracy: 0.8302 - val_f1_m: 1.1192\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 238us/sample - loss: 0.0807 - accuracy: 0.9729 - f1_m: 1.0345 - val_loss: 0.7605 - val_accuracy: 0.8370 - val_f1_m: 1.1108\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 240us/sample - loss: 0.0920 - accuracy: 0.9638 - f1_m: 1.0432 - val_loss: 0.8588 - val_accuracy: 0.8343 - val_f1_m: 1.0969\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 480us/sample - loss: 0.2239 - accuracy: 0.9249 - f1_m: 1.1318 - val_loss: 0.6565 - val_accuracy: 0.8181 - val_f1_m: 1.1791\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 289us/sample - loss: 0.1957 - accuracy: 0.9304 - f1_m: 1.1228 - val_loss: 0.6399 - val_accuracy: 0.8180 - val_f1_m: 1.1943\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 291us/sample - loss: 0.1746 - accuracy: 0.9367 - f1_m: 1.1164 - val_loss: 0.6300 - val_accuracy: 0.8146 - val_f1_m: 1.1958\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 291us/sample - loss: 0.1717 - accuracy: 0.9376 - f1_m: 1.1061 - val_loss: 0.6157 - val_accuracy: 0.8126 - val_f1_m: 1.2275\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 289us/sample - loss: 0.1675 - accuracy: 0.9362 - f1_m: 1.1141 - val_loss: 0.6520 - val_accuracy: 0.8244 - val_f1_m: 1.1696\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 289us/sample - loss: 0.1689 - accuracy: 0.9364 - f1_m: 1.0964 - val_loss: 0.6756 - val_accuracy: 0.8309 - val_f1_m: 1.1354\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 291us/sample - loss: 0.1629 - accuracy: 0.9398 - f1_m: 1.1035 - val_loss: 0.6515 - val_accuracy: 0.8173 - val_f1_m: 1.2001\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 290us/sample - loss: 0.1298 - accuracy: 0.9533 - f1_m: 1.0727 - val_loss: 0.7708 - val_accuracy: 0.8167 - val_f1_m: 1.1297\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 294us/sample - loss: 0.1453 - accuracy: 0.9476 - f1_m: 1.0861 - val_loss: 0.6806 - val_accuracy: 0.8178 - val_f1_m: 1.1695\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 287us/sample - loss: 0.1331 - accuracy: 0.9527 - f1_m: 1.0759 - val_loss: 0.7480 - val_accuracy: 0.8240 - val_f1_m: 1.1405\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 1s 298us/sample - loss: 0.1466 - accuracy: 0.9549 - f1_m: 1.0803 - val_loss: 0.5347 - val_accuracy: 0.8463 - val_f1_m: 1.1527\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 191us/sample - loss: 0.1319 - accuracy: 0.9587 - f1_m: 1.0765 - val_loss: 0.5145 - val_accuracy: 0.8473 - val_f1_m: 1.1559\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 191us/sample - loss: 0.1048 - accuracy: 0.9671 - f1_m: 1.0644 - val_loss: 0.5336 - val_accuracy: 0.8467 - val_f1_m: 1.1454\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 191us/sample - loss: 0.0987 - accuracy: 0.9698 - f1_m: 1.0589 - val_loss: 0.5271 - val_accuracy: 0.8459 - val_f1_m: 1.1472\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 193us/sample - loss: 0.0907 - accuracy: 0.9724 - f1_m: 1.0549 - val_loss: 0.5469 - val_accuracy: 0.8395 - val_f1_m: 1.1453\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 196us/sample - loss: 0.0888 - accuracy: 0.9749 - f1_m: 1.0481 - val_loss: 0.5296 - val_accuracy: 0.8496 - val_f1_m: 1.1506\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 193us/sample - loss: 0.0772 - accuracy: 0.9793 - f1_m: 1.0418 - val_loss: 0.5349 - val_accuracy: 0.8491 - val_f1_m: 1.1343\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 196us/sample - loss: 0.0682 - accuracy: 0.9809 - f1_m: 1.0313 - val_loss: 0.5560 - val_accuracy: 0.8502 - val_f1_m: 1.1341\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 193us/sample - loss: 0.0742 - accuracy: 0.9787 - f1_m: 1.0433 - val_loss: 0.5886 - val_accuracy: 0.8439 - val_f1_m: 1.1337\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 195us/sample - loss: 0.0593 - accuracy: 0.9840 - f1_m: 1.0281 - val_loss: 0.5679 - val_accuracy: 0.8511 - val_f1_m: 1.1177\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 1s 331us/sample - loss: 0.1038 - accuracy: 0.9707 - f1_m: 1.0053 - val_loss: 0.6655 - val_accuracy: 0.8521 - val_f1_m: 1.0739\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 220us/sample - loss: 0.0577 - accuracy: 0.9827 - f1_m: 1.0040 - val_loss: 0.7072 - val_accuracy: 0.8493 - val_f1_m: 1.0785\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 219us/sample - loss: 0.0500 - accuracy: 0.9853 - f1_m: 0.9900 - val_loss: 0.6708 - val_accuracy: 0.8527 - val_f1_m: 1.0820\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 216us/sample - loss: 0.0401 - accuracy: 0.9878 - f1_m: 0.9888 - val_loss: 0.7072 - val_accuracy: 0.8477 - val_f1_m: 1.0869\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 218us/sample - loss: 0.0410 - accuracy: 0.9873 - f1_m: 0.9908 - val_loss: 0.6861 - val_accuracy: 0.8543 - val_f1_m: 1.0639\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 220us/sample - loss: 0.0259 - accuracy: 0.9929 - f1_m: 0.9777 - val_loss: 0.6987 - val_accuracy: 0.8610 - val_f1_m: 1.0657\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 218us/sample - loss: 0.0195 - accuracy: 0.9947 - f1_m: 0.9693 - val_loss: 0.7564 - val_accuracy: 0.8588 - val_f1_m: 1.0448\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 215us/sample - loss: 0.0215 - accuracy: 0.9947 - f1_m: 0.9675 - val_loss: 0.7513 - val_accuracy: 0.8588 - val_f1_m: 1.0537\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 219us/sample - loss: 0.0215 - accuracy: 0.9933 - f1_m: 0.9656 - val_loss: 0.7949 - val_accuracy: 0.8566 - val_f1_m: 1.0467\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 216us/sample - loss: 0.0264 - accuracy: 0.9909 - f1_m: 0.9789 - val_loss: 0.8423 - val_accuracy: 0.8529 - val_f1_m: 1.0524\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 3s 572us/sample - loss: 0.1069 - accuracy: 0.9727 - f1_m: 0.9943 - val_loss: 0.6614 - val_accuracy: 0.8503 - val_f1_m: 1.0691\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 254us/sample - loss: 0.0544 - accuracy: 0.9844 - f1_m: 0.9862 - val_loss: 0.7863 - val_accuracy: 0.8509 - val_f1_m: 1.0547\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 253us/sample - loss: 0.0454 - accuracy: 0.9844 - f1_m: 0.9817 - val_loss: 0.7369 - val_accuracy: 0.8548 - val_f1_m: 1.0581\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 256us/sample - loss: 0.0244 - accuracy: 0.9900 - f1_m: 0.9657 - val_loss: 0.8170 - val_accuracy: 0.8431 - val_f1_m: 1.0699\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 253us/sample - loss: 0.0412 - accuracy: 0.9851 - f1_m: 0.9785 - val_loss: 0.6964 - val_accuracy: 0.8513 - val_f1_m: 1.0703\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 251us/sample - loss: 0.0182 - accuracy: 0.9944 - f1_m: 0.9646 - val_loss: 0.9270 - val_accuracy: 0.8643 - val_f1_m: 1.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 251us/sample - loss: 0.0201 - accuracy: 0.9944 - f1_m: 0.9611 - val_loss: 0.8778 - val_accuracy: 0.8554 - val_f1_m: 1.0401\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 253us/sample - loss: 0.0482 - accuracy: 0.9844 - f1_m: 0.9733 - val_loss: 0.8182 - val_accuracy: 0.8425 - val_f1_m: 1.0682\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 251us/sample - loss: 0.0255 - accuracy: 0.9918 - f1_m: 0.9675 - val_loss: 0.9003 - val_accuracy: 0.8557 - val_f1_m: 1.0383\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 253us/sample - loss: 0.0150 - accuracy: 0.9956 - f1_m: 0.9579 - val_loss: 0.9766 - val_accuracy: 0.8528 - val_f1_m: 1.0357\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 504us/sample - loss: 0.1349 - accuracy: 0.9611 - f1_m: 1.0335 - val_loss: 0.7826 - val_accuracy: 0.8333 - val_f1_m: 1.0952\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 315us/sample - loss: 0.0816 - accuracy: 0.9733 - f1_m: 1.0073 - val_loss: 0.7833 - val_accuracy: 0.8344 - val_f1_m: 1.0976\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 313us/sample - loss: 0.0687 - accuracy: 0.9762 - f1_m: 1.0080 - val_loss: 0.9195 - val_accuracy: 0.8310 - val_f1_m: 1.0820\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 313us/sample - loss: 0.0640 - accuracy: 0.9802 - f1_m: 0.9982 - val_loss: 0.9487 - val_accuracy: 0.8200 - val_f1_m: 1.0929\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 316us/sample - loss: 0.0528 - accuracy: 0.9816 - f1_m: 0.9900 - val_loss: 0.9611 - val_accuracy: 0.8265 - val_f1_m: 1.0663\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 313us/sample - loss: 0.0345 - accuracy: 0.9876 - f1_m: 0.9737 - val_loss: 1.0058 - val_accuracy: 0.8381 - val_f1_m: 1.0625\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 313us/sample - loss: 0.0497 - accuracy: 0.9824 - f1_m: 0.9837 - val_loss: 1.1317 - val_accuracy: 0.8346 - val_f1_m: 1.0462\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 314us/sample - loss: 0.0802 - accuracy: 0.9696 - f1_m: 1.0036 - val_loss: 1.0246 - val_accuracy: 0.8296 - val_f1_m: 1.0757\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 313us/sample - loss: 0.0434 - accuracy: 0.9858 - f1_m: 0.9810 - val_loss: 1.1960 - val_accuracy: 0.8211 - val_f1_m: 1.0508\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 315us/sample - loss: 0.0536 - accuracy: 0.9838 - f1_m: 0.9786 - val_loss: 1.1358 - val_accuracy: 0.8324 - val_f1_m: 1.0510\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 1s 276us/sample - loss: 0.2807 - accuracy: 0.9012 - f1_m: 1.2401 - val_loss: 0.5080 - val_accuracy: 0.8360 - val_f1_m: 1.2582\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.2698 - accuracy: 0.9060 - f1_m: 1.2283 - val_loss: 0.4798 - val_accuracy: 0.8397 - val_f1_m: 1.2856\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.2652 - accuracy: 0.9050 - f1_m: 1.2275 - val_loss: 0.4970 - val_accuracy: 0.8306 - val_f1_m: 1.3064\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.2708 - accuracy: 0.9064 - f1_m: 1.2303 - val_loss: 0.4834 - val_accuracy: 0.8392 - val_f1_m: 1.2710\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.2578 - accuracy: 0.9100 - f1_m: 1.2269 - val_loss: 0.4902 - val_accuracy: 0.8352 - val_f1_m: 1.2642\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 184us/sample - loss: 0.2629 - accuracy: 0.9048 - f1_m: 1.2222 - val_loss: 0.4878 - val_accuracy: 0.8358 - val_f1_m: 1.2763\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.2460 - accuracy: 0.9140 - f1_m: 1.2243 - val_loss: 0.5174 - val_accuracy: 0.8248 - val_f1_m: 1.2683\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.2402 - accuracy: 0.9172 - f1_m: 1.2146 - val_loss: 0.4916 - val_accuracy: 0.8321 - val_f1_m: 1.2653\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.2341 - accuracy: 0.9158 - f1_m: 1.2103 - val_loss: 0.4784 - val_accuracy: 0.8408 - val_f1_m: 1.2569\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.2327 - accuracy: 0.9178 - f1_m: 1.2130 - val_loss: 0.4961 - val_accuracy: 0.8385 - val_f1_m: 1.2509\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.1944 - accuracy: 0.9292 - f1_m: 1.1328 - val_loss: 0.5210 - val_accuracy: 0.8569 - val_f1_m: 1.1536\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 196us/sample - loss: 0.1819 - accuracy: 0.9356 - f1_m: 1.1299 - val_loss: 0.4823 - val_accuracy: 0.8521 - val_f1_m: 1.1700\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 195us/sample - loss: 0.1679 - accuracy: 0.9402 - f1_m: 1.1308 - val_loss: 0.5273 - val_accuracy: 0.8479 - val_f1_m: 1.1723\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 194us/sample - loss: 0.1765 - accuracy: 0.9368 - f1_m: 1.1301 - val_loss: 0.5151 - val_accuracy: 0.8529 - val_f1_m: 1.1575\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 194us/sample - loss: 0.1668 - accuracy: 0.9404 - f1_m: 1.1245 - val_loss: 0.5144 - val_accuracy: 0.8538 - val_f1_m: 1.1700\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 198us/sample - loss: 0.1709 - accuracy: 0.9392 - f1_m: 1.1221 - val_loss: 0.5223 - val_accuracy: 0.8488 - val_f1_m: 1.1585\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 192us/sample - loss: 0.1525 - accuracy: 0.9436 - f1_m: 1.1174 - val_loss: 0.5181 - val_accuracy: 0.8534 - val_f1_m: 1.1669\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 194us/sample - loss: 0.1443 - accuracy: 0.9518 - f1_m: 1.1073 - val_loss: 0.5540 - val_accuracy: 0.8482 - val_f1_m: 1.1560\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 194us/sample - loss: 0.1447 - accuracy: 0.9506 - f1_m: 1.1044 - val_loss: 0.5299 - val_accuracy: 0.8536 - val_f1_m: 1.1376\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 196us/sample - loss: 0.1444 - accuracy: 0.9488 - f1_m: 1.0979 - val_loss: 0.5374 - val_accuracy: 0.8521 - val_f1_m: 1.1538\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 354us/sample - loss: 0.1569 - accuracy: 0.9468 - f1_m: 1.0645 - val_loss: 0.6902 - val_accuracy: 0.8392 - val_f1_m: 1.1173\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.1234 - accuracy: 0.9596 - f1_m: 1.0535 - val_loss: 0.6829 - val_accuracy: 0.8403 - val_f1_m: 1.1242\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 230us/sample - loss: 0.1116 - accuracy: 0.9632 - f1_m: 1.0586 - val_loss: 0.7105 - val_accuracy: 0.8338 - val_f1_m: 1.1349\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 228us/sample - loss: 0.1104 - accuracy: 0.9608 - f1_m: 1.0566 - val_loss: 0.7473 - val_accuracy: 0.8399 - val_f1_m: 1.1040\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.1045 - accuracy: 0.9640 - f1_m: 1.0514 - val_loss: 0.7338 - val_accuracy: 0.8372 - val_f1_m: 1.1127\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.1010 - accuracy: 0.9660 - f1_m: 1.0539 - val_loss: 0.7824 - val_accuracy: 0.8287 - val_f1_m: 1.1137\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 227us/sample - loss: 0.1046 - accuracy: 0.9608 - f1_m: 1.0481 - val_loss: 0.7503 - val_accuracy: 0.8392 - val_f1_m: 1.1039\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 227us/sample - loss: 0.0803 - accuracy: 0.9728 - f1_m: 1.0319 - val_loss: 0.7614 - val_accuracy: 0.8330 - val_f1_m: 1.0995\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.0770 - accuracy: 0.9730 - f1_m: 1.0248 - val_loss: 0.8020 - val_accuracy: 0.8400 - val_f1_m: 1.0961\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.0800 - accuracy: 0.9718 - f1_m: 1.0297 - val_loss: 0.8390 - val_accuracy: 0.8373 - val_f1_m: 1.0952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 444us/sample - loss: 0.1844 - accuracy: 0.9392 - f1_m: 1.0967 - val_loss: 0.6360 - val_accuracy: 0.8273 - val_f1_m: 1.1805\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 274us/sample - loss: 0.1753 - accuracy: 0.9370 - f1_m: 1.0999 - val_loss: 0.6440 - val_accuracy: 0.8138 - val_f1_m: 1.1845\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 276us/sample - loss: 0.1507 - accuracy: 0.9478 - f1_m: 1.0958 - val_loss: 0.7050 - val_accuracy: 0.8271 - val_f1_m: 1.1563\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 278us/sample - loss: 0.1514 - accuracy: 0.9448 - f1_m: 1.0889 - val_loss: 0.7271 - val_accuracy: 0.8246 - val_f1_m: 1.1302\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 274us/sample - loss: 0.1752 - accuracy: 0.9364 - f1_m: 1.1066 - val_loss: 0.7291 - val_accuracy: 0.8238 - val_f1_m: 1.1325\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 276us/sample - loss: 0.1318 - accuracy: 0.9516 - f1_m: 1.0788 - val_loss: 0.7795 - val_accuracy: 0.8264 - val_f1_m: 1.1290\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 276us/sample - loss: 0.1401 - accuracy: 0.9512 - f1_m: 1.0787 - val_loss: 0.7452 - val_accuracy: 0.8164 - val_f1_m: 1.1279\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 274us/sample - loss: 0.1249 - accuracy: 0.9556 - f1_m: 1.0694 - val_loss: 0.7989 - val_accuracy: 0.8226 - val_f1_m: 1.1190\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 274us/sample - loss: 0.1349 - accuracy: 0.9490 - f1_m: 1.0722 - val_loss: 0.7007 - val_accuracy: 0.8267 - val_f1_m: 1.1487\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 272us/sample - loss: 0.1244 - accuracy: 0.9540 - f1_m: 1.0643 - val_loss: 0.7720 - val_accuracy: 0.8286 - val_f1_m: 1.1213\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 1s 276us/sample - loss: 0.1111 - accuracy: 0.9660 - f1_m: 1.0412 - val_loss: 0.5561 - val_accuracy: 0.8449 - val_f1_m: 1.1342\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.0903 - accuracy: 0.9750 - f1_m: 1.0375 - val_loss: 0.5599 - val_accuracy: 0.8484 - val_f1_m: 1.1333\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 181us/sample - loss: 0.0783 - accuracy: 0.9782 - f1_m: 1.0457 - val_loss: 0.5662 - val_accuracy: 0.8467 - val_f1_m: 1.1308\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 181us/sample - loss: 0.0807 - accuracy: 0.9730 - f1_m: 1.0407 - val_loss: 0.6081 - val_accuracy: 0.8446 - val_f1_m: 1.1287\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 183us/sample - loss: 0.0649 - accuracy: 0.9810 - f1_m: 1.0241 - val_loss: 0.5609 - val_accuracy: 0.8502 - val_f1_m: 1.1143\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.0565 - accuracy: 0.9844 - f1_m: 1.0176 - val_loss: 0.5934 - val_accuracy: 0.8479 - val_f1_m: 1.1109\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.0487 - accuracy: 0.9896 - f1_m: 1.0150 - val_loss: 0.5794 - val_accuracy: 0.8507 - val_f1_m: 1.1125\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.0460 - accuracy: 0.9866 - f1_m: 1.0072 - val_loss: 0.6351 - val_accuracy: 0.8446 - val_f1_m: 1.1034\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 182us/sample - loss: 0.0447 - accuracy: 0.9890 - f1_m: 1.0002 - val_loss: 0.6214 - val_accuracy: 0.8484 - val_f1_m: 1.1019\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 180us/sample - loss: 0.0422 - accuracy: 0.9894 - f1_m: 1.0039 - val_loss: 0.6147 - val_accuracy: 0.8479 - val_f1_m: 1.0975\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.1062 - accuracy: 0.9764 - f1_m: 0.9947 - val_loss: 0.7185 - val_accuracy: 0.8552 - val_f1_m: 1.0692\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 205us/sample - loss: 0.0654 - accuracy: 0.9802 - f1_m: 0.9922 - val_loss: 0.7109 - val_accuracy: 0.8542 - val_f1_m: 1.0691\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 206us/sample - loss: 0.0454 - accuracy: 0.9878 - f1_m: 0.9903 - val_loss: 0.7548 - val_accuracy: 0.8487 - val_f1_m: 1.0720\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 208us/sample - loss: 0.0523 - accuracy: 0.9834 - f1_m: 0.9900 - val_loss: 0.6952 - val_accuracy: 0.8586 - val_f1_m: 1.0682\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 208us/sample - loss: 0.0386 - accuracy: 0.9874 - f1_m: 0.9839 - val_loss: 0.7713 - val_accuracy: 0.8441 - val_f1_m: 1.0628\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 204us/sample - loss: 0.0293 - accuracy: 0.9918 - f1_m: 0.9799 - val_loss: 0.7477 - val_accuracy: 0.8570 - val_f1_m: 1.0524\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 205us/sample - loss: 0.0192 - accuracy: 0.9942 - f1_m: 0.9700 - val_loss: 0.7400 - val_accuracy: 0.8585 - val_f1_m: 1.0506\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 220us/sample - loss: 0.0186 - accuracy: 0.9952 - f1_m: 0.9654 - val_loss: 0.8057 - val_accuracy: 0.8602 - val_f1_m: 1.0459\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 206us/sample - loss: 0.0178 - accuracy: 0.9958 - f1_m: 0.9634 - val_loss: 0.8181 - val_accuracy: 0.8571 - val_f1_m: 1.0371\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 205us/sample - loss: 0.0161 - accuracy: 0.9944 - f1_m: 0.9621 - val_loss: 0.8132 - val_accuracy: 0.8551 - val_f1_m: 1.0537\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 372us/sample - loss: 0.1026 - accuracy: 0.9732 - f1_m: 0.9917 - val_loss: 0.6562 - val_accuracy: 0.8464 - val_f1_m: 1.0870\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 242us/sample - loss: 0.0437 - accuracy: 0.9894 - f1_m: 0.9727 - val_loss: 0.6910 - val_accuracy: 0.8541 - val_f1_m: 1.0670\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 242us/sample - loss: 0.0323 - accuracy: 0.9896 - f1_m: 0.9743 - val_loss: 0.8113 - val_accuracy: 0.8527 - val_f1_m: 1.0442\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 240us/sample - loss: 0.0221 - accuracy: 0.9922 - f1_m: 0.9692 - val_loss: 0.9127 - val_accuracy: 0.8450 - val_f1_m: 1.0471\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 241us/sample - loss: 0.0321 - accuracy: 0.9894 - f1_m: 0.9703 - val_loss: 0.8772 - val_accuracy: 0.8537 - val_f1_m: 1.0276\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 241us/sample - loss: 0.0247 - accuracy: 0.9910 - f1_m: 0.9686 - val_loss: 0.9069 - val_accuracy: 0.8529 - val_f1_m: 1.0389\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 241us/sample - loss: 0.0426 - accuracy: 0.9858 - f1_m: 0.9777 - val_loss: 0.8133 - val_accuracy: 0.8569 - val_f1_m: 1.0435\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 240us/sample - loss: 0.0138 - accuracy: 0.9960 - f1_m: 0.9631 - val_loss: 0.9032 - val_accuracy: 0.8610 - val_f1_m: 1.0238\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 242us/sample - loss: 0.0045 - accuracy: 0.9990 - f1_m: 0.9519 - val_loss: 0.9856 - val_accuracy: 0.8571 - val_f1_m: 1.0244\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 242us/sample - loss: 0.0085 - accuracy: 0.9972 - f1_m: 0.9546 - val_loss: 1.0444 - val_accuracy: 0.8515 - val_f1_m: 1.0218\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 469us/sample - loss: 0.1192 - accuracy: 0.9714 - f1_m: 1.0166 - val_loss: 0.6686 - val_accuracy: 0.8400 - val_f1_m: 1.1202\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 2s 300us/sample - loss: 0.0699 - accuracy: 0.9822 - f1_m: 0.9993 - val_loss: 0.7762 - val_accuracy: 0.8380 - val_f1_m: 1.0949\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0496 - accuracy: 0.9858 - f1_m: 0.9843 - val_loss: 0.9045 - val_accuracy: 0.8359 - val_f1_m: 1.0781\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0484 - accuracy: 0.9854 - f1_m: 0.9840 - val_loss: 0.9651 - val_accuracy: 0.8333 - val_f1_m: 1.0563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.0488 - accuracy: 0.9838 - f1_m: 0.9891 - val_loss: 0.9835 - val_accuracy: 0.8268 - val_f1_m: 1.0696\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0572 - accuracy: 0.9802 - f1_m: 0.9901 - val_loss: 1.0359 - val_accuracy: 0.8330 - val_f1_m: 1.0596\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0459 - accuracy: 0.9844 - f1_m: 0.9829 - val_loss: 0.9975 - val_accuracy: 0.8231 - val_f1_m: 1.0770\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0494 - accuracy: 0.9830 - f1_m: 0.9861 - val_loss: 1.0130 - val_accuracy: 0.8330 - val_f1_m: 1.0560\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 296us/sample - loss: 0.0475 - accuracy: 0.9840 - f1_m: 0.9816 - val_loss: 1.1113 - val_accuracy: 0.8301 - val_f1_m: 1.0520\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0599 - accuracy: 0.9784 - f1_m: 0.9858 - val_loss: 0.9928 - val_accuracy: 0.8342 - val_f1_m: 1.0616\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 1s 273us/sample - loss: 0.2582 - accuracy: 0.9136 - f1_m: 1.2095 - val_loss: 0.4990 - val_accuracy: 0.8359 - val_f1_m: 1.2505\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 188us/sample - loss: 0.2642 - accuracy: 0.9098 - f1_m: 1.2046 - val_loss: 0.4999 - val_accuracy: 0.8363 - val_f1_m: 1.2506\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 190us/sample - loss: 0.2503 - accuracy: 0.9147 - f1_m: 1.2119 - val_loss: 0.4963 - val_accuracy: 0.8340 - val_f1_m: 1.2559\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 185us/sample - loss: 0.2423 - accuracy: 0.9187 - f1_m: 1.2096 - val_loss: 0.5020 - val_accuracy: 0.8333 - val_f1_m: 1.2512\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 198us/sample - loss: 0.2381 - accuracy: 0.9180 - f1_m: 1.2041 - val_loss: 0.5020 - val_accuracy: 0.8344 - val_f1_m: 1.2449\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 186us/sample - loss: 0.2424 - accuracy: 0.9164 - f1_m: 1.2077 - val_loss: 0.5152 - val_accuracy: 0.8313 - val_f1_m: 1.2436\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 190us/sample - loss: 0.2253 - accuracy: 0.9260 - f1_m: 1.1923 - val_loss: 0.5096 - val_accuracy: 0.8320 - val_f1_m: 1.2342\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 187us/sample - loss: 0.2262 - accuracy: 0.9215 - f1_m: 1.1895 - val_loss: 0.5543 - val_accuracy: 0.8236 - val_f1_m: 1.2501\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 190us/sample - loss: 0.2238 - accuracy: 0.9240 - f1_m: 1.1852 - val_loss: 0.5120 - val_accuracy: 0.8367 - val_f1_m: 1.2441\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 187us/sample - loss: 0.2193 - accuracy: 0.9245 - f1_m: 1.1876 - val_loss: 0.5104 - val_accuracy: 0.8357 - val_f1_m: 1.2348\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 291us/sample - loss: 0.1959 - accuracy: 0.9369 - f1_m: 1.1154 - val_loss: 0.5405 - val_accuracy: 0.8497 - val_f1_m: 1.1683\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 187us/sample - loss: 0.1939 - accuracy: 0.9371 - f1_m: 1.1194 - val_loss: 0.5178 - val_accuracy: 0.8572 - val_f1_m: 1.1524\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 200us/sample - loss: 0.1708 - accuracy: 0.9455 - f1_m: 1.1132 - val_loss: 0.5423 - val_accuracy: 0.8520 - val_f1_m: 1.1505\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 198us/sample - loss: 0.1632 - accuracy: 0.9473 - f1_m: 1.1020 - val_loss: 0.5577 - val_accuracy: 0.8483 - val_f1_m: 1.1542\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 204us/sample - loss: 0.1640 - accuracy: 0.9453 - f1_m: 1.1107 - val_loss: 0.5186 - val_accuracy: 0.8578 - val_f1_m: 1.1397\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 198us/sample - loss: 0.1581 - accuracy: 0.9465 - f1_m: 1.1092 - val_loss: 0.5251 - val_accuracy: 0.8551 - val_f1_m: 1.1485\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 196us/sample - loss: 0.1488 - accuracy: 0.9504 - f1_m: 1.1000 - val_loss: 0.5698 - val_accuracy: 0.8495 - val_f1_m: 1.1183\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 199us/sample - loss: 0.1460 - accuracy: 0.9484 - f1_m: 1.0893 - val_loss: 0.5617 - val_accuracy: 0.8479 - val_f1_m: 1.1556\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 197us/sample - loss: 0.1435 - accuracy: 0.9524 - f1_m: 1.0924 - val_loss: 0.5477 - val_accuracy: 0.8545 - val_f1_m: 1.1412\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 198us/sample - loss: 0.1419 - accuracy: 0.9516 - f1_m: 1.0954 - val_loss: 0.5815 - val_accuracy: 0.8503 - val_f1_m: 1.1416\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 363us/sample - loss: 0.1542 - accuracy: 0.9549 - f1_m: 1.0526 - val_loss: 0.6958 - val_accuracy: 0.8375 - val_f1_m: 1.1253\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 236us/sample - loss: 0.1156 - accuracy: 0.9655 - f1_m: 1.0452 - val_loss: 0.7389 - val_accuracy: 0.8400 - val_f1_m: 1.1030\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 236us/sample - loss: 0.1126 - accuracy: 0.9625 - f1_m: 1.0412 - val_loss: 0.7271 - val_accuracy: 0.8295 - val_f1_m: 1.1212\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 234us/sample - loss: 0.0906 - accuracy: 0.9729 - f1_m: 1.0340 - val_loss: 0.7457 - val_accuracy: 0.8352 - val_f1_m: 1.1093\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 227us/sample - loss: 0.0951 - accuracy: 0.9685 - f1_m: 1.0322 - val_loss: 0.7534 - val_accuracy: 0.8380 - val_f1_m: 1.0950\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 214us/sample - loss: 0.0875 - accuracy: 0.9713 - f1_m: 1.0377 - val_loss: 0.7830 - val_accuracy: 0.8389 - val_f1_m: 1.1085\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 223us/sample - loss: 0.0828 - accuracy: 0.9715 - f1_m: 1.0309 - val_loss: 0.8249 - val_accuracy: 0.8336 - val_f1_m: 1.0870\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 221us/sample - loss: 0.0787 - accuracy: 0.9767 - f1_m: 1.0212 - val_loss: 0.8316 - val_accuracy: 0.8422 - val_f1_m: 1.0899\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 229us/sample - loss: 0.0692 - accuracy: 0.9782 - f1_m: 1.0171 - val_loss: 0.8955 - val_accuracy: 0.8368 - val_f1_m: 1.0852\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 225us/sample - loss: 0.0834 - accuracy: 0.9704 - f1_m: 1.0230 - val_loss: 0.8708 - val_accuracy: 0.8388 - val_f1_m: 1.0828\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 436us/sample - loss: 0.1788 - accuracy: 0.9413 - f1_m: 1.0937 - val_loss: 0.6313 - val_accuracy: 0.8298 - val_f1_m: 1.1526\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 267us/sample - loss: 0.1494 - accuracy: 0.9496 - f1_m: 1.0798 - val_loss: 0.6417 - val_accuracy: 0.8272 - val_f1_m: 1.1525\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 2s 276us/sample - loss: 0.1515 - accuracy: 0.9478 - f1_m: 1.0819 - val_loss: 0.6356 - val_accuracy: 0.8364 - val_f1_m: 1.1424\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 2s 279us/sample - loss: 0.1389 - accuracy: 0.9505 - f1_m: 1.0719 - val_loss: 0.6486 - val_accuracy: 0.8339 - val_f1_m: 1.1293\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 2s 284us/sample - loss: 0.1402 - accuracy: 0.9511 - f1_m: 1.0654 - val_loss: 0.6992 - val_accuracy: 0.8342 - val_f1_m: 1.1280\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 2s 290us/sample - loss: 0.1327 - accuracy: 0.9509 - f1_m: 1.0669 - val_loss: 0.7255 - val_accuracy: 0.8332 - val_f1_m: 1.1068\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 2s 285us/sample - loss: 0.1181 - accuracy: 0.9578 - f1_m: 1.0599 - val_loss: 0.6818 - val_accuracy: 0.8289 - val_f1_m: 1.1254\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 272us/sample - loss: 0.1152 - accuracy: 0.9607 - f1_m: 1.0528 - val_loss: 0.7670 - val_accuracy: 0.8340 - val_f1_m: 1.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 267us/sample - loss: 0.1216 - accuracy: 0.9560 - f1_m: 1.0569 - val_loss: 0.6641 - val_accuracy: 0.8235 - val_f1_m: 1.1605\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 267us/sample - loss: 0.1158 - accuracy: 0.9567 - f1_m: 1.0459 - val_loss: 0.7365 - val_accuracy: 0.8286 - val_f1_m: 1.1190\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 1s 257us/sample - loss: 0.1023 - accuracy: 0.9738 - f1_m: 1.0167 - val_loss: 0.5878 - val_accuracy: 0.8478 - val_f1_m: 1.1235\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 172us/sample - loss: 0.0787 - accuracy: 0.9796 - f1_m: 1.0083 - val_loss: 0.6077 - val_accuracy: 0.8487 - val_f1_m: 1.1136\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 170us/sample - loss: 0.0647 - accuracy: 0.9844 - f1_m: 1.0098 - val_loss: 0.6137 - val_accuracy: 0.8418 - val_f1_m: 1.1194\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 173us/sample - loss: 0.0544 - accuracy: 0.9885 - f1_m: 1.0030 - val_loss: 0.6181 - val_accuracy: 0.8408 - val_f1_m: 1.1063\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 170us/sample - loss: 0.0524 - accuracy: 0.9871 - f1_m: 1.0034 - val_loss: 0.5853 - val_accuracy: 0.8486 - val_f1_m: 1.1268\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 172us/sample - loss: 0.0468 - accuracy: 0.9889 - f1_m: 1.0013 - val_loss: 0.6150 - val_accuracy: 0.8507 - val_f1_m: 1.1017\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 172us/sample - loss: 0.0388 - accuracy: 0.9907 - f1_m: 0.9920 - val_loss: 0.6654 - val_accuracy: 0.8436 - val_f1_m: 1.0925\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 172us/sample - loss: 0.0374 - accuracy: 0.9902 - f1_m: 0.9890 - val_loss: 0.6388 - val_accuracy: 0.8464 - val_f1_m: 1.0936\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 172us/sample - loss: 0.0359 - accuracy: 0.9913 - f1_m: 0.9910 - val_loss: 0.6321 - val_accuracy: 0.8529 - val_f1_m: 1.0894\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 171us/sample - loss: 0.0264 - accuracy: 0.9935 - f1_m: 0.9792 - val_loss: 0.6649 - val_accuracy: 0.8479 - val_f1_m: 1.0821\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 286us/sample - loss: 0.1096 - accuracy: 0.9773 - f1_m: 0.9900 - val_loss: 0.6530 - val_accuracy: 0.8519 - val_f1_m: 1.0859\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 194us/sample - loss: 0.0670 - accuracy: 0.9855 - f1_m: 0.9850 - val_loss: 0.6544 - val_accuracy: 0.8593 - val_f1_m: 1.0706\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 194us/sample - loss: 0.0474 - accuracy: 0.9880 - f1_m: 0.9812 - val_loss: 0.7346 - val_accuracy: 0.8535 - val_f1_m: 1.0585\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 195us/sample - loss: 0.0361 - accuracy: 0.9909 - f1_m: 0.9765 - val_loss: 0.7204 - val_accuracy: 0.8592 - val_f1_m: 1.0570\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 194us/sample - loss: 0.0271 - accuracy: 0.9924 - f1_m: 0.9693 - val_loss: 0.7140 - val_accuracy: 0.8562 - val_f1_m: 1.0598\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 195us/sample - loss: 0.0205 - accuracy: 0.9949 - f1_m: 0.9673 - val_loss: 0.7686 - val_accuracy: 0.8565 - val_f1_m: 1.0523\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 195us/sample - loss: 0.0241 - accuracy: 0.9916 - f1_m: 0.9706 - val_loss: 0.8040 - val_accuracy: 0.8598 - val_f1_m: 1.0473\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 195us/sample - loss: 0.0163 - accuracy: 0.9960 - f1_m: 0.9676 - val_loss: 0.8206 - val_accuracy: 0.8555 - val_f1_m: 1.0409\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 193us/sample - loss: 0.0254 - accuracy: 0.9925 - f1_m: 0.9705 - val_loss: 0.8066 - val_accuracy: 0.8643 - val_f1_m: 1.0429\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 196us/sample - loss: 0.0129 - accuracy: 0.9962 - f1_m: 0.9609 - val_loss: 0.8230 - val_accuracy: 0.8569 - val_f1_m: 1.0402\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 3s 519us/sample - loss: 0.1130 - accuracy: 0.9784 - f1_m: 0.9806 - val_loss: 0.6090 - val_accuracy: 0.8550 - val_f1_m: 1.0997\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 226us/sample - loss: 0.0413 - accuracy: 0.9895 - f1_m: 0.9769 - val_loss: 0.7549 - val_accuracy: 0.8519 - val_f1_m: 1.0568\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 226us/sample - loss: 0.0217 - accuracy: 0.9956 - f1_m: 0.9653 - val_loss: 0.8184 - val_accuracy: 0.8490 - val_f1_m: 1.0405\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 226us/sample - loss: 0.0212 - accuracy: 0.9935 - f1_m: 0.9627 - val_loss: 0.8774 - val_accuracy: 0.8453 - val_f1_m: 1.0451\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 233us/sample - loss: 0.0426 - accuracy: 0.9827 - f1_m: 0.9713 - val_loss: 0.9068 - val_accuracy: 0.8493 - val_f1_m: 1.0410\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 230us/sample - loss: 0.0202 - accuracy: 0.9935 - f1_m: 0.9632 - val_loss: 0.8835 - val_accuracy: 0.8580 - val_f1_m: 1.0297\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 228us/sample - loss: 0.0074 - accuracy: 0.9982 - f1_m: 0.9530 - val_loss: 1.0089 - val_accuracy: 0.8493 - val_f1_m: 1.0293\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 229us/sample - loss: 0.0161 - accuracy: 0.9942 - f1_m: 0.9588 - val_loss: 1.0471 - val_accuracy: 0.8503 - val_f1_m: 1.0234\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 228us/sample - loss: 0.0414 - accuracy: 0.9855 - f1_m: 0.9723 - val_loss: 1.0547 - val_accuracy: 0.8484 - val_f1_m: 1.0261\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 228us/sample - loss: 0.0312 - accuracy: 0.9900 - f1_m: 0.9625 - val_loss: 0.9954 - val_accuracy: 0.8472 - val_f1_m: 1.0357\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 442us/sample - loss: 0.1175 - accuracy: 0.9689 - f1_m: 1.0192 - val_loss: 0.6250 - val_accuracy: 0.8321 - val_f1_m: 1.1385\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 2s 285us/sample - loss: 0.0623 - accuracy: 0.9815 - f1_m: 0.9942 - val_loss: 0.7829 - val_accuracy: 0.8340 - val_f1_m: 1.0908\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 2s 282us/sample - loss: 0.0511 - accuracy: 0.9860 - f1_m: 0.9822 - val_loss: 0.9342 - val_accuracy: 0.8360 - val_f1_m: 1.0748\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 2s 285us/sample - loss: 0.0519 - accuracy: 0.9825 - f1_m: 0.9846 - val_loss: 0.9215 - val_accuracy: 0.8344 - val_f1_m: 1.0662\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 2s 283us/sample - loss: 0.0536 - accuracy: 0.9825 - f1_m: 0.9871 - val_loss: 0.9069 - val_accuracy: 0.8341 - val_f1_m: 1.0687\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 2s 283us/sample - loss: 0.0419 - accuracy: 0.9875 - f1_m: 0.9798 - val_loss: 0.9712 - val_accuracy: 0.8413 - val_f1_m: 1.0480\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 2s 281us/sample - loss: 0.0442 - accuracy: 0.9847 - f1_m: 0.9797 - val_loss: 1.2452 - val_accuracy: 0.8290 - val_f1_m: 1.0237\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 2s 283us/sample - loss: 0.0265 - accuracy: 0.9904 - f1_m: 0.9632 - val_loss: 1.1435 - val_accuracy: 0.8355 - val_f1_m: 1.0308\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 2s 285us/sample - loss: 0.0584 - accuracy: 0.9807 - f1_m: 0.9834 - val_loss: 1.0337 - val_accuracy: 0.8339 - val_f1_m: 1.0503\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 2s 285us/sample - loss: 0.0547 - accuracy: 0.9811 - f1_m: 0.9819 - val_loss: 0.8536 - val_accuracy: 0.8360 - val_f1_m: 1.0747\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 1s 243us/sample - loss: 0.2359 - accuracy: 0.9222 - f1_m: 1.1807 - val_loss: 0.5421 - val_accuracy: 0.8277 - val_f1_m: 1.2282\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 0.2313 - accuracy: 0.9200 - f1_m: 1.1840 - val_loss: 0.5211 - val_accuracy: 0.8341 - val_f1_m: 1.2324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 0.2251 - accuracy: 0.9245 - f1_m: 1.1792 - val_loss: 0.5142 - val_accuracy: 0.8396 - val_f1_m: 1.2261\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 0.2198 - accuracy: 0.9225 - f1_m: 1.1770 - val_loss: 0.5095 - val_accuracy: 0.8399 - val_f1_m: 1.2260\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 164us/sample - loss: 0.2188 - accuracy: 0.9218 - f1_m: 1.1808 - val_loss: 0.5448 - val_accuracy: 0.8294 - val_f1_m: 1.2226\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 0.2167 - accuracy: 0.9282 - f1_m: 1.1810 - val_loss: 0.5452 - val_accuracy: 0.8324 - val_f1_m: 1.2244\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 0.2085 - accuracy: 0.9300 - f1_m: 1.1777 - val_loss: 0.5291 - val_accuracy: 0.8384 - val_f1_m: 1.2191\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 0.2070 - accuracy: 0.9293 - f1_m: 1.1668 - val_loss: 0.5419 - val_accuracy: 0.8290 - val_f1_m: 1.2346\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 0.2029 - accuracy: 0.9298 - f1_m: 1.1600 - val_loss: 0.5641 - val_accuracy: 0.8257 - val_f1_m: 1.2119\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 0.2023 - accuracy: 0.9302 - f1_m: 1.1622 - val_loss: 0.5676 - val_accuracy: 0.8290 - val_f1_m: 1.2046\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 259us/sample - loss: 0.1687 - accuracy: 0.9413 - f1_m: 1.1005 - val_loss: 0.5878 - val_accuracy: 0.8483 - val_f1_m: 1.1348\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 177us/sample - loss: 0.1568 - accuracy: 0.9480 - f1_m: 1.0887 - val_loss: 0.5632 - val_accuracy: 0.8519 - val_f1_m: 1.1258\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.1591 - accuracy: 0.9460 - f1_m: 1.0946 - val_loss: 0.5609 - val_accuracy: 0.8585 - val_f1_m: 1.1186\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 173us/sample - loss: 0.1425 - accuracy: 0.9515 - f1_m: 1.0961 - val_loss: 0.5681 - val_accuracy: 0.8563 - val_f1_m: 1.1340\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.1375 - accuracy: 0.9557 - f1_m: 1.0901 - val_loss: 0.5643 - val_accuracy: 0.8560 - val_f1_m: 1.1289\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.1307 - accuracy: 0.9557 - f1_m: 1.0830 - val_loss: 0.5900 - val_accuracy: 0.8528 - val_f1_m: 1.1290\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.1317 - accuracy: 0.9562 - f1_m: 1.0844 - val_loss: 0.6343 - val_accuracy: 0.8482 - val_f1_m: 1.1361\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.1284 - accuracy: 0.9545 - f1_m: 1.0814 - val_loss: 0.5749 - val_accuracy: 0.8599 - val_f1_m: 1.1124\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.1285 - accuracy: 0.9552 - f1_m: 1.0855 - val_loss: 0.6031 - val_accuracy: 0.8586 - val_f1_m: 1.1090\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 177us/sample - loss: 0.1250 - accuracy: 0.9593 - f1_m: 1.0753 - val_loss: 0.6111 - val_accuracy: 0.8576 - val_f1_m: 1.1180\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 308us/sample - loss: 0.1327 - accuracy: 0.9628 - f1_m: 1.0315 - val_loss: 0.7555 - val_accuracy: 0.8394 - val_f1_m: 1.1050\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 207us/sample - loss: 0.1055 - accuracy: 0.9653 - f1_m: 1.0420 - val_loss: 0.7898 - val_accuracy: 0.8430 - val_f1_m: 1.0916\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 205us/sample - loss: 0.0863 - accuracy: 0.9740 - f1_m: 1.0229 - val_loss: 0.8094 - val_accuracy: 0.8473 - val_f1_m: 1.0919\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 205us/sample - loss: 0.0795 - accuracy: 0.9728 - f1_m: 1.0273 - val_loss: 0.7800 - val_accuracy: 0.8451 - val_f1_m: 1.0835\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 205us/sample - loss: 0.0869 - accuracy: 0.9713 - f1_m: 1.0228 - val_loss: 0.8174 - val_accuracy: 0.8412 - val_f1_m: 1.0883\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 205us/sample - loss: 0.0785 - accuracy: 0.9755 - f1_m: 1.0210 - val_loss: 0.8513 - val_accuracy: 0.8413 - val_f1_m: 1.0801\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 205us/sample - loss: 0.0689 - accuracy: 0.9772 - f1_m: 1.0130 - val_loss: 1.0471 - val_accuracy: 0.8284 - val_f1_m: 1.0832\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 205us/sample - loss: 0.0704 - accuracy: 0.9757 - f1_m: 1.0209 - val_loss: 0.8911 - val_accuracy: 0.8437 - val_f1_m: 1.0772\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 207us/sample - loss: 0.0555 - accuracy: 0.9820 - f1_m: 1.0075 - val_loss: 0.9203 - val_accuracy: 0.8346 - val_f1_m: 1.0741\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 205us/sample - loss: 0.0723 - accuracy: 0.9748 - f1_m: 1.0118 - val_loss: 0.9327 - val_accuracy: 0.8430 - val_f1_m: 1.0624\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 391us/sample - loss: 0.1562 - accuracy: 0.9485 - f1_m: 1.0657 - val_loss: 0.6776 - val_accuracy: 0.8280 - val_f1_m: 1.1343\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 2s 253us/sample - loss: 0.1386 - accuracy: 0.9553 - f1_m: 1.0632 - val_loss: 0.6698 - val_accuracy: 0.8321 - val_f1_m: 1.1277\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 250us/sample - loss: 0.1390 - accuracy: 0.9525 - f1_m: 1.0696 - val_loss: 0.6768 - val_accuracy: 0.8393 - val_f1_m: 1.1267\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 2s 255us/sample - loss: 0.1182 - accuracy: 0.9573 - f1_m: 1.0604 - val_loss: 0.8343 - val_accuracy: 0.8272 - val_f1_m: 1.1031\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 250us/sample - loss: 0.1195 - accuracy: 0.9583 - f1_m: 1.0525 - val_loss: 0.7793 - val_accuracy: 0.8220 - val_f1_m: 1.1248\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 2s 257us/sample - loss: 0.1317 - accuracy: 0.9540 - f1_m: 1.0555 - val_loss: 0.7336 - val_accuracy: 0.8235 - val_f1_m: 1.1460\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 2s 253us/sample - loss: 0.1196 - accuracy: 0.9578 - f1_m: 1.0573 - val_loss: 0.7629 - val_accuracy: 0.8340 - val_f1_m: 1.1026\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 2s 253us/sample - loss: 0.1039 - accuracy: 0.9618 - f1_m: 1.0387 - val_loss: 0.7097 - val_accuracy: 0.8362 - val_f1_m: 1.1094\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 2s 252us/sample - loss: 0.0891 - accuracy: 0.9665 - f1_m: 1.0334 - val_loss: 0.8279 - val_accuracy: 0.8368 - val_f1_m: 1.0887\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 2s 252us/sample - loss: 0.1024 - accuracy: 0.9640 - f1_m: 1.0374 - val_loss: 0.7885 - val_accuracy: 0.8304 - val_f1_m: 1.1060\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 1s 242us/sample - loss: 0.0821 - accuracy: 0.9795 - f1_m: 1.0066 - val_loss: 0.6588 - val_accuracy: 0.8478 - val_f1_m: 1.0930\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 0.0582 - accuracy: 0.9847 - f1_m: 0.9953 - val_loss: 0.6605 - val_accuracy: 0.8473 - val_f1_m: 1.0804\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 0.0507 - accuracy: 0.9865 - f1_m: 0.9969 - val_loss: 0.6801 - val_accuracy: 0.8457 - val_f1_m: 1.0871\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 0.0399 - accuracy: 0.9892 - f1_m: 0.9909 - val_loss: 0.6628 - val_accuracy: 0.8542 - val_f1_m: 1.0905\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 0.0325 - accuracy: 0.9927 - f1_m: 0.9813 - val_loss: 0.7093 - val_accuracy: 0.8419 - val_f1_m: 1.0906\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 160us/sample - loss: 0.0301 - accuracy: 0.9935 - f1_m: 0.9823 - val_loss: 0.6788 - val_accuracy: 0.8487 - val_f1_m: 1.0916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 0.0253 - accuracy: 0.9940 - f1_m: 0.9813 - val_loss: 0.7577 - val_accuracy: 0.8471 - val_f1_m: 1.0815\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 163us/sample - loss: 0.0228 - accuracy: 0.9943 - f1_m: 0.9740 - val_loss: 0.7022 - val_accuracy: 0.8493 - val_f1_m: 1.0770\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 161us/sample - loss: 0.0190 - accuracy: 0.9972 - f1_m: 0.9730 - val_loss: 0.7608 - val_accuracy: 0.8471 - val_f1_m: 1.0645\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 162us/sample - loss: 0.0232 - accuracy: 0.9937 - f1_m: 0.9784 - val_loss: 0.7154 - val_accuracy: 0.8546 - val_f1_m: 1.0752\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 272us/sample - loss: 0.0652 - accuracy: 0.9853 - f1_m: 0.9780 - val_loss: 0.7884 - val_accuracy: 0.8577 - val_f1_m: 1.0544\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 187us/sample - loss: 0.0342 - accuracy: 0.9925 - f1_m: 0.9714 - val_loss: 0.8186 - val_accuracy: 0.8580 - val_f1_m: 1.0486\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 183us/sample - loss: 0.0291 - accuracy: 0.9917 - f1_m: 0.9695 - val_loss: 0.8198 - val_accuracy: 0.8571 - val_f1_m: 1.0423\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 187us/sample - loss: 0.0194 - accuracy: 0.9940 - f1_m: 0.9673 - val_loss: 0.8279 - val_accuracy: 0.8596 - val_f1_m: 1.0448\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 185us/sample - loss: 0.0173 - accuracy: 0.9952 - f1_m: 0.9637 - val_loss: 0.8689 - val_accuracy: 0.8519 - val_f1_m: 1.0431\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 185us/sample - loss: 0.0240 - accuracy: 0.9905 - f1_m: 0.9714 - val_loss: 0.8833 - val_accuracy: 0.8519 - val_f1_m: 1.0500\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 185us/sample - loss: 0.0070 - accuracy: 0.9982 - f1_m: 0.9547 - val_loss: 0.9056 - val_accuracy: 0.8579 - val_f1_m: 1.0332\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 183us/sample - loss: 0.0037 - accuracy: 0.9997 - f1_m: 0.9500 - val_loss: 0.8974 - val_accuracy: 0.8595 - val_f1_m: 1.0330\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 185us/sample - loss: 0.0026 - accuracy: 0.9995 - f1_m: 0.9475 - val_loss: 0.9337 - val_accuracy: 0.8617 - val_f1_m: 1.0273\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 183us/sample - loss: 0.0290 - accuracy: 0.9910 - f1_m: 0.9665 - val_loss: 0.9340 - val_accuracy: 0.8544 - val_f1_m: 1.0337\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 323us/sample - loss: 0.0794 - accuracy: 0.9830 - f1_m: 0.9801 - val_loss: 0.7102 - val_accuracy: 0.8552 - val_f1_m: 1.0593\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 215us/sample - loss: 0.0293 - accuracy: 0.9918 - f1_m: 0.9686 - val_loss: 0.8385 - val_accuracy: 0.8592 - val_f1_m: 1.0377\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 218us/sample - loss: 0.0266 - accuracy: 0.9923 - f1_m: 0.9671 - val_loss: 0.8607 - val_accuracy: 0.8471 - val_f1_m: 1.0361\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 215us/sample - loss: 0.0187 - accuracy: 0.9952 - f1_m: 0.9634 - val_loss: 0.9148 - val_accuracy: 0.8562 - val_f1_m: 1.0337\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 218us/sample - loss: 0.0270 - accuracy: 0.9923 - f1_m: 0.9647 - val_loss: 0.9154 - val_accuracy: 0.8467 - val_f1_m: 1.0366\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 215us/sample - loss: 0.0096 - accuracy: 0.9967 - f1_m: 0.9557 - val_loss: 1.0757 - val_accuracy: 0.8541 - val_f1_m: 1.0190\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 218us/sample - loss: 0.0464 - accuracy: 0.9847 - f1_m: 0.9718 - val_loss: 0.9536 - val_accuracy: 0.8452 - val_f1_m: 1.0446\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 218us/sample - loss: 0.0294 - accuracy: 0.9897 - f1_m: 0.9653 - val_loss: 1.0342 - val_accuracy: 0.8579 - val_f1_m: 1.0259\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 217us/sample - loss: 0.0227 - accuracy: 0.9923 - f1_m: 0.9583 - val_loss: 1.0205 - val_accuracy: 0.8491 - val_f1_m: 1.0314\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 218us/sample - loss: 0.0134 - accuracy: 0.9950 - f1_m: 0.9567 - val_loss: 1.1425 - val_accuracy: 0.8469 - val_f1_m: 1.0196\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 3s 417us/sample - loss: 0.0971 - accuracy: 0.9753 - f1_m: 1.0046 - val_loss: 0.7570 - val_accuracy: 0.8238 - val_f1_m: 1.0995\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 2s 275us/sample - loss: 0.0532 - accuracy: 0.9832 - f1_m: 0.9923 - val_loss: 0.8658 - val_accuracy: 0.8379 - val_f1_m: 1.0700\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 2s 276us/sample - loss: 0.0314 - accuracy: 0.9900 - f1_m: 0.9684 - val_loss: 1.1682 - val_accuracy: 0.8346 - val_f1_m: 1.0355\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 2s 275us/sample - loss: 0.0578 - accuracy: 0.9817 - f1_m: 0.9850 - val_loss: 0.9827 - val_accuracy: 0.8328 - val_f1_m: 1.0620\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 2s 273us/sample - loss: 0.0489 - accuracy: 0.9825 - f1_m: 0.9807 - val_loss: 1.1096 - val_accuracy: 0.8298 - val_f1_m: 1.0453\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 2s 275us/sample - loss: 0.0353 - accuracy: 0.9887 - f1_m: 0.9734 - val_loss: 1.0484 - val_accuracy: 0.8306 - val_f1_m: 1.0519\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 2s 276us/sample - loss: 0.0399 - accuracy: 0.9873 - f1_m: 0.9735 - val_loss: 1.1459 - val_accuracy: 0.8405 - val_f1_m: 1.0390\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 2s 273us/sample - loss: 0.0478 - accuracy: 0.9845 - f1_m: 0.9739 - val_loss: 1.0807 - val_accuracy: 0.8263 - val_f1_m: 1.0570\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 2s 274us/sample - loss: 0.0524 - accuracy: 0.9843 - f1_m: 0.9843 - val_loss: 1.1386 - val_accuracy: 0.8367 - val_f1_m: 1.0393\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 2s 276us/sample - loss: 0.0423 - accuracy: 0.9865 - f1_m: 0.9725 - val_loss: 1.0364 - val_accuracy: 0.8353 - val_f1_m: 1.0500\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 232us/sample - loss: 0.2310 - accuracy: 0.9223 - f1_m: 1.1711 - val_loss: 0.5635 - val_accuracy: 0.8281 - val_f1_m: 1.1991\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 158us/sample - loss: 0.2237 - accuracy: 0.9248 - f1_m: 1.1697 - val_loss: 0.5423 - val_accuracy: 0.8320 - val_f1_m: 1.2229\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 156us/sample - loss: 0.2180 - accuracy: 0.9262 - f1_m: 1.1642 - val_loss: 0.5625 - val_accuracy: 0.8309 - val_f1_m: 1.2082\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.2061 - accuracy: 0.9266 - f1_m: 1.1599 - val_loss: 0.5623 - val_accuracy: 0.8287 - val_f1_m: 1.2137\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 158us/sample - loss: 0.2029 - accuracy: 0.9323 - f1_m: 1.1640 - val_loss: 0.5310 - val_accuracy: 0.8360 - val_f1_m: 1.2036\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.1987 - accuracy: 0.9312 - f1_m: 1.1567 - val_loss: 0.5426 - val_accuracy: 0.8329 - val_f1_m: 1.2152\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 158us/sample - loss: 0.1940 - accuracy: 0.9342 - f1_m: 1.1444 - val_loss: 0.6519 - val_accuracy: 0.8105 - val_f1_m: 1.2283\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.1931 - accuracy: 0.9328 - f1_m: 1.1549 - val_loss: 0.5365 - val_accuracy: 0.8342 - val_f1_m: 1.2145\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 158us/sample - loss: 0.1868 - accuracy: 0.9352 - f1_m: 1.1503 - val_loss: 0.5500 - val_accuracy: 0.8344 - val_f1_m: 1.2072\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 156us/sample - loss: 0.1799 - accuracy: 0.9383 - f1_m: 1.1461 - val_loss: 0.5550 - val_accuracy: 0.8302 - val_f1_m: 1.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 249us/sample - loss: 0.1672 - accuracy: 0.9468 - f1_m: 1.0866 - val_loss: 0.5807 - val_accuracy: 0.8546 - val_f1_m: 1.1163\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.1567 - accuracy: 0.9478 - f1_m: 1.0864 - val_loss: 0.5712 - val_accuracy: 0.8584 - val_f1_m: 1.1210\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.1499 - accuracy: 0.9492 - f1_m: 1.0855 - val_loss: 0.5948 - val_accuracy: 0.8596 - val_f1_m: 1.1006\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.1331 - accuracy: 0.9557 - f1_m: 1.0815 - val_loss: 0.6153 - val_accuracy: 0.8517 - val_f1_m: 1.1273\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.1297 - accuracy: 0.9566 - f1_m: 1.0772 - val_loss: 0.6012 - val_accuracy: 0.8556 - val_f1_m: 1.1170\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.1239 - accuracy: 0.9591 - f1_m: 1.0718 - val_loss: 0.5986 - val_accuracy: 0.8540 - val_f1_m: 1.1260\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.1202 - accuracy: 0.9597 - f1_m: 1.0694 - val_loss: 0.6910 - val_accuracy: 0.8427 - val_f1_m: 1.1269\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.1278 - accuracy: 0.9572 - f1_m: 1.0676 - val_loss: 0.6025 - val_accuracy: 0.8560 - val_f1_m: 1.1362\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.1125 - accuracy: 0.9626 - f1_m: 1.0747 - val_loss: 0.6188 - val_accuracy: 0.8543 - val_f1_m: 1.1093\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.1134 - accuracy: 0.9614 - f1_m: 1.0620 - val_loss: 0.6650 - val_accuracy: 0.8539 - val_f1_m: 1.1062\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 296us/sample - loss: 0.1287 - accuracy: 0.9662 - f1_m: 1.0246 - val_loss: 0.8006 - val_accuracy: 0.8420 - val_f1_m: 1.0793\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 197us/sample - loss: 0.0951 - accuracy: 0.9726 - f1_m: 1.0281 - val_loss: 0.8408 - val_accuracy: 0.8440 - val_f1_m: 1.0845\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 197us/sample - loss: 0.0914 - accuracy: 0.9712 - f1_m: 1.0284 - val_loss: 0.8750 - val_accuracy: 0.8412 - val_f1_m: 1.0662\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 198us/sample - loss: 0.0735 - accuracy: 0.9775 - f1_m: 1.0102 - val_loss: 0.8646 - val_accuracy: 0.8368 - val_f1_m: 1.0883\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 199us/sample - loss: 0.0728 - accuracy: 0.9763 - f1_m: 1.0222 - val_loss: 0.9283 - val_accuracy: 0.8383 - val_f1_m: 1.0654\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 198us/sample - loss: 0.0750 - accuracy: 0.9737 - f1_m: 1.0142 - val_loss: 0.8541 - val_accuracy: 0.8353 - val_f1_m: 1.0889\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 198us/sample - loss: 0.0642 - accuracy: 0.9789 - f1_m: 1.0116 - val_loss: 0.9439 - val_accuracy: 0.8241 - val_f1_m: 1.0850\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 201us/sample - loss: 0.0572 - accuracy: 0.9803 - f1_m: 1.0070 - val_loss: 0.9740 - val_accuracy: 0.8345 - val_f1_m: 1.0607\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 198us/sample - loss: 0.0609 - accuracy: 0.9771 - f1_m: 1.0089 - val_loss: 1.0392 - val_accuracy: 0.8407 - val_f1_m: 1.0528\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 199us/sample - loss: 0.0604 - accuracy: 0.9803 - f1_m: 1.0062 - val_loss: 0.9844 - val_accuracy: 0.8423 - val_f1_m: 1.0548\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 379us/sample - loss: 0.1529 - accuracy: 0.9514 - f1_m: 1.0620 - val_loss: 0.6478 - val_accuracy: 0.8280 - val_f1_m: 1.1437\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 2s 243us/sample - loss: 0.1326 - accuracy: 0.9602 - f1_m: 1.0645 - val_loss: 0.6363 - val_accuracy: 0.8429 - val_f1_m: 1.1404\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 2s 244us/sample - loss: 0.1307 - accuracy: 0.9554 - f1_m: 1.0620 - val_loss: 0.7181 - val_accuracy: 0.8414 - val_f1_m: 1.0923\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 2s 245us/sample - loss: 0.1118 - accuracy: 0.9612 - f1_m: 1.0384 - val_loss: 0.6826 - val_accuracy: 0.8304 - val_f1_m: 1.1380\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 2s 245us/sample - loss: 0.1001 - accuracy: 0.9657 - f1_m: 1.0431 - val_loss: 0.7473 - val_accuracy: 0.8335 - val_f1_m: 1.0986\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 2s 245us/sample - loss: 0.0965 - accuracy: 0.9678 - f1_m: 1.0373 - val_loss: 0.6706 - val_accuracy: 0.8383 - val_f1_m: 1.1203\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 2s 243us/sample - loss: 0.1185 - accuracy: 0.9571 - f1_m: 1.0473 - val_loss: 0.7730 - val_accuracy: 0.8334 - val_f1_m: 1.1099\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 2s 244us/sample - loss: 0.0950 - accuracy: 0.9666 - f1_m: 1.0306 - val_loss: 0.7325 - val_accuracy: 0.8131 - val_f1_m: 1.1428\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 2s 244us/sample - loss: 0.1051 - accuracy: 0.9652 - f1_m: 1.0452 - val_loss: 0.8046 - val_accuracy: 0.8335 - val_f1_m: 1.0972\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 2s 244us/sample - loss: 0.0863 - accuracy: 0.9688 - f1_m: 1.0302 - val_loss: 0.8730 - val_accuracy: 0.8320 - val_f1_m: 1.0768\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 1s 230us/sample - loss: 0.0773 - accuracy: 0.9822 - f1_m: 0.9907 - val_loss: 0.6913 - val_accuracy: 0.8488 - val_f1_m: 1.0772\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 158us/sample - loss: 0.0591 - accuracy: 0.9834 - f1_m: 0.9979 - val_loss: 0.6576 - val_accuracy: 0.8546 - val_f1_m: 1.0843\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.0490 - accuracy: 0.9866 - f1_m: 0.9943 - val_loss: 0.6896 - val_accuracy: 0.8467 - val_f1_m: 1.0713\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.0322 - accuracy: 0.9917 - f1_m: 0.9859 - val_loss: 0.7049 - val_accuracy: 0.8510 - val_f1_m: 1.0800\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.0316 - accuracy: 0.9935 - f1_m: 0.9809 - val_loss: 0.7016 - val_accuracy: 0.8533 - val_f1_m: 1.0664\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 156us/sample - loss: 0.0195 - accuracy: 0.9962 - f1_m: 0.9733 - val_loss: 0.7106 - val_accuracy: 0.8527 - val_f1_m: 1.0716\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.0139 - accuracy: 0.9975 - f1_m: 0.9619 - val_loss: 0.7243 - val_accuracy: 0.8576 - val_f1_m: 1.0714\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 158us/sample - loss: 0.0125 - accuracy: 0.9986 - f1_m: 0.9632 - val_loss: 0.7260 - val_accuracy: 0.8545 - val_f1_m: 1.0636\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 155us/sample - loss: 0.0114 - accuracy: 0.9985 - f1_m: 0.9615 - val_loss: 0.7183 - val_accuracy: 0.8599 - val_f1_m: 1.0668\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 157us/sample - loss: 0.0086 - accuracy: 0.9992 - f1_m: 0.9561 - val_loss: 0.7403 - val_accuracy: 0.8569 - val_f1_m: 1.0589\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 257us/sample - loss: 0.0847 - accuracy: 0.9815 - f1_m: 0.9850 - val_loss: 0.7984 - val_accuracy: 0.8577 - val_f1_m: 1.0434\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 179us/sample - loss: 0.0482 - accuracy: 0.9860 - f1_m: 0.9789 - val_loss: 0.7311 - val_accuracy: 0.8630 - val_f1_m: 1.0462\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 179us/sample - loss: 0.0378 - accuracy: 0.9892 - f1_m: 0.9797 - val_loss: 0.7662 - val_accuracy: 0.8629 - val_f1_m: 1.0518\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 178us/sample - loss: 0.0237 - accuracy: 0.9925 - f1_m: 0.9697 - val_loss: 0.7945 - val_accuracy: 0.8634 - val_f1_m: 1.0475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 178us/sample - loss: 0.0217 - accuracy: 0.9938 - f1_m: 0.9679 - val_loss: 0.7998 - val_accuracy: 0.8623 - val_f1_m: 1.0329\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 178us/sample - loss: 0.0106 - accuracy: 0.9972 - f1_m: 0.9576 - val_loss: 0.8199 - val_accuracy: 0.8612 - val_f1_m: 1.0432\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 179us/sample - loss: 0.0111 - accuracy: 0.9977 - f1_m: 0.9544 - val_loss: 0.8918 - val_accuracy: 0.8623 - val_f1_m: 1.0310\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 179us/sample - loss: 0.0288 - accuracy: 0.9900 - f1_m: 0.9666 - val_loss: 0.9006 - val_accuracy: 0.8597 - val_f1_m: 1.0294\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 178us/sample - loss: 0.0245 - accuracy: 0.9908 - f1_m: 0.9686 - val_loss: 0.9069 - val_accuracy: 0.8500 - val_f1_m: 1.0479\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 178us/sample - loss: 0.0080 - accuracy: 0.9986 - f1_m: 0.9570 - val_loss: 0.8922 - val_accuracy: 0.8642 - val_f1_m: 1.0332\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 309us/sample - loss: 0.0819 - accuracy: 0.9811 - f1_m: 0.9840 - val_loss: 0.6769 - val_accuracy: 0.8505 - val_f1_m: 1.0809\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 209us/sample - loss: 0.0368 - accuracy: 0.9897 - f1_m: 0.9730 - val_loss: 0.8114 - val_accuracy: 0.8591 - val_f1_m: 1.0375\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 208us/sample - loss: 0.0168 - accuracy: 0.9948 - f1_m: 0.9603 - val_loss: 0.9284 - val_accuracy: 0.8558 - val_f1_m: 1.0226\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 212us/sample - loss: 0.0120 - accuracy: 0.9955 - f1_m: 0.9562 - val_loss: 0.9501 - val_accuracy: 0.8619 - val_f1_m: 1.0222\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 208us/sample - loss: 0.0165 - accuracy: 0.9943 - f1_m: 0.9603 - val_loss: 1.0547 - val_accuracy: 0.8572 - val_f1_m: 1.0176\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 209us/sample - loss: 0.0237 - accuracy: 0.9928 - f1_m: 0.9642 - val_loss: 1.0039 - val_accuracy: 0.8486 - val_f1_m: 1.0261\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 209us/sample - loss: 0.0401 - accuracy: 0.9834 - f1_m: 0.9701 - val_loss: 1.0322 - val_accuracy: 0.8509 - val_f1_m: 1.0327\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 211us/sample - loss: 0.0172 - accuracy: 0.9937 - f1_m: 0.9587 - val_loss: 1.0684 - val_accuracy: 0.8577 - val_f1_m: 1.0208\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 209us/sample - loss: 0.0056 - accuracy: 0.9988 - f1_m: 0.9528 - val_loss: 1.1101 - val_accuracy: 0.8614 - val_f1_m: 1.0067\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 209us/sample - loss: 0.0072 - accuracy: 0.9974 - f1_m: 0.9510 - val_loss: 1.1611 - val_accuracy: 0.8618 - val_f1_m: 1.0136\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 3s 390us/sample - loss: 0.0967 - accuracy: 0.9772 - f1_m: 1.0039 - val_loss: 0.7071 - val_accuracy: 0.8366 - val_f1_m: 1.0903\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 2s 264us/sample - loss: 0.0565 - accuracy: 0.9829 - f1_m: 0.9847 - val_loss: 0.8717 - val_accuracy: 0.8401 - val_f1_m: 1.0643\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 2s 263us/sample - loss: 0.0447 - accuracy: 0.9877 - f1_m: 0.9792 - val_loss: 0.9839 - val_accuracy: 0.8453 - val_f1_m: 1.0484\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 2s 262us/sample - loss: 0.0483 - accuracy: 0.9834 - f1_m: 0.9815 - val_loss: 0.8681 - val_accuracy: 0.8459 - val_f1_m: 1.0567\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 2s 262us/sample - loss: 0.0361 - accuracy: 0.9875 - f1_m: 0.9704 - val_loss: 0.9982 - val_accuracy: 0.8328 - val_f1_m: 1.0427\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 2s 266us/sample - loss: 0.0666 - accuracy: 0.9783 - f1_m: 0.9877 - val_loss: 0.7465 - val_accuracy: 0.8359 - val_f1_m: 1.0984\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 2s 265us/sample - loss: 0.0353 - accuracy: 0.9878 - f1_m: 0.9762 - val_loss: 1.0599 - val_accuracy: 0.8397 - val_f1_m: 1.0365\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 2s 263us/sample - loss: 0.0329 - accuracy: 0.9883 - f1_m: 0.9694 - val_loss: 1.0956 - val_accuracy: 0.8359 - val_f1_m: 1.0431\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 2s 262us/sample - loss: 0.0343 - accuracy: 0.9898 - f1_m: 0.9717 - val_loss: 1.1278 - val_accuracy: 0.8422 - val_f1_m: 1.0302\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 2s 263us/sample - loss: 0.0209 - accuracy: 0.9928 - f1_m: 0.9600 - val_loss: 1.2198 - val_accuracy: 0.8323 - val_f1_m: 1.0338\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 3s 377us/sample - loss: 0.2040 - accuracy: 0.9309 - f1_m: 1.1512 - val_loss: 0.5730 - val_accuracy: 0.8274 - val_f1_m: 1.2017\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 149us/sample - loss: 0.1944 - accuracy: 0.9337 - f1_m: 1.1477 - val_loss: 0.5400 - val_accuracy: 0.8358 - val_f1_m: 1.2014\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.1897 - accuracy: 0.9353 - f1_m: 1.1480 - val_loss: 0.5738 - val_accuracy: 0.8322 - val_f1_m: 1.1876\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 153us/sample - loss: 0.1833 - accuracy: 0.9373 - f1_m: 1.1416 - val_loss: 0.6176 - val_accuracy: 0.8199 - val_f1_m: 1.1819\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 149us/sample - loss: 0.1830 - accuracy: 0.9373 - f1_m: 1.1390 - val_loss: 0.5449 - val_accuracy: 0.8337 - val_f1_m: 1.1986\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.1798 - accuracy: 0.9371 - f1_m: 1.1399 - val_loss: 0.5513 - val_accuracy: 0.8352 - val_f1_m: 1.1854\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.1736 - accuracy: 0.9419 - f1_m: 1.1337 - val_loss: 0.5431 - val_accuracy: 0.8389 - val_f1_m: 1.1859\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.1692 - accuracy: 0.9436 - f1_m: 1.1301 - val_loss: 0.5960 - val_accuracy: 0.8265 - val_f1_m: 1.1825\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.1707 - accuracy: 0.9404 - f1_m: 1.1297 - val_loss: 0.5763 - val_accuracy: 0.8346 - val_f1_m: 1.1775\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.1623 - accuracy: 0.9436 - f1_m: 1.1246 - val_loss: 0.5743 - val_accuracy: 0.8325 - val_f1_m: 1.1918\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 238us/sample - loss: 0.1506 - accuracy: 0.9550 - f1_m: 1.0687 - val_loss: 0.6168 - val_accuracy: 0.8571 - val_f1_m: 1.0997\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.1315 - accuracy: 0.9614 - f1_m: 1.0699 - val_loss: 0.6074 - val_accuracy: 0.8530 - val_f1_m: 1.1203\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 162us/sample - loss: 0.1298 - accuracy: 0.9566 - f1_m: 1.0593 - val_loss: 0.6077 - val_accuracy: 0.8557 - val_f1_m: 1.1139\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.1209 - accuracy: 0.9591 - f1_m: 1.0662 - val_loss: 0.6680 - val_accuracy: 0.8466 - val_f1_m: 1.0960\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 163us/sample - loss: 0.1191 - accuracy: 0.9614 - f1_m: 1.0686 - val_loss: 0.6181 - val_accuracy: 0.8558 - val_f1_m: 1.1143\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.1129 - accuracy: 0.9627 - f1_m: 1.0594 - val_loss: 0.6438 - val_accuracy: 0.8558 - val_f1_m: 1.1078\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 163us/sample - loss: 0.1124 - accuracy: 0.9643 - f1_m: 1.0636 - val_loss: 0.6448 - val_accuracy: 0.8595 - val_f1_m: 1.0945\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.1037 - accuracy: 0.9676 - f1_m: 1.0535 - val_loss: 0.6764 - val_accuracy: 0.8512 - val_f1_m: 1.0983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 163us/sample - loss: 0.1119 - accuracy: 0.9621 - f1_m: 1.0613 - val_loss: 0.6635 - val_accuracy: 0.8583 - val_f1_m: 1.0960\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 161us/sample - loss: 0.0998 - accuracy: 0.9667 - f1_m: 1.0521 - val_loss: 0.7253 - val_accuracy: 0.8433 - val_f1_m: 1.1033\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 284us/sample - loss: 0.1031 - accuracy: 0.9690 - f1_m: 1.0184 - val_loss: 0.8495 - val_accuracy: 0.8427 - val_f1_m: 1.0695\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 191us/sample - loss: 0.0970 - accuracy: 0.9687 - f1_m: 1.0210 - val_loss: 0.8364 - val_accuracy: 0.8377 - val_f1_m: 1.0965\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 191us/sample - loss: 0.0691 - accuracy: 0.9769 - f1_m: 1.0176 - val_loss: 0.9013 - val_accuracy: 0.8421 - val_f1_m: 1.0703\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 190us/sample - loss: 0.0493 - accuracy: 0.9830 - f1_m: 0.9979 - val_loss: 0.9848 - val_accuracy: 0.8322 - val_f1_m: 1.0585\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 191us/sample - loss: 0.0631 - accuracy: 0.9779 - f1_m: 1.0044 - val_loss: 0.9640 - val_accuracy: 0.8429 - val_f1_m: 1.0694\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 192us/sample - loss: 0.0650 - accuracy: 0.9766 - f1_m: 0.9979 - val_loss: 0.9662 - val_accuracy: 0.8397 - val_f1_m: 1.0705\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 190us/sample - loss: 0.0508 - accuracy: 0.9837 - f1_m: 0.9974 - val_loss: 1.0124 - val_accuracy: 0.8388 - val_f1_m: 1.0524\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 192us/sample - loss: 0.0452 - accuracy: 0.9854 - f1_m: 0.9942 - val_loss: 1.0433 - val_accuracy: 0.8415 - val_f1_m: 1.0477\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 190us/sample - loss: 0.0596 - accuracy: 0.9773 - f1_m: 1.0033 - val_loss: 1.0766 - val_accuracy: 0.8371 - val_f1_m: 1.0551\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 192us/sample - loss: 0.0679 - accuracy: 0.9760 - f1_m: 1.0035 - val_loss: 1.0466 - val_accuracy: 0.8377 - val_f1_m: 1.0507\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 3s 359us/sample - loss: 0.1313 - accuracy: 0.9574 - f1_m: 1.0449 - val_loss: 0.7776 - val_accuracy: 0.8370 - val_f1_m: 1.0996\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 236us/sample - loss: 0.1182 - accuracy: 0.9600 - f1_m: 1.0427 - val_loss: 0.7225 - val_accuracy: 0.8335 - val_f1_m: 1.1108\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 234us/sample - loss: 0.0973 - accuracy: 0.9679 - f1_m: 1.0319 - val_loss: 0.8014 - val_accuracy: 0.8416 - val_f1_m: 1.0918\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 237us/sample - loss: 0.1046 - accuracy: 0.9623 - f1_m: 1.0349 - val_loss: 0.7789 - val_accuracy: 0.8310 - val_f1_m: 1.0985\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 238us/sample - loss: 0.0932 - accuracy: 0.9681 - f1_m: 1.0306 - val_loss: 0.8278 - val_accuracy: 0.8346 - val_f1_m: 1.0809\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 239us/sample - loss: 0.0875 - accuracy: 0.9670 - f1_m: 1.0245 - val_loss: 0.9117 - val_accuracy: 0.8377 - val_f1_m: 1.0609\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 236us/sample - loss: 0.0986 - accuracy: 0.9634 - f1_m: 1.0339 - val_loss: 0.8170 - val_accuracy: 0.8350 - val_f1_m: 1.0841\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 238us/sample - loss: 0.1236 - accuracy: 0.9527 - f1_m: 1.0435 - val_loss: 0.7148 - val_accuracy: 0.8378 - val_f1_m: 1.1115\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 236us/sample - loss: 0.0785 - accuracy: 0.9721 - f1_m: 1.0210 - val_loss: 0.7860 - val_accuracy: 0.8352 - val_f1_m: 1.0933\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 236us/sample - loss: 0.0724 - accuracy: 0.9721 - f1_m: 1.0138 - val_loss: 0.8250 - val_accuracy: 0.8366 - val_f1_m: 1.0918\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 218us/sample - loss: 0.0581 - accuracy: 0.9883 - f1_m: 0.9852 - val_loss: 0.7619 - val_accuracy: 0.8517 - val_f1_m: 1.0714\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.0377 - accuracy: 0.9914 - f1_m: 0.9812 - val_loss: 0.7471 - val_accuracy: 0.8525 - val_f1_m: 1.0666\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.0286 - accuracy: 0.9926 - f1_m: 0.9743 - val_loss: 0.7657 - val_accuracy: 0.8487 - val_f1_m: 1.0643\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.0220 - accuracy: 0.9947 - f1_m: 0.9717 - val_loss: 0.7460 - val_accuracy: 0.8570 - val_f1_m: 1.0579\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.0183 - accuracy: 0.9946 - f1_m: 0.9705 - val_loss: 0.7429 - val_accuracy: 0.8591 - val_f1_m: 1.0671\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.0112 - accuracy: 0.9987 - f1_m: 0.9627 - val_loss: 0.7655 - val_accuracy: 0.8594 - val_f1_m: 1.0511\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.0078 - accuracy: 0.9993 - f1_m: 0.9578 - val_loss: 0.7610 - val_accuracy: 0.8553 - val_f1_m: 1.0617\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.0068 - accuracy: 0.9996 - f1_m: 0.9543 - val_loss: 0.8022 - val_accuracy: 0.8617 - val_f1_m: 1.0474\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 151us/sample - loss: 0.0249 - accuracy: 0.9924 - f1_m: 0.9689 - val_loss: 0.8239 - val_accuracy: 0.8508 - val_f1_m: 1.0493\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.0119 - accuracy: 0.9981 - f1_m: 0.9628 - val_loss: 0.8524 - val_accuracy: 0.8472 - val_f1_m: 1.0643\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0606 - accuracy: 0.9863 - f1_m: 0.9755 - val_loss: 0.7775 - val_accuracy: 0.8585 - val_f1_m: 1.0462\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 171us/sample - loss: 0.0347 - accuracy: 0.9906 - f1_m: 0.9738 - val_loss: 0.8356 - val_accuracy: 0.8571 - val_f1_m: 1.0563\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 171us/sample - loss: 0.0375 - accuracy: 0.9876 - f1_m: 0.9764 - val_loss: 0.8315 - val_accuracy: 0.8588 - val_f1_m: 1.0412\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 174us/sample - loss: 0.0155 - accuracy: 0.9964 - f1_m: 0.9612 - val_loss: 0.8383 - val_accuracy: 0.8628 - val_f1_m: 1.0301\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 171us/sample - loss: 0.0096 - accuracy: 0.9967 - f1_m: 0.9577 - val_loss: 0.8586 - val_accuracy: 0.8615 - val_f1_m: 1.0324\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 173us/sample - loss: 0.0107 - accuracy: 0.9964 - f1_m: 0.9570 - val_loss: 0.8503 - val_accuracy: 0.8660 - val_f1_m: 1.0396\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 171us/sample - loss: 0.0165 - accuracy: 0.9950 - f1_m: 0.9609 - val_loss: 0.9038 - val_accuracy: 0.8643 - val_f1_m: 1.0280\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.0106 - accuracy: 0.9974 - f1_m: 0.9562 - val_loss: 1.0303 - val_accuracy: 0.8577 - val_f1_m: 1.0304\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.0321 - accuracy: 0.9893 - f1_m: 0.9737 - val_loss: 0.9627 - val_accuracy: 0.8573 - val_f1_m: 1.0320\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.0059 - accuracy: 0.9989 - f1_m: 0.9527 - val_loss: 0.9062 - val_accuracy: 0.8661 - val_f1_m: 1.0259\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 292us/sample - loss: 0.0691 - accuracy: 0.9840 - f1_m: 0.9730 - val_loss: 0.7549 - val_accuracy: 0.8532 - val_f1_m: 1.0563\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 203us/sample - loss: 0.0227 - accuracy: 0.9939 - f1_m: 0.9643 - val_loss: 0.8401 - val_accuracy: 0.8559 - val_f1_m: 1.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 200us/sample - loss: 0.0080 - accuracy: 0.9976 - f1_m: 0.9517 - val_loss: 0.9747 - val_accuracy: 0.8642 - val_f1_m: 1.0194\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 204us/sample - loss: 0.0103 - accuracy: 0.9973 - f1_m: 0.9554 - val_loss: 1.0327 - val_accuracy: 0.8546 - val_f1_m: 1.0174\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0262 - accuracy: 0.9919 - f1_m: 0.9614 - val_loss: 0.9598 - val_accuracy: 0.8636 - val_f1_m: 1.0246\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0166 - accuracy: 0.9951 - f1_m: 0.9608 - val_loss: 1.0368 - val_accuracy: 0.8659 - val_f1_m: 1.0180\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 206us/sample - loss: 0.0156 - accuracy: 0.9951 - f1_m: 0.9556 - val_loss: 0.9967 - val_accuracy: 0.8656 - val_f1_m: 1.0178\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 202us/sample - loss: 0.0273 - accuracy: 0.9913 - f1_m: 0.9673 - val_loss: 1.0844 - val_accuracy: 0.8630 - val_f1_m: 1.0182\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 201us/sample - loss: 0.0183 - accuracy: 0.9940 - f1_m: 0.9600 - val_loss: 1.0780 - val_accuracy: 0.8602 - val_f1_m: 1.0196\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 201us/sample - loss: 0.0276 - accuracy: 0.9916 - f1_m: 0.9621 - val_loss: 1.2159 - val_accuracy: 0.8524 - val_f1_m: 1.0139\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 3s 374us/sample - loss: 0.0834 - accuracy: 0.9779 - f1_m: 0.9884 - val_loss: 0.7837 - val_accuracy: 0.8356 - val_f1_m: 1.0838\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 254us/sample - loss: 0.0391 - accuracy: 0.9889 - f1_m: 0.9756 - val_loss: 0.8614 - val_accuracy: 0.8364 - val_f1_m: 1.0714\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 255us/sample - loss: 0.0411 - accuracy: 0.9877 - f1_m: 0.9755 - val_loss: 0.9945 - val_accuracy: 0.8470 - val_f1_m: 1.0483\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 255us/sample - loss: 0.0485 - accuracy: 0.9841 - f1_m: 0.9770 - val_loss: 0.9583 - val_accuracy: 0.8422 - val_f1_m: 1.0508\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0389 - accuracy: 0.9877 - f1_m: 0.9741 - val_loss: 1.2022 - val_accuracy: 0.8389 - val_f1_m: 1.0345\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0446 - accuracy: 0.9854 - f1_m: 0.9780 - val_loss: 1.0816 - val_accuracy: 0.8420 - val_f1_m: 1.0403\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0167 - accuracy: 0.9946 - f1_m: 0.9602 - val_loss: 1.2118 - val_accuracy: 0.8384 - val_f1_m: 1.0267\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 254us/sample - loss: 0.0358 - accuracy: 0.9877 - f1_m: 0.9662 - val_loss: 1.1174 - val_accuracy: 0.8341 - val_f1_m: 1.0377\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 255us/sample - loss: 0.0363 - accuracy: 0.9887 - f1_m: 0.9696 - val_loss: 0.9752 - val_accuracy: 0.8370 - val_f1_m: 1.0622\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 255us/sample - loss: 0.0400 - accuracy: 0.9870 - f1_m: 0.9735 - val_loss: 1.0624 - val_accuracy: 0.8423 - val_f1_m: 1.0367\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 207us/sample - loss: 0.1877 - accuracy: 0.9369 - f1_m: 1.1325 - val_loss: 0.5552 - val_accuracy: 0.8360 - val_f1_m: 1.1907\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 146us/sample - loss: 0.1808 - accuracy: 0.9369 - f1_m: 1.1325 - val_loss: 0.5692 - val_accuracy: 0.8371 - val_f1_m: 1.1885\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.1750 - accuracy: 0.9411 - f1_m: 1.1336 - val_loss: 0.5591 - val_accuracy: 0.8347 - val_f1_m: 1.1826\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 144us/sample - loss: 0.1729 - accuracy: 0.9403 - f1_m: 1.1271 - val_loss: 0.5675 - val_accuracy: 0.8307 - val_f1_m: 1.1873\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 144us/sample - loss: 0.1607 - accuracy: 0.9480 - f1_m: 1.1273 - val_loss: 0.5642 - val_accuracy: 0.8352 - val_f1_m: 1.1868\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 144us/sample - loss: 0.1583 - accuracy: 0.9455 - f1_m: 1.1247 - val_loss: 0.6155 - val_accuracy: 0.8235 - val_f1_m: 1.1796\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 144us/sample - loss: 0.1573 - accuracy: 0.9447 - f1_m: 1.1197 - val_loss: 0.5783 - val_accuracy: 0.8345 - val_f1_m: 1.1713\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.1610 - accuracy: 0.9435 - f1_m: 1.1243 - val_loss: 0.5915 - val_accuracy: 0.8288 - val_f1_m: 1.1877\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.1551 - accuracy: 0.9451 - f1_m: 1.1202 - val_loss: 0.5836 - val_accuracy: 0.8401 - val_f1_m: 1.1561\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 144us/sample - loss: 0.1504 - accuracy: 0.9473 - f1_m: 1.1094 - val_loss: 0.6659 - val_accuracy: 0.8193 - val_f1_m: 1.1821\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 225us/sample - loss: 0.1309 - accuracy: 0.9607 - f1_m: 1.0585 - val_loss: 0.6816 - val_accuracy: 0.8578 - val_f1_m: 1.0949\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 159us/sample - loss: 0.1174 - accuracy: 0.9605 - f1_m: 1.0602 - val_loss: 0.6716 - val_accuracy: 0.8532 - val_f1_m: 1.0975\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 156us/sample - loss: 0.1115 - accuracy: 0.9629 - f1_m: 1.0593 - val_loss: 0.6695 - val_accuracy: 0.8521 - val_f1_m: 1.1055\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 156us/sample - loss: 0.1085 - accuracy: 0.9648 - f1_m: 1.0554 - val_loss: 0.6824 - val_accuracy: 0.8478 - val_f1_m: 1.0939\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 158us/sample - loss: 0.1022 - accuracy: 0.9649 - f1_m: 1.0573 - val_loss: 0.6609 - val_accuracy: 0.8617 - val_f1_m: 1.0934\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 157us/sample - loss: 0.1048 - accuracy: 0.9640 - f1_m: 1.0528 - val_loss: 0.6923 - val_accuracy: 0.8494 - val_f1_m: 1.1055\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 156us/sample - loss: 0.0931 - accuracy: 0.9679 - f1_m: 1.0393 - val_loss: 0.6914 - val_accuracy: 0.8551 - val_f1_m: 1.0925\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 156us/sample - loss: 0.0899 - accuracy: 0.9695 - f1_m: 1.0429 - val_loss: 0.6815 - val_accuracy: 0.8593 - val_f1_m: 1.0816\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 157us/sample - loss: 0.0913 - accuracy: 0.9675 - f1_m: 1.0409 - val_loss: 0.7098 - val_accuracy: 0.8587 - val_f1_m: 1.0880\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 156us/sample - loss: 0.0828 - accuracy: 0.9743 - f1_m: 1.0363 - val_loss: 0.7367 - val_accuracy: 0.8485 - val_f1_m: 1.0933\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 277us/sample - loss: 0.0980 - accuracy: 0.9743 - f1_m: 1.0101 - val_loss: 0.9811 - val_accuracy: 0.8407 - val_f1_m: 1.0688\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 184us/sample - loss: 0.0923 - accuracy: 0.9705 - f1_m: 1.0129 - val_loss: 0.9720 - val_accuracy: 0.8359 - val_f1_m: 1.0800\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 185us/sample - loss: 0.0694 - accuracy: 0.9768 - f1_m: 1.0100 - val_loss: 0.9244 - val_accuracy: 0.8487 - val_f1_m: 1.0696\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 184us/sample - loss: 0.0495 - accuracy: 0.9839 - f1_m: 0.9962 - val_loss: 0.9561 - val_accuracy: 0.8444 - val_f1_m: 1.0565\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 186us/sample - loss: 0.0540 - accuracy: 0.9828 - f1_m: 1.0060 - val_loss: 0.9964 - val_accuracy: 0.8436 - val_f1_m: 1.0582\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 187us/sample - loss: 0.0497 - accuracy: 0.9825 - f1_m: 0.9930 - val_loss: 1.0987 - val_accuracy: 0.8171 - val_f1_m: 1.0788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 197us/sample - loss: 0.0551 - accuracy: 0.9803 - f1_m: 1.0007 - val_loss: 1.0750 - val_accuracy: 0.8333 - val_f1_m: 1.0649\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 196us/sample - loss: 0.0521 - accuracy: 0.9815 - f1_m: 0.9942 - val_loss: 1.1075 - val_accuracy: 0.8420 - val_f1_m: 1.0480\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 185us/sample - loss: 0.0510 - accuracy: 0.9827 - f1_m: 0.9926 - val_loss: 1.0520 - val_accuracy: 0.8368 - val_f1_m: 1.0530\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 184us/sample - loss: 0.0443 - accuracy: 0.9836 - f1_m: 0.9901 - val_loss: 1.1887 - val_accuracy: 0.8335 - val_f1_m: 1.0437\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 3s 343us/sample - loss: 0.1210 - accuracy: 0.9611 - f1_m: 1.0355 - val_loss: 0.7405 - val_accuracy: 0.8457 - val_f1_m: 1.0999\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 2s 230us/sample - loss: 0.1009 - accuracy: 0.9643 - f1_m: 1.0329 - val_loss: 0.7663 - val_accuracy: 0.8414 - val_f1_m: 1.0871\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 2s 230us/sample - loss: 0.1064 - accuracy: 0.9612 - f1_m: 1.0336 - val_loss: 0.7047 - val_accuracy: 0.8352 - val_f1_m: 1.1227\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 2s 231us/sample - loss: 0.0949 - accuracy: 0.9684 - f1_m: 1.0275 - val_loss: 0.7696 - val_accuracy: 0.8374 - val_f1_m: 1.0977\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 2s 229us/sample - loss: 0.0869 - accuracy: 0.9695 - f1_m: 1.0158 - val_loss: 0.7866 - val_accuracy: 0.8371 - val_f1_m: 1.0969\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 2s 230us/sample - loss: 0.0858 - accuracy: 0.9697 - f1_m: 1.0201 - val_loss: 0.8655 - val_accuracy: 0.8301 - val_f1_m: 1.0818\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 2s 231us/sample - loss: 0.1001 - accuracy: 0.9635 - f1_m: 1.0256 - val_loss: 0.7297 - val_accuracy: 0.8385 - val_f1_m: 1.1128\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 2s 230us/sample - loss: 0.0869 - accuracy: 0.9684 - f1_m: 1.0228 - val_loss: 0.8769 - val_accuracy: 0.8333 - val_f1_m: 1.0660\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 2s 231us/sample - loss: 0.0739 - accuracy: 0.9725 - f1_m: 1.0132 - val_loss: 0.7878 - val_accuracy: 0.8364 - val_f1_m: 1.0948\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 2s 231us/sample - loss: 0.0750 - accuracy: 0.9715 - f1_m: 1.0146 - val_loss: 0.9328 - val_accuracy: 0.8385 - val_f1_m: 1.0597\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 208us/sample - loss: 0.0653 - accuracy: 0.9869 - f1_m: 0.9760 - val_loss: 0.8211 - val_accuracy: 0.8522 - val_f1_m: 1.0576\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0414 - accuracy: 0.9892 - f1_m: 0.9770 - val_loss: 0.7254 - val_accuracy: 0.8525 - val_f1_m: 1.0642\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 146us/sample - loss: 0.0251 - accuracy: 0.9951 - f1_m: 0.9703 - val_loss: 0.7597 - val_accuracy: 0.8571 - val_f1_m: 1.0597\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0188 - accuracy: 0.9957 - f1_m: 0.9663 - val_loss: 0.7465 - val_accuracy: 0.8558 - val_f1_m: 1.0529\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0144 - accuracy: 0.9972 - f1_m: 0.9615 - val_loss: 0.7925 - val_accuracy: 0.8539 - val_f1_m: 1.0525\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0133 - accuracy: 0.9976 - f1_m: 0.9570 - val_loss: 0.8254 - val_accuracy: 0.8515 - val_f1_m: 1.0517\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0152 - accuracy: 0.9965 - f1_m: 0.9641 - val_loss: 0.7876 - val_accuracy: 0.8583 - val_f1_m: 1.0518\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0109 - accuracy: 0.9977 - f1_m: 0.9588 - val_loss: 0.8341 - val_accuracy: 0.8571 - val_f1_m: 1.0446\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0069 - accuracy: 0.9988 - f1_m: 0.9531 - val_loss: 0.8198 - val_accuracy: 0.8579 - val_f1_m: 1.0415\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 145us/sample - loss: 0.0079 - accuracy: 0.9992 - f1_m: 0.9553 - val_loss: 0.8458 - val_accuracy: 0.8543 - val_f1_m: 1.0426\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 236us/sample - loss: 0.0656 - accuracy: 0.9887 - f1_m: 0.9683 - val_loss: 0.8577 - val_accuracy: 0.8620 - val_f1_m: 1.0447\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 0.0341 - accuracy: 0.9919 - f1_m: 0.9689 - val_loss: 0.8417 - val_accuracy: 0.8632 - val_f1_m: 1.0323\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 0.0375 - accuracy: 0.9884 - f1_m: 0.9726 - val_loss: 0.8298 - val_accuracy: 0.8610 - val_f1_m: 1.0361\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 0.0222 - accuracy: 0.9935 - f1_m: 0.9659 - val_loss: 0.8919 - val_accuracy: 0.8631 - val_f1_m: 1.0257\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 168us/sample - loss: 0.0067 - accuracy: 0.9987 - f1_m: 0.9533 - val_loss: 0.9115 - val_accuracy: 0.8639 - val_f1_m: 1.0223\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 0.0043 - accuracy: 0.9991 - f1_m: 0.9519 - val_loss: 0.9513 - val_accuracy: 0.8595 - val_f1_m: 1.0257\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 166us/sample - loss: 0.0062 - accuracy: 0.9984 - f1_m: 0.9515 - val_loss: 0.9330 - val_accuracy: 0.8677 - val_f1_m: 1.0240\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 166us/sample - loss: 0.0014 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.9560 - val_accuracy: 0.8669 - val_f1_m: 1.0178\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 166us/sample - loss: 5.9617e-04 - accuracy: 1.0000 - f1_m: 0.9457 - val_loss: 0.9731 - val_accuracy: 0.8687 - val_f1_m: 1.0143\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 187us/sample - loss: 4.6107e-04 - accuracy: 1.0000 - f1_m: 0.9458 - val_loss: 0.9878 - val_accuracy: 0.8694 - val_f1_m: 1.0143\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 277us/sample - loss: 0.0615 - accuracy: 0.9861 - f1_m: 0.9712 - val_loss: 0.9078 - val_accuracy: 0.8613 - val_f1_m: 1.0366\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 198us/sample - loss: 0.0196 - accuracy: 0.9948 - f1_m: 0.9581 - val_loss: 0.8533 - val_accuracy: 0.8665 - val_f1_m: 1.0328\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 194us/sample - loss: 0.0107 - accuracy: 0.9971 - f1_m: 0.9549 - val_loss: 0.9584 - val_accuracy: 0.8614 - val_f1_m: 1.0181\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 194us/sample - loss: 0.0238 - accuracy: 0.9928 - f1_m: 0.9630 - val_loss: 0.9316 - val_accuracy: 0.8593 - val_f1_m: 1.0200\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 193us/sample - loss: 0.0109 - accuracy: 0.9971 - f1_m: 0.9559 - val_loss: 1.0359 - val_accuracy: 0.8647 - val_f1_m: 1.0183\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 197us/sample - loss: 0.0244 - accuracy: 0.9923 - f1_m: 0.9604 - val_loss: 1.0131 - val_accuracy: 0.8586 - val_f1_m: 1.0223\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 195us/sample - loss: 0.0207 - accuracy: 0.9937 - f1_m: 0.9585 - val_loss: 1.2194 - val_accuracy: 0.8575 - val_f1_m: 1.0084\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 195us/sample - loss: 0.0206 - accuracy: 0.9932 - f1_m: 0.9627 - val_loss: 1.0762 - val_accuracy: 0.8618 - val_f1_m: 1.0109\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 195us/sample - loss: 0.0095 - accuracy: 0.9971 - f1_m: 0.9542 - val_loss: 1.1433 - val_accuracy: 0.8648 - val_f1_m: 1.0002\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 199us/sample - loss: 0.0060 - accuracy: 0.9979 - f1_m: 0.9509 - val_loss: 1.3203 - val_accuracy: 0.8572 - val_f1_m: 1.0006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 3s 357us/sample - loss: 0.0841 - accuracy: 0.9803 - f1_m: 0.9924 - val_loss: 0.7164 - val_accuracy: 0.8490 - val_f1_m: 1.0769\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 2s 247us/sample - loss: 0.0440 - accuracy: 0.9880 - f1_m: 0.9772 - val_loss: 0.8901 - val_accuracy: 0.8427 - val_f1_m: 1.0521\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 2s 247us/sample - loss: 0.0349 - accuracy: 0.9876 - f1_m: 0.9773 - val_loss: 1.0038 - val_accuracy: 0.8318 - val_f1_m: 1.0499\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 2s 245us/sample - loss: 0.0434 - accuracy: 0.9839 - f1_m: 0.9777 - val_loss: 1.1242 - val_accuracy: 0.8436 - val_f1_m: 1.0257\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 2s 245us/sample - loss: 0.0481 - accuracy: 0.9835 - f1_m: 0.9800 - val_loss: 0.8730 - val_accuracy: 0.8523 - val_f1_m: 1.0453\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 2s 245us/sample - loss: 0.0311 - accuracy: 0.9899 - f1_m: 0.9668 - val_loss: 0.9328 - val_accuracy: 0.8383 - val_f1_m: 1.0516\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 2s 247us/sample - loss: 0.0360 - accuracy: 0.9875 - f1_m: 0.9760 - val_loss: 1.2285 - val_accuracy: 0.8438 - val_f1_m: 1.0271\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 2s 247us/sample - loss: 0.0436 - accuracy: 0.9857 - f1_m: 0.9727 - val_loss: 1.0920 - val_accuracy: 0.8425 - val_f1_m: 1.0307\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 2s 246us/sample - loss: 0.0288 - accuracy: 0.9900 - f1_m: 0.9679 - val_loss: 1.1301 - val_accuracy: 0.8480 - val_f1_m: 1.0193\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 2s 245us/sample - loss: 0.0404 - accuracy: 0.9868 - f1_m: 0.9688 - val_loss: 1.0121 - val_accuracy: 0.8393 - val_f1_m: 1.0493\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 189us/sample - loss: 0.1749 - accuracy: 0.9414 - f1_m: 1.1183 - val_loss: 0.5871 - val_accuracy: 0.8348 - val_f1_m: 1.1675\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 131us/sample - loss: 0.1636 - accuracy: 0.9448 - f1_m: 1.1169 - val_loss: 0.6047 - val_accuracy: 0.8318 - val_f1_m: 1.1600\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.1589 - accuracy: 0.9460 - f1_m: 1.1111 - val_loss: 0.5908 - val_accuracy: 0.8346 - val_f1_m: 1.1644\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.1570 - accuracy: 0.9451 - f1_m: 1.1120 - val_loss: 0.6030 - val_accuracy: 0.8369 - val_f1_m: 1.1606\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.1476 - accuracy: 0.9494 - f1_m: 1.1137 - val_loss: 0.6017 - val_accuracy: 0.8336 - val_f1_m: 1.1501\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 133us/sample - loss: 0.1539 - accuracy: 0.9459 - f1_m: 1.1103 - val_loss: 0.6297 - val_accuracy: 0.8255 - val_f1_m: 1.1630\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.1404 - accuracy: 0.9526 - f1_m: 1.1098 - val_loss: 0.6068 - val_accuracy: 0.8326 - val_f1_m: 1.1489\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 131us/sample - loss: 0.1409 - accuracy: 0.9523 - f1_m: 1.1016 - val_loss: 0.6940 - val_accuracy: 0.8207 - val_f1_m: 1.1501\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.1427 - accuracy: 0.9507 - f1_m: 1.0994 - val_loss: 0.6293 - val_accuracy: 0.8326 - val_f1_m: 1.1735\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.1337 - accuracy: 0.9566 - f1_m: 1.1043 - val_loss: 0.6274 - val_accuracy: 0.8324 - val_f1_m: 1.1542\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 207us/sample - loss: 0.1303 - accuracy: 0.9601 - f1_m: 1.0508 - val_loss: 0.7108 - val_accuracy: 0.8586 - val_f1_m: 1.0807\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.1162 - accuracy: 0.9635 - f1_m: 1.0417 - val_loss: 0.7356 - val_accuracy: 0.8513 - val_f1_m: 1.0813\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.1055 - accuracy: 0.9661 - f1_m: 1.0452 - val_loss: 0.6965 - val_accuracy: 0.8541 - val_f1_m: 1.0912\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0918 - accuracy: 0.9699 - f1_m: 1.0378 - val_loss: 0.6972 - val_accuracy: 0.8627 - val_f1_m: 1.0828\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0910 - accuracy: 0.9693 - f1_m: 1.0406 - val_loss: 0.7275 - val_accuracy: 0.8545 - val_f1_m: 1.0746\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0877 - accuracy: 0.9704 - f1_m: 1.0362 - val_loss: 0.7191 - val_accuracy: 0.8543 - val_f1_m: 1.0748\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.0861 - accuracy: 0.9707 - f1_m: 1.0351 - val_loss: 0.7180 - val_accuracy: 0.8535 - val_f1_m: 1.0798\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0821 - accuracy: 0.9711 - f1_m: 1.0331 - val_loss: 0.7207 - val_accuracy: 0.8521 - val_f1_m: 1.0773\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.0846 - accuracy: 0.9699 - f1_m: 1.0280 - val_loss: 0.7511 - val_accuracy: 0.8578 - val_f1_m: 1.0885\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0801 - accuracy: 0.9724 - f1_m: 1.0262 - val_loss: 0.7496 - val_accuracy: 0.8582 - val_f1_m: 1.0704\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 249us/sample - loss: 0.1101 - accuracy: 0.9712 - f1_m: 1.0110 - val_loss: 0.9804 - val_accuracy: 0.8448 - val_f1_m: 1.0551\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 171us/sample - loss: 0.0724 - accuracy: 0.9753 - f1_m: 1.0049 - val_loss: 0.9531 - val_accuracy: 0.8441 - val_f1_m: 1.0612\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 173us/sample - loss: 0.0575 - accuracy: 0.9820 - f1_m: 0.9954 - val_loss: 1.0430 - val_accuracy: 0.8371 - val_f1_m: 1.0469\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 171us/sample - loss: 0.0641 - accuracy: 0.9783 - f1_m: 0.9994 - val_loss: 0.9784 - val_accuracy: 0.8406 - val_f1_m: 1.0571\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 174us/sample - loss: 0.0555 - accuracy: 0.9833 - f1_m: 0.9935 - val_loss: 1.0394 - val_accuracy: 0.8443 - val_f1_m: 1.0420\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 171us/sample - loss: 0.0438 - accuracy: 0.9843 - f1_m: 0.9964 - val_loss: 1.1401 - val_accuracy: 0.8422 - val_f1_m: 1.0351\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 172us/sample - loss: 0.0629 - accuracy: 0.9755 - f1_m: 1.0014 - val_loss: 1.0651 - val_accuracy: 0.8452 - val_f1_m: 1.0300\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 172us/sample - loss: 0.0491 - accuracy: 0.9821 - f1_m: 0.9936 - val_loss: 1.1179 - val_accuracy: 0.8448 - val_f1_m: 1.0363\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 173us/sample - loss: 0.0477 - accuracy: 0.9830 - f1_m: 0.9889 - val_loss: 1.1194 - val_accuracy: 0.8424 - val_f1_m: 1.0454\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 177us/sample - loss: 0.0321 - accuracy: 0.9896 - f1_m: 0.9788 - val_loss: 1.0958 - val_accuracy: 0.8450 - val_f1_m: 1.0368\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 3s 322us/sample - loss: 0.1347 - accuracy: 0.9559 - f1_m: 1.0520 - val_loss: 0.7191 - val_accuracy: 0.8441 - val_f1_m: 1.1014\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 216us/sample - loss: 0.1014 - accuracy: 0.9684 - f1_m: 1.0353 - val_loss: 0.7588 - val_accuracy: 0.8376 - val_f1_m: 1.1045\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 216us/sample - loss: 0.0991 - accuracy: 0.9681 - f1_m: 1.0288 - val_loss: 0.8718 - val_accuracy: 0.8391 - val_f1_m: 1.0673\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 216us/sample - loss: 0.0847 - accuracy: 0.9736 - f1_m: 1.0252 - val_loss: 0.8733 - val_accuracy: 0.8369 - val_f1_m: 1.0860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 217us/sample - loss: 0.1012 - accuracy: 0.9631 - f1_m: 1.0343 - val_loss: 0.8131 - val_accuracy: 0.8448 - val_f1_m: 1.0783\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 214us/sample - loss: 0.0886 - accuracy: 0.9716 - f1_m: 1.0163 - val_loss: 0.7495 - val_accuracy: 0.8406 - val_f1_m: 1.0968\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 216us/sample - loss: 0.1044 - accuracy: 0.9626 - f1_m: 1.0330 - val_loss: 0.7681 - val_accuracy: 0.8465 - val_f1_m: 1.0762\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 214us/sample - loss: 0.0762 - accuracy: 0.9750 - f1_m: 1.0136 - val_loss: 0.7751 - val_accuracy: 0.8385 - val_f1_m: 1.0820\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 214us/sample - loss: 0.1014 - accuracy: 0.9632 - f1_m: 1.0197 - val_loss: 0.7769 - val_accuracy: 0.8372 - val_f1_m: 1.1047\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2s 214us/sample - loss: 0.0675 - accuracy: 0.9745 - f1_m: 1.0122 - val_loss: 0.8531 - val_accuracy: 0.8407 - val_f1_m: 1.0643\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 191us/sample - loss: 0.0664 - accuracy: 0.9847 - f1_m: 0.9787 - val_loss: 0.8121 - val_accuracy: 0.8599 - val_f1_m: 1.0444\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 133us/sample - loss: 0.0342 - accuracy: 0.9915 - f1_m: 0.9682 - val_loss: 0.7963 - val_accuracy: 0.8528 - val_f1_m: 1.0490\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.0209 - accuracy: 0.9948 - f1_m: 0.9659 - val_loss: 0.8356 - val_accuracy: 0.8612 - val_f1_m: 1.0468\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.0198 - accuracy: 0.9939 - f1_m: 0.9675 - val_loss: 0.8126 - val_accuracy: 0.8631 - val_f1_m: 1.0408\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.0131 - accuracy: 0.9966 - f1_m: 0.9630 - val_loss: 0.8215 - val_accuracy: 0.8556 - val_f1_m: 1.0414\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.0097 - accuracy: 0.9984 - f1_m: 0.9587 - val_loss: 0.8062 - val_accuracy: 0.8613 - val_f1_m: 1.0414\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.0070 - accuracy: 0.9994 - f1_m: 0.9546 - val_loss: 0.8678 - val_accuracy: 0.8604 - val_f1_m: 1.0334\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.0098 - accuracy: 0.9976 - f1_m: 0.9571 - val_loss: 0.8440 - val_accuracy: 0.8513 - val_f1_m: 1.0359\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 132us/sample - loss: 0.0200 - accuracy: 0.9944 - f1_m: 0.9686 - val_loss: 0.8031 - val_accuracy: 0.8625 - val_f1_m: 1.0438\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 131us/sample - loss: 0.0056 - accuracy: 0.9992 - f1_m: 0.9542 - val_loss: 0.8348 - val_accuracy: 0.8674 - val_f1_m: 1.0349\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 211us/sample - loss: 0.0706 - accuracy: 0.9852 - f1_m: 0.9704 - val_loss: 0.8391 - val_accuracy: 0.8632 - val_f1_m: 1.0309\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0329 - accuracy: 0.9918 - f1_m: 0.9634 - val_loss: 0.8292 - val_accuracy: 0.8649 - val_f1_m: 1.0342\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0192 - accuracy: 0.9948 - f1_m: 0.9622 - val_loss: 0.8341 - val_accuracy: 0.8678 - val_f1_m: 1.0298\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0113 - accuracy: 0.9973 - f1_m: 0.9567 - val_loss: 0.8685 - val_accuracy: 0.8654 - val_f1_m: 1.0235\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0054 - accuracy: 0.9989 - f1_m: 0.9521 - val_loss: 1.1112 - val_accuracy: 0.8541 - val_f1_m: 1.0111\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 150us/sample - loss: 0.0262 - accuracy: 0.9918 - f1_m: 0.9660 - val_loss: 1.0153 - val_accuracy: 0.8576 - val_f1_m: 1.0242\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 148us/sample - loss: 0.0205 - accuracy: 0.9926 - f1_m: 0.9673 - val_loss: 0.9495 - val_accuracy: 0.8611 - val_f1_m: 1.0190\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0071 - accuracy: 0.9983 - f1_m: 0.9542 - val_loss: 0.9644 - val_accuracy: 0.8680 - val_f1_m: 1.0142\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0079 - accuracy: 0.9977 - f1_m: 0.9526 - val_loss: 1.0402 - val_accuracy: 0.8625 - val_f1_m: 1.0118\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 149us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9504 - val_loss: 0.9922 - val_accuracy: 0.8616 - val_f1_m: 1.0187\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 3s 427us/sample - loss: 0.0811 - accuracy: 0.9830 - f1_m: 0.9737 - val_loss: 0.8030 - val_accuracy: 0.8663 - val_f1_m: 1.0321\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 181us/sample - loss: 0.0238 - accuracy: 0.9936 - f1_m: 0.9601 - val_loss: 0.8268 - val_accuracy: 0.8607 - val_f1_m: 1.0319\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 181us/sample - loss: 0.0140 - accuracy: 0.9961 - f1_m: 0.9580 - val_loss: 0.9226 - val_accuracy: 0.8643 - val_f1_m: 1.0201\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 183us/sample - loss: 0.0064 - accuracy: 0.9974 - f1_m: 0.9531 - val_loss: 1.0269 - val_accuracy: 0.8675 - val_f1_m: 1.0145\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 184us/sample - loss: 0.0213 - accuracy: 0.9931 - f1_m: 0.9595 - val_loss: 1.0328 - val_accuracy: 0.8493 - val_f1_m: 1.0261\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 182us/sample - loss: 0.0283 - accuracy: 0.9905 - f1_m: 0.9665 - val_loss: 0.9115 - val_accuracy: 0.8641 - val_f1_m: 1.0253\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 182us/sample - loss: 0.0177 - accuracy: 0.9941 - f1_m: 0.9604 - val_loss: 1.0309 - val_accuracy: 0.8611 - val_f1_m: 1.0172\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 183us/sample - loss: 0.0274 - accuracy: 0.9909 - f1_m: 0.9634 - val_loss: 1.0663 - val_accuracy: 0.8609 - val_f1_m: 1.0103\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 181us/sample - loss: 0.0126 - accuracy: 0.9945 - f1_m: 0.9577 - val_loss: 1.1521 - val_accuracy: 0.8529 - val_f1_m: 1.0132\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 182us/sample - loss: 0.0123 - accuracy: 0.9964 - f1_m: 0.9538 - val_loss: 1.2225 - val_accuracy: 0.8638 - val_f1_m: 1.0038\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 3s 339us/sample - loss: 0.0937 - accuracy: 0.9783 - f1_m: 0.9930 - val_loss: 0.7155 - val_accuracy: 0.8483 - val_f1_m: 1.0695\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 235us/sample - loss: 0.0373 - accuracy: 0.9901 - f1_m: 0.9768 - val_loss: 0.8222 - val_accuracy: 0.8495 - val_f1_m: 1.0611\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 237us/sample - loss: 0.0364 - accuracy: 0.9876 - f1_m: 0.9732 - val_loss: 0.9207 - val_accuracy: 0.8530 - val_f1_m: 1.0353\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 0.0441 - accuracy: 0.9859 - f1_m: 0.9785 - val_loss: 0.9031 - val_accuracy: 0.8479 - val_f1_m: 1.0482\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 0.0584 - accuracy: 0.9824 - f1_m: 0.9843 - val_loss: 0.8648 - val_accuracy: 0.8440 - val_f1_m: 1.0557\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 0.0281 - accuracy: 0.9906 - f1_m: 0.9708 - val_loss: 1.0195 - val_accuracy: 0.8522 - val_f1_m: 1.0297\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0097 - accuracy: 0.9973 - f1_m: 0.9557 - val_loss: 1.1761 - val_accuracy: 0.8472 - val_f1_m: 1.0274\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0452 - accuracy: 0.9854 - f1_m: 0.9753 - val_loss: 1.0229 - val_accuracy: 0.8525 - val_f1_m: 1.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 0.0258 - accuracy: 0.9931 - f1_m: 0.9639 - val_loss: 1.0604 - val_accuracy: 0.8505 - val_f1_m: 1.0390\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.0457 - accuracy: 0.9844 - f1_m: 0.9731 - val_loss: 1.0198 - val_accuracy: 0.8417 - val_f1_m: 1.0416\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 189us/sample - loss: 0.1759 - accuracy: 0.9411 - f1_m: 1.1037 - val_loss: 0.6103 - val_accuracy: 0.8337 - val_f1_m: 1.1650\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 135us/sample - loss: 0.1588 - accuracy: 0.9473 - f1_m: 1.1103 - val_loss: 0.6073 - val_accuracy: 0.8382 - val_f1_m: 1.1451\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 136us/sample - loss: 0.1580 - accuracy: 0.9465 - f1_m: 1.1082 - val_loss: 0.6147 - val_accuracy: 0.8328 - val_f1_m: 1.1511\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 133us/sample - loss: 0.1506 - accuracy: 0.9507 - f1_m: 1.1029 - val_loss: 0.6548 - val_accuracy: 0.8293 - val_f1_m: 1.1625\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 136us/sample - loss: 0.1473 - accuracy: 0.9505 - f1_m: 1.1052 - val_loss: 0.6114 - val_accuracy: 0.8342 - val_f1_m: 1.1379\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 133us/sample - loss: 0.1447 - accuracy: 0.9548 - f1_m: 1.0988 - val_loss: 0.6220 - val_accuracy: 0.8328 - val_f1_m: 1.1422\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 135us/sample - loss: 0.1440 - accuracy: 0.9506 - f1_m: 1.1042 - val_loss: 0.6079 - val_accuracy: 0.8362 - val_f1_m: 1.1579\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 134us/sample - loss: 0.1365 - accuracy: 0.9541 - f1_m: 1.0989 - val_loss: 0.6192 - val_accuracy: 0.8350 - val_f1_m: 1.1479\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 135us/sample - loss: 0.1385 - accuracy: 0.9538 - f1_m: 1.0929 - val_loss: 0.6257 - val_accuracy: 0.8364 - val_f1_m: 1.1462\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 139us/sample - loss: 0.1329 - accuracy: 0.9545 - f1_m: 1.0880 - val_loss: 0.6387 - val_accuracy: 0.8328 - val_f1_m: 1.1403\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 208us/sample - loss: 0.1323 - accuracy: 0.9601 - f1_m: 1.0432 - val_loss: 0.7378 - val_accuracy: 0.8542 - val_f1_m: 1.0780\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.1085 - accuracy: 0.9680 - f1_m: 1.0401 - val_loss: 0.7348 - val_accuracy: 0.8566 - val_f1_m: 1.0688\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 147us/sample - loss: 0.1018 - accuracy: 0.9693 - f1_m: 1.0387 - val_loss: 0.7495 - val_accuracy: 0.8514 - val_f1_m: 1.0776\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0888 - accuracy: 0.9695 - f1_m: 1.0320 - val_loss: 0.7558 - val_accuracy: 0.8509 - val_f1_m: 1.0683\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 148us/sample - loss: 0.0912 - accuracy: 0.9709 - f1_m: 1.0360 - val_loss: 0.7344 - val_accuracy: 0.8545 - val_f1_m: 1.0763\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0853 - accuracy: 0.9722 - f1_m: 1.0286 - val_loss: 0.7407 - val_accuracy: 0.8541 - val_f1_m: 1.0828\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 147us/sample - loss: 0.0902 - accuracy: 0.9704 - f1_m: 1.0357 - val_loss: 0.7700 - val_accuracy: 0.8550 - val_f1_m: 1.0802\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 147us/sample - loss: 0.0827 - accuracy: 0.9726 - f1_m: 1.0293 - val_loss: 0.7560 - val_accuracy: 0.8607 - val_f1_m: 1.0690\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 147us/sample - loss: 0.0791 - accuracy: 0.9726 - f1_m: 1.0301 - val_loss: 0.7791 - val_accuracy: 0.8572 - val_f1_m: 1.0619\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0845 - accuracy: 0.9692 - f1_m: 1.0272 - val_loss: 0.7563 - val_accuracy: 0.8568 - val_f1_m: 1.0662\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 248us/sample - loss: 0.1127 - accuracy: 0.9722 - f1_m: 1.0033 - val_loss: 0.9965 - val_accuracy: 0.8418 - val_f1_m: 1.0482\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 172us/sample - loss: 0.0856 - accuracy: 0.9751 - f1_m: 1.0062 - val_loss: 1.0092 - val_accuracy: 0.8433 - val_f1_m: 1.0460\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 173us/sample - loss: 0.0655 - accuracy: 0.9821 - f1_m: 0.9960 - val_loss: 0.9597 - val_accuracy: 0.8465 - val_f1_m: 1.0508\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 172us/sample - loss: 0.0728 - accuracy: 0.9781 - f1_m: 1.0013 - val_loss: 0.9573 - val_accuracy: 0.8504 - val_f1_m: 1.0396\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 173us/sample - loss: 0.0568 - accuracy: 0.9816 - f1_m: 0.9982 - val_loss: 1.0277 - val_accuracy: 0.8510 - val_f1_m: 1.0442\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 172us/sample - loss: 0.0425 - accuracy: 0.9859 - f1_m: 0.9886 - val_loss: 1.1037 - val_accuracy: 0.8423 - val_f1_m: 1.0344\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 173us/sample - loss: 0.0590 - accuracy: 0.9799 - f1_m: 0.9953 - val_loss: 1.0804 - val_accuracy: 0.8407 - val_f1_m: 1.0442\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 172us/sample - loss: 0.0535 - accuracy: 0.9812 - f1_m: 0.9942 - val_loss: 1.0340 - val_accuracy: 0.8447 - val_f1_m: 1.0373\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 174us/sample - loss: 0.0438 - accuracy: 0.9849 - f1_m: 0.9866 - val_loss: 0.9778 - val_accuracy: 0.8433 - val_f1_m: 1.0503\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 172us/sample - loss: 0.0501 - accuracy: 0.9827 - f1_m: 0.9929 - val_loss: 1.0467 - val_accuracy: 0.8437 - val_f1_m: 1.0410\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 3s 312us/sample - loss: 0.1277 - accuracy: 0.9632 - f1_m: 1.0347 - val_loss: 0.7184 - val_accuracy: 0.8404 - val_f1_m: 1.1049\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 215us/sample - loss: 0.1023 - accuracy: 0.9659 - f1_m: 1.0390 - val_loss: 0.6796 - val_accuracy: 0.8484 - val_f1_m: 1.1017\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 215us/sample - loss: 0.0888 - accuracy: 0.9698 - f1_m: 1.0252 - val_loss: 0.7359 - val_accuracy: 0.8355 - val_f1_m: 1.1065\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 215us/sample - loss: 0.0874 - accuracy: 0.9701 - f1_m: 1.0233 - val_loss: 0.7323 - val_accuracy: 0.8404 - val_f1_m: 1.1074\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 217us/sample - loss: 0.1038 - accuracy: 0.9640 - f1_m: 1.0341 - val_loss: 0.7233 - val_accuracy: 0.8472 - val_f1_m: 1.0884\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 215us/sample - loss: 0.1017 - accuracy: 0.9618 - f1_m: 1.0294 - val_loss: 0.7335 - val_accuracy: 0.8424 - val_f1_m: 1.0926\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 215us/sample - loss: 0.0781 - accuracy: 0.9720 - f1_m: 1.0227 - val_loss: 0.7528 - val_accuracy: 0.8476 - val_f1_m: 1.0706\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 217us/sample - loss: 0.0994 - accuracy: 0.9660 - f1_m: 1.0209 - val_loss: 0.7985 - val_accuracy: 0.8463 - val_f1_m: 1.0616\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 216us/sample - loss: 0.0783 - accuracy: 0.9724 - f1_m: 1.0172 - val_loss: 0.8938 - val_accuracy: 0.8447 - val_f1_m: 1.0616\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 216us/sample - loss: 0.0816 - accuracy: 0.9713 - f1_m: 1.0134 - val_loss: 0.7928 - val_accuracy: 0.8373 - val_f1_m: 1.0722\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 190us/sample - loss: 0.0655 - accuracy: 0.9872 - f1_m: 0.9717 - val_loss: 0.8238 - val_accuracy: 0.8525 - val_f1_m: 1.0534\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 134us/sample - loss: 0.0412 - accuracy: 0.9893 - f1_m: 0.9745 - val_loss: 0.7989 - val_accuracy: 0.8596 - val_f1_m: 1.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 135us/sample - loss: 0.0219 - accuracy: 0.9956 - f1_m: 0.9628 - val_loss: 0.8157 - val_accuracy: 0.8622 - val_f1_m: 1.0413\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 134us/sample - loss: 0.0204 - accuracy: 0.9946 - f1_m: 0.9642 - val_loss: 0.8478 - val_accuracy: 0.8578 - val_f1_m: 1.0393\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 134us/sample - loss: 0.0152 - accuracy: 0.9955 - f1_m: 0.9614 - val_loss: 0.8494 - val_accuracy: 0.8654 - val_f1_m: 1.0282\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 134us/sample - loss: 0.0080 - accuracy: 0.9989 - f1_m: 0.9566 - val_loss: 0.8563 - val_accuracy: 0.8645 - val_f1_m: 1.0332\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 134us/sample - loss: 0.0056 - accuracy: 0.9989 - f1_m: 0.9510 - val_loss: 0.8747 - val_accuracy: 0.8624 - val_f1_m: 1.0319\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 135us/sample - loss: 0.0114 - accuracy: 0.9968 - f1_m: 0.9586 - val_loss: 0.9337 - val_accuracy: 0.8531 - val_f1_m: 1.0422\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 133us/sample - loss: 0.0134 - accuracy: 0.9962 - f1_m: 0.9617 - val_loss: 0.8511 - val_accuracy: 0.8616 - val_f1_m: 1.0294\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 134us/sample - loss: 0.0031 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.8773 - val_accuracy: 0.8659 - val_f1_m: 1.0275\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 214us/sample - loss: 0.0731 - accuracy: 0.9851 - f1_m: 0.9682 - val_loss: 0.8870 - val_accuracy: 0.8622 - val_f1_m: 1.0304\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 155us/sample - loss: 0.0366 - accuracy: 0.9919 - f1_m: 0.9688 - val_loss: 0.8216 - val_accuracy: 0.8642 - val_f1_m: 1.0351\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 155us/sample - loss: 0.0217 - accuracy: 0.9942 - f1_m: 0.9625 - val_loss: 0.8641 - val_accuracy: 0.8630 - val_f1_m: 1.0278\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 154us/sample - loss: 0.0186 - accuracy: 0.9955 - f1_m: 0.9595 - val_loss: 0.9382 - val_accuracy: 0.8674 - val_f1_m: 1.0218\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 154us/sample - loss: 0.0096 - accuracy: 0.9975 - f1_m: 0.9538 - val_loss: 0.9704 - val_accuracy: 0.8632 - val_f1_m: 1.0162\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 156us/sample - loss: 0.0077 - accuracy: 0.9979 - f1_m: 0.9523 - val_loss: 0.9599 - val_accuracy: 0.8646 - val_f1_m: 1.0169\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 155us/sample - loss: 0.0300 - accuracy: 0.9908 - f1_m: 0.9666 - val_loss: 0.8483 - val_accuracy: 0.8642 - val_f1_m: 1.0282\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 155us/sample - loss: 0.0187 - accuracy: 0.9940 - f1_m: 0.9648 - val_loss: 0.9727 - val_accuracy: 0.8603 - val_f1_m: 1.0205\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 155us/sample - loss: 0.0173 - accuracy: 0.9938 - f1_m: 0.9634 - val_loss: 0.9660 - val_accuracy: 0.8648 - val_f1_m: 1.0237\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 157us/sample - loss: 0.0098 - accuracy: 0.9968 - f1_m: 0.9559 - val_loss: 0.9949 - val_accuracy: 0.8610 - val_f1_m: 1.0181\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 256us/sample - loss: 0.0737 - accuracy: 0.9853 - f1_m: 0.9676 - val_loss: 0.7470 - val_accuracy: 0.8643 - val_f1_m: 1.0453\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 183us/sample - loss: 0.0290 - accuracy: 0.9911 - f1_m: 0.9636 - val_loss: 0.8866 - val_accuracy: 0.8642 - val_f1_m: 1.0274\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 182us/sample - loss: 0.0127 - accuracy: 0.9960 - f1_m: 0.9583 - val_loss: 1.0332 - val_accuracy: 0.8667 - val_f1_m: 1.0082\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 184us/sample - loss: 0.0091 - accuracy: 0.9973 - f1_m: 0.9541 - val_loss: 1.0537 - val_accuracy: 0.8709 - val_f1_m: 1.0039\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 184us/sample - loss: 0.0293 - accuracy: 0.9904 - f1_m: 0.9644 - val_loss: 1.0473 - val_accuracy: 0.8644 - val_f1_m: 1.0120\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 184us/sample - loss: 0.0140 - accuracy: 0.9965 - f1_m: 0.9572 - val_loss: 1.0660 - val_accuracy: 0.8627 - val_f1_m: 1.0183\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 183us/sample - loss: 0.0057 - accuracy: 0.9984 - f1_m: 0.9527 - val_loss: 1.0844 - val_accuracy: 0.8693 - val_f1_m: 1.0076\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 184us/sample - loss: 0.0243 - accuracy: 0.9920 - f1_m: 0.9607 - val_loss: 1.2807 - val_accuracy: 0.8615 - val_f1_m: 1.0014\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 182us/sample - loss: 0.0425 - accuracy: 0.9871 - f1_m: 0.9661 - val_loss: 1.1475 - val_accuracy: 0.8609 - val_f1_m: 1.0126\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 184us/sample - loss: 0.0029 - accuracy: 0.9993 - f1_m: 0.9494 - val_loss: 1.2297 - val_accuracy: 0.8688 - val_f1_m: 1.0002\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 3s 331us/sample - loss: 0.0792 - accuracy: 0.9791 - f1_m: 0.9911 - val_loss: 0.7474 - val_accuracy: 0.8457 - val_f1_m: 1.0694\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 234us/sample - loss: 0.0353 - accuracy: 0.9893 - f1_m: 0.9739 - val_loss: 0.8453 - val_accuracy: 0.8487 - val_f1_m: 1.0520\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 234us/sample - loss: 0.0356 - accuracy: 0.9881 - f1_m: 0.9702 - val_loss: 1.0505 - val_accuracy: 0.8424 - val_f1_m: 1.0401\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 232us/sample - loss: 0.0403 - accuracy: 0.9878 - f1_m: 0.9725 - val_loss: 0.9026 - val_accuracy: 0.8476 - val_f1_m: 1.0465\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 234us/sample - loss: 0.0432 - accuracy: 0.9849 - f1_m: 0.9760 - val_loss: 0.9822 - val_accuracy: 0.8407 - val_f1_m: 1.0437\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 234us/sample - loss: 0.0418 - accuracy: 0.9858 - f1_m: 0.9767 - val_loss: 1.1846 - val_accuracy: 0.8329 - val_f1_m: 1.0335\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 232us/sample - loss: 0.0667 - accuracy: 0.9784 - f1_m: 0.9866 - val_loss: 1.0116 - val_accuracy: 0.8441 - val_f1_m: 1.0259\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 233us/sample - loss: 0.0070 - accuracy: 0.9982 - f1_m: 0.9566 - val_loss: 1.1983 - val_accuracy: 0.8527 - val_f1_m: 1.0120\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 232us/sample - loss: 0.0384 - accuracy: 0.9866 - f1_m: 0.9686 - val_loss: 1.1222 - val_accuracy: 0.8379 - val_f1_m: 1.0255\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 233us/sample - loss: 0.0345 - accuracy: 0.9875 - f1_m: 0.9716 - val_loss: 1.1134 - val_accuracy: 0.8448 - val_f1_m: 1.0353\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 182us/sample - loss: 0.1562 - accuracy: 0.9468 - f1_m: 1.0914 - val_loss: 0.6252 - val_accuracy: 0.8384 - val_f1_m: 1.1476\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.1404 - accuracy: 0.9553 - f1_m: 1.0936 - val_loss: 0.6464 - val_accuracy: 0.8349 - val_f1_m: 1.1442\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.1409 - accuracy: 0.9520 - f1_m: 1.0902 - val_loss: 0.6167 - val_accuracy: 0.8395 - val_f1_m: 1.1389\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 131us/sample - loss: 0.1412 - accuracy: 0.9526 - f1_m: 1.0975 - val_loss: 0.6758 - val_accuracy: 0.8235 - val_f1_m: 1.1315\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 131us/sample - loss: 0.1407 - accuracy: 0.9531 - f1_m: 1.0928 - val_loss: 0.6318 - val_accuracy: 0.8376 - val_f1_m: 1.1328\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.1283 - accuracy: 0.9560 - f1_m: 1.0868 - val_loss: 0.6692 - val_accuracy: 0.8355 - val_f1_m: 1.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 130us/sample - loss: 0.1293 - accuracy: 0.9574 - f1_m: 1.0820 - val_loss: 0.6608 - val_accuracy: 0.8343 - val_f1_m: 1.1331\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.1224 - accuracy: 0.9618 - f1_m: 1.0864 - val_loss: 0.6460 - val_accuracy: 0.8352 - val_f1_m: 1.1181\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 130us/sample - loss: 0.1272 - accuracy: 0.9586 - f1_m: 1.0825 - val_loss: 0.7120 - val_accuracy: 0.8257 - val_f1_m: 1.1442\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.1222 - accuracy: 0.9594 - f1_m: 1.0812 - val_loss: 0.6628 - val_accuracy: 0.8387 - val_f1_m: 1.1300\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 197us/sample - loss: 0.1078 - accuracy: 0.9671 - f1_m: 1.0273 - val_loss: 0.7679 - val_accuracy: 0.8572 - val_f1_m: 1.0703\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 142us/sample - loss: 0.0958 - accuracy: 0.9682 - f1_m: 1.0270 - val_loss: 0.7451 - val_accuracy: 0.8529 - val_f1_m: 1.0711\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 142us/sample - loss: 0.0955 - accuracy: 0.9682 - f1_m: 1.0309 - val_loss: 0.7797 - val_accuracy: 0.8542 - val_f1_m: 1.0653\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 141us/sample - loss: 0.0860 - accuracy: 0.9716 - f1_m: 1.0225 - val_loss: 0.8056 - val_accuracy: 0.8443 - val_f1_m: 1.0811\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 141us/sample - loss: 0.0943 - accuracy: 0.9680 - f1_m: 1.0319 - val_loss: 0.7501 - val_accuracy: 0.8601 - val_f1_m: 1.0751\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 142us/sample - loss: 0.0747 - accuracy: 0.9734 - f1_m: 1.0273 - val_loss: 0.7899 - val_accuracy: 0.8583 - val_f1_m: 1.0628\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 142us/sample - loss: 0.0787 - accuracy: 0.9736 - f1_m: 1.0216 - val_loss: 0.7928 - val_accuracy: 0.8527 - val_f1_m: 1.0635\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 149us/sample - loss: 0.0706 - accuracy: 0.9762 - f1_m: 1.0183 - val_loss: 0.8128 - val_accuracy: 0.8534 - val_f1_m: 1.0547\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 141us/sample - loss: 0.0730 - accuracy: 0.9748 - f1_m: 1.0172 - val_loss: 0.7938 - val_accuracy: 0.8643 - val_f1_m: 1.0694\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 142us/sample - loss: 0.0659 - accuracy: 0.9766 - f1_m: 1.0192 - val_loss: 0.8036 - val_accuracy: 0.8573 - val_f1_m: 1.0662\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 4s 402us/sample - loss: 0.0914 - accuracy: 0.9720 - f1_m: 0.9959 - val_loss: 0.9257 - val_accuracy: 0.8454 - val_f1_m: 1.0547\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 170us/sample - loss: 0.0629 - accuracy: 0.9806 - f1_m: 0.9964 - val_loss: 0.9746 - val_accuracy: 0.8420 - val_f1_m: 1.0560\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 168us/sample - loss: 0.0629 - accuracy: 0.9798 - f1_m: 0.9974 - val_loss: 0.9900 - val_accuracy: 0.8385 - val_f1_m: 1.0425\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 171us/sample - loss: 0.0568 - accuracy: 0.9812 - f1_m: 0.9947 - val_loss: 1.0206 - val_accuracy: 0.8438 - val_f1_m: 1.0375\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 169us/sample - loss: 0.0534 - accuracy: 0.9814 - f1_m: 0.9925 - val_loss: 0.9511 - val_accuracy: 0.8461 - val_f1_m: 1.0455\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 170us/sample - loss: 0.0509 - accuracy: 0.9819 - f1_m: 0.9923 - val_loss: 1.0146 - val_accuracy: 0.8525 - val_f1_m: 1.0474\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 169us/sample - loss: 0.0442 - accuracy: 0.9846 - f1_m: 0.9877 - val_loss: 1.0647 - val_accuracy: 0.8527 - val_f1_m: 1.0337\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 170us/sample - loss: 0.0443 - accuracy: 0.9851 - f1_m: 0.9855 - val_loss: 1.0411 - val_accuracy: 0.8465 - val_f1_m: 1.0463\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 170us/sample - loss: 0.0391 - accuracy: 0.9847 - f1_m: 0.9866 - val_loss: 1.0886 - val_accuracy: 0.8532 - val_f1_m: 1.0376\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 169us/sample - loss: 0.0427 - accuracy: 0.9839 - f1_m: 0.9835 - val_loss: 1.1123 - val_accuracy: 0.8513 - val_f1_m: 1.0268\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 306us/sample - loss: 0.1059 - accuracy: 0.9644 - f1_m: 1.0198 - val_loss: 0.6913 - val_accuracy: 0.8425 - val_f1_m: 1.1067\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 212us/sample - loss: 0.0931 - accuracy: 0.9686 - f1_m: 1.0206 - val_loss: 0.7905 - val_accuracy: 0.8385 - val_f1_m: 1.0843\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 212us/sample - loss: 0.0968 - accuracy: 0.9662 - f1_m: 1.0256 - val_loss: 0.7300 - val_accuracy: 0.8488 - val_f1_m: 1.0832\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 211us/sample - loss: 0.0774 - accuracy: 0.9723 - f1_m: 1.0173 - val_loss: 0.9579 - val_accuracy: 0.8407 - val_f1_m: 1.0434\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 213us/sample - loss: 0.0757 - accuracy: 0.9729 - f1_m: 1.0118 - val_loss: 0.7657 - val_accuracy: 0.8494 - val_f1_m: 1.0719\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 213us/sample - loss: 0.0726 - accuracy: 0.9736 - f1_m: 1.0097 - val_loss: 0.8716 - val_accuracy: 0.8438 - val_f1_m: 1.0611\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 211us/sample - loss: 0.0879 - accuracy: 0.9684 - f1_m: 1.0147 - val_loss: 0.8896 - val_accuracy: 0.8426 - val_f1_m: 1.0543\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 212us/sample - loss: 0.0813 - accuracy: 0.9710 - f1_m: 1.0132 - val_loss: 0.8243 - val_accuracy: 0.8413 - val_f1_m: 1.0691\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 213us/sample - loss: 0.0726 - accuracy: 0.9751 - f1_m: 1.0052 - val_loss: 0.8574 - val_accuracy: 0.8359 - val_f1_m: 1.0716\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 211us/sample - loss: 0.0803 - accuracy: 0.9708 - f1_m: 1.0098 - val_loss: 0.8793 - val_accuracy: 0.8400 - val_f1_m: 1.0720\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 183us/sample - loss: 0.0518 - accuracy: 0.9898 - f1_m: 0.9670 - val_loss: 0.8475 - val_accuracy: 0.8569 - val_f1_m: 1.0345\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.0282 - accuracy: 0.9924 - f1_m: 0.9656 - val_loss: 0.9239 - val_accuracy: 0.8532 - val_f1_m: 1.0346\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 133us/sample - loss: 0.0206 - accuracy: 0.9941 - f1_m: 0.9632 - val_loss: 0.8514 - val_accuracy: 0.8576 - val_f1_m: 1.0450\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.0273 - accuracy: 0.9924 - f1_m: 0.9652 - val_loss: 0.8470 - val_accuracy: 0.8652 - val_f1_m: 1.0370\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 133us/sample - loss: 0.0112 - accuracy: 0.9978 - f1_m: 0.9576 - val_loss: 0.8640 - val_accuracy: 0.8602 - val_f1_m: 1.0339\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 132us/sample - loss: 0.0062 - accuracy: 0.9987 - f1_m: 0.9514 - val_loss: 0.8810 - val_accuracy: 0.8643 - val_f1_m: 1.0257\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 133us/sample - loss: 0.0047 - accuracy: 0.9996 - f1_m: 0.9489 - val_loss: 0.8840 - val_accuracy: 0.8659 - val_f1_m: 1.0281\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 130us/sample - loss: 0.0035 - accuracy: 0.9994 - f1_m: 0.9482 - val_loss: 0.8720 - val_accuracy: 0.8641 - val_f1_m: 1.0309\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 133us/sample - loss: 0.0052 - accuracy: 0.9989 - f1_m: 0.9515 - val_loss: 0.8995 - val_accuracy: 0.8646 - val_f1_m: 1.0313\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 131us/sample - loss: 0.0027 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.8998 - val_accuracy: 0.8634 - val_f1_m: 1.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 208us/sample - loss: 0.0416 - accuracy: 0.9879 - f1_m: 0.9664 - val_loss: 0.9951 - val_accuracy: 0.8597 - val_f1_m: 1.0143\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 152us/sample - loss: 0.0198 - accuracy: 0.9937 - f1_m: 0.9592 - val_loss: 0.9577 - val_accuracy: 0.8612 - val_f1_m: 1.0183\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0173 - accuracy: 0.9953 - f1_m: 0.9589 - val_loss: 0.9328 - val_accuracy: 0.8580 - val_f1_m: 1.0265\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0057 - accuracy: 0.9983 - f1_m: 0.9525 - val_loss: 0.9527 - val_accuracy: 0.8642 - val_f1_m: 1.0185\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0047 - accuracy: 0.9990 - f1_m: 0.9480 - val_loss: 0.9634 - val_accuracy: 0.8627 - val_f1_m: 1.0206\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 153us/sample - loss: 0.0189 - accuracy: 0.9934 - f1_m: 0.9589 - val_loss: 1.0945 - val_accuracy: 0.8595 - val_f1_m: 1.0275\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 152us/sample - loss: 0.0218 - accuracy: 0.9926 - f1_m: 0.9612 - val_loss: 1.0471 - val_accuracy: 0.8648 - val_f1_m: 1.0055\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 152us/sample - loss: 0.0095 - accuracy: 0.9970 - f1_m: 0.9547 - val_loss: 1.0346 - val_accuracy: 0.8622 - val_f1_m: 1.0182\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 152us/sample - loss: 0.0017 - accuracy: 0.9997 - f1_m: 0.9473 - val_loss: 1.0224 - val_accuracy: 0.8664 - val_f1_m: 1.0151\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 152us/sample - loss: 7.0355e-04 - accuracy: 1.0000 - f1_m: 0.9457 - val_loss: 1.0533 - val_accuracy: 0.8675 - val_f1_m: 1.0101\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 252us/sample - loss: 0.0520 - accuracy: 0.9886 - f1_m: 0.9614 - val_loss: 0.9006 - val_accuracy: 0.8617 - val_f1_m: 1.0296\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 179us/sample - loss: 0.0161 - accuracy: 0.9954 - f1_m: 0.9566 - val_loss: 1.0707 - val_accuracy: 0.8652 - val_f1_m: 1.0087\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 181us/sample - loss: 0.0157 - accuracy: 0.9951 - f1_m: 0.9558 - val_loss: 1.0412 - val_accuracy: 0.8654 - val_f1_m: 1.0182\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 181us/sample - loss: 0.0101 - accuracy: 0.9977 - f1_m: 0.9510 - val_loss: 1.1902 - val_accuracy: 0.8649 - val_f1_m: 1.0072\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 181us/sample - loss: 0.0142 - accuracy: 0.9951 - f1_m: 0.9558 - val_loss: 1.1680 - val_accuracy: 0.8683 - val_f1_m: 1.0057\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 181us/sample - loss: 0.0379 - accuracy: 0.9887 - f1_m: 0.9613 - val_loss: 1.1182 - val_accuracy: 0.8611 - val_f1_m: 1.0130\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 181us/sample - loss: 0.0170 - accuracy: 0.9943 - f1_m: 0.9578 - val_loss: 1.0581 - val_accuracy: 0.8710 - val_f1_m: 1.0118\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 181us/sample - loss: 0.0062 - accuracy: 0.9979 - f1_m: 0.9515 - val_loss: 1.1553 - val_accuracy: 0.8676 - val_f1_m: 1.0059\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 180us/sample - loss: 0.0045 - accuracy: 0.9990 - f1_m: 0.9493 - val_loss: 1.2346 - val_accuracy: 0.8627 - val_f1_m: 1.0062\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 179us/sample - loss: 0.0293 - accuracy: 0.9909 - f1_m: 0.9609 - val_loss: 1.0110 - val_accuracy: 0.8619 - val_f1_m: 1.0206\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 322us/sample - loss: 0.0859 - accuracy: 0.9803 - f1_m: 0.9822 - val_loss: 0.7541 - val_accuracy: 0.8551 - val_f1_m: 1.0604\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 230us/sample - loss: 0.0345 - accuracy: 0.9911 - f1_m: 0.9694 - val_loss: 0.8801 - val_accuracy: 0.8444 - val_f1_m: 1.0396\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 229us/sample - loss: 0.0213 - accuracy: 0.9916 - f1_m: 0.9624 - val_loss: 1.1385 - val_accuracy: 0.8392 - val_f1_m: 1.0295\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 230us/sample - loss: 0.0464 - accuracy: 0.9851 - f1_m: 0.9748 - val_loss: 0.9878 - val_accuracy: 0.8401 - val_f1_m: 1.0401\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 230us/sample - loss: 0.0380 - accuracy: 0.9881 - f1_m: 0.9724 - val_loss: 0.9507 - val_accuracy: 0.8435 - val_f1_m: 1.0342\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 229us/sample - loss: 0.0218 - accuracy: 0.9917 - f1_m: 0.9638 - val_loss: 1.0712 - val_accuracy: 0.8493 - val_f1_m: 1.0289\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 230us/sample - loss: 0.0452 - accuracy: 0.9843 - f1_m: 0.9717 - val_loss: 1.0679 - val_accuracy: 0.8372 - val_f1_m: 1.0364\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 229us/sample - loss: 0.0352 - accuracy: 0.9887 - f1_m: 0.9726 - val_loss: 1.1132 - val_accuracy: 0.8421 - val_f1_m: 1.0299\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 231us/sample - loss: 0.0433 - accuracy: 0.9861 - f1_m: 0.9711 - val_loss: 1.0196 - val_accuracy: 0.8460 - val_f1_m: 1.0400\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 229us/sample - loss: 0.0334 - accuracy: 0.9886 - f1_m: 0.9691 - val_loss: 1.0731 - val_accuracy: 0.8453 - val_f1_m: 1.0298\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 179us/sample - loss: 0.1426 - accuracy: 0.9547 - f1_m: 1.0795 - val_loss: 0.6785 - val_accuracy: 0.8337 - val_f1_m: 1.1267\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 131us/sample - loss: 0.1397 - accuracy: 0.9554 - f1_m: 1.0819 - val_loss: 0.6534 - val_accuracy: 0.8361 - val_f1_m: 1.1369\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 127us/sample - loss: 0.1268 - accuracy: 0.9609 - f1_m: 1.0729 - val_loss: 0.6775 - val_accuracy: 0.8351 - val_f1_m: 1.1426\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 128us/sample - loss: 0.1307 - accuracy: 0.9577 - f1_m: 1.0802 - val_loss: 0.6661 - val_accuracy: 0.8369 - val_f1_m: 1.1189\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 129us/sample - loss: 0.1241 - accuracy: 0.9600 - f1_m: 1.0730 - val_loss: 0.6695 - val_accuracy: 0.8377 - val_f1_m: 1.1188\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 128us/sample - loss: 0.1224 - accuracy: 0.9602 - f1_m: 1.0762 - val_loss: 0.6688 - val_accuracy: 0.8400 - val_f1_m: 1.1186\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 127us/sample - loss: 0.1229 - accuracy: 0.9574 - f1_m: 1.0709 - val_loss: 0.6789 - val_accuracy: 0.8388 - val_f1_m: 1.1207\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 129us/sample - loss: 0.1157 - accuracy: 0.9620 - f1_m: 1.0709 - val_loss: 0.6807 - val_accuracy: 0.8405 - val_f1_m: 1.1122\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 129us/sample - loss: 0.1111 - accuracy: 0.9620 - f1_m: 1.0711 - val_loss: 0.6970 - val_accuracy: 0.8388 - val_f1_m: 1.1099\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 130us/sample - loss: 0.1138 - accuracy: 0.9608 - f1_m: 1.0702 - val_loss: 0.6877 - val_accuracy: 0.8370 - val_f1_m: 1.1225\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 193us/sample - loss: 0.1080 - accuracy: 0.9657 - f1_m: 1.0247 - val_loss: 0.8192 - val_accuracy: 0.8520 - val_f1_m: 1.0662\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 140us/sample - loss: 0.0972 - accuracy: 0.9693 - f1_m: 1.0273 - val_loss: 0.8299 - val_accuracy: 0.8559 - val_f1_m: 1.0727\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 0.0880 - accuracy: 0.9708 - f1_m: 1.0225 - val_loss: 0.8446 - val_accuracy: 0.8496 - val_f1_m: 1.0754\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 141us/sample - loss: 0.0807 - accuracy: 0.9757 - f1_m: 1.0176 - val_loss: 0.7981 - val_accuracy: 0.8618 - val_f1_m: 1.0613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 139us/sample - loss: 0.0874 - accuracy: 0.9713 - f1_m: 1.0220 - val_loss: 0.8085 - val_accuracy: 0.8583 - val_f1_m: 1.0588\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 139us/sample - loss: 0.0762 - accuracy: 0.9723 - f1_m: 1.0224 - val_loss: 0.8246 - val_accuracy: 0.8596 - val_f1_m: 1.0655\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 141us/sample - loss: 0.0692 - accuracy: 0.9765 - f1_m: 1.0175 - val_loss: 0.8153 - val_accuracy: 0.8548 - val_f1_m: 1.0529\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 139us/sample - loss: 0.0720 - accuracy: 0.9758 - f1_m: 1.0177 - val_loss: 0.8534 - val_accuracy: 0.8535 - val_f1_m: 1.0661\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 140us/sample - loss: 0.0665 - accuracy: 0.9776 - f1_m: 1.0144 - val_loss: 0.8392 - val_accuracy: 0.8563 - val_f1_m: 1.0608\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 0.0684 - accuracy: 0.9760 - f1_m: 1.0140 - val_loss: 0.8323 - val_accuracy: 0.8599 - val_f1_m: 1.0551\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 231us/sample - loss: 0.0928 - accuracy: 0.9771 - f1_m: 0.9964 - val_loss: 1.0212 - val_accuracy: 0.8409 - val_f1_m: 1.0548\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 166us/sample - loss: 0.0711 - accuracy: 0.9787 - f1_m: 0.9979 - val_loss: 0.9711 - val_accuracy: 0.8511 - val_f1_m: 1.0409\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 164us/sample - loss: 0.0630 - accuracy: 0.9831 - f1_m: 0.9875 - val_loss: 0.9640 - val_accuracy: 0.8401 - val_f1_m: 1.0467\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 166us/sample - loss: 0.0517 - accuracy: 0.9855 - f1_m: 0.9924 - val_loss: 0.9459 - val_accuracy: 0.8474 - val_f1_m: 1.0439\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 164us/sample - loss: 0.0536 - accuracy: 0.9819 - f1_m: 0.9948 - val_loss: 1.0171 - val_accuracy: 0.8468 - val_f1_m: 1.0485\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 165us/sample - loss: 0.0505 - accuracy: 0.9831 - f1_m: 0.9891 - val_loss: 1.0186 - val_accuracy: 0.8536 - val_f1_m: 1.0296\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 164us/sample - loss: 0.0391 - accuracy: 0.9873 - f1_m: 0.9820 - val_loss: 1.1103 - val_accuracy: 0.8481 - val_f1_m: 1.0296\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 165us/sample - loss: 0.0465 - accuracy: 0.9832 - f1_m: 0.9879 - val_loss: 1.0694 - val_accuracy: 0.8520 - val_f1_m: 1.0402\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 165us/sample - loss: 0.0541 - accuracy: 0.9819 - f1_m: 0.9916 - val_loss: 1.0978 - val_accuracy: 0.8430 - val_f1_m: 1.0448\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 163us/sample - loss: 0.0510 - accuracy: 0.9831 - f1_m: 0.9929 - val_loss: 1.0789 - val_accuracy: 0.8499 - val_f1_m: 1.0282\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 3s 296us/sample - loss: 0.1087 - accuracy: 0.9659 - f1_m: 1.0229 - val_loss: 0.7544 - val_accuracy: 0.8440 - val_f1_m: 1.0904\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0966 - accuracy: 0.9659 - f1_m: 1.0208 - val_loss: 0.8317 - val_accuracy: 0.8436 - val_f1_m: 1.0664\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0959 - accuracy: 0.9686 - f1_m: 1.0178 - val_loss: 0.7418 - val_accuracy: 0.8436 - val_f1_m: 1.0934\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 207us/sample - loss: 0.0757 - accuracy: 0.9743 - f1_m: 1.0148 - val_loss: 0.7899 - val_accuracy: 0.8452 - val_f1_m: 1.0848\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0835 - accuracy: 0.9709 - f1_m: 1.0143 - val_loss: 0.7901 - val_accuracy: 0.8358 - val_f1_m: 1.0916\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0757 - accuracy: 0.9733 - f1_m: 1.0073 - val_loss: 0.8758 - val_accuracy: 0.8463 - val_f1_m: 1.0658\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0678 - accuracy: 0.9748 - f1_m: 1.0079 - val_loss: 0.8460 - val_accuracy: 0.8311 - val_f1_m: 1.0956\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0815 - accuracy: 0.9706 - f1_m: 1.0081 - val_loss: 0.9311 - val_accuracy: 0.8432 - val_f1_m: 1.0558\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0817 - accuracy: 0.9713 - f1_m: 1.0128 - val_loss: 0.9080 - val_accuracy: 0.8406 - val_f1_m: 1.0618\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 208us/sample - loss: 0.0835 - accuracy: 0.9705 - f1_m: 1.0087 - val_loss: 0.9536 - val_accuracy: 0.8406 - val_f1_m: 1.0460\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 176us/sample - loss: 0.0546 - accuracy: 0.9897 - f1_m: 0.9643 - val_loss: 0.8983 - val_accuracy: 0.8569 - val_f1_m: 1.0411\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 128us/sample - loss: 0.0343 - accuracy: 0.9915 - f1_m: 0.9661 - val_loss: 0.8776 - val_accuracy: 0.8647 - val_f1_m: 1.0349\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 129us/sample - loss: 0.0175 - accuracy: 0.9954 - f1_m: 0.9601 - val_loss: 0.9174 - val_accuracy: 0.8596 - val_f1_m: 1.0304\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 128us/sample - loss: 0.0125 - accuracy: 0.9965 - f1_m: 0.9570 - val_loss: 0.8822 - val_accuracy: 0.8573 - val_f1_m: 1.0376\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 127us/sample - loss: 0.0081 - accuracy: 0.9981 - f1_m: 0.9536 - val_loss: 0.8690 - val_accuracy: 0.8660 - val_f1_m: 1.0321\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 129us/sample - loss: 0.0072 - accuracy: 0.9983 - f1_m: 0.9543 - val_loss: 0.8860 - val_accuracy: 0.8661 - val_f1_m: 1.0293\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 127us/sample - loss: 0.0063 - accuracy: 0.9982 - f1_m: 0.9540 - val_loss: 0.9299 - val_accuracy: 0.8615 - val_f1_m: 1.0249\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 129us/sample - loss: 0.0031 - accuracy: 0.9998 - f1_m: 0.9490 - val_loss: 0.9361 - val_accuracy: 0.8677 - val_f1_m: 1.0195\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 126us/sample - loss: 0.0015 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.9425 - val_accuracy: 0.8705 - val_f1_m: 1.0221\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - f1_m: 0.9465 - val_loss: 0.9428 - val_accuracy: 0.8675 - val_f1_m: 1.0226\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 198us/sample - loss: 0.0559 - accuracy: 0.9889 - f1_m: 0.9622 - val_loss: 0.8912 - val_accuracy: 0.8604 - val_f1_m: 1.0358\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 149us/sample - loss: 0.0220 - accuracy: 0.9947 - f1_m: 0.9578 - val_loss: 0.8717 - val_accuracy: 0.8678 - val_f1_m: 1.0200\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 148us/sample - loss: 0.0158 - accuracy: 0.9957 - f1_m: 0.9587 - val_loss: 0.9801 - val_accuracy: 0.8613 - val_f1_m: 1.0252\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 148us/sample - loss: 0.0076 - accuracy: 0.9984 - f1_m: 0.9520 - val_loss: 0.9466 - val_accuracy: 0.8670 - val_f1_m: 1.0165\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 148us/sample - loss: 0.0076 - accuracy: 0.9983 - f1_m: 0.9520 - val_loss: 1.0104 - val_accuracy: 0.8662 - val_f1_m: 1.0118\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 146us/sample - loss: 0.0121 - accuracy: 0.9961 - f1_m: 0.9569 - val_loss: 1.0468 - val_accuracy: 0.8568 - val_f1_m: 1.0250\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 148us/sample - loss: 0.0338 - accuracy: 0.9883 - f1_m: 0.9670 - val_loss: 1.0064 - val_accuracy: 0.8625 - val_f1_m: 1.0119\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 148us/sample - loss: 0.0118 - accuracy: 0.9962 - f1_m: 0.9570 - val_loss: 0.9424 - val_accuracy: 0.8666 - val_f1_m: 1.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 147us/sample - loss: 0.0019 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 0.9924 - val_accuracy: 0.8671 - val_f1_m: 1.0059\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 147us/sample - loss: 6.5034e-04 - accuracy: 1.0000 - f1_m: 0.9457 - val_loss: 1.0195 - val_accuracy: 0.8691 - val_f1_m: 1.0034\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 242us/sample - loss: 0.0587 - accuracy: 0.9880 - f1_m: 0.9674 - val_loss: 0.7826 - val_accuracy: 0.8680 - val_f1_m: 1.0443\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 176us/sample - loss: 0.0219 - accuracy: 0.9938 - f1_m: 0.9599 - val_loss: 0.9610 - val_accuracy: 0.8704 - val_f1_m: 1.0127\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 175us/sample - loss: 0.0103 - accuracy: 0.9964 - f1_m: 0.9542 - val_loss: 1.0144 - val_accuracy: 0.8708 - val_f1_m: 1.0095\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 175us/sample - loss: 0.0138 - accuracy: 0.9958 - f1_m: 0.9548 - val_loss: 1.1176 - val_accuracy: 0.8687 - val_f1_m: 1.0100\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 175us/sample - loss: 0.0193 - accuracy: 0.9944 - f1_m: 0.9581 - val_loss: 1.0346 - val_accuracy: 0.8627 - val_f1_m: 1.0136\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 175us/sample - loss: 0.0163 - accuracy: 0.9937 - f1_m: 0.9576 - val_loss: 1.2031 - val_accuracy: 0.8649 - val_f1_m: 1.0038\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 175us/sample - loss: 0.0136 - accuracy: 0.9956 - f1_m: 0.9551 - val_loss: 1.2024 - val_accuracy: 0.8695 - val_f1_m: 1.0032\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 174us/sample - loss: 0.0170 - accuracy: 0.9939 - f1_m: 0.9539 - val_loss: 1.1998 - val_accuracy: 0.8641 - val_f1_m: 1.0026\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 175us/sample - loss: 0.0189 - accuracy: 0.9933 - f1_m: 0.9562 - val_loss: 1.1409 - val_accuracy: 0.8699 - val_f1_m: 1.0044\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 176us/sample - loss: 0.0148 - accuracy: 0.9951 - f1_m: 0.9559 - val_loss: 1.1671 - val_accuracy: 0.8694 - val_f1_m: 1.0020\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 3s 314us/sample - loss: 0.0697 - accuracy: 0.9818 - f1_m: 0.9769 - val_loss: 0.7526 - val_accuracy: 0.8480 - val_f1_m: 1.0673\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 225us/sample - loss: 0.0294 - accuracy: 0.9905 - f1_m: 0.9700 - val_loss: 0.9713 - val_accuracy: 0.8562 - val_f1_m: 1.0362\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 225us/sample - loss: 0.0416 - accuracy: 0.9856 - f1_m: 0.9698 - val_loss: 0.9698 - val_accuracy: 0.8452 - val_f1_m: 1.0331\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 224us/sample - loss: 0.0346 - accuracy: 0.9891 - f1_m: 0.9728 - val_loss: 1.2700 - val_accuracy: 0.8508 - val_f1_m: 1.0177\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 225us/sample - loss: 0.0313 - accuracy: 0.9900 - f1_m: 0.9673 - val_loss: 1.1718 - val_accuracy: 0.8523 - val_f1_m: 1.0215\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0485 - accuracy: 0.9831 - f1_m: 0.9768 - val_loss: 0.9507 - val_accuracy: 0.8538 - val_f1_m: 1.0388\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0271 - accuracy: 0.9913 - f1_m: 0.9632 - val_loss: 1.2433 - val_accuracy: 0.8486 - val_f1_m: 1.0202\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0645 - accuracy: 0.9791 - f1_m: 0.9787 - val_loss: 0.9278 - val_accuracy: 0.8451 - val_f1_m: 1.0517\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 225us/sample - loss: 0.0289 - accuracy: 0.9893 - f1_m: 0.9664 - val_loss: 1.0315 - val_accuracy: 0.8428 - val_f1_m: 1.0349\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0298 - accuracy: 0.9904 - f1_m: 0.9648 - val_loss: 1.0885 - val_accuracy: 0.8518 - val_f1_m: 1.0242\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 174us/sample - loss: 0.1328 - accuracy: 0.9566 - f1_m: 1.0729 - val_loss: 0.6922 - val_accuracy: 0.8396 - val_f1_m: 1.1216\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 128us/sample - loss: 0.1230 - accuracy: 0.9602 - f1_m: 1.0677 - val_loss: 0.7022 - val_accuracy: 0.8413 - val_f1_m: 1.1106\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.1169 - accuracy: 0.9600 - f1_m: 1.0676 - val_loss: 0.7338 - val_accuracy: 0.8329 - val_f1_m: 1.1086\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 126us/sample - loss: 0.1144 - accuracy: 0.9625 - f1_m: 1.0643 - val_loss: 0.6975 - val_accuracy: 0.8396 - val_f1_m: 1.1174\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 127us/sample - loss: 0.1091 - accuracy: 0.9653 - f1_m: 1.0637 - val_loss: 0.7111 - val_accuracy: 0.8383 - val_f1_m: 1.1102\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.1172 - accuracy: 0.9603 - f1_m: 1.0653 - val_loss: 0.7030 - val_accuracy: 0.8434 - val_f1_m: 1.1132\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 126us/sample - loss: 0.1084 - accuracy: 0.9658 - f1_m: 1.0666 - val_loss: 0.7551 - val_accuracy: 0.8315 - val_f1_m: 1.1051\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 127us/sample - loss: 0.1051 - accuracy: 0.9652 - f1_m: 1.0633 - val_loss: 0.7587 - val_accuracy: 0.8333 - val_f1_m: 1.1153\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 127us/sample - loss: 0.1071 - accuracy: 0.9631 - f1_m: 1.0666 - val_loss: 0.7546 - val_accuracy: 0.8378 - val_f1_m: 1.1139\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 126us/sample - loss: 0.1012 - accuracy: 0.9670 - f1_m: 1.0600 - val_loss: 0.7308 - val_accuracy: 0.8437 - val_f1_m: 1.0973\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 188us/sample - loss: 0.1008 - accuracy: 0.9676 - f1_m: 1.0250 - val_loss: 0.8161 - val_accuracy: 0.8616 - val_f1_m: 1.0504\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 138us/sample - loss: 0.0813 - accuracy: 0.9735 - f1_m: 1.0185 - val_loss: 0.8495 - val_accuracy: 0.8566 - val_f1_m: 1.0625\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 137us/sample - loss: 0.0804 - accuracy: 0.9728 - f1_m: 1.0187 - val_loss: 0.8379 - val_accuracy: 0.8533 - val_f1_m: 1.0535\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 138us/sample - loss: 0.0726 - accuracy: 0.9762 - f1_m: 1.0170 - val_loss: 0.8445 - val_accuracy: 0.8576 - val_f1_m: 1.0525\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 138us/sample - loss: 0.0693 - accuracy: 0.9766 - f1_m: 1.0129 - val_loss: 0.8822 - val_accuracy: 0.8581 - val_f1_m: 1.0526\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 138us/sample - loss: 0.0703 - accuracy: 0.9753 - f1_m: 1.0101 - val_loss: 0.8926 - val_accuracy: 0.8594 - val_f1_m: 1.0505\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 138us/sample - loss: 0.0628 - accuracy: 0.9774 - f1_m: 1.0115 - val_loss: 0.8662 - val_accuracy: 0.8556 - val_f1_m: 1.0541\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 137us/sample - loss: 0.0659 - accuracy: 0.9754 - f1_m: 1.0117 - val_loss: 0.8728 - val_accuracy: 0.8570 - val_f1_m: 1.0604\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 137us/sample - loss: 0.0602 - accuracy: 0.9792 - f1_m: 1.0131 - val_loss: 0.9071 - val_accuracy: 0.8612 - val_f1_m: 1.0433\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 138us/sample - loss: 0.0699 - accuracy: 0.9745 - f1_m: 1.0138 - val_loss: 0.9341 - val_accuracy: 0.8495 - val_f1_m: 1.0524\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.0749 - accuracy: 0.9785 - f1_m: 0.9948 - val_loss: 1.0286 - val_accuracy: 0.8432 - val_f1_m: 1.0427\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 162us/sample - loss: 0.0545 - accuracy: 0.9848 - f1_m: 0.9875 - val_loss: 1.0233 - val_accuracy: 0.8433 - val_f1_m: 1.0482\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 163us/sample - loss: 0.0494 - accuracy: 0.9834 - f1_m: 0.9881 - val_loss: 1.0502 - val_accuracy: 0.8458 - val_f1_m: 1.0384\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 163us/sample - loss: 0.0431 - accuracy: 0.9859 - f1_m: 0.9851 - val_loss: 1.0004 - val_accuracy: 0.8451 - val_f1_m: 1.0429\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 163us/sample - loss: 0.0396 - accuracy: 0.9872 - f1_m: 0.9837 - val_loss: 1.1303 - val_accuracy: 0.8540 - val_f1_m: 1.0297\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 162us/sample - loss: 0.0577 - accuracy: 0.9789 - f1_m: 0.9917 - val_loss: 1.1108 - val_accuracy: 0.8465 - val_f1_m: 1.0260\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 163us/sample - loss: 0.0529 - accuracy: 0.9817 - f1_m: 0.9887 - val_loss: 1.1320 - val_accuracy: 0.8469 - val_f1_m: 1.0200\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 163us/sample - loss: 0.0453 - accuracy: 0.9843 - f1_m: 0.9840 - val_loss: 1.0696 - val_accuracy: 0.8521 - val_f1_m: 1.0354\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 164us/sample - loss: 0.0309 - accuracy: 0.9899 - f1_m: 0.9763 - val_loss: 1.2085 - val_accuracy: 0.8453 - val_f1_m: 1.0360\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 162us/sample - loss: 0.0349 - accuracy: 0.9863 - f1_m: 0.9804 - val_loss: 1.2191 - val_accuracy: 0.8536 - val_f1_m: 1.0173\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 3s 288us/sample - loss: 0.1018 - accuracy: 0.9661 - f1_m: 1.0141 - val_loss: 0.7906 - val_accuracy: 0.8460 - val_f1_m: 1.0694\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.0801 - accuracy: 0.9732 - f1_m: 1.0131 - val_loss: 0.8554 - val_accuracy: 0.8408 - val_f1_m: 1.0653\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 206us/sample - loss: 0.0878 - accuracy: 0.9707 - f1_m: 1.0159 - val_loss: 0.8391 - val_accuracy: 0.8377 - val_f1_m: 1.0766\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.0846 - accuracy: 0.9714 - f1_m: 1.0168 - val_loss: 0.8159 - val_accuracy: 0.8460 - val_f1_m: 1.0663\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.0799 - accuracy: 0.9727 - f1_m: 1.0102 - val_loss: 0.8541 - val_accuracy: 0.8458 - val_f1_m: 1.0677\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.0637 - accuracy: 0.9767 - f1_m: 1.0031 - val_loss: 0.8435 - val_accuracy: 0.8450 - val_f1_m: 1.0637\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.0730 - accuracy: 0.9730 - f1_m: 1.0043 - val_loss: 0.9142 - val_accuracy: 0.8358 - val_f1_m: 1.0537\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.0779 - accuracy: 0.9716 - f1_m: 1.0088 - val_loss: 0.8869 - val_accuracy: 0.8518 - val_f1_m: 1.0551\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.0774 - accuracy: 0.9724 - f1_m: 1.0031 - val_loss: 0.8337 - val_accuracy: 0.8358 - val_f1_m: 1.0749\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.0787 - accuracy: 0.9717 - f1_m: 1.0123 - val_loss: 0.8626 - val_accuracy: 0.8437 - val_f1_m: 1.0596\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0431 - accuracy: 0.9912 - f1_m: 0.9667 - val_loss: 0.9218 - val_accuracy: 0.8628 - val_f1_m: 1.0394\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 127us/sample - loss: 0.0217 - accuracy: 0.9956 - f1_m: 0.9635 - val_loss: 0.9309 - val_accuracy: 0.8605 - val_f1_m: 1.0348\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0131 - accuracy: 0.9970 - f1_m: 0.9580 - val_loss: 0.9209 - val_accuracy: 0.8570 - val_f1_m: 1.0312\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0118 - accuracy: 0.9973 - f1_m: 0.9583 - val_loss: 0.9411 - val_accuracy: 0.8637 - val_f1_m: 1.0213\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0082 - accuracy: 0.9976 - f1_m: 0.9558 - val_loss: 0.9806 - val_accuracy: 0.8637 - val_f1_m: 1.0233\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 127us/sample - loss: 0.0065 - accuracy: 0.9981 - f1_m: 0.9554 - val_loss: 0.9714 - val_accuracy: 0.8607 - val_f1_m: 1.0275\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0063 - accuracy: 0.9985 - f1_m: 0.9524 - val_loss: 0.9621 - val_accuracy: 0.8640 - val_f1_m: 1.0239\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 127us/sample - loss: 0.0024 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.9734 - val_accuracy: 0.8666 - val_f1_m: 1.0195\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0012 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 1.0025 - val_accuracy: 0.8687 - val_f1_m: 1.0185\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 127us/sample - loss: 0.0011 - accuracy: 1.0000 - f1_m: 0.9464 - val_loss: 0.9919 - val_accuracy: 0.8646 - val_f1_m: 1.0204\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 193us/sample - loss: 0.0408 - accuracy: 0.9923 - f1_m: 0.9612 - val_loss: 0.9539 - val_accuracy: 0.8627 - val_f1_m: 1.0206\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 145us/sample - loss: 0.0215 - accuracy: 0.9941 - f1_m: 0.9605 - val_loss: 0.9382 - val_accuracy: 0.8671 - val_f1_m: 1.0274\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 143us/sample - loss: 0.0130 - accuracy: 0.9965 - f1_m: 0.9569 - val_loss: 1.0942 - val_accuracy: 0.8557 - val_f1_m: 1.0110\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 145us/sample - loss: 0.0123 - accuracy: 0.9960 - f1_m: 0.9579 - val_loss: 1.0156 - val_accuracy: 0.8589 - val_f1_m: 1.0195\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 0.0170 - accuracy: 0.9946 - f1_m: 0.9577 - val_loss: 1.0230 - val_accuracy: 0.8654 - val_f1_m: 1.0144\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 0.0067 - accuracy: 0.9977 - f1_m: 0.9511 - val_loss: 1.0370 - val_accuracy: 0.8646 - val_f1_m: 1.0068\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 143us/sample - loss: 0.0010 - accuracy: 0.9999 - f1_m: 0.9468 - val_loss: 1.0656 - val_accuracy: 0.8680 - val_f1_m: 1.0048\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 145us/sample - loss: 5.3589e-04 - accuracy: 1.0000 - f1_m: 0.9459 - val_loss: 1.0782 - val_accuracy: 0.8679 - val_f1_m: 1.0071\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 2.5655e-04 - accuracy: 1.0000 - f1_m: 0.9458 - val_loss: 1.0934 - val_accuracy: 0.8686 - val_f1_m: 1.0056\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 1.9909e-04 - accuracy: 1.0000 - f1_m: 0.9458 - val_loss: 1.1035 - val_accuracy: 0.8682 - val_f1_m: 1.0033\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 236us/sample - loss: 0.0482 - accuracy: 0.9903 - f1_m: 0.9621 - val_loss: 1.0135 - val_accuracy: 0.8700 - val_f1_m: 1.0115\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0123 - accuracy: 0.9968 - f1_m: 0.9548 - val_loss: 1.0374 - val_accuracy: 0.8701 - val_f1_m: 1.0149\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0101 - accuracy: 0.9969 - f1_m: 0.9548 - val_loss: 1.1065 - val_accuracy: 0.8693 - val_f1_m: 1.0037\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0168 - accuracy: 0.9943 - f1_m: 0.9561 - val_loss: 1.2428 - val_accuracy: 0.8566 - val_f1_m: 1.0130\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 171us/sample - loss: 0.0236 - accuracy: 0.9919 - f1_m: 0.9595 - val_loss: 1.0603 - val_accuracy: 0.8670 - val_f1_m: 1.0080\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0211 - accuracy: 0.9935 - f1_m: 0.9578 - val_loss: 1.2624 - val_accuracy: 0.8676 - val_f1_m: 1.0017\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 173us/sample - loss: 0.0157 - accuracy: 0.9943 - f1_m: 0.9574 - val_loss: 1.3078 - val_accuracy: 0.8661 - val_f1_m: 0.9972\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 174us/sample - loss: 0.0124 - accuracy: 0.9964 - f1_m: 0.9540 - val_loss: 1.2338 - val_accuracy: 0.8585 - val_f1_m: 1.0070\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 173us/sample - loss: 0.0120 - accuracy: 0.9961 - f1_m: 0.9533 - val_loss: 1.3290 - val_accuracy: 0.8671 - val_f1_m: 1.0008\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0092 - accuracy: 0.9971 - f1_m: 0.9510 - val_loss: 1.2979 - val_accuracy: 0.8612 - val_f1_m: 1.0039\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 3s 304us/sample - loss: 0.0687 - accuracy: 0.9819 - f1_m: 0.9766 - val_loss: 0.8868 - val_accuracy: 0.8519 - val_f1_m: 1.0508\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.0323 - accuracy: 0.9910 - f1_m: 0.9697 - val_loss: 0.8862 - val_accuracy: 0.8523 - val_f1_m: 1.0439\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 222us/sample - loss: 0.0270 - accuracy: 0.9909 - f1_m: 0.9636 - val_loss: 0.9369 - val_accuracy: 0.8510 - val_f1_m: 1.0352\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.0370 - accuracy: 0.9877 - f1_m: 0.9723 - val_loss: 1.1022 - val_accuracy: 0.8476 - val_f1_m: 1.0293\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.0374 - accuracy: 0.9879 - f1_m: 0.9688 - val_loss: 1.0468 - val_accuracy: 0.8509 - val_f1_m: 1.0312\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.0416 - accuracy: 0.9859 - f1_m: 0.9712 - val_loss: 0.9961 - val_accuracy: 0.8528 - val_f1_m: 1.0334\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 220us/sample - loss: 0.0395 - accuracy: 0.9864 - f1_m: 0.9722 - val_loss: 1.1666 - val_accuracy: 0.8483 - val_f1_m: 1.0225\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.0343 - accuracy: 0.9890 - f1_m: 0.9669 - val_loss: 1.0295 - val_accuracy: 0.8515 - val_f1_m: 1.0315\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 220us/sample - loss: 0.0174 - accuracy: 0.9939 - f1_m: 0.9622 - val_loss: 1.2812 - val_accuracy: 0.8483 - val_f1_m: 1.0133\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.0319 - accuracy: 0.9899 - f1_m: 0.9638 - val_loss: 1.1101 - val_accuracy: 0.8361 - val_f1_m: 1.0442\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 165us/sample - loss: 0.1335 - accuracy: 0.9596 - f1_m: 1.0668 - val_loss: 0.7396 - val_accuracy: 0.8409 - val_f1_m: 1.1132\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 1s 119us/sample - loss: 0.1192 - accuracy: 0.9632 - f1_m: 1.0630 - val_loss: 0.7521 - val_accuracy: 0.8361 - val_f1_m: 1.0988\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.1229 - accuracy: 0.9609 - f1_m: 1.0639 - val_loss: 0.7310 - val_accuracy: 0.8399 - val_f1_m: 1.1037\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 1s 121us/sample - loss: 0.1182 - accuracy: 0.9611 - f1_m: 1.0663 - val_loss: 0.7439 - val_accuracy: 0.8463 - val_f1_m: 1.0966\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 1s 119us/sample - loss: 0.1100 - accuracy: 0.9619 - f1_m: 1.0642 - val_loss: 0.7340 - val_accuracy: 0.8447 - val_f1_m: 1.0958\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.1078 - accuracy: 0.9656 - f1_m: 1.0584 - val_loss: 0.7870 - val_accuracy: 0.8376 - val_f1_m: 1.1031\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 1s 121us/sample - loss: 0.1080 - accuracy: 0.9631 - f1_m: 1.0603 - val_loss: 0.8032 - val_accuracy: 0.8356 - val_f1_m: 1.1011\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.1031 - accuracy: 0.9671 - f1_m: 1.0604 - val_loss: 0.7762 - val_accuracy: 0.8367 - val_f1_m: 1.1029\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 1s 119us/sample - loss: 0.1014 - accuracy: 0.9661 - f1_m: 1.0570 - val_loss: 0.7685 - val_accuracy: 0.8413 - val_f1_m: 1.0872\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 1s 119us/sample - loss: 0.1002 - accuracy: 0.9666 - f1_m: 1.0591 - val_loss: 0.8047 - val_accuracy: 0.8398 - val_f1_m: 1.0972\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 179us/sample - loss: 0.1026 - accuracy: 0.9705 - f1_m: 1.0163 - val_loss: 0.8759 - val_accuracy: 0.8603 - val_f1_m: 1.0485\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 1s 131us/sample - loss: 0.0880 - accuracy: 0.9738 - f1_m: 1.0154 - val_loss: 0.9021 - val_accuracy: 0.8544 - val_f1_m: 1.0561\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 1s 131us/sample - loss: 0.0848 - accuracy: 0.9730 - f1_m: 1.0136 - val_loss: 0.8913 - val_accuracy: 0.8569 - val_f1_m: 1.0480\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 1s 130us/sample - loss: 0.0744 - accuracy: 0.9759 - f1_m: 1.0100 - val_loss: 0.8842 - val_accuracy: 0.8552 - val_f1_m: 1.0492\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 1s 134us/sample - loss: 0.0768 - accuracy: 0.9743 - f1_m: 1.0172 - val_loss: 0.9375 - val_accuracy: 0.8464 - val_f1_m: 1.0457\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 1s 130us/sample - loss: 0.0665 - accuracy: 0.9768 - f1_m: 1.0086 - val_loss: 0.9185 - val_accuracy: 0.8564 - val_f1_m: 1.0580\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 1s 132us/sample - loss: 0.0624 - accuracy: 0.9785 - f1_m: 1.0087 - val_loss: 0.8755 - val_accuracy: 0.8505 - val_f1_m: 1.0543\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 1s 130us/sample - loss: 0.0693 - accuracy: 0.9753 - f1_m: 1.0126 - val_loss: 0.9000 - val_accuracy: 0.8544 - val_f1_m: 1.0480\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 1s 131us/sample - loss: 0.0604 - accuracy: 0.9790 - f1_m: 1.0045 - val_loss: 0.8823 - val_accuracy: 0.8560 - val_f1_m: 1.0617\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 1s 131us/sample - loss: 0.0582 - accuracy: 0.9796 - f1_m: 1.0075 - val_loss: 1.0241 - val_accuracy: 0.8409 - val_f1_m: 1.0552\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 219us/sample - loss: 0.0955 - accuracy: 0.9782 - f1_m: 0.9923 - val_loss: 1.0841 - val_accuracy: 0.8427 - val_f1_m: 1.0442\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 157us/sample - loss: 0.0635 - accuracy: 0.9832 - f1_m: 0.9903 - val_loss: 0.9859 - val_accuracy: 0.8474 - val_f1_m: 1.0460\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 157us/sample - loss: 0.0533 - accuracy: 0.9848 - f1_m: 0.9885 - val_loss: 0.9952 - val_accuracy: 0.8488 - val_f1_m: 1.0397\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 157us/sample - loss: 0.0485 - accuracy: 0.9834 - f1_m: 0.9891 - val_loss: 1.0829 - val_accuracy: 0.8476 - val_f1_m: 1.0383\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 155us/sample - loss: 0.0544 - accuracy: 0.9820 - f1_m: 0.9900 - val_loss: 1.1049 - val_accuracy: 0.8456 - val_f1_m: 1.0330\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 158us/sample - loss: 0.0396 - accuracy: 0.9863 - f1_m: 0.9856 - val_loss: 1.1585 - val_accuracy: 0.8467 - val_f1_m: 1.0365\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 156us/sample - loss: 0.0522 - accuracy: 0.9825 - f1_m: 0.9825 - val_loss: 1.1113 - val_accuracy: 0.8427 - val_f1_m: 1.0467\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 2s 155us/sample - loss: 0.0359 - accuracy: 0.9877 - f1_m: 0.9819 - val_loss: 1.1393 - val_accuracy: 0.8499 - val_f1_m: 1.0336\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 157us/sample - loss: 0.0481 - accuracy: 0.9842 - f1_m: 0.9853 - val_loss: 1.1902 - val_accuracy: 0.8387 - val_f1_m: 1.0447\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 156us/sample - loss: 0.0446 - accuracy: 0.9845 - f1_m: 0.9835 - val_loss: 1.1443 - val_accuracy: 0.8496 - val_f1_m: 1.0280\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 3s 275us/sample - loss: 0.1032 - accuracy: 0.9679 - f1_m: 1.0140 - val_loss: 0.7936 - val_accuracy: 0.8508 - val_f1_m: 1.0664\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 198us/sample - loss: 0.0905 - accuracy: 0.9690 - f1_m: 1.0078 - val_loss: 0.7918 - val_accuracy: 0.8442 - val_f1_m: 1.0809\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 197us/sample - loss: 0.0842 - accuracy: 0.9706 - f1_m: 1.0122 - val_loss: 0.8061 - val_accuracy: 0.8460 - val_f1_m: 1.0694\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 197us/sample - loss: 0.0805 - accuracy: 0.9729 - f1_m: 1.0107 - val_loss: 0.7901 - val_accuracy: 0.8537 - val_f1_m: 1.0592\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 197us/sample - loss: 0.0684 - accuracy: 0.9757 - f1_m: 1.0054 - val_loss: 0.8924 - val_accuracy: 0.8499 - val_f1_m: 1.0491\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 197us/sample - loss: 0.0943 - accuracy: 0.9673 - f1_m: 1.0080 - val_loss: 0.8499 - val_accuracy: 0.8521 - val_f1_m: 1.0695\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 197us/sample - loss: 0.0804 - accuracy: 0.9712 - f1_m: 1.0056 - val_loss: 0.7951 - val_accuracy: 0.8557 - val_f1_m: 1.0629\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 197us/sample - loss: 0.0574 - accuracy: 0.9802 - f1_m: 0.9986 - val_loss: 0.9374 - val_accuracy: 0.8475 - val_f1_m: 1.0453\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 196us/sample - loss: 0.0592 - accuracy: 0.9787 - f1_m: 0.9986 - val_loss: 0.8841 - val_accuracy: 0.8462 - val_f1_m: 1.0553\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 196us/sample - loss: 0.0754 - accuracy: 0.9736 - f1_m: 1.0056 - val_loss: 0.9322 - val_accuracy: 0.8486 - val_f1_m: 1.0436\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 165us/sample - loss: 0.0539 - accuracy: 0.9891 - f1_m: 0.9651 - val_loss: 0.9664 - val_accuracy: 0.8633 - val_f1_m: 1.0308\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.0278 - accuracy: 0.9938 - f1_m: 0.9631 - val_loss: 0.9644 - val_accuracy: 0.8603 - val_f1_m: 1.0294\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 1s 122us/sample - loss: 0.0161 - accuracy: 0.9966 - f1_m: 0.9573 - val_loss: 0.9657 - val_accuracy: 0.8596 - val_f1_m: 1.0243\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 1s 119us/sample - loss: 0.0095 - accuracy: 0.9978 - f1_m: 0.9564 - val_loss: 0.9926 - val_accuracy: 0.8598 - val_f1_m: 1.0306\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 1s 121us/sample - loss: 0.0167 - accuracy: 0.9959 - f1_m: 0.9600 - val_loss: 0.9907 - val_accuracy: 0.8598 - val_f1_m: 1.0244\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.0061 - accuracy: 0.9987 - f1_m: 0.9532 - val_loss: 1.0257 - val_accuracy: 0.8632 - val_f1_m: 1.0199\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.0134 - accuracy: 0.9954 - f1_m: 0.9589 - val_loss: 1.0332 - val_accuracy: 0.8662 - val_f1_m: 1.0209\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.0067 - accuracy: 0.9988 - f1_m: 0.9555 - val_loss: 1.0223 - val_accuracy: 0.8621 - val_f1_m: 1.0199\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 1s 119us/sample - loss: 0.0086 - accuracy: 0.9977 - f1_m: 0.9543 - val_loss: 1.0268 - val_accuracy: 0.8645 - val_f1_m: 1.0220\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 1s 120us/sample - loss: 0.0022 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 1.0342 - val_accuracy: 0.8669 - val_f1_m: 1.0193\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 187us/sample - loss: 0.0470 - accuracy: 0.9900 - f1_m: 0.9604 - val_loss: 0.9957 - val_accuracy: 0.8624 - val_f1_m: 1.0230\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 1s 139us/sample - loss: 0.0233 - accuracy: 0.9939 - f1_m: 0.9593 - val_loss: 0.9766 - val_accuracy: 0.8665 - val_f1_m: 1.0143\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 1s 139us/sample - loss: 0.0149 - accuracy: 0.9953 - f1_m: 0.9588 - val_loss: 0.9782 - val_accuracy: 0.8694 - val_f1_m: 1.0114\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 1s 138us/sample - loss: 0.0073 - accuracy: 0.9977 - f1_m: 0.9531 - val_loss: 1.0490 - val_accuracy: 0.8647 - val_f1_m: 1.0105\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 1s 140us/sample - loss: 0.0038 - accuracy: 0.9990 - f1_m: 0.9511 - val_loss: 1.0520 - val_accuracy: 0.8661 - val_f1_m: 1.0061\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 1s 138us/sample - loss: 0.0027 - accuracy: 0.9992 - f1_m: 0.9483 - val_loss: 1.0904 - val_accuracy: 0.8658 - val_f1_m: 1.0111\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 1s 139us/sample - loss: 5.9906e-04 - accuracy: 1.0000 - f1_m: 0.9457 - val_loss: 1.0673 - val_accuracy: 0.8656 - val_f1_m: 1.0027\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 1s 140us/sample - loss: 2.7874e-04 - accuracy: 1.0000 - f1_m: 0.9460 - val_loss: 1.0892 - val_accuracy: 0.8669 - val_f1_m: 0.9997\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 1s 139us/sample - loss: 2.0610e-04 - accuracy: 1.0000 - f1_m: 0.9459 - val_loss: 1.1108 - val_accuracy: 0.8688 - val_f1_m: 0.9999\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 1s 139us/sample - loss: 1.6858e-04 - accuracy: 1.0000 - f1_m: 0.9458 - val_loss: 1.1285 - val_accuracy: 0.8688 - val_f1_m: 0.9989\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 226us/sample - loss: 0.0595 - accuracy: 0.9887 - f1_m: 0.9630 - val_loss: 0.9459 - val_accuracy: 0.8583 - val_f1_m: 1.0375\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 168us/sample - loss: 0.0185 - accuracy: 0.9947 - f1_m: 0.9573 - val_loss: 1.0260 - val_accuracy: 0.8692 - val_f1_m: 1.0154\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 167us/sample - loss: 0.0056 - accuracy: 0.9985 - f1_m: 0.9528 - val_loss: 1.1496 - val_accuracy: 0.8657 - val_f1_m: 1.0051\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 168us/sample - loss: 0.0135 - accuracy: 0.9950 - f1_m: 0.9546 - val_loss: 1.1688 - val_accuracy: 0.8641 - val_f1_m: 1.0035\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 169us/sample - loss: 0.0269 - accuracy: 0.9914 - f1_m: 0.9611 - val_loss: 1.1517 - val_accuracy: 0.8643 - val_f1_m: 1.0152\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 167us/sample - loss: 0.0073 - accuracy: 0.9979 - f1_m: 0.9526 - val_loss: 1.1725 - val_accuracy: 0.8680 - val_f1_m: 1.0040\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 168us/sample - loss: 0.0172 - accuracy: 0.9947 - f1_m: 0.9552 - val_loss: 1.1856 - val_accuracy: 0.8620 - val_f1_m: 1.0065\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 165us/sample - loss: 0.0212 - accuracy: 0.9930 - f1_m: 0.9566 - val_loss: 1.1941 - val_accuracy: 0.8654 - val_f1_m: 1.0100\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 168us/sample - loss: 0.0099 - accuracy: 0.9963 - f1_m: 0.9530 - val_loss: 1.2167 - val_accuracy: 0.8658 - val_f1_m: 1.0000\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 168us/sample - loss: 0.0076 - accuracy: 0.9976 - f1_m: 0.9513 - val_loss: 1.4147 - val_accuracy: 0.8626 - val_f1_m: 0.9972\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 3s 294us/sample - loss: 0.0629 - accuracy: 0.9839 - f1_m: 0.9770 - val_loss: 0.9054 - val_accuracy: 0.8501 - val_f1_m: 1.0484\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 213us/sample - loss: 0.0441 - accuracy: 0.9860 - f1_m: 0.9738 - val_loss: 0.9061 - val_accuracy: 0.8477 - val_f1_m: 1.0438\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 215us/sample - loss: 0.0192 - accuracy: 0.9937 - f1_m: 0.9632 - val_loss: 1.1393 - val_accuracy: 0.8464 - val_f1_m: 1.0220\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 214us/sample - loss: 0.0274 - accuracy: 0.9902 - f1_m: 0.9641 - val_loss: 1.2535 - val_accuracy: 0.8382 - val_f1_m: 1.0264\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 214us/sample - loss: 0.0541 - accuracy: 0.9825 - f1_m: 0.9749 - val_loss: 0.9763 - val_accuracy: 0.8347 - val_f1_m: 1.0576\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 216us/sample - loss: 0.0328 - accuracy: 0.9891 - f1_m: 0.9712 - val_loss: 1.0571 - val_accuracy: 0.8488 - val_f1_m: 1.0263\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 213us/sample - loss: 0.0148 - accuracy: 0.9961 - f1_m: 0.9558 - val_loss: 1.1903 - val_accuracy: 0.8459 - val_f1_m: 1.0203\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 229us/sample - loss: 0.0568 - accuracy: 0.9802 - f1_m: 0.9744 - val_loss: 0.9824 - val_accuracy: 0.8467 - val_f1_m: 1.0416\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 214us/sample - loss: 0.0205 - accuracy: 0.9936 - f1_m: 0.9635 - val_loss: 1.1937 - val_accuracy: 0.8447 - val_f1_m: 1.0195\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 213us/sample - loss: 0.0288 - accuracy: 0.9897 - f1_m: 0.9624 - val_loss: 1.2129 - val_accuracy: 0.8515 - val_f1_m: 1.0110\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 158us/sample - loss: 0.1318 - accuracy: 0.9596 - f1_m: 1.0576 - val_loss: 0.8079 - val_accuracy: 0.8383 - val_f1_m: 1.0927\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.1245 - accuracy: 0.9609 - f1_m: 1.0582 - val_loss: 0.7672 - val_accuracy: 0.8428 - val_f1_m: 1.0856\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 1s 115us/sample - loss: 0.1167 - accuracy: 0.9602 - f1_m: 1.0605 - val_loss: 0.8069 - val_accuracy: 0.8332 - val_f1_m: 1.0962\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 1s 118us/sample - loss: 0.1097 - accuracy: 0.9645 - f1_m: 1.0591 - val_loss: 0.8063 - val_accuracy: 0.8376 - val_f1_m: 1.0829\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 1s 115us/sample - loss: 0.1048 - accuracy: 0.9667 - f1_m: 1.0544 - val_loss: 0.7962 - val_accuracy: 0.8376 - val_f1_m: 1.0967\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.1061 - accuracy: 0.9658 - f1_m: 1.0571 - val_loss: 0.7976 - val_accuracy: 0.8393 - val_f1_m: 1.0923\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 1s 117us/sample - loss: 0.1046 - accuracy: 0.9669 - f1_m: 1.0597 - val_loss: 0.8345 - val_accuracy: 0.8396 - val_f1_m: 1.0976\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 1s 115us/sample - loss: 0.1049 - accuracy: 0.9654 - f1_m: 1.0577 - val_loss: 0.7983 - val_accuracy: 0.8419 - val_f1_m: 1.0917\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.1002 - accuracy: 0.9656 - f1_m: 1.0526 - val_loss: 0.8333 - val_accuracy: 0.8391 - val_f1_m: 1.0749\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.0969 - accuracy: 0.9680 - f1_m: 1.0547 - val_loss: 0.8214 - val_accuracy: 0.8472 - val_f1_m: 1.0982\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 175us/sample - loss: 0.1006 - accuracy: 0.9714 - f1_m: 1.0113 - val_loss: 0.9034 - val_accuracy: 0.8548 - val_f1_m: 1.0549\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 1s 127us/sample - loss: 0.0874 - accuracy: 0.9724 - f1_m: 1.0163 - val_loss: 0.9118 - val_accuracy: 0.8620 - val_f1_m: 1.0515\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 1s 127us/sample - loss: 0.0788 - accuracy: 0.9750 - f1_m: 1.0122 - val_loss: 0.9156 - val_accuracy: 0.8542 - val_f1_m: 1.0552\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 1s 127us/sample - loss: 0.0740 - accuracy: 0.9757 - f1_m: 1.0140 - val_loss: 0.9017 - val_accuracy: 0.8532 - val_f1_m: 1.0437\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 1s 126us/sample - loss: 0.0709 - accuracy: 0.9765 - f1_m: 1.0095 - val_loss: 0.9440 - val_accuracy: 0.8522 - val_f1_m: 1.0450\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 1s 128us/sample - loss: 0.0682 - accuracy: 0.9767 - f1_m: 1.0111 - val_loss: 0.9040 - val_accuracy: 0.8552 - val_f1_m: 1.0562\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 1s 128us/sample - loss: 0.0672 - accuracy: 0.9761 - f1_m: 1.0116 - val_loss: 0.9448 - val_accuracy: 0.8532 - val_f1_m: 1.0447\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 1s 128us/sample - loss: 0.0615 - accuracy: 0.9792 - f1_m: 1.0072 - val_loss: 0.9248 - val_accuracy: 0.8560 - val_f1_m: 1.0477\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 1s 128us/sample - loss: 0.0709 - accuracy: 0.9754 - f1_m: 1.0080 - val_loss: 0.9630 - val_accuracy: 0.8557 - val_f1_m: 1.0493\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 1s 127us/sample - loss: 0.0640 - accuracy: 0.9778 - f1_m: 1.0060 - val_loss: 0.9086 - val_accuracy: 0.8574 - val_f1_m: 1.0390\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 210us/sample - loss: 0.0946 - accuracy: 0.9769 - f1_m: 0.9940 - val_loss: 0.9969 - val_accuracy: 0.8434 - val_f1_m: 1.0435\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 153us/sample - loss: 0.0643 - accuracy: 0.9812 - f1_m: 0.9944 - val_loss: 1.0215 - val_accuracy: 0.8539 - val_f1_m: 1.0414\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 152us/sample - loss: 0.0478 - accuracy: 0.9867 - f1_m: 0.9866 - val_loss: 1.0243 - val_accuracy: 0.8490 - val_f1_m: 1.0392\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 151us/sample - loss: 0.0489 - accuracy: 0.9832 - f1_m: 0.9866 - val_loss: 1.0289 - val_accuracy: 0.8536 - val_f1_m: 1.0299\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 153us/sample - loss: 0.0536 - accuracy: 0.9841 - f1_m: 0.9898 - val_loss: 1.0004 - val_accuracy: 0.8511 - val_f1_m: 1.0317\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 153us/sample - loss: 0.0465 - accuracy: 0.9842 - f1_m: 0.9882 - val_loss: 1.0382 - val_accuracy: 0.8564 - val_f1_m: 1.0288\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 152us/sample - loss: 0.0418 - accuracy: 0.9845 - f1_m: 0.9847 - val_loss: 1.0508 - val_accuracy: 0.8504 - val_f1_m: 1.0372\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 153us/sample - loss: 0.0480 - accuracy: 0.9835 - f1_m: 0.9844 - val_loss: 1.1293 - val_accuracy: 0.8472 - val_f1_m: 1.0321\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 151us/sample - loss: 0.0425 - accuracy: 0.9849 - f1_m: 0.9833 - val_loss: 1.1343 - val_accuracy: 0.8519 - val_f1_m: 1.0286\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 152us/sample - loss: 0.0378 - accuracy: 0.9869 - f1_m: 0.9798 - val_loss: 1.1983 - val_accuracy: 0.8492 - val_f1_m: 1.0210\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 3s 269us/sample - loss: 0.1089 - accuracy: 0.9679 - f1_m: 1.0161 - val_loss: 0.7578 - val_accuracy: 0.8454 - val_f1_m: 1.0740\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 192us/sample - loss: 0.0866 - accuracy: 0.9730 - f1_m: 1.0111 - val_loss: 0.8568 - val_accuracy: 0.8519 - val_f1_m: 1.0573\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 192us/sample - loss: 0.0817 - accuracy: 0.9739 - f1_m: 1.0089 - val_loss: 0.7957 - val_accuracy: 0.8372 - val_f1_m: 1.0744\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000/11000 [==============================] - 2s 192us/sample - loss: 0.0838 - accuracy: 0.9725 - f1_m: 1.0087 - val_loss: 0.8508 - val_accuracy: 0.8504 - val_f1_m: 1.0523\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 203us/sample - loss: 0.0649 - accuracy: 0.9775 - f1_m: 1.0013 - val_loss: 0.8370 - val_accuracy: 0.8508 - val_f1_m: 1.0556\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 194us/sample - loss: 0.0839 - accuracy: 0.9692 - f1_m: 1.0133 - val_loss: 0.7968 - val_accuracy: 0.8486 - val_f1_m: 1.0649\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 195us/sample - loss: 0.0686 - accuracy: 0.9755 - f1_m: 1.0011 - val_loss: 0.9280 - val_accuracy: 0.8533 - val_f1_m: 1.0430\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 192us/sample - loss: 0.0798 - accuracy: 0.9727 - f1_m: 1.0088 - val_loss: 0.8453 - val_accuracy: 0.8519 - val_f1_m: 1.0452\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 192us/sample - loss: 0.0737 - accuracy: 0.9745 - f1_m: 1.0025 - val_loss: 0.8366 - val_accuracy: 0.8423 - val_f1_m: 1.0762\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 192us/sample - loss: 0.0766 - accuracy: 0.9730 - f1_m: 1.0095 - val_loss: 0.7976 - val_accuracy: 0.8426 - val_f1_m: 1.0676\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 159us/sample - loss: 0.0539 - accuracy: 0.9893 - f1_m: 0.9629 - val_loss: 1.0191 - val_accuracy: 0.8617 - val_f1_m: 1.0251\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 1s 117us/sample - loss: 0.0240 - accuracy: 0.9955 - f1_m: 0.9601 - val_loss: 0.9744 - val_accuracy: 0.8650 - val_f1_m: 1.0180\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 1s 115us/sample - loss: 0.0161 - accuracy: 0.9961 - f1_m: 0.9601 - val_loss: 0.9696 - val_accuracy: 0.8727 - val_f1_m: 1.0219\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.0118 - accuracy: 0.9965 - f1_m: 0.9572 - val_loss: 1.0145 - val_accuracy: 0.8618 - val_f1_m: 1.0245\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 1s 115us/sample - loss: 0.0066 - accuracy: 0.9988 - f1_m: 0.9549 - val_loss: 0.9959 - val_accuracy: 0.8679 - val_f1_m: 1.0179\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 1s 115us/sample - loss: 0.0026 - accuracy: 0.9996 - f1_m: 0.9482 - val_loss: 1.0186 - val_accuracy: 0.8712 - val_f1_m: 1.0132\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.0028 - accuracy: 0.9995 - f1_m: 0.9480 - val_loss: 1.0270 - val_accuracy: 0.8639 - val_f1_m: 1.0108\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 1s 115us/sample - loss: 0.0027 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.9902 - val_accuracy: 0.8694 - val_f1_m: 1.0171\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.0019 - accuracy: 0.9997 - f1_m: 0.9481 - val_loss: 0.9984 - val_accuracy: 0.8704 - val_f1_m: 1.0125\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 1s 116us/sample - loss: 0.0011 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 1.0176 - val_accuracy: 0.8713 - val_f1_m: 1.0112\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 179us/sample - loss: 0.0581 - accuracy: 0.9901 - f1_m: 0.9586 - val_loss: 0.9815 - val_accuracy: 0.8609 - val_f1_m: 1.0238\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 136us/sample - loss: 0.0287 - accuracy: 0.9935 - f1_m: 0.9610 - val_loss: 0.9000 - val_accuracy: 0.8698 - val_f1_m: 1.0182\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 0.0144 - accuracy: 0.9957 - f1_m: 0.9560 - val_loss: 0.9722 - val_accuracy: 0.8663 - val_f1_m: 1.0142\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 0.0133 - accuracy: 0.9961 - f1_m: 0.9562 - val_loss: 1.0702 - val_accuracy: 0.8566 - val_f1_m: 1.0176\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 0.0150 - accuracy: 0.9955 - f1_m: 0.9575 - val_loss: 1.0368 - val_accuracy: 0.8647 - val_f1_m: 1.0215\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 1s 136us/sample - loss: 0.0038 - accuracy: 0.9985 - f1_m: 0.9500 - val_loss: 1.0729 - val_accuracy: 0.8606 - val_f1_m: 1.0033\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 1s 134us/sample - loss: 0.0040 - accuracy: 0.9991 - f1_m: 0.9503 - val_loss: 1.0696 - val_accuracy: 0.8698 - val_f1_m: 1.0003\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 0.0014 - accuracy: 0.9998 - f1_m: 0.9478 - val_loss: 1.1001 - val_accuracy: 0.8686 - val_f1_m: 1.0022\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 1s 134us/sample - loss: 4.1817e-04 - accuracy: 1.0000 - f1_m: 0.9463 - val_loss: 1.1075 - val_accuracy: 0.8684 - val_f1_m: 0.9998\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 2.2080e-04 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 1.1207 - val_accuracy: 0.8686 - val_f1_m: 0.9982\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 219us/sample - loss: 0.0614 - accuracy: 0.9886 - f1_m: 0.9588 - val_loss: 0.8930 - val_accuracy: 0.8681 - val_f1_m: 1.0230\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 160us/sample - loss: 0.0159 - accuracy: 0.9954 - f1_m: 0.9570 - val_loss: 0.9733 - val_accuracy: 0.8704 - val_f1_m: 1.0113\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 161us/sample - loss: 0.0074 - accuracy: 0.9977 - f1_m: 0.9525 - val_loss: 1.0556 - val_accuracy: 0.8692 - val_f1_m: 1.0048\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 161us/sample - loss: 0.0027 - accuracy: 0.9991 - f1_m: 0.9492 - val_loss: 1.2091 - val_accuracy: 0.8692 - val_f1_m: 0.9926\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 161us/sample - loss: 0.0011 - accuracy: 0.9995 - f1_m: 0.9476 - val_loss: 1.3205 - val_accuracy: 0.8704 - val_f1_m: 0.9952\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 161us/sample - loss: 0.0431 - accuracy: 0.9901 - f1_m: 0.9612 - val_loss: 1.2001 - val_accuracy: 0.8561 - val_f1_m: 1.0062\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 162us/sample - loss: 0.0281 - accuracy: 0.9905 - f1_m: 0.9639 - val_loss: 1.1217 - val_accuracy: 0.8654 - val_f1_m: 1.0087\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 158us/sample - loss: 0.0084 - accuracy: 0.9968 - f1_m: 0.9529 - val_loss: 1.0695 - val_accuracy: 0.8671 - val_f1_m: 1.0093\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 161us/sample - loss: 0.0040 - accuracy: 0.9984 - f1_m: 0.9507 - val_loss: 1.2273 - val_accuracy: 0.8704 - val_f1_m: 0.9982\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 165us/sample - loss: 0.0034 - accuracy: 0.9984 - f1_m: 0.9493 - val_loss: 1.3588 - val_accuracy: 0.8699 - val_f1_m: 0.9905\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 3s 285us/sample - loss: 0.0685 - accuracy: 0.9822 - f1_m: 0.9766 - val_loss: 0.8924 - val_accuracy: 0.8469 - val_f1_m: 1.0507\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 208us/sample - loss: 0.0344 - accuracy: 0.9898 - f1_m: 0.9691 - val_loss: 1.0286 - val_accuracy: 0.8527 - val_f1_m: 1.0267\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 207us/sample - loss: 0.0412 - accuracy: 0.9856 - f1_m: 0.9711 - val_loss: 0.9987 - val_accuracy: 0.8520 - val_f1_m: 1.0259\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 207us/sample - loss: 0.0414 - accuracy: 0.9857 - f1_m: 0.9708 - val_loss: 1.1242 - val_accuracy: 0.8466 - val_f1_m: 1.0281\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 208us/sample - loss: 0.0281 - accuracy: 0.9899 - f1_m: 0.9646 - val_loss: 1.1263 - val_accuracy: 0.8557 - val_f1_m: 1.0159\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 206us/sample - loss: 0.0471 - accuracy: 0.9845 - f1_m: 0.9724 - val_loss: 1.1310 - val_accuracy: 0.8531 - val_f1_m: 1.0286\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000/11000 [==============================] - 2s 206us/sample - loss: 0.0186 - accuracy: 0.9938 - f1_m: 0.9587 - val_loss: 1.4129 - val_accuracy: 0.8392 - val_f1_m: 1.0170\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 206us/sample - loss: 0.0508 - accuracy: 0.9836 - f1_m: 0.9743 - val_loss: 1.0816 - val_accuracy: 0.8589 - val_f1_m: 1.0203\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 205us/sample - loss: 0.0242 - accuracy: 0.9920 - f1_m: 0.9626 - val_loss: 1.1030 - val_accuracy: 0.8459 - val_f1_m: 1.0277\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 208us/sample - loss: 0.0279 - accuracy: 0.9893 - f1_m: 0.9644 - val_loss: 1.1279 - val_accuracy: 0.8611 - val_f1_m: 1.0281\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 152us/sample - loss: 0.1175 - accuracy: 0.9630 - f1_m: 1.0498 - val_loss: 0.8139 - val_accuracy: 0.8402 - val_f1_m: 1.0882\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 1s 112us/sample - loss: 0.1102 - accuracy: 0.9637 - f1_m: 1.0560 - val_loss: 0.7875 - val_accuracy: 0.8447 - val_f1_m: 1.0904\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 1s 110us/sample - loss: 0.1051 - accuracy: 0.9667 - f1_m: 1.0528 - val_loss: 0.8145 - val_accuracy: 0.8393 - val_f1_m: 1.0966\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 1s 110us/sample - loss: 0.1034 - accuracy: 0.9651 - f1_m: 1.0576 - val_loss: 0.7870 - val_accuracy: 0.8445 - val_f1_m: 1.0834\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 1s 111us/sample - loss: 0.1057 - accuracy: 0.9637 - f1_m: 1.0529 - val_loss: 0.7820 - val_accuracy: 0.8441 - val_f1_m: 1.0867\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 1s 111us/sample - loss: 0.1042 - accuracy: 0.9648 - f1_m: 1.0532 - val_loss: 0.8154 - val_accuracy: 0.8419 - val_f1_m: 1.0865\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 1s 111us/sample - loss: 0.0979 - accuracy: 0.9679 - f1_m: 1.0465 - val_loss: 0.8269 - val_accuracy: 0.8464 - val_f1_m: 1.0879\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 1s 112us/sample - loss: 0.0911 - accuracy: 0.9702 - f1_m: 1.0444 - val_loss: 0.8093 - val_accuracy: 0.8468 - val_f1_m: 1.0800\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 1s 110us/sample - loss: 0.0910 - accuracy: 0.9687 - f1_m: 1.0473 - val_loss: 0.8198 - val_accuracy: 0.8451 - val_f1_m: 1.0804\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 1s 110us/sample - loss: 0.0928 - accuracy: 0.9684 - f1_m: 1.0476 - val_loss: 0.8216 - val_accuracy: 0.8475 - val_f1_m: 1.0740\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 166us/sample - loss: 0.0876 - accuracy: 0.9731 - f1_m: 1.0133 - val_loss: 0.9117 - val_accuracy: 0.8519 - val_f1_m: 1.0494\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 1s 122us/sample - loss: 0.0752 - accuracy: 0.9765 - f1_m: 1.0078 - val_loss: 0.8889 - val_accuracy: 0.8613 - val_f1_m: 1.0555\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 1s 122us/sample - loss: 0.0731 - accuracy: 0.9771 - f1_m: 1.0089 - val_loss: 0.8852 - val_accuracy: 0.8539 - val_f1_m: 1.0555\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 1s 123us/sample - loss: 0.0662 - accuracy: 0.9776 - f1_m: 1.0070 - val_loss: 0.9126 - val_accuracy: 0.8579 - val_f1_m: 1.0501\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 1s 122us/sample - loss: 0.0704 - accuracy: 0.9763 - f1_m: 1.0103 - val_loss: 0.9065 - val_accuracy: 0.8541 - val_f1_m: 1.0515\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 1s 122us/sample - loss: 0.0689 - accuracy: 0.9750 - f1_m: 1.0081 - val_loss: 0.9778 - val_accuracy: 0.8560 - val_f1_m: 1.0445\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 1s 123us/sample - loss: 0.0585 - accuracy: 0.9798 - f1_m: 1.0039 - val_loss: 0.9358 - val_accuracy: 0.8541 - val_f1_m: 1.0445\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 1s 121us/sample - loss: 0.0568 - accuracy: 0.9804 - f1_m: 0.9996 - val_loss: 0.9314 - val_accuracy: 0.8619 - val_f1_m: 1.0407\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 1s 123us/sample - loss: 0.0535 - accuracy: 0.9818 - f1_m: 1.0020 - val_loss: 0.9485 - val_accuracy: 0.8518 - val_f1_m: 1.0434\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 1s 123us/sample - loss: 0.0632 - accuracy: 0.9774 - f1_m: 1.0052 - val_loss: 0.9430 - val_accuracy: 0.8591 - val_f1_m: 1.0417\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0742 - accuracy: 0.9802 - f1_m: 0.9930 - val_loss: 1.0398 - val_accuracy: 0.8494 - val_f1_m: 1.0401\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 148us/sample - loss: 0.0586 - accuracy: 0.9831 - f1_m: 0.9880 - val_loss: 1.0021 - val_accuracy: 0.8487 - val_f1_m: 1.0481\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 155us/sample - loss: 0.0447 - accuracy: 0.9854 - f1_m: 0.9819 - val_loss: 1.0014 - val_accuracy: 0.8512 - val_f1_m: 1.0392\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 149us/sample - loss: 0.0434 - accuracy: 0.9870 - f1_m: 0.9851 - val_loss: 1.1056 - val_accuracy: 0.8471 - val_f1_m: 1.0265\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 148us/sample - loss: 0.0449 - accuracy: 0.9856 - f1_m: 0.9858 - val_loss: 1.1344 - val_accuracy: 0.8479 - val_f1_m: 1.0262\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 148us/sample - loss: 0.0483 - accuracy: 0.9827 - f1_m: 0.9878 - val_loss: 1.1402 - val_accuracy: 0.8509 - val_f1_m: 1.0213\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 146us/sample - loss: 0.0403 - accuracy: 0.9856 - f1_m: 0.9819 - val_loss: 1.1380 - val_accuracy: 0.8468 - val_f1_m: 1.0251\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 148us/sample - loss: 0.0363 - accuracy: 0.9864 - f1_m: 0.9780 - val_loss: 1.2548 - val_accuracy: 0.8489 - val_f1_m: 1.0105\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 146us/sample - loss: 0.0331 - accuracy: 0.9877 - f1_m: 0.9782 - val_loss: 1.1801 - val_accuracy: 0.8471 - val_f1_m: 1.0239\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 146us/sample - loss: 0.0455 - accuracy: 0.9837 - f1_m: 0.9835 - val_loss: 1.2513 - val_accuracy: 0.8460 - val_f1_m: 1.0277\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 3s 260us/sample - loss: 0.1010 - accuracy: 0.9671 - f1_m: 1.0160 - val_loss: 0.8180 - val_accuracy: 0.8486 - val_f1_m: 1.0581\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 186us/sample - loss: 0.0781 - accuracy: 0.9714 - f1_m: 1.0111 - val_loss: 0.8377 - val_accuracy: 0.8491 - val_f1_m: 1.0572\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 187us/sample - loss: 0.0723 - accuracy: 0.9750 - f1_m: 1.0070 - val_loss: 0.8263 - val_accuracy: 0.8462 - val_f1_m: 1.0581\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 189us/sample - loss: 0.0692 - accuracy: 0.9756 - f1_m: 1.0022 - val_loss: 0.8818 - val_accuracy: 0.8451 - val_f1_m: 1.0587\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 187us/sample - loss: 0.0749 - accuracy: 0.9736 - f1_m: 1.0077 - val_loss: 0.8283 - val_accuracy: 0.8468 - val_f1_m: 1.0680\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 188us/sample - loss: 0.0582 - accuracy: 0.9786 - f1_m: 1.0003 - val_loss: 0.8690 - val_accuracy: 0.8472 - val_f1_m: 1.0497\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 187us/sample - loss: 0.0817 - accuracy: 0.9707 - f1_m: 1.0060 - val_loss: 0.9255 - val_accuracy: 0.8386 - val_f1_m: 1.0660\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 186us/sample - loss: 0.0678 - accuracy: 0.9766 - f1_m: 1.0012 - val_loss: 0.9021 - val_accuracy: 0.8541 - val_f1_m: 1.0443\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 188us/sample - loss: 0.0736 - accuracy: 0.9748 - f1_m: 1.0043 - val_loss: 0.8593 - val_accuracy: 0.8506 - val_f1_m: 1.0483\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500/11500 [==============================] - 2s 185us/sample - loss: 0.0641 - accuracy: 0.9784 - f1_m: 0.9958 - val_loss: 0.9514 - val_accuracy: 0.8441 - val_f1_m: 1.0484\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 151us/sample - loss: 0.0433 - accuracy: 0.9919 - f1_m: 0.9617 - val_loss: 1.0175 - val_accuracy: 0.8633 - val_f1_m: 1.0200\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 1s 112us/sample - loss: 0.0207 - accuracy: 0.9950 - f1_m: 0.9601 - val_loss: 1.0135 - val_accuracy: 0.8656 - val_f1_m: 1.0227\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 1s 110us/sample - loss: 0.0143 - accuracy: 0.9963 - f1_m: 0.9575 - val_loss: 1.0219 - val_accuracy: 0.8667 - val_f1_m: 1.0173\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 1s 113us/sample - loss: 0.0053 - accuracy: 0.9987 - f1_m: 0.9520 - val_loss: 1.0089 - val_accuracy: 0.8665 - val_f1_m: 1.0206\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 1s 112us/sample - loss: 0.0021 - accuracy: 0.9999 - f1_m: 0.9486 - val_loss: 1.0042 - val_accuracy: 0.8656 - val_f1_m: 1.0137\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 1s 112us/sample - loss: 0.0054 - accuracy: 0.9986 - f1_m: 0.9517 - val_loss: 0.9967 - val_accuracy: 0.8693 - val_f1_m: 1.0166\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 1s 111us/sample - loss: 0.0140 - accuracy: 0.9957 - f1_m: 0.9599 - val_loss: 1.0561 - val_accuracy: 0.8633 - val_f1_m: 1.0146\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 1s 112us/sample - loss: 0.0128 - accuracy: 0.9960 - f1_m: 0.9582 - val_loss: 1.0175 - val_accuracy: 0.8627 - val_f1_m: 1.0253\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 1s 112us/sample - loss: 0.0065 - accuracy: 0.9981 - f1_m: 0.9540 - val_loss: 1.0743 - val_accuracy: 0.8612 - val_f1_m: 1.0152\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 1s 110us/sample - loss: 0.0090 - accuracy: 0.9974 - f1_m: 0.9560 - val_loss: 1.0607 - val_accuracy: 0.8666 - val_f1_m: 1.0095\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 175us/sample - loss: 0.0446 - accuracy: 0.9915 - f1_m: 0.9601 - val_loss: 1.0116 - val_accuracy: 0.8656 - val_f1_m: 1.0105\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 131us/sample - loss: 0.0188 - accuracy: 0.9941 - f1_m: 0.9576 - val_loss: 0.9928 - val_accuracy: 0.8627 - val_f1_m: 1.0145\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 1s 130us/sample - loss: 0.0112 - accuracy: 0.9969 - f1_m: 0.9535 - val_loss: 1.0189 - val_accuracy: 0.8648 - val_f1_m: 1.0081\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 1s 130us/sample - loss: 0.0115 - accuracy: 0.9964 - f1_m: 0.9568 - val_loss: 1.0880 - val_accuracy: 0.8653 - val_f1_m: 1.0028\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 131us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9499 - val_loss: 1.0404 - val_accuracy: 0.8653 - val_f1_m: 1.0056\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 1s 130us/sample - loss: 9.6891e-04 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 1.0483 - val_accuracy: 0.8688 - val_f1_m: 1.0012\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 1s 130us/sample - loss: 3.0377e-04 - accuracy: 1.0000 - f1_m: 0.9466 - val_loss: 1.0776 - val_accuracy: 0.8688 - val_f1_m: 1.0047\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 1s 129us/sample - loss: 2.1230e-04 - accuracy: 1.0000 - f1_m: 0.9465 - val_loss: 1.0948 - val_accuracy: 0.8706 - val_f1_m: 1.0021\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 131us/sample - loss: 1.7153e-04 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 1.1053 - val_accuracy: 0.8684 - val_f1_m: 1.0031\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 1s 129us/sample - loss: 1.4363e-04 - accuracy: 1.0000 - f1_m: 0.9465 - val_loss: 1.1223 - val_accuracy: 0.8696 - val_f1_m: 1.0005\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 4s 378us/sample - loss: 0.0513 - accuracy: 0.9897 - f1_m: 0.9619 - val_loss: 0.9214 - val_accuracy: 0.8725 - val_f1_m: 1.0194\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 157us/sample - loss: 0.0153 - accuracy: 0.9954 - f1_m: 0.9575 - val_loss: 1.0605 - val_accuracy: 0.8727 - val_f1_m: 1.0053\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 156us/sample - loss: 0.0093 - accuracy: 0.9974 - f1_m: 0.9537 - val_loss: 1.0920 - val_accuracy: 0.8700 - val_f1_m: 1.0025\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 157us/sample - loss: 0.0156 - accuracy: 0.9950 - f1_m: 0.9556 - val_loss: 1.2740 - val_accuracy: 0.8629 - val_f1_m: 0.9999\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 157us/sample - loss: 0.0202 - accuracy: 0.9918 - f1_m: 0.9606 - val_loss: 1.2418 - val_accuracy: 0.8673 - val_f1_m: 1.0026\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 158us/sample - loss: 0.0135 - accuracy: 0.9948 - f1_m: 0.9565 - val_loss: 1.1911 - val_accuracy: 0.8724 - val_f1_m: 1.0031\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 157us/sample - loss: 0.0054 - accuracy: 0.9979 - f1_m: 0.9518 - val_loss: 1.2128 - val_accuracy: 0.8761 - val_f1_m: 0.9941\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 157us/sample - loss: 6.6735e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 1.3095 - val_accuracy: 0.8767 - val_f1_m: 0.9873\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 159us/sample - loss: 0.0184 - accuracy: 0.9944 - f1_m: 0.9552 - val_loss: 1.3073 - val_accuracy: 0.8598 - val_f1_m: 1.0076\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 157us/sample - loss: 0.0368 - accuracy: 0.9897 - f1_m: 0.9615 - val_loss: 1.2989 - val_accuracy: 0.8646 - val_f1_m: 0.9981\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 3s 277us/sample - loss: 0.0620 - accuracy: 0.9853 - f1_m: 0.9744 - val_loss: 0.8788 - val_accuracy: 0.8548 - val_f1_m: 1.0384\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0254 - accuracy: 0.9920 - f1_m: 0.9635 - val_loss: 1.1112 - val_accuracy: 0.8558 - val_f1_m: 1.0150\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0437 - accuracy: 0.9858 - f1_m: 0.9694 - val_loss: 1.0922 - val_accuracy: 0.8486 - val_f1_m: 1.0287\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0340 - accuracy: 0.9890 - f1_m: 0.9692 - val_loss: 1.0603 - val_accuracy: 0.8536 - val_f1_m: 1.0237\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0275 - accuracy: 0.9914 - f1_m: 0.9624 - val_loss: 1.0765 - val_accuracy: 0.8509 - val_f1_m: 1.0215\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0368 - accuracy: 0.9885 - f1_m: 0.9680 - val_loss: 1.1391 - val_accuracy: 0.8447 - val_f1_m: 1.0214\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0406 - accuracy: 0.9881 - f1_m: 0.9681 - val_loss: 1.2070 - val_accuracy: 0.8549 - val_f1_m: 1.0102\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 203us/sample - loss: 0.0168 - accuracy: 0.9950 - f1_m: 0.9593 - val_loss: 1.3683 - val_accuracy: 0.8518 - val_f1_m: 1.0017\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 202us/sample - loss: 0.0424 - accuracy: 0.9870 - f1_m: 0.9720 - val_loss: 1.1721 - val_accuracy: 0.8518 - val_f1_m: 1.0171\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 204us/sample - loss: 0.0393 - accuracy: 0.9872 - f1_m: 0.9654 - val_loss: 1.0966 - val_accuracy: 0.8535 - val_f1_m: 1.0195\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 135us/sample - loss: 0.1190 - accuracy: 0.9647 - f1_m: 1.0523 - val_loss: 0.8213 - val_accuracy: 0.8456 - val_f1_m: 1.0797\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 97us/sample - loss: 0.1118 - accuracy: 0.9637 - f1_m: 1.0527 - val_loss: 0.8233 - val_accuracy: 0.8435 - val_f1_m: 1.0882\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 1s 97us/sample - loss: 0.1071 - accuracy: 0.9652 - f1_m: 1.0472 - val_loss: 0.8143 - val_accuracy: 0.8472 - val_f1_m: 1.0777\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 97us/sample - loss: 0.1049 - accuracy: 0.9653 - f1_m: 1.0522 - val_loss: 0.8322 - val_accuracy: 0.8481 - val_f1_m: 1.0728\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 98us/sample - loss: 0.1024 - accuracy: 0.9653 - f1_m: 1.0501 - val_loss: 0.8145 - val_accuracy: 0.8447 - val_f1_m: 1.0884\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1s 96us/sample - loss: 0.0952 - accuracy: 0.9688 - f1_m: 1.0453 - val_loss: 0.8550 - val_accuracy: 0.8346 - val_f1_m: 1.0892\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 97us/sample - loss: 0.0958 - accuracy: 0.9682 - f1_m: 1.0479 - val_loss: 0.8232 - val_accuracy: 0.8436 - val_f1_m: 1.0701\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 98us/sample - loss: 0.0930 - accuracy: 0.9690 - f1_m: 1.0480 - val_loss: 0.8860 - val_accuracy: 0.8369 - val_f1_m: 1.0790\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 96us/sample - loss: 0.0919 - accuracy: 0.9696 - f1_m: 1.0452 - val_loss: 0.8408 - val_accuracy: 0.8471 - val_f1_m: 1.0708\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1s 97us/sample - loss: 0.0888 - accuracy: 0.9712 - f1_m: 1.0436 - val_loss: 0.8748 - val_accuracy: 0.8389 - val_f1_m: 1.0670\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 148us/sample - loss: 0.0918 - accuracy: 0.9737 - f1_m: 1.0080 - val_loss: 0.9413 - val_accuracy: 0.8631 - val_f1_m: 1.0384\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 108us/sample - loss: 0.0813 - accuracy: 0.9773 - f1_m: 1.0075 - val_loss: 0.9538 - val_accuracy: 0.8560 - val_f1_m: 1.0443\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1s 108us/sample - loss: 0.0746 - accuracy: 0.9773 - f1_m: 1.0056 - val_loss: 0.9431 - val_accuracy: 0.8599 - val_f1_m: 1.0459\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 108us/sample - loss: 0.0698 - accuracy: 0.9781 - f1_m: 1.0028 - val_loss: 0.9028 - val_accuracy: 0.8587 - val_f1_m: 1.0505\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 107us/sample - loss: 0.0685 - accuracy: 0.9775 - f1_m: 1.0026 - val_loss: 0.8935 - val_accuracy: 0.8584 - val_f1_m: 1.0449\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1s 107us/sample - loss: 0.0644 - accuracy: 0.9797 - f1_m: 1.0021 - val_loss: 0.9817 - val_accuracy: 0.8524 - val_f1_m: 1.0528\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 107us/sample - loss: 0.0680 - accuracy: 0.9766 - f1_m: 1.0038 - val_loss: 0.9200 - val_accuracy: 0.8575 - val_f1_m: 1.0366\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 107us/sample - loss: 0.0567 - accuracy: 0.9817 - f1_m: 1.0033 - val_loss: 0.8991 - val_accuracy: 0.8597 - val_f1_m: 1.0483\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 107us/sample - loss: 0.0527 - accuracy: 0.9818 - f1_m: 0.9985 - val_loss: 0.9553 - val_accuracy: 0.8585 - val_f1_m: 1.0399\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1s 108us/sample - loss: 0.0584 - accuracy: 0.9787 - f1_m: 1.0022 - val_loss: 0.9318 - val_accuracy: 0.8584 - val_f1_m: 1.0475\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 184us/sample - loss: 0.0753 - accuracy: 0.9821 - f1_m: 0.9824 - val_loss: 1.0793 - val_accuracy: 0.8453 - val_f1_m: 1.0424\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 2s 131us/sample - loss: 0.0578 - accuracy: 0.9845 - f1_m: 0.9862 - val_loss: 1.0449 - val_accuracy: 0.8534 - val_f1_m: 1.0329\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 132us/sample - loss: 0.0455 - accuracy: 0.9860 - f1_m: 0.9798 - val_loss: 1.0960 - val_accuracy: 0.8516 - val_f1_m: 1.0254\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 133us/sample - loss: 0.0404 - accuracy: 0.9858 - f1_m: 0.9833 - val_loss: 1.1656 - val_accuracy: 0.8520 - val_f1_m: 1.0167\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 2s 131us/sample - loss: 0.0452 - accuracy: 0.9841 - f1_m: 0.9842 - val_loss: 1.1902 - val_accuracy: 0.8491 - val_f1_m: 1.0213\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 132us/sample - loss: 0.0359 - accuracy: 0.9872 - f1_m: 0.9783 - val_loss: 1.1423 - val_accuracy: 0.8547 - val_f1_m: 1.0167\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 2s 132us/sample - loss: 0.0526 - accuracy: 0.9818 - f1_m: 0.9871 - val_loss: 1.1809 - val_accuracy: 0.8534 - val_f1_m: 1.0250\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 132us/sample - loss: 0.0303 - accuracy: 0.9902 - f1_m: 0.9747 - val_loss: 1.2408 - val_accuracy: 0.8524 - val_f1_m: 1.0240\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 2s 132us/sample - loss: 0.0205 - accuracy: 0.9930 - f1_m: 0.9682 - val_loss: 1.2465 - val_accuracy: 0.8547 - val_f1_m: 1.0221\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 131us/sample - loss: 0.0471 - accuracy: 0.9850 - f1_m: 0.9824 - val_loss: 1.2338 - val_accuracy: 0.8524 - val_f1_m: 1.0170\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 3s 240us/sample - loss: 0.0985 - accuracy: 0.9678 - f1_m: 1.0100 - val_loss: 0.7863 - val_accuracy: 0.8503 - val_f1_m: 1.0610\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 2s 171us/sample - loss: 0.0798 - accuracy: 0.9738 - f1_m: 1.0069 - val_loss: 0.8237 - val_accuracy: 0.8533 - val_f1_m: 1.0597\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 178us/sample - loss: 0.0703 - accuracy: 0.9758 - f1_m: 1.0034 - val_loss: 0.8562 - val_accuracy: 0.8564 - val_f1_m: 1.0398\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 173us/sample - loss: 0.0830 - accuracy: 0.9704 - f1_m: 1.0068 - val_loss: 0.8507 - val_accuracy: 0.8451 - val_f1_m: 1.0561\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 2s 172us/sample - loss: 0.0840 - accuracy: 0.9719 - f1_m: 1.0048 - val_loss: 0.8259 - val_accuracy: 0.8528 - val_f1_m: 1.0570\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 172us/sample - loss: 0.0706 - accuracy: 0.9764 - f1_m: 1.0058 - val_loss: 0.7877 - val_accuracy: 0.8520 - val_f1_m: 1.0625\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 2s 174us/sample - loss: 0.0534 - accuracy: 0.9797 - f1_m: 0.9980 - val_loss: 0.9132 - val_accuracy: 0.8576 - val_f1_m: 1.0378\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 173us/sample - loss: 0.0721 - accuracy: 0.9743 - f1_m: 1.0003 - val_loss: 0.9719 - val_accuracy: 0.8494 - val_f1_m: 1.0515\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 2s 174us/sample - loss: 0.0847 - accuracy: 0.9695 - f1_m: 1.0123 - val_loss: 0.8985 - val_accuracy: 0.8461 - val_f1_m: 1.0494\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 172us/sample - loss: 0.0669 - accuracy: 0.9769 - f1_m: 0.9957 - val_loss: 0.9594 - val_accuracy: 0.8556 - val_f1_m: 1.0305\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 135us/sample - loss: 0.0486 - accuracy: 0.9910 - f1_m: 0.9636 - val_loss: 0.9784 - val_accuracy: 0.8676 - val_f1_m: 1.0179\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 98us/sample - loss: 0.0251 - accuracy: 0.9947 - f1_m: 0.9596 - val_loss: 0.9838 - val_accuracy: 0.8711 - val_f1_m: 1.0195\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1s 97us/sample - loss: 0.0167 - accuracy: 0.9950 - f1_m: 0.9607 - val_loss: 0.9707 - val_accuracy: 0.8712 - val_f1_m: 1.0181\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 96us/sample - loss: 0.0114 - accuracy: 0.9971 - f1_m: 0.9554 - val_loss: 0.9862 - val_accuracy: 0.8676 - val_f1_m: 1.0127\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 98us/sample - loss: 0.0078 - accuracy: 0.9983 - f1_m: 0.9537 - val_loss: 1.0107 - val_accuracy: 0.8700 - val_f1_m: 1.0126\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 1s 96us/sample - loss: 0.0034 - accuracy: 0.9992 - f1_m: 0.9504 - val_loss: 0.9865 - val_accuracy: 0.8733 - val_f1_m: 1.0112\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 96us/sample - loss: 0.0023 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 1.0031 - val_accuracy: 0.8759 - val_f1_m: 1.0058\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 97us/sample - loss: 6.2608e-04 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 1.0146 - val_accuracy: 0.8758 - val_f1_m: 1.0075\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 97us/sample - loss: 5.2355e-04 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 1.0223 - val_accuracy: 0.8764 - val_f1_m: 1.0017\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1s 98us/sample - loss: 4.2873e-04 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 1.0208 - val_accuracy: 0.8770 - val_f1_m: 1.0054\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 152us/sample - loss: 0.0520 - accuracy: 0.9902 - f1_m: 0.9599 - val_loss: 1.0024 - val_accuracy: 0.8622 - val_f1_m: 1.0160\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 110us/sample - loss: 0.0246 - accuracy: 0.9940 - f1_m: 0.9608 - val_loss: 1.0172 - val_accuracy: 0.8705 - val_f1_m: 1.0159\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1s 110us/sample - loss: 0.0153 - accuracy: 0.9948 - f1_m: 0.9580 - val_loss: 0.9544 - val_accuracy: 0.8709 - val_f1_m: 1.0137\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 110us/sample - loss: 0.0103 - accuracy: 0.9977 - f1_m: 0.9537 - val_loss: 1.0119 - val_accuracy: 0.8681 - val_f1_m: 1.0125\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 111us/sample - loss: 0.0101 - accuracy: 0.9967 - f1_m: 0.9559 - val_loss: 1.0087 - val_accuracy: 0.8677 - val_f1_m: 1.0153\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1s 110us/sample - loss: 0.0106 - accuracy: 0.9964 - f1_m: 0.9551 - val_loss: 1.1085 - val_accuracy: 0.8600 - val_f1_m: 1.0176\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 110us/sample - loss: 0.0081 - accuracy: 0.9975 - f1_m: 0.9554 - val_loss: 1.0571 - val_accuracy: 0.8677 - val_f1_m: 1.0128\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 111us/sample - loss: 0.0071 - accuracy: 0.9977 - f1_m: 0.9532 - val_loss: 1.1175 - val_accuracy: 0.8695 - val_f1_m: 1.0122\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 111us/sample - loss: 0.0147 - accuracy: 0.9961 - f1_m: 0.9560 - val_loss: 1.0845 - val_accuracy: 0.8633 - val_f1_m: 1.0287\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1s 110us/sample - loss: 0.0074 - accuracy: 0.9977 - f1_m: 0.9565 - val_loss: 1.0581 - val_accuracy: 0.8740 - val_f1_m: 0.9978\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 191us/sample - loss: 0.0475 - accuracy: 0.9909 - f1_m: 0.9597 - val_loss: 0.9405 - val_accuracy: 0.8700 - val_f1_m: 1.0161\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 2s 140us/sample - loss: 0.0174 - accuracy: 0.9948 - f1_m: 0.9590 - val_loss: 1.1034 - val_accuracy: 0.8650 - val_f1_m: 1.0105\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 139us/sample - loss: 0.0158 - accuracy: 0.9948 - f1_m: 0.9575 - val_loss: 1.2718 - val_accuracy: 0.8711 - val_f1_m: 0.9983\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 139us/sample - loss: 0.0166 - accuracy: 0.9954 - f1_m: 0.9538 - val_loss: 1.1741 - val_accuracy: 0.8695 - val_f1_m: 0.9985\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 2s 140us/sample - loss: 0.0076 - accuracy: 0.9977 - f1_m: 0.9533 - val_loss: 1.2672 - val_accuracy: 0.8662 - val_f1_m: 0.9963\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 139us/sample - loss: 0.0105 - accuracy: 0.9967 - f1_m: 0.9527 - val_loss: 1.2557 - val_accuracy: 0.8679 - val_f1_m: 1.0026\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 2s 138us/sample - loss: 0.0341 - accuracy: 0.9904 - f1_m: 0.9600 - val_loss: 1.2111 - val_accuracy: 0.8677 - val_f1_m: 1.0009\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 139us/sample - loss: 0.0141 - accuracy: 0.9954 - f1_m: 0.9540 - val_loss: 1.1960 - val_accuracy: 0.8691 - val_f1_m: 1.0025\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 2s 138us/sample - loss: 0.0093 - accuracy: 0.9968 - f1_m: 0.9525 - val_loss: 1.3598 - val_accuracy: 0.8690 - val_f1_m: 0.9963\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 139us/sample - loss: 0.0037 - accuracy: 0.9987 - f1_m: 0.9496 - val_loss: 1.4679 - val_accuracy: 0.8710 - val_f1_m: 0.9899\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 3s 257us/sample - loss: 0.0669 - accuracy: 0.9835 - f1_m: 0.9750 - val_loss: 0.8961 - val_accuracy: 0.8550 - val_f1_m: 1.0424\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 2s 187us/sample - loss: 0.0280 - accuracy: 0.9917 - f1_m: 0.9673 - val_loss: 0.9472 - val_accuracy: 0.8584 - val_f1_m: 1.0269\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 187us/sample - loss: 0.0313 - accuracy: 0.9902 - f1_m: 0.9657 - val_loss: 1.0379 - val_accuracy: 0.8553 - val_f1_m: 1.0258\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 187us/sample - loss: 0.0467 - accuracy: 0.9851 - f1_m: 0.9746 - val_loss: 1.0863 - val_accuracy: 0.8443 - val_f1_m: 1.0383\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 2s 187us/sample - loss: 0.0379 - accuracy: 0.9877 - f1_m: 0.9707 - val_loss: 1.1083 - val_accuracy: 0.8545 - val_f1_m: 1.0199\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 185us/sample - loss: 0.0343 - accuracy: 0.9893 - f1_m: 0.9647 - val_loss: 1.1424 - val_accuracy: 0.8529 - val_f1_m: 1.0132\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 2s 188us/sample - loss: 0.0331 - accuracy: 0.9883 - f1_m: 0.9676 - val_loss: 1.2233 - val_accuracy: 0.8631 - val_f1_m: 1.0124\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 187us/sample - loss: 0.0086 - accuracy: 0.9967 - f1_m: 0.9542 - val_loss: 1.3142 - val_accuracy: 0.8595 - val_f1_m: 0.9987\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 2s 185us/sample - loss: 0.0384 - accuracy: 0.9880 - f1_m: 0.9661 - val_loss: 1.0039 - val_accuracy: 0.8509 - val_f1_m: 1.0223\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 187us/sample - loss: 0.0398 - accuracy: 0.9858 - f1_m: 0.9738 - val_loss: 1.1086 - val_accuracy: 0.8555 - val_f1_m: 1.0140\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 140us/sample - loss: 0.1085 - accuracy: 0.9657 - f1_m: 1.0471 - val_loss: 0.8575 - val_accuracy: 0.8404 - val_f1_m: 1.0786\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 1s 106us/sample - loss: 0.1004 - accuracy: 0.9694 - f1_m: 1.0448 - val_loss: 0.8637 - val_accuracy: 0.8428 - val_f1_m: 1.0811\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 1s 103us/sample - loss: 0.0993 - accuracy: 0.9683 - f1_m: 1.0456 - val_loss: 0.8956 - val_accuracy: 0.8376 - val_f1_m: 1.0734\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 1s 104us/sample - loss: 0.0924 - accuracy: 0.9708 - f1_m: 1.0387 - val_loss: 0.8721 - val_accuracy: 0.8440 - val_f1_m: 1.0661\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 1s 105us/sample - loss: 0.0911 - accuracy: 0.9700 - f1_m: 1.0436 - val_loss: 0.8479 - val_accuracy: 0.8449 - val_f1_m: 1.0723\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 1s 103us/sample - loss: 0.0882 - accuracy: 0.9717 - f1_m: 1.0411 - val_loss: 0.9072 - val_accuracy: 0.8309 - val_f1_m: 1.0739\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 1s 104us/sample - loss: 0.0883 - accuracy: 0.9703 - f1_m: 1.0408 - val_loss: 0.8903 - val_accuracy: 0.8411 - val_f1_m: 1.0589\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 1s 104us/sample - loss: 0.0866 - accuracy: 0.9710 - f1_m: 1.0396 - val_loss: 0.8667 - val_accuracy: 0.8393 - val_f1_m: 1.0733\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 105us/sample - loss: 0.0877 - accuracy: 0.9708 - f1_m: 1.0431 - val_loss: 0.8921 - val_accuracy: 0.8383 - val_f1_m: 1.0742\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 1s 103us/sample - loss: 0.0794 - accuracy: 0.9731 - f1_m: 1.0365 - val_loss: 0.9238 - val_accuracy: 0.8363 - val_f1_m: 1.0765\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 154us/sample - loss: 0.0817 - accuracy: 0.9761 - f1_m: 1.0018 - val_loss: 0.9543 - val_accuracy: 0.8596 - val_f1_m: 1.0357\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 0.0730 - accuracy: 0.9755 - f1_m: 1.0029 - val_loss: 0.9359 - val_accuracy: 0.8608 - val_f1_m: 1.0385\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 0.0691 - accuracy: 0.9774 - f1_m: 1.0049 - val_loss: 0.9478 - val_accuracy: 0.8571 - val_f1_m: 1.0400\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 0.0680 - accuracy: 0.9773 - f1_m: 1.0025 - val_loss: 0.9360 - val_accuracy: 0.8581 - val_f1_m: 1.0363\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 0.0615 - accuracy: 0.9798 - f1_m: 1.0011 - val_loss: 0.9873 - val_accuracy: 0.8480 - val_f1_m: 1.0496\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 0.0602 - accuracy: 0.9798 - f1_m: 1.0026 - val_loss: 1.0907 - val_accuracy: 0.8337 - val_f1_m: 1.0522\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 0.0629 - accuracy: 0.9798 - f1_m: 1.0006 - val_loss: 0.9372 - val_accuracy: 0.8611 - val_f1_m: 1.0334\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 0.0587 - accuracy: 0.9801 - f1_m: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.8515 - val_f1_m: 1.0384\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 1s 115us/sample - loss: 0.0484 - accuracy: 0.9829 - f1_m: 0.9968 - val_loss: 0.9970 - val_accuracy: 0.8579 - val_f1_m: 1.0243\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 1s 115us/sample - loss: 0.0479 - accuracy: 0.9840 - f1_m: 0.9955 - val_loss: 0.9499 - val_accuracy: 0.8599 - val_f1_m: 1.0366\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 190us/sample - loss: 0.0751 - accuracy: 0.9825 - f1_m: 0.9833 - val_loss: 1.1085 - val_accuracy: 0.8529 - val_f1_m: 1.0237\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 140us/sample - loss: 0.0562 - accuracy: 0.9842 - f1_m: 0.9784 - val_loss: 1.1034 - val_accuracy: 0.8481 - val_f1_m: 1.0251\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 139us/sample - loss: 0.0465 - accuracy: 0.9862 - f1_m: 0.9798 - val_loss: 1.1188 - val_accuracy: 0.8573 - val_f1_m: 1.0213\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 138us/sample - loss: 0.0440 - accuracy: 0.9848 - f1_m: 0.9802 - val_loss: 1.1441 - val_accuracy: 0.8523 - val_f1_m: 1.0216\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 138us/sample - loss: 0.0368 - accuracy: 0.9867 - f1_m: 0.9779 - val_loss: 1.1750 - val_accuracy: 0.8473 - val_f1_m: 1.0186\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 139us/sample - loss: 0.0310 - accuracy: 0.9893 - f1_m: 0.9744 - val_loss: 1.2406 - val_accuracy: 0.8465 - val_f1_m: 1.0141\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 138us/sample - loss: 0.0334 - accuracy: 0.9885 - f1_m: 0.9751 - val_loss: 1.2485 - val_accuracy: 0.8567 - val_f1_m: 1.0094\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 138us/sample - loss: 0.0433 - accuracy: 0.9846 - f1_m: 0.9822 - val_loss: 1.2165 - val_accuracy: 0.8535 - val_f1_m: 1.0144\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 137us/sample - loss: 0.0406 - accuracy: 0.9850 - f1_m: 0.9797 - val_loss: 1.2826 - val_accuracy: 0.8461 - val_f1_m: 1.0230\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 138us/sample - loss: 0.0434 - accuracy: 0.9840 - f1_m: 0.9788 - val_loss: 1.3226 - val_accuracy: 0.8456 - val_f1_m: 1.0057\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 3s 245us/sample - loss: 0.0919 - accuracy: 0.9720 - f1_m: 1.0059 - val_loss: 0.8384 - val_accuracy: 0.8549 - val_f1_m: 1.0580\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 178us/sample - loss: 0.0994 - accuracy: 0.9675 - f1_m: 1.0115 - val_loss: 0.8204 - val_accuracy: 0.8424 - val_f1_m: 1.0692\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 177us/sample - loss: 0.0785 - accuracy: 0.9738 - f1_m: 1.0122 - val_loss: 0.8205 - val_accuracy: 0.8519 - val_f1_m: 1.0576\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 176us/sample - loss: 0.0794 - accuracy: 0.9736 - f1_m: 1.0047 - val_loss: 0.7431 - val_accuracy: 0.8509 - val_f1_m: 1.0719\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 178us/sample - loss: 0.0800 - accuracy: 0.9718 - f1_m: 1.0104 - val_loss: 0.8511 - val_accuracy: 0.8555 - val_f1_m: 1.0443\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 178us/sample - loss: 0.0612 - accuracy: 0.9790 - f1_m: 0.9991 - val_loss: 0.9101 - val_accuracy: 0.8507 - val_f1_m: 1.0457\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 177us/sample - loss: 0.0738 - accuracy: 0.9743 - f1_m: 1.0019 - val_loss: 0.8882 - val_accuracy: 0.8576 - val_f1_m: 1.0451\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 177us/sample - loss: 0.0749 - accuracy: 0.9727 - f1_m: 1.0081 - val_loss: 0.9105 - val_accuracy: 0.8404 - val_f1_m: 1.0695\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 178us/sample - loss: 0.0725 - accuracy: 0.9746 - f1_m: 0.9997 - val_loss: 0.9344 - val_accuracy: 0.8492 - val_f1_m: 1.0407\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 178us/sample - loss: 0.0500 - accuracy: 0.9833 - f1_m: 0.9902 - val_loss: 0.9189 - val_accuracy: 0.8512 - val_f1_m: 1.0449\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 140us/sample - loss: 0.0415 - accuracy: 0.9926 - f1_m: 0.9586 - val_loss: 1.0280 - val_accuracy: 0.8680 - val_f1_m: 1.0124\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 1s 106us/sample - loss: 0.0242 - accuracy: 0.9955 - f1_m: 0.9552 - val_loss: 1.0248 - val_accuracy: 0.8693 - val_f1_m: 1.0070\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 1s 106us/sample - loss: 0.0100 - accuracy: 0.9978 - f1_m: 0.9531 - val_loss: 1.0420 - val_accuracy: 0.8685 - val_f1_m: 1.0146\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 1s 105us/sample - loss: 0.0075 - accuracy: 0.9986 - f1_m: 0.9523 - val_loss: 1.0331 - val_accuracy: 0.8707 - val_f1_m: 1.0026\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 1s 104us/sample - loss: 0.0130 - accuracy: 0.9964 - f1_m: 0.9570 - val_loss: 1.1250 - val_accuracy: 0.8640 - val_f1_m: 1.0064\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 1s 106us/sample - loss: 0.0064 - accuracy: 0.9986 - f1_m: 0.9537 - val_loss: 1.0743 - val_accuracy: 0.8707 - val_f1_m: 1.0103\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 1s 105us/sample - loss: 0.0065 - accuracy: 0.9984 - f1_m: 0.9523 - val_loss: 1.1116 - val_accuracy: 0.8636 - val_f1_m: 1.0065\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 1s 104us/sample - loss: 0.0192 - accuracy: 0.9940 - f1_m: 0.9629 - val_loss: 1.0753 - val_accuracy: 0.8689 - val_f1_m: 1.0189\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 1s 105us/sample - loss: 0.0045 - accuracy: 0.9990 - f1_m: 0.9522 - val_loss: 1.0431 - val_accuracy: 0.8687 - val_f1_m: 1.0127\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 1s 106us/sample - loss: 8.3451e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 1.0505 - val_accuracy: 0.8715 - val_f1_m: 1.0078\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 166us/sample - loss: 0.0424 - accuracy: 0.9914 - f1_m: 0.9586 - val_loss: 1.0652 - val_accuracy: 0.8657 - val_f1_m: 1.0113\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 2s 122us/sample - loss: 0.0180 - accuracy: 0.9955 - f1_m: 0.9551 - val_loss: 1.0326 - val_accuracy: 0.8691 - val_f1_m: 1.0123\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 122us/sample - loss: 0.0068 - accuracy: 0.9982 - f1_m: 0.9519 - val_loss: 1.1560 - val_accuracy: 0.8572 - val_f1_m: 1.0092\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 121us/sample - loss: 0.0255 - accuracy: 0.9930 - f1_m: 0.9606 - val_loss: 1.1493 - val_accuracy: 0.8580 - val_f1_m: 1.0122\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 122us/sample - loss: 0.0088 - accuracy: 0.9969 - f1_m: 0.9558 - val_loss: 1.0461 - val_accuracy: 0.8701 - val_f1_m: 1.0132\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 121us/sample - loss: 0.0050 - accuracy: 0.9985 - f1_m: 0.9524 - val_loss: 1.1552 - val_accuracy: 0.8647 - val_f1_m: 0.9979\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 122us/sample - loss: 0.0143 - accuracy: 0.9958 - f1_m: 0.9571 - val_loss: 1.0943 - val_accuracy: 0.8688 - val_f1_m: 1.0052\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 123us/sample - loss: 0.0058 - accuracy: 0.9980 - f1_m: 0.9527 - val_loss: 1.1688 - val_accuracy: 0.8676 - val_f1_m: 0.9999\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 123us/sample - loss: 0.0042 - accuracy: 0.9989 - f1_m: 0.9508 - val_loss: 1.1262 - val_accuracy: 0.8697 - val_f1_m: 1.0027\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 122us/sample - loss: 3.9262e-04 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 1.1498 - val_accuracy: 0.8708 - val_f1_m: 0.9966\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 199us/sample - loss: 0.0553 - accuracy: 0.9906 - f1_m: 0.9585 - val_loss: 1.0246 - val_accuracy: 0.8653 - val_f1_m: 1.0161\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 146us/sample - loss: 0.0169 - accuracy: 0.9952 - f1_m: 0.9562 - val_loss: 1.0740 - val_accuracy: 0.8631 - val_f1_m: 1.0123\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 148us/sample - loss: 0.0089 - accuracy: 0.9975 - f1_m: 0.9541 - val_loss: 1.1698 - val_accuracy: 0.8725 - val_f1_m: 1.0051\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 148us/sample - loss: 0.0078 - accuracy: 0.9982 - f1_m: 0.9512 - val_loss: 1.3282 - val_accuracy: 0.8669 - val_f1_m: 0.9974\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 146us/sample - loss: 0.0243 - accuracy: 0.9921 - f1_m: 0.9596 - val_loss: 1.2100 - val_accuracy: 0.8660 - val_f1_m: 1.0017\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 146us/sample - loss: 0.0173 - accuracy: 0.9934 - f1_m: 0.9579 - val_loss: 1.2784 - val_accuracy: 0.8663 - val_f1_m: 0.9988\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 146us/sample - loss: 0.0136 - accuracy: 0.9960 - f1_m: 0.9534 - val_loss: 1.2885 - val_accuracy: 0.8624 - val_f1_m: 1.0013\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 147us/sample - loss: 0.0293 - accuracy: 0.9912 - f1_m: 0.9598 - val_loss: 1.1994 - val_accuracy: 0.8676 - val_f1_m: 1.0036\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 147us/sample - loss: 0.0100 - accuracy: 0.9966 - f1_m: 0.9532 - val_loss: 1.5051 - val_accuracy: 0.8673 - val_f1_m: 0.9924\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 147us/sample - loss: 0.0155 - accuracy: 0.9958 - f1_m: 0.9544 - val_loss: 1.2714 - val_accuracy: 0.8705 - val_f1_m: 0.9985\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 5s 426us/sample - loss: 0.0617 - accuracy: 0.9838 - f1_m: 0.9733 - val_loss: 0.9564 - val_accuracy: 0.8525 - val_f1_m: 1.0328\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 193us/sample - loss: 0.0366 - accuracy: 0.9898 - f1_m: 0.9702 - val_loss: 0.9190 - val_accuracy: 0.8588 - val_f1_m: 1.0315\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 192us/sample - loss: 0.0303 - accuracy: 0.9909 - f1_m: 0.9660 - val_loss: 0.9420 - val_accuracy: 0.8553 - val_f1_m: 1.0319\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 193us/sample - loss: 0.0396 - accuracy: 0.9875 - f1_m: 0.9706 - val_loss: 1.0027 - val_accuracy: 0.8496 - val_f1_m: 1.0305\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 192us/sample - loss: 0.0367 - accuracy: 0.9876 - f1_m: 0.9691 - val_loss: 0.9657 - val_accuracy: 0.8539 - val_f1_m: 1.0410\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 193us/sample - loss: 0.0396 - accuracy: 0.9882 - f1_m: 0.9688 - val_loss: 0.9552 - val_accuracy: 0.8551 - val_f1_m: 1.0308\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 192us/sample - loss: 0.0195 - accuracy: 0.9929 - f1_m: 0.9632 - val_loss: 1.1315 - val_accuracy: 0.8592 - val_f1_m: 1.0162\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 193us/sample - loss: 0.0323 - accuracy: 0.9898 - f1_m: 0.9664 - val_loss: 1.0968 - val_accuracy: 0.8579 - val_f1_m: 1.0262\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 192us/sample - loss: 0.0533 - accuracy: 0.9841 - f1_m: 0.9771 - val_loss: 1.1506 - val_accuracy: 0.8536 - val_f1_m: 1.0131\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 193us/sample - loss: 0.0319 - accuracy: 0.9898 - f1_m: 0.9647 - val_loss: 1.0258 - val_accuracy: 0.8587 - val_f1_m: 1.0185\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 138us/sample - loss: 0.1083 - accuracy: 0.9667 - f1_m: 1.0442 - val_loss: 0.8723 - val_accuracy: 0.8421 - val_f1_m: 1.0651\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0970 - accuracy: 0.9712 - f1_m: 1.0366 - val_loss: 0.9023 - val_accuracy: 0.8401 - val_f1_m: 1.0741\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0947 - accuracy: 0.9712 - f1_m: 1.0386 - val_loss: 0.9029 - val_accuracy: 0.8363 - val_f1_m: 1.0687\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 1s 101us/sample - loss: 0.0930 - accuracy: 0.9693 - f1_m: 1.0366 - val_loss: 0.8677 - val_accuracy: 0.8423 - val_f1_m: 1.0701\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0875 - accuracy: 0.9722 - f1_m: 1.0382 - val_loss: 0.8813 - val_accuracy: 0.8414 - val_f1_m: 1.0758\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 1s 101us/sample - loss: 0.0883 - accuracy: 0.9694 - f1_m: 1.0395 - val_loss: 0.8836 - val_accuracy: 0.8371 - val_f1_m: 1.0750\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 0.0827 - accuracy: 0.9727 - f1_m: 1.0350 - val_loss: 0.8900 - val_accuracy: 0.8430 - val_f1_m: 1.0727\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 1s 100us/sample - loss: 0.0803 - accuracy: 0.9735 - f1_m: 1.0325 - val_loss: 0.9194 - val_accuracy: 0.8391 - val_f1_m: 1.0745\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0830 - accuracy: 0.9711 - f1_m: 1.0351 - val_loss: 0.9202 - val_accuracy: 0.8403 - val_f1_m: 1.0638\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 1s 101us/sample - loss: 0.0824 - accuracy: 0.9721 - f1_m: 1.0325 - val_loss: 0.9216 - val_accuracy: 0.8363 - val_f1_m: 1.0743\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 151us/sample - loss: 0.0792 - accuracy: 0.9757 - f1_m: 1.0051 - val_loss: 0.9489 - val_accuracy: 0.8559 - val_f1_m: 1.0407\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 1s 112us/sample - loss: 0.0686 - accuracy: 0.9778 - f1_m: 1.0017 - val_loss: 0.9208 - val_accuracy: 0.8569 - val_f1_m: 1.0356\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 1s 112us/sample - loss: 0.0607 - accuracy: 0.9793 - f1_m: 1.0011 - val_loss: 0.9365 - val_accuracy: 0.8597 - val_f1_m: 1.0368\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 1s 112us/sample - loss: 0.0580 - accuracy: 0.9804 - f1_m: 0.9983 - val_loss: 0.9726 - val_accuracy: 0.8634 - val_f1_m: 1.0346\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000/13000 [==============================] - 1s 111us/sample - loss: 0.0552 - accuracy: 0.9801 - f1_m: 1.0049 - val_loss: 1.0058 - val_accuracy: 0.8591 - val_f1_m: 1.0411\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 1s 112us/sample - loss: 0.0565 - accuracy: 0.9802 - f1_m: 0.9998 - val_loss: 0.9621 - val_accuracy: 0.8523 - val_f1_m: 1.0465\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 1s 111us/sample - loss: 0.0502 - accuracy: 0.9828 - f1_m: 0.9967 - val_loss: 0.9692 - val_accuracy: 0.8546 - val_f1_m: 1.0414\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 1s 112us/sample - loss: 0.0514 - accuracy: 0.9822 - f1_m: 0.9961 - val_loss: 1.0180 - val_accuracy: 0.8620 - val_f1_m: 1.0326\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 1s 111us/sample - loss: 0.0504 - accuracy: 0.9829 - f1_m: 0.9958 - val_loss: 1.0399 - val_accuracy: 0.8573 - val_f1_m: 1.0391\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 1s 112us/sample - loss: 0.0515 - accuracy: 0.9806 - f1_m: 0.9936 - val_loss: 1.0113 - val_accuracy: 0.8577 - val_f1_m: 1.0344\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 184us/sample - loss: 0.0820 - accuracy: 0.9786 - f1_m: 0.9860 - val_loss: 1.1243 - val_accuracy: 0.8553 - val_f1_m: 1.0232\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 135us/sample - loss: 0.0472 - accuracy: 0.9862 - f1_m: 0.9764 - val_loss: 1.1425 - val_accuracy: 0.8540 - val_f1_m: 1.0220\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 134us/sample - loss: 0.0313 - accuracy: 0.9890 - f1_m: 0.9743 - val_loss: 1.1483 - val_accuracy: 0.8523 - val_f1_m: 1.0168\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 134us/sample - loss: 0.0326 - accuracy: 0.9898 - f1_m: 0.9740 - val_loss: 1.2548 - val_accuracy: 0.8499 - val_f1_m: 1.0057\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 134us/sample - loss: 0.0394 - accuracy: 0.9855 - f1_m: 0.9800 - val_loss: 1.1973 - val_accuracy: 0.8499 - val_f1_m: 1.0173\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 135us/sample - loss: 0.0362 - accuracy: 0.9872 - f1_m: 0.9770 - val_loss: 1.2184 - val_accuracy: 0.8511 - val_f1_m: 1.0206\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 135us/sample - loss: 0.0423 - accuracy: 0.9853 - f1_m: 0.9785 - val_loss: 1.2338 - val_accuracy: 0.8537 - val_f1_m: 1.0134\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 135us/sample - loss: 0.0264 - accuracy: 0.9916 - f1_m: 0.9698 - val_loss: 1.2545 - val_accuracy: 0.8541 - val_f1_m: 1.0100\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 134us/sample - loss: 0.0256 - accuracy: 0.9909 - f1_m: 0.9702 - val_loss: 1.2802 - val_accuracy: 0.8531 - val_f1_m: 1.0133\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 135us/sample - loss: 0.0480 - accuracy: 0.9838 - f1_m: 0.9777 - val_loss: 1.1657 - val_accuracy: 0.8489 - val_f1_m: 1.0258\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 3s 238us/sample - loss: 0.0984 - accuracy: 0.9710 - f1_m: 1.0106 - val_loss: 0.7470 - val_accuracy: 0.8557 - val_f1_m: 1.0597\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 173us/sample - loss: 0.0787 - accuracy: 0.9752 - f1_m: 1.0037 - val_loss: 0.8310 - val_accuracy: 0.8576 - val_f1_m: 1.0461\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 175us/sample - loss: 0.0844 - accuracy: 0.9704 - f1_m: 1.0087 - val_loss: 0.8835 - val_accuracy: 0.8524 - val_f1_m: 1.0447\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 173us/sample - loss: 0.0850 - accuracy: 0.9728 - f1_m: 1.0066 - val_loss: 0.7486 - val_accuracy: 0.8517 - val_f1_m: 1.0706\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 174us/sample - loss: 0.0766 - accuracy: 0.9735 - f1_m: 1.0046 - val_loss: 0.7635 - val_accuracy: 0.8543 - val_f1_m: 1.0602\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 173us/sample - loss: 0.0555 - accuracy: 0.9808 - f1_m: 0.9970 - val_loss: 0.8320 - val_accuracy: 0.8590 - val_f1_m: 1.0498\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 175us/sample - loss: 0.0785 - accuracy: 0.9728 - f1_m: 1.0071 - val_loss: 0.8708 - val_accuracy: 0.8463 - val_f1_m: 1.0521\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 172us/sample - loss: 0.0832 - accuracy: 0.9714 - f1_m: 1.0066 - val_loss: 0.8374 - val_accuracy: 0.8604 - val_f1_m: 1.0519\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 172us/sample - loss: 0.0555 - accuracy: 0.9804 - f1_m: 0.9933 - val_loss: 0.8287 - val_accuracy: 0.8533 - val_f1_m: 1.0532\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 174us/sample - loss: 0.0834 - accuracy: 0.9704 - f1_m: 1.0072 - val_loss: 0.8082 - val_accuracy: 0.8524 - val_f1_m: 1.0746\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 138us/sample - loss: 0.0349 - accuracy: 0.9928 - f1_m: 0.9590 - val_loss: 1.0531 - val_accuracy: 0.8707 - val_f1_m: 1.0119\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0171 - accuracy: 0.9956 - f1_m: 0.9557 - val_loss: 1.0341 - val_accuracy: 0.8666 - val_f1_m: 1.0207\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0137 - accuracy: 0.9959 - f1_m: 0.9575 - val_loss: 1.0491 - val_accuracy: 0.8696 - val_f1_m: 1.0156\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 1s 103us/sample - loss: 0.0067 - accuracy: 0.9978 - f1_m: 0.9531 - val_loss: 1.0195 - val_accuracy: 0.8663 - val_f1_m: 1.0214\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0043 - accuracy: 0.9989 - f1_m: 0.9504 - val_loss: 1.0507 - val_accuracy: 0.8696 - val_f1_m: 1.0072\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0047 - accuracy: 0.9988 - f1_m: 0.9498 - val_loss: 1.0580 - val_accuracy: 0.8670 - val_f1_m: 1.0142\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 1s 100us/sample - loss: 0.0083 - accuracy: 0.9972 - f1_m: 0.9539 - val_loss: 1.0896 - val_accuracy: 0.8654 - val_f1_m: 1.0137\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0172 - accuracy: 0.9946 - f1_m: 0.9572 - val_loss: 1.0554 - val_accuracy: 0.8661 - val_f1_m: 1.0144\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 1s 102us/sample - loss: 0.0090 - accuracy: 0.9977 - f1_m: 0.9533 - val_loss: 1.0485 - val_accuracy: 0.8681 - val_f1_m: 1.0100\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 1s 101us/sample - loss: 0.0032 - accuracy: 0.9991 - f1_m: 0.9502 - val_loss: 1.0111 - val_accuracy: 0.8719 - val_f1_m: 1.0109\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 158us/sample - loss: 0.0375 - accuracy: 0.9925 - f1_m: 0.9581 - val_loss: 1.0574 - val_accuracy: 0.8697 - val_f1_m: 1.0033\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0128 - accuracy: 0.9972 - f1_m: 0.9546 - val_loss: 1.0164 - val_accuracy: 0.8760 - val_f1_m: 1.0098\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0105 - accuracy: 0.9969 - f1_m: 0.9538 - val_loss: 1.0754 - val_accuracy: 0.8640 - val_f1_m: 1.0109\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0156 - accuracy: 0.9942 - f1_m: 0.9567 - val_loss: 1.1006 - val_accuracy: 0.8720 - val_f1_m: 1.0043\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0063 - accuracy: 0.9980 - f1_m: 0.9530 - val_loss: 1.0924 - val_accuracy: 0.8730 - val_f1_m: 1.0054\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 119us/sample - loss: 0.0103 - accuracy: 0.9968 - f1_m: 0.9550 - val_loss: 1.1185 - val_accuracy: 0.8671 - val_f1_m: 1.0063\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0086 - accuracy: 0.9967 - f1_m: 0.9541 - val_loss: 1.1184 - val_accuracy: 0.8736 - val_f1_m: 0.9998\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0033 - accuracy: 0.9992 - f1_m: 0.9496 - val_loss: 1.1425 - val_accuracy: 0.8730 - val_f1_m: 1.0051\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0049 - accuracy: 0.9985 - f1_m: 0.9508 - val_loss: 1.1525 - val_accuracy: 0.8699 - val_f1_m: 1.0007\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0209 - accuracy: 0.9932 - f1_m: 0.9588 - val_loss: 1.2389 - val_accuracy: 0.8671 - val_f1_m: 1.0041\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 192us/sample - loss: 0.0529 - accuracy: 0.9895 - f1_m: 0.9611 - val_loss: 1.0695 - val_accuracy: 0.8719 - val_f1_m: 1.0009\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 145us/sample - loss: 0.0129 - accuracy: 0.9962 - f1_m: 0.9538 - val_loss: 1.1271 - val_accuracy: 0.8727 - val_f1_m: 0.9959\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 145us/sample - loss: 0.0067 - accuracy: 0.9977 - f1_m: 0.9522 - val_loss: 1.2130 - val_accuracy: 0.8701 - val_f1_m: 0.9952\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 0.0065 - accuracy: 0.9974 - f1_m: 0.9520 - val_loss: 1.2770 - val_accuracy: 0.8629 - val_f1_m: 1.0013\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 144us/sample - loss: 0.0121 - accuracy: 0.9964 - f1_m: 0.9546 - val_loss: 1.3685 - val_accuracy: 0.8710 - val_f1_m: 0.9907\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 144us/sample - loss: 0.0383 - accuracy: 0.9886 - f1_m: 0.9613 - val_loss: 1.3717 - val_accuracy: 0.8659 - val_f1_m: 0.9986\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 144us/sample - loss: 0.0144 - accuracy: 0.9951 - f1_m: 0.9551 - val_loss: 1.2693 - val_accuracy: 0.8750 - val_f1_m: 0.9934\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 144us/sample - loss: 0.0066 - accuracy: 0.9982 - f1_m: 0.9506 - val_loss: 1.3080 - val_accuracy: 0.8741 - val_f1_m: 0.9899\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 0.0088 - accuracy: 0.9974 - f1_m: 0.9506 - val_loss: 1.2905 - val_accuracy: 0.8721 - val_f1_m: 0.9960\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 144us/sample - loss: 0.0157 - accuracy: 0.9957 - f1_m: 0.9527 - val_loss: 1.3646 - val_accuracy: 0.8659 - val_f1_m: 1.0013\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 3s 252us/sample - loss: 0.0731 - accuracy: 0.9831 - f1_m: 0.9776 - val_loss: 0.7820 - val_accuracy: 0.8554 - val_f1_m: 1.0484\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 189us/sample - loss: 0.0347 - accuracy: 0.9905 - f1_m: 0.9709 - val_loss: 0.8423 - val_accuracy: 0.8566 - val_f1_m: 1.0409\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 188us/sample - loss: 0.0313 - accuracy: 0.9908 - f1_m: 0.9659 - val_loss: 0.9480 - val_accuracy: 0.8529 - val_f1_m: 1.0441\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 187us/sample - loss: 0.0427 - accuracy: 0.9858 - f1_m: 0.9742 - val_loss: 1.0121 - val_accuracy: 0.8536 - val_f1_m: 1.0202\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 189us/sample - loss: 0.0344 - accuracy: 0.9892 - f1_m: 0.9669 - val_loss: 0.9970 - val_accuracy: 0.8506 - val_f1_m: 1.0245\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 190us/sample - loss: 0.0354 - accuracy: 0.9890 - f1_m: 0.9686 - val_loss: 1.0125 - val_accuracy: 0.8586 - val_f1_m: 1.0236\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 188us/sample - loss: 0.0354 - accuracy: 0.9890 - f1_m: 0.9653 - val_loss: 1.0551 - val_accuracy: 0.8579 - val_f1_m: 1.0252\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 188us/sample - loss: 0.0326 - accuracy: 0.9899 - f1_m: 0.9667 - val_loss: 1.0522 - val_accuracy: 0.8546 - val_f1_m: 1.0142\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 188us/sample - loss: 0.0279 - accuracy: 0.9912 - f1_m: 0.9639 - val_loss: 1.1735 - val_accuracy: 0.8586 - val_f1_m: 1.0133\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 189us/sample - loss: 0.0353 - accuracy: 0.9902 - f1_m: 0.9666 - val_loss: 1.1581 - val_accuracy: 0.8584 - val_f1_m: 1.0148\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 133us/sample - loss: 0.1006 - accuracy: 0.9684 - f1_m: 1.0374 - val_loss: 0.9402 - val_accuracy: 0.8408 - val_f1_m: 1.0617\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0889 - accuracy: 0.9707 - f1_m: 1.0340 - val_loss: 0.9380 - val_accuracy: 0.8385 - val_f1_m: 1.0705\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 0.0866 - accuracy: 0.9721 - f1_m: 1.0289 - val_loss: 0.9525 - val_accuracy: 0.8322 - val_f1_m: 1.0622\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 0.0862 - accuracy: 0.9707 - f1_m: 1.0360 - val_loss: 0.9452 - val_accuracy: 0.8406 - val_f1_m: 1.0662\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 0.0838 - accuracy: 0.9722 - f1_m: 1.0297 - val_loss: 0.9386 - val_accuracy: 0.8418 - val_f1_m: 1.0697\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0824 - accuracy: 0.9740 - f1_m: 1.0313 - val_loss: 0.9705 - val_accuracy: 0.8405 - val_f1_m: 1.0660\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 0.0806 - accuracy: 0.9739 - f1_m: 1.0367 - val_loss: 0.9512 - val_accuracy: 0.8446 - val_f1_m: 1.0619\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0770 - accuracy: 0.9745 - f1_m: 1.0292 - val_loss: 0.9452 - val_accuracy: 0.8391 - val_f1_m: 1.0635\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 0.0757 - accuracy: 0.9756 - f1_m: 1.0268 - val_loss: 0.9702 - val_accuracy: 0.8392 - val_f1_m: 1.0611\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 0.0785 - accuracy: 0.9734 - f1_m: 1.0263 - val_loss: 0.9859 - val_accuracy: 0.8334 - val_f1_m: 1.0695\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 148us/sample - loss: 0.0822 - accuracy: 0.9768 - f1_m: 0.9993 - val_loss: 1.0034 - val_accuracy: 0.8551 - val_f1_m: 1.0305\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 1s 109us/sample - loss: 0.0680 - accuracy: 0.9801 - f1_m: 0.9962 - val_loss: 0.9876 - val_accuracy: 0.8589 - val_f1_m: 1.0423\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 1s 108us/sample - loss: 0.0802 - accuracy: 0.9736 - f1_m: 1.0028 - val_loss: 0.9975 - val_accuracy: 0.8594 - val_f1_m: 1.0388\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 1s 109us/sample - loss: 0.0595 - accuracy: 0.9810 - f1_m: 0.9972 - val_loss: 1.0565 - val_accuracy: 0.8448 - val_f1_m: 1.0379\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 1s 107us/sample - loss: 0.0581 - accuracy: 0.9818 - f1_m: 0.9987 - val_loss: 1.0352 - val_accuracy: 0.8505 - val_f1_m: 1.0364\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 1s 109us/sample - loss: 0.0623 - accuracy: 0.9793 - f1_m: 0.9987 - val_loss: 1.0516 - val_accuracy: 0.8506 - val_f1_m: 1.0397\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 1s 109us/sample - loss: 0.0585 - accuracy: 0.9806 - f1_m: 0.9984 - val_loss: 1.0220 - val_accuracy: 0.8498 - val_f1_m: 1.0476\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 1s 108us/sample - loss: 0.0515 - accuracy: 0.9819 - f1_m: 0.9961 - val_loss: 1.0137 - val_accuracy: 0.8534 - val_f1_m: 1.0380\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 1s 107us/sample - loss: 0.0579 - accuracy: 0.9801 - f1_m: 0.9954 - val_loss: 1.0614 - val_accuracy: 0.8512 - val_f1_m: 1.0370\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 1s 108us/sample - loss: 0.0475 - accuracy: 0.9836 - f1_m: 0.9981 - val_loss: 1.0661 - val_accuracy: 0.8529 - val_f1_m: 1.0329\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500/13500 [==============================] - 2s 178us/sample - loss: 0.0645 - accuracy: 0.9835 - f1_m: 0.9819 - val_loss: 1.1407 - val_accuracy: 0.8554 - val_f1_m: 1.0199\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 132us/sample - loss: 0.0561 - accuracy: 0.9823 - f1_m: 0.9836 - val_loss: 1.1735 - val_accuracy: 0.8605 - val_f1_m: 1.0081\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 131us/sample - loss: 0.0370 - accuracy: 0.9881 - f1_m: 0.9742 - val_loss: 1.1687 - val_accuracy: 0.8560 - val_f1_m: 1.0163\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 131us/sample - loss: 0.0400 - accuracy: 0.9879 - f1_m: 0.9747 - val_loss: 1.2440 - val_accuracy: 0.8555 - val_f1_m: 1.0126\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 132us/sample - loss: 0.0303 - accuracy: 0.9900 - f1_m: 0.9729 - val_loss: 1.2537 - val_accuracy: 0.8525 - val_f1_m: 1.0130\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 131us/sample - loss: 0.0518 - accuracy: 0.9830 - f1_m: 0.9809 - val_loss: 1.2848 - val_accuracy: 0.8529 - val_f1_m: 1.0112\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 131us/sample - loss: 0.0455 - accuracy: 0.9844 - f1_m: 0.9784 - val_loss: 1.1813 - val_accuracy: 0.8580 - val_f1_m: 1.0188\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 131us/sample - loss: 0.0297 - accuracy: 0.9898 - f1_m: 0.9752 - val_loss: 1.3251 - val_accuracy: 0.8520 - val_f1_m: 1.0127\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 131us/sample - loss: 0.0351 - accuracy: 0.9879 - f1_m: 0.9754 - val_loss: 1.2717 - val_accuracy: 0.8562 - val_f1_m: 1.0129\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 131us/sample - loss: 0.0396 - accuracy: 0.9862 - f1_m: 0.9775 - val_loss: 1.3166 - val_accuracy: 0.8500 - val_f1_m: 1.0140\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 3s 231us/sample - loss: 0.0964 - accuracy: 0.9694 - f1_m: 1.0083 - val_loss: 0.7383 - val_accuracy: 0.8555 - val_f1_m: 1.0679\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 170us/sample - loss: 0.0784 - accuracy: 0.9739 - f1_m: 1.0066 - val_loss: 0.8512 - val_accuracy: 0.8592 - val_f1_m: 1.0458\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 169us/sample - loss: 0.0919 - accuracy: 0.9681 - f1_m: 1.0134 - val_loss: 0.7869 - val_accuracy: 0.8548 - val_f1_m: 1.0731\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 169us/sample - loss: 0.0759 - accuracy: 0.9742 - f1_m: 1.0071 - val_loss: 0.7772 - val_accuracy: 0.8512 - val_f1_m: 1.0739\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 170us/sample - loss: 0.0799 - accuracy: 0.9725 - f1_m: 1.0081 - val_loss: 0.8005 - val_accuracy: 0.8571 - val_f1_m: 1.0511\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 169us/sample - loss: 0.0675 - accuracy: 0.9767 - f1_m: 1.0007 - val_loss: 0.8781 - val_accuracy: 0.8558 - val_f1_m: 1.0509\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 169us/sample - loss: 0.0902 - accuracy: 0.9684 - f1_m: 1.0120 - val_loss: 0.7903 - val_accuracy: 0.8485 - val_f1_m: 1.0603\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 170us/sample - loss: 0.0689 - accuracy: 0.9750 - f1_m: 1.0030 - val_loss: 0.8877 - val_accuracy: 0.8538 - val_f1_m: 1.0575\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 169us/sample - loss: 0.0626 - accuracy: 0.9780 - f1_m: 0.9964 - val_loss: 0.8957 - val_accuracy: 0.8508 - val_f1_m: 1.0534\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 168us/sample - loss: 0.0726 - accuracy: 0.9748 - f1_m: 1.0052 - val_loss: 0.8478 - val_accuracy: 0.8569 - val_f1_m: 1.0504\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 134us/sample - loss: 0.0398 - accuracy: 0.9927 - f1_m: 0.9595 - val_loss: 1.0375 - val_accuracy: 0.8720 - val_f1_m: 1.0110\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0240 - accuracy: 0.9947 - f1_m: 0.9552 - val_loss: 1.0830 - val_accuracy: 0.8682 - val_f1_m: 1.0105\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0142 - accuracy: 0.9970 - f1_m: 0.9546 - val_loss: 1.0350 - val_accuracy: 0.8686 - val_f1_m: 1.0081\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0097 - accuracy: 0.9979 - f1_m: 0.9551 - val_loss: 1.0746 - val_accuracy: 0.8672 - val_f1_m: 1.0096\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0094 - accuracy: 0.9972 - f1_m: 0.9527 - val_loss: 1.0608 - val_accuracy: 0.8672 - val_f1_m: 1.0072\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 0.0053 - accuracy: 0.9987 - f1_m: 0.9515 - val_loss: 1.0600 - val_accuracy: 0.8725 - val_f1_m: 1.0124\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0039 - accuracy: 0.9991 - f1_m: 0.9508 - val_loss: 1.0714 - val_accuracy: 0.8745 - val_f1_m: 1.0074\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 0.0022 - accuracy: 0.9996 - f1_m: 0.9494 - val_loss: 1.1105 - val_accuracy: 0.8708 - val_f1_m: 1.0012\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 1s 99us/sample - loss: 8.1638e-04 - accuracy: 0.9999 - f1_m: 0.9473 - val_loss: 1.1087 - val_accuracy: 0.8737 - val_f1_m: 1.0008\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 1s 98us/sample - loss: 4.6854e-04 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 1.1263 - val_accuracy: 0.8738 - val_f1_m: 1.0053\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 154us/sample - loss: 0.0436 - accuracy: 0.9913 - f1_m: 0.9601 - val_loss: 1.0487 - val_accuracy: 0.8729 - val_f1_m: 1.0064\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 115us/sample - loss: 0.0191 - accuracy: 0.9959 - f1_m: 0.9557 - val_loss: 1.0921 - val_accuracy: 0.8702 - val_f1_m: 1.0024\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 116us/sample - loss: 0.0156 - accuracy: 0.9958 - f1_m: 0.9567 - val_loss: 1.1012 - val_accuracy: 0.8734 - val_f1_m: 1.0033\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 115us/sample - loss: 0.0049 - accuracy: 0.9986 - f1_m: 0.9504 - val_loss: 1.0944 - val_accuracy: 0.8722 - val_f1_m: 0.9980\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 116us/sample - loss: 0.0019 - accuracy: 0.9996 - f1_m: 0.9488 - val_loss: 1.1823 - val_accuracy: 0.8734 - val_f1_m: 0.9984\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 115us/sample - loss: 0.0106 - accuracy: 0.9970 - f1_m: 0.9542 - val_loss: 1.2772 - val_accuracy: 0.8662 - val_f1_m: 0.9971\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 116us/sample - loss: 0.0125 - accuracy: 0.9954 - f1_m: 0.9564 - val_loss: 1.1957 - val_accuracy: 0.8715 - val_f1_m: 0.9988\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 114us/sample - loss: 0.0215 - accuracy: 0.9930 - f1_m: 0.9607 - val_loss: 1.1689 - val_accuracy: 0.8631 - val_f1_m: 1.0083\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 115us/sample - loss: 0.0133 - accuracy: 0.9964 - f1_m: 0.9549 - val_loss: 1.0828 - val_accuracy: 0.8702 - val_f1_m: 0.9994\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 115us/sample - loss: 0.0033 - accuracy: 0.9989 - f1_m: 0.9495 - val_loss: 1.1726 - val_accuracy: 0.8723 - val_f1_m: 0.9983\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 3s 188us/sample - loss: 0.0500 - accuracy: 0.9900 - f1_m: 0.9602 - val_loss: 1.0667 - val_accuracy: 0.8691 - val_f1_m: 1.0078\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0162 - accuracy: 0.9964 - f1_m: 0.9558 - val_loss: 1.1363 - val_accuracy: 0.8714 - val_f1_m: 1.0012\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0076 - accuracy: 0.9981 - f1_m: 0.9521 - val_loss: 1.1547 - val_accuracy: 0.8726 - val_f1_m: 0.9967\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500/13500 [==============================] - 2s 139us/sample - loss: 0.0176 - accuracy: 0.9951 - f1_m: 0.9563 - val_loss: 1.1791 - val_accuracy: 0.8663 - val_f1_m: 1.0098\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0241 - accuracy: 0.9934 - f1_m: 0.9589 - val_loss: 1.2088 - val_accuracy: 0.8734 - val_f1_m: 0.9948\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0233 - accuracy: 0.9930 - f1_m: 0.9567 - val_loss: 1.2726 - val_accuracy: 0.8705 - val_f1_m: 0.9989\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 139us/sample - loss: 0.0124 - accuracy: 0.9964 - f1_m: 0.9541 - val_loss: 1.2216 - val_accuracy: 0.8726 - val_f1_m: 0.9980\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0087 - accuracy: 0.9973 - f1_m: 0.9529 - val_loss: 1.5278 - val_accuracy: 0.8746 - val_f1_m: 0.9899\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0151 - accuracy: 0.9959 - f1_m: 0.9539 - val_loss: 1.3730 - val_accuracy: 0.8620 - val_f1_m: 1.0013\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0177 - accuracy: 0.9950 - f1_m: 0.9548 - val_loss: 1.3569 - val_accuracy: 0.8688 - val_f1_m: 0.9996\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 3s 247us/sample - loss: 0.0591 - accuracy: 0.9839 - f1_m: 0.9727 - val_loss: 0.9706 - val_accuracy: 0.8548 - val_f1_m: 1.0363\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 183us/sample - loss: 0.0284 - accuracy: 0.9904 - f1_m: 0.9679 - val_loss: 1.0368 - val_accuracy: 0.8657 - val_f1_m: 1.0203\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 184us/sample - loss: 0.0371 - accuracy: 0.9887 - f1_m: 0.9672 - val_loss: 1.0671 - val_accuracy: 0.8505 - val_f1_m: 1.0220\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 184us/sample - loss: 0.0456 - accuracy: 0.9851 - f1_m: 0.9726 - val_loss: 1.0283 - val_accuracy: 0.8555 - val_f1_m: 1.0279\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 185us/sample - loss: 0.0355 - accuracy: 0.9893 - f1_m: 0.9685 - val_loss: 1.0530 - val_accuracy: 0.8549 - val_f1_m: 1.0316\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 183us/sample - loss: 0.0300 - accuracy: 0.9900 - f1_m: 0.9665 - val_loss: 1.1142 - val_accuracy: 0.8532 - val_f1_m: 1.0156\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 184us/sample - loss: 0.0353 - accuracy: 0.9885 - f1_m: 0.9641 - val_loss: 1.1392 - val_accuracy: 0.8568 - val_f1_m: 1.0149\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 183us/sample - loss: 0.0380 - accuracy: 0.9866 - f1_m: 0.9704 - val_loss: 1.0520 - val_accuracy: 0.8595 - val_f1_m: 1.0186\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 184us/sample - loss: 0.0314 - accuracy: 0.9899 - f1_m: 0.9648 - val_loss: 1.1706 - val_accuracy: 0.8563 - val_f1_m: 1.0058\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 183us/sample - loss: 0.0316 - accuracy: 0.9912 - f1_m: 0.9633 - val_loss: 1.0469 - val_accuracy: 0.8555 - val_f1_m: 1.0228\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 133us/sample - loss: 0.1135 - accuracy: 0.9679 - f1_m: 1.0359 - val_loss: 0.9712 - val_accuracy: 0.8402 - val_f1_m: 1.0601\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0979 - accuracy: 0.9711 - f1_m: 1.0320 - val_loss: 0.9883 - val_accuracy: 0.8298 - val_f1_m: 1.0698\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 1s 97us/sample - loss: 0.0975 - accuracy: 0.9691 - f1_m: 1.0366 - val_loss: 0.9902 - val_accuracy: 0.8357 - val_f1_m: 1.0707\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 109us/sample - loss: 0.0940 - accuracy: 0.9706 - f1_m: 1.0323 - val_loss: 0.9622 - val_accuracy: 0.8340 - val_f1_m: 1.0731\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 1s 97us/sample - loss: 0.0926 - accuracy: 0.9708 - f1_m: 1.0317 - val_loss: 0.9900 - val_accuracy: 0.8393 - val_f1_m: 1.0588\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0841 - accuracy: 0.9736 - f1_m: 1.0320 - val_loss: 0.9877 - val_accuracy: 0.8385 - val_f1_m: 1.0639\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0836 - accuracy: 0.9726 - f1_m: 1.0301 - val_loss: 0.9730 - val_accuracy: 0.8407 - val_f1_m: 1.0671\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0835 - accuracy: 0.9712 - f1_m: 1.0299 - val_loss: 0.9789 - val_accuracy: 0.8377 - val_f1_m: 1.0637\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0808 - accuracy: 0.9726 - f1_m: 1.0329 - val_loss: 0.9818 - val_accuracy: 0.8387 - val_f1_m: 1.0632\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0798 - accuracy: 0.9739 - f1_m: 1.0287 - val_loss: 0.9893 - val_accuracy: 0.8342 - val_f1_m: 1.0613\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 146us/sample - loss: 0.0897 - accuracy: 0.9743 - f1_m: 1.0023 - val_loss: 1.0120 - val_accuracy: 0.8548 - val_f1_m: 1.0440\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 1s 105us/sample - loss: 0.0746 - accuracy: 0.9769 - f1_m: 1.0003 - val_loss: 1.0193 - val_accuracy: 0.8515 - val_f1_m: 1.0320\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 1s 104us/sample - loss: 0.0650 - accuracy: 0.9802 - f1_m: 1.0031 - val_loss: 1.0299 - val_accuracy: 0.8553 - val_f1_m: 1.0355\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 1s 104us/sample - loss: 0.0669 - accuracy: 0.9774 - f1_m: 1.0006 - val_loss: 1.0033 - val_accuracy: 0.8583 - val_f1_m: 1.0336\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 1s 106us/sample - loss: 0.0582 - accuracy: 0.9804 - f1_m: 0.9996 - val_loss: 1.0219 - val_accuracy: 0.8603 - val_f1_m: 1.0304\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 1s 105us/sample - loss: 0.0559 - accuracy: 0.9805 - f1_m: 1.0007 - val_loss: 1.0280 - val_accuracy: 0.8537 - val_f1_m: 1.0358\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 1s 104us/sample - loss: 0.0525 - accuracy: 0.9831 - f1_m: 0.9946 - val_loss: 1.0500 - val_accuracy: 0.8578 - val_f1_m: 1.0339\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 1s 105us/sample - loss: 0.0549 - accuracy: 0.9802 - f1_m: 0.9953 - val_loss: 1.0274 - val_accuracy: 0.8585 - val_f1_m: 1.0370\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 1s 104us/sample - loss: 0.0479 - accuracy: 0.9838 - f1_m: 0.9955 - val_loss: 1.0725 - val_accuracy: 0.8587 - val_f1_m: 1.0251\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 1s 104us/sample - loss: 0.0453 - accuracy: 0.9841 - f1_m: 0.9934 - val_loss: 1.1285 - val_accuracy: 0.8483 - val_f1_m: 1.0370\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 5s 344us/sample - loss: 0.0731 - accuracy: 0.9809 - f1_m: 0.9803 - val_loss: 1.0787 - val_accuracy: 0.8605 - val_f1_m: 1.0239\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 129us/sample - loss: 0.0539 - accuracy: 0.9840 - f1_m: 0.9824 - val_loss: 1.1764 - val_accuracy: 0.8617 - val_f1_m: 1.0110\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 129us/sample - loss: 0.0417 - accuracy: 0.9875 - f1_m: 0.9727 - val_loss: 1.1871 - val_accuracy: 0.8548 - val_f1_m: 1.0217\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 128us/sample - loss: 0.0408 - accuracy: 0.9875 - f1_m: 0.9776 - val_loss: 1.1239 - val_accuracy: 0.8602 - val_f1_m: 1.0196\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 130us/sample - loss: 0.0400 - accuracy: 0.9866 - f1_m: 0.9778 - val_loss: 1.2372 - val_accuracy: 0.8517 - val_f1_m: 1.0120\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 129us/sample - loss: 0.0388 - accuracy: 0.9867 - f1_m: 0.9782 - val_loss: 1.2660 - val_accuracy: 0.8555 - val_f1_m: 1.0131\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 2s 127us/sample - loss: 0.0310 - accuracy: 0.9893 - f1_m: 0.9720 - val_loss: 1.2573 - val_accuracy: 0.8612 - val_f1_m: 1.0091\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 129us/sample - loss: 0.0295 - accuracy: 0.9899 - f1_m: 0.9718 - val_loss: 1.2377 - val_accuracy: 0.8570 - val_f1_m: 1.0145\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 129us/sample - loss: 0.0413 - accuracy: 0.9856 - f1_m: 0.9758 - val_loss: 1.2843 - val_accuracy: 0.8543 - val_f1_m: 1.0067\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 129us/sample - loss: 0.0307 - accuracy: 0.9898 - f1_m: 0.9721 - val_loss: 1.3369 - val_accuracy: 0.8555 - val_f1_m: 1.0092\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 3s 227us/sample - loss: 0.1087 - accuracy: 0.9644 - f1_m: 1.0167 - val_loss: 0.8174 - val_accuracy: 0.8500 - val_f1_m: 1.0611\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 166us/sample - loss: 0.0838 - accuracy: 0.9746 - f1_m: 1.0068 - val_loss: 0.8071 - val_accuracy: 0.8570 - val_f1_m: 1.0670\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 166us/sample - loss: 0.0816 - accuracy: 0.9721 - f1_m: 1.0109 - val_loss: 0.8361 - val_accuracy: 0.8485 - val_f1_m: 1.0597\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 165us/sample - loss: 0.0859 - accuracy: 0.9698 - f1_m: 1.0123 - val_loss: 0.8363 - val_accuracy: 0.8513 - val_f1_m: 1.0658\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 167us/sample - loss: 0.0749 - accuracy: 0.9751 - f1_m: 1.0064 - val_loss: 0.8460 - val_accuracy: 0.8520 - val_f1_m: 1.0507\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 167us/sample - loss: 0.0761 - accuracy: 0.9735 - f1_m: 1.0039 - val_loss: 0.9218 - val_accuracy: 0.8497 - val_f1_m: 1.0462\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 168us/sample - loss: 0.0803 - accuracy: 0.9721 - f1_m: 1.0097 - val_loss: 0.8883 - val_accuracy: 0.8542 - val_f1_m: 1.0479\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 167us/sample - loss: 0.0696 - accuracy: 0.9756 - f1_m: 1.0012 - val_loss: 0.8474 - val_accuracy: 0.8510 - val_f1_m: 1.0679\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 167us/sample - loss: 0.0721 - accuracy: 0.9726 - f1_m: 1.0055 - val_loss: 0.8697 - val_accuracy: 0.8537 - val_f1_m: 1.0503\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 166us/sample - loss: 0.0705 - accuracy: 0.9749 - f1_m: 1.0025 - val_loss: 0.9447 - val_accuracy: 0.8433 - val_f1_m: 1.0505\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 128us/sample - loss: 0.0416 - accuracy: 0.9922 - f1_m: 0.9587 - val_loss: 1.0282 - val_accuracy: 0.8687 - val_f1_m: 1.0155\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 1s 96us/sample - loss: 0.0188 - accuracy: 0.9955 - f1_m: 0.9578 - val_loss: 1.0733 - val_accuracy: 0.8713 - val_f1_m: 1.0083\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 1s 94us/sample - loss: 0.0076 - accuracy: 0.9979 - f1_m: 0.9543 - val_loss: 1.0725 - val_accuracy: 0.8703 - val_f1_m: 1.0073\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0098 - accuracy: 0.9968 - f1_m: 0.9549 - val_loss: 1.0490 - val_accuracy: 0.8708 - val_f1_m: 1.0144\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 1s 96us/sample - loss: 0.0095 - accuracy: 0.9971 - f1_m: 0.9535 - val_loss: 1.0700 - val_accuracy: 0.8705 - val_f1_m: 1.0104\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 1s 96us/sample - loss: 0.0030 - accuracy: 0.9995 - f1_m: 0.9496 - val_loss: 1.0910 - val_accuracy: 0.8757 - val_f1_m: 0.9997\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0073 - accuracy: 0.9983 - f1_m: 0.9514 - val_loss: 1.0830 - val_accuracy: 0.8720 - val_f1_m: 1.0062\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 0.0018 - accuracy: 0.9998 - f1_m: 0.9492 - val_loss: 1.0928 - val_accuracy: 0.8757 - val_f1_m: 0.9974\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 4.9438e-04 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 1.0911 - val_accuracy: 0.8770 - val_f1_m: 0.9985\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 1s 95us/sample - loss: 3.3031e-04 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 1.1046 - val_accuracy: 0.8773 - val_f1_m: 0.9973\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 147us/sample - loss: 0.0472 - accuracy: 0.9926 - f1_m: 0.9585 - val_loss: 0.9610 - val_accuracy: 0.8737 - val_f1_m: 1.0093\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 114us/sample - loss: 0.0230 - accuracy: 0.9944 - f1_m: 0.9571 - val_loss: 1.0864 - val_accuracy: 0.8652 - val_f1_m: 1.0053\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 111us/sample - loss: 0.0119 - accuracy: 0.9959 - f1_m: 0.9559 - val_loss: 1.1505 - val_accuracy: 0.8690 - val_f1_m: 1.0069\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 112us/sample - loss: 0.0075 - accuracy: 0.9975 - f1_m: 0.9523 - val_loss: 1.1011 - val_accuracy: 0.8697 - val_f1_m: 1.0003\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 111us/sample - loss: 0.0064 - accuracy: 0.9981 - f1_m: 0.9526 - val_loss: 1.1524 - val_accuracy: 0.8683 - val_f1_m: 0.9984\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 113us/sample - loss: 0.0057 - accuracy: 0.9981 - f1_m: 0.9514 - val_loss: 1.2224 - val_accuracy: 0.8692 - val_f1_m: 1.0040\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 112us/sample - loss: 0.0053 - accuracy: 0.9984 - f1_m: 0.9514 - val_loss: 1.2376 - val_accuracy: 0.8607 - val_f1_m: 0.9995\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 111us/sample - loss: 0.0160 - accuracy: 0.9941 - f1_m: 0.9588 - val_loss: 1.1383 - val_accuracy: 0.8700 - val_f1_m: 1.0073\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 111us/sample - loss: 0.0101 - accuracy: 0.9966 - f1_m: 0.9548 - val_loss: 1.1751 - val_accuracy: 0.8752 - val_f1_m: 0.9979\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 113us/sample - loss: 0.0053 - accuracy: 0.9984 - f1_m: 0.9511 - val_loss: 1.1764 - val_accuracy: 0.8733 - val_f1_m: 0.9960\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 3s 184us/sample - loss: 0.0535 - accuracy: 0.9909 - f1_m: 0.9599 - val_loss: 0.9873 - val_accuracy: 0.8710 - val_f1_m: 1.0078\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 138us/sample - loss: 0.0191 - accuracy: 0.9950 - f1_m: 0.9560 - val_loss: 1.0835 - val_accuracy: 0.8733 - val_f1_m: 1.0062\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 138us/sample - loss: 0.0116 - accuracy: 0.9972 - f1_m: 0.9531 - val_loss: 1.1154 - val_accuracy: 0.8648 - val_f1_m: 1.0156\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 141us/sample - loss: 0.0129 - accuracy: 0.9956 - f1_m: 0.9546 - val_loss: 1.2201 - val_accuracy: 0.8730 - val_f1_m: 0.9971\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 0.0186 - accuracy: 0.9940 - f1_m: 0.9562 - val_loss: 1.3192 - val_accuracy: 0.8643 - val_f1_m: 0.9932\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 138us/sample - loss: 0.0175 - accuracy: 0.9956 - f1_m: 0.9546 - val_loss: 1.1778 - val_accuracy: 0.8655 - val_f1_m: 1.0031\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 138us/sample - loss: 0.0123 - accuracy: 0.9956 - f1_m: 0.9564 - val_loss: 1.1624 - val_accuracy: 0.8718 - val_f1_m: 0.9960\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 0.0060 - accuracy: 0.9981 - f1_m: 0.9522 - val_loss: 1.3209 - val_accuracy: 0.8718 - val_f1_m: 0.9865\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 136us/sample - loss: 0.0113 - accuracy: 0.9967 - f1_m: 0.9533 - val_loss: 1.4390 - val_accuracy: 0.8697 - val_f1_m: 0.9907\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 2s 140us/sample - loss: 0.0155 - accuracy: 0.9948 - f1_m: 0.9553 - val_loss: 1.3472 - val_accuracy: 0.8692 - val_f1_m: 1.0002\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 3s 243us/sample - loss: 0.0727 - accuracy: 0.9829 - f1_m: 0.9771 - val_loss: 0.7891 - val_accuracy: 0.8630 - val_f1_m: 1.0469\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 3s 182us/sample - loss: 0.0335 - accuracy: 0.9901 - f1_m: 0.9712 - val_loss: 0.8089 - val_accuracy: 0.8640 - val_f1_m: 1.0341\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 3s 181us/sample - loss: 0.0380 - accuracy: 0.9879 - f1_m: 0.9702 - val_loss: 1.0180 - val_accuracy: 0.8587 - val_f1_m: 1.0298\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 3s 180us/sample - loss: 0.0410 - accuracy: 0.9872 - f1_m: 0.9699 - val_loss: 0.9415 - val_accuracy: 0.8550 - val_f1_m: 1.0396\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 3s 179us/sample - loss: 0.0292 - accuracy: 0.9901 - f1_m: 0.9680 - val_loss: 1.0288 - val_accuracy: 0.8570 - val_f1_m: 1.0309\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 3s 179us/sample - loss: 0.0312 - accuracy: 0.9894 - f1_m: 0.9662 - val_loss: 1.0556 - val_accuracy: 0.8523 - val_f1_m: 1.0267\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 3s 181us/sample - loss: 0.0501 - accuracy: 0.9839 - f1_m: 0.9719 - val_loss: 1.0465 - val_accuracy: 0.8538 - val_f1_m: 1.0251\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 3s 179us/sample - loss: 0.0378 - accuracy: 0.9884 - f1_m: 0.9693 - val_loss: 1.1484 - val_accuracy: 0.8572 - val_f1_m: 1.0230\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 3s 181us/sample - loss: 0.0399 - accuracy: 0.9872 - f1_m: 0.9686 - val_loss: 1.0538 - val_accuracy: 0.8590 - val_f1_m: 1.0314\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 3s 181us/sample - loss: 0.0253 - accuracy: 0.9916 - f1_m: 0.9662 - val_loss: 1.2928 - val_accuracy: 0.8585 - val_f1_m: 1.0035\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 125us/sample - loss: 0.0970 - accuracy: 0.9712 - f1_m: 1.0321 - val_loss: 1.0327 - val_accuracy: 0.8242 - val_f1_m: 1.0753\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 1s 93us/sample - loss: 0.0929 - accuracy: 0.9702 - f1_m: 1.0316 - val_loss: 0.9893 - val_accuracy: 0.8375 - val_f1_m: 1.0707\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0893 - accuracy: 0.9690 - f1_m: 1.0340 - val_loss: 0.9926 - val_accuracy: 0.8402 - val_f1_m: 1.0625\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0864 - accuracy: 0.9714 - f1_m: 1.0298 - val_loss: 0.9740 - val_accuracy: 0.8402 - val_f1_m: 1.0576\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 1s 91us/sample - loss: 0.0820 - accuracy: 0.9740 - f1_m: 1.0303 - val_loss: 1.0298 - val_accuracy: 0.8325 - val_f1_m: 1.0569\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0812 - accuracy: 0.9732 - f1_m: 1.0299 - val_loss: 1.0203 - val_accuracy: 0.8369 - val_f1_m: 1.0615\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0836 - accuracy: 0.9726 - f1_m: 1.0306 - val_loss: 1.0122 - val_accuracy: 0.8415 - val_f1_m: 1.0569\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0779 - accuracy: 0.9730 - f1_m: 1.0285 - val_loss: 0.9989 - val_accuracy: 0.8416 - val_f1_m: 1.0590\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 1s 93us/sample - loss: 0.0756 - accuracy: 0.9758 - f1_m: 1.0276 - val_loss: 1.0335 - val_accuracy: 0.8367 - val_f1_m: 1.0568\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0771 - accuracy: 0.9724 - f1_m: 1.0272 - val_loss: 1.0106 - val_accuracy: 0.8373 - val_f1_m: 1.0605\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 137us/sample - loss: 0.0726 - accuracy: 0.9767 - f1_m: 0.9989 - val_loss: 1.0464 - val_accuracy: 0.8562 - val_f1_m: 1.0388\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 1s 102us/sample - loss: 0.0623 - accuracy: 0.9803 - f1_m: 0.9957 - val_loss: 1.0539 - val_accuracy: 0.8505 - val_f1_m: 1.0282\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 1s 102us/sample - loss: 0.0638 - accuracy: 0.9768 - f1_m: 1.0035 - val_loss: 1.0113 - val_accuracy: 0.8558 - val_f1_m: 1.0397\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 1s 103us/sample - loss: 0.0549 - accuracy: 0.9819 - f1_m: 0.9944 - val_loss: 1.0797 - val_accuracy: 0.8480 - val_f1_m: 1.0454\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 1s 103us/sample - loss: 0.0496 - accuracy: 0.9823 - f1_m: 0.9963 - val_loss: 1.0368 - val_accuracy: 0.8571 - val_f1_m: 1.0288\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 1s 103us/sample - loss: 0.0538 - accuracy: 0.9809 - f1_m: 0.9971 - val_loss: 1.1222 - val_accuracy: 0.8455 - val_f1_m: 1.0407\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 1s 102us/sample - loss: 0.0519 - accuracy: 0.9817 - f1_m: 0.9963 - val_loss: 1.0656 - val_accuracy: 0.8505 - val_f1_m: 1.0384\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 105us/sample - loss: 0.0477 - accuracy: 0.9847 - f1_m: 0.9937 - val_loss: 1.0998 - val_accuracy: 0.8502 - val_f1_m: 1.0273\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 1s 102us/sample - loss: 0.0452 - accuracy: 0.9850 - f1_m: 0.9908 - val_loss: 1.0844 - val_accuracy: 0.8525 - val_f1_m: 1.0363\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 1s 103us/sample - loss: 0.0455 - accuracy: 0.9841 - f1_m: 0.9903 - val_loss: 1.0847 - val_accuracy: 0.8544 - val_f1_m: 1.0255\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 168us/sample - loss: 0.0664 - accuracy: 0.9827 - f1_m: 0.9804 - val_loss: 1.2296 - val_accuracy: 0.8558 - val_f1_m: 1.0204\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 124us/sample - loss: 0.0494 - accuracy: 0.9848 - f1_m: 0.9771 - val_loss: 1.0882 - val_accuracy: 0.8520 - val_f1_m: 1.0235\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 125us/sample - loss: 0.0436 - accuracy: 0.9868 - f1_m: 0.9775 - val_loss: 1.1892 - val_accuracy: 0.8578 - val_f1_m: 1.0092\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 126us/sample - loss: 0.0356 - accuracy: 0.9892 - f1_m: 0.9720 - val_loss: 1.2099 - val_accuracy: 0.8565 - val_f1_m: 1.0205\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 126us/sample - loss: 0.0504 - accuracy: 0.9825 - f1_m: 0.9821 - val_loss: 1.3500 - val_accuracy: 0.8558 - val_f1_m: 1.0100\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 123us/sample - loss: 0.0274 - accuracy: 0.9913 - f1_m: 0.9727 - val_loss: 1.2838 - val_accuracy: 0.8580 - val_f1_m: 0.9998\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 126us/sample - loss: 0.0295 - accuracy: 0.9891 - f1_m: 0.9698 - val_loss: 1.2794 - val_accuracy: 0.8467 - val_f1_m: 1.0093\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 124us/sample - loss: 0.0413 - accuracy: 0.9850 - f1_m: 0.9757 - val_loss: 1.3086 - val_accuracy: 0.8493 - val_f1_m: 1.0039\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 125us/sample - loss: 0.0326 - accuracy: 0.9899 - f1_m: 0.9716 - val_loss: 1.3457 - val_accuracy: 0.8575 - val_f1_m: 1.0045\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 124us/sample - loss: 0.0318 - accuracy: 0.9890 - f1_m: 0.9704 - val_loss: 1.3289 - val_accuracy: 0.8575 - val_f1_m: 1.0043\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 3s 220us/sample - loss: 0.0998 - accuracy: 0.9670 - f1_m: 1.0135 - val_loss: 0.7922 - val_accuracy: 0.8533 - val_f1_m: 1.0605\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 162us/sample - loss: 0.0750 - accuracy: 0.9754 - f1_m: 1.0061 - val_loss: 0.8404 - val_accuracy: 0.8540 - val_f1_m: 1.0577\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14500/14500 [==============================] - 2s 162us/sample - loss: 0.0783 - accuracy: 0.9732 - f1_m: 1.0070 - val_loss: 0.8534 - val_accuracy: 0.8525 - val_f1_m: 1.0514\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 162us/sample - loss: 0.0868 - accuracy: 0.9715 - f1_m: 1.0063 - val_loss: 0.8642 - val_accuracy: 0.8409 - val_f1_m: 1.0777\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 161us/sample - loss: 0.0753 - accuracy: 0.9725 - f1_m: 1.0072 - val_loss: 0.8667 - val_accuracy: 0.8584 - val_f1_m: 1.0503\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 161us/sample - loss: 0.0800 - accuracy: 0.9719 - f1_m: 1.0036 - val_loss: 0.8801 - val_accuracy: 0.8520 - val_f1_m: 1.0561\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 162us/sample - loss: 0.0750 - accuracy: 0.9729 - f1_m: 1.0040 - val_loss: 0.8908 - val_accuracy: 0.8473 - val_f1_m: 1.0466\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 161us/sample - loss: 0.0711 - accuracy: 0.9731 - f1_m: 1.0074 - val_loss: 0.9396 - val_accuracy: 0.8485 - val_f1_m: 1.0506\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 161us/sample - loss: 0.0729 - accuracy: 0.9748 - f1_m: 0.9987 - val_loss: 0.9330 - val_accuracy: 0.8387 - val_f1_m: 1.0525\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 161us/sample - loss: 0.0716 - accuracy: 0.9744 - f1_m: 1.0033 - val_loss: 0.8714 - val_accuracy: 0.8502 - val_f1_m: 1.0631\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 126us/sample - loss: 0.0301 - accuracy: 0.9939 - f1_m: 0.9579 - val_loss: 1.1063 - val_accuracy: 0.8691 - val_f1_m: 1.0033\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0177 - accuracy: 0.9950 - f1_m: 0.9556 - val_loss: 1.1083 - val_accuracy: 0.8684 - val_f1_m: 1.0101\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 1s 93us/sample - loss: 0.0108 - accuracy: 0.9974 - f1_m: 0.9540 - val_loss: 1.0890 - val_accuracy: 0.8700 - val_f1_m: 1.0094\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0065 - accuracy: 0.9983 - f1_m: 0.9528 - val_loss: 1.1374 - val_accuracy: 0.8704 - val_f1_m: 0.9990\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 1s 93us/sample - loss: 0.0019 - accuracy: 0.9997 - f1_m: 0.9499 - val_loss: 1.0910 - val_accuracy: 0.8735 - val_f1_m: 1.0029\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 1s 91us/sample - loss: 0.0142 - accuracy: 0.9954 - f1_m: 0.9581 - val_loss: 1.0979 - val_accuracy: 0.8687 - val_f1_m: 1.0087\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 0.0054 - accuracy: 0.9984 - f1_m: 0.9533 - val_loss: 1.0976 - val_accuracy: 0.8744 - val_f1_m: 1.0026\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 9.9274e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 1.1010 - val_accuracy: 0.8733 - val_f1_m: 1.0051\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 3.6633e-04 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 1.1071 - val_accuracy: 0.8747 - val_f1_m: 1.0029\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 1s 92us/sample - loss: 2.8002e-04 - accuracy: 1.0000 - f1_m: 0.9466 - val_loss: 1.1223 - val_accuracy: 0.8756 - val_f1_m: 1.0014\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 143us/sample - loss: 0.0366 - accuracy: 0.9926 - f1_m: 0.9587 - val_loss: 1.1353 - val_accuracy: 0.8678 - val_f1_m: 1.0025\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 108us/sample - loss: 0.0139 - accuracy: 0.9960 - f1_m: 0.9535 - val_loss: 1.0343 - val_accuracy: 0.8722 - val_f1_m: 1.0063\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 108us/sample - loss: 0.0068 - accuracy: 0.9985 - f1_m: 0.9528 - val_loss: 1.1716 - val_accuracy: 0.8718 - val_f1_m: 0.9982\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 110us/sample - loss: 0.0097 - accuracy: 0.9969 - f1_m: 0.9538 - val_loss: 1.1590 - val_accuracy: 0.8713 - val_f1_m: 0.9952\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9489 - val_loss: 1.1483 - val_accuracy: 0.8775 - val_f1_m: 0.9970\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 0.0084 - accuracy: 0.9972 - f1_m: 0.9529 - val_loss: 1.2549 - val_accuracy: 0.8709 - val_f1_m: 1.0009\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 0.0123 - accuracy: 0.9956 - f1_m: 0.9548 - val_loss: 1.3190 - val_accuracy: 0.8715 - val_f1_m: 0.9910\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 0.0141 - accuracy: 0.9957 - f1_m: 0.9537 - val_loss: 1.2636 - val_accuracy: 0.8602 - val_f1_m: 0.9912\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 108us/sample - loss: 0.0084 - accuracy: 0.9973 - f1_m: 0.9518 - val_loss: 1.1822 - val_accuracy: 0.8669 - val_f1_m: 0.9948\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 0.0130 - accuracy: 0.9961 - f1_m: 0.9543 - val_loss: 1.2308 - val_accuracy: 0.8682 - val_f1_m: 0.9989\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 3s 177us/sample - loss: 0.0465 - accuracy: 0.9909 - f1_m: 0.9595 - val_loss: 1.0507 - val_accuracy: 0.8731 - val_f1_m: 1.0185\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0175 - accuracy: 0.9951 - f1_m: 0.9547 - val_loss: 1.0206 - val_accuracy: 0.8700 - val_f1_m: 1.0165\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0081 - accuracy: 0.9977 - f1_m: 0.9529 - val_loss: 1.1964 - val_accuracy: 0.8722 - val_f1_m: 1.0050\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 133us/sample - loss: 0.0095 - accuracy: 0.9973 - f1_m: 0.9530 - val_loss: 1.3181 - val_accuracy: 0.8631 - val_f1_m: 0.9948\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0303 - accuracy: 0.9898 - f1_m: 0.9610 - val_loss: 1.1985 - val_accuracy: 0.8698 - val_f1_m: 0.9977\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0203 - accuracy: 0.9941 - f1_m: 0.9567 - val_loss: 1.2941 - val_accuracy: 0.8631 - val_f1_m: 0.9983\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0067 - accuracy: 0.9977 - f1_m: 0.9529 - val_loss: 1.3252 - val_accuracy: 0.8747 - val_f1_m: 0.9959\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0123 - accuracy: 0.9957 - f1_m: 0.9539 - val_loss: 1.4346 - val_accuracy: 0.8695 - val_f1_m: 0.9844\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0156 - accuracy: 0.9948 - f1_m: 0.9540 - val_loss: 1.3492 - val_accuracy: 0.8684 - val_f1_m: 1.0001\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0305 - accuracy: 0.9908 - f1_m: 0.9605 - val_loss: 1.3253 - val_accuracy: 0.8718 - val_f1_m: 0.9961\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 3s 236us/sample - loss: 0.0658 - accuracy: 0.9833 - f1_m: 0.9727 - val_loss: 0.9061 - val_accuracy: 0.8591 - val_f1_m: 1.0339\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 3s 177us/sample - loss: 0.0309 - accuracy: 0.9910 - f1_m: 0.9665 - val_loss: 1.1674 - val_accuracy: 0.8564 - val_f1_m: 1.0170\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 3s 177us/sample - loss: 0.0319 - accuracy: 0.9896 - f1_m: 0.9664 - val_loss: 1.1505 - val_accuracy: 0.8589 - val_f1_m: 1.0148\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 3s 175us/sample - loss: 0.0353 - accuracy: 0.9892 - f1_m: 0.9671 - val_loss: 1.0619 - val_accuracy: 0.8609 - val_f1_m: 1.0229\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 3s 176us/sample - loss: 0.0327 - accuracy: 0.9895 - f1_m: 0.9661 - val_loss: 1.1734 - val_accuracy: 0.8625 - val_f1_m: 1.0100\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14500/14500 [==============================] - 3s 177us/sample - loss: 0.0510 - accuracy: 0.9828 - f1_m: 0.9723 - val_loss: 1.1310 - val_accuracy: 0.8600 - val_f1_m: 1.0105\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 3s 176us/sample - loss: 0.0282 - accuracy: 0.9907 - f1_m: 0.9650 - val_loss: 1.2437 - val_accuracy: 0.8578 - val_f1_m: 1.0079\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 3s 177us/sample - loss: 0.0403 - accuracy: 0.9870 - f1_m: 0.9678 - val_loss: 1.2128 - val_accuracy: 0.8556 - val_f1_m: 1.0135\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 3s 176us/sample - loss: 0.0284 - accuracy: 0.9912 - f1_m: 0.9640 - val_loss: 1.1579 - val_accuracy: 0.8591 - val_f1_m: 1.0113\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 3s 175us/sample - loss: 0.0248 - accuracy: 0.9917 - f1_m: 0.9620 - val_loss: 1.1930 - val_accuracy: 0.8598 - val_f1_m: 1.0087\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 122us/sample - loss: 0.1041 - accuracy: 0.9708 - f1_m: 1.0323 - val_loss: 1.0135 - val_accuracy: 0.8420 - val_f1_m: 1.0536\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 1s 91us/sample - loss: 0.0986 - accuracy: 0.9709 - f1_m: 1.0291 - val_loss: 1.0472 - val_accuracy: 0.8388 - val_f1_m: 1.0630\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.0928 - accuracy: 0.9723 - f1_m: 1.0269 - val_loss: 1.0377 - val_accuracy: 0.8352 - val_f1_m: 1.0531\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.0901 - accuracy: 0.9724 - f1_m: 1.0333 - val_loss: 1.0586 - val_accuracy: 0.8340 - val_f1_m: 1.0604\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 1s 91us/sample - loss: 0.0832 - accuracy: 0.9739 - f1_m: 1.0304 - val_loss: 1.0224 - val_accuracy: 0.8418 - val_f1_m: 1.0558\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0825 - accuracy: 0.9743 - f1_m: 1.0307 - val_loss: 1.0855 - val_accuracy: 0.8386 - val_f1_m: 1.0446\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.0812 - accuracy: 0.9725 - f1_m: 1.0337 - val_loss: 1.0759 - val_accuracy: 0.8424 - val_f1_m: 1.0484\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0792 - accuracy: 0.9748 - f1_m: 1.0292 - val_loss: 1.0349 - val_accuracy: 0.8356 - val_f1_m: 1.0590\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.0766 - accuracy: 0.9759 - f1_m: 1.0280 - val_loss: 1.0708 - val_accuracy: 0.8330 - val_f1_m: 1.0517\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0772 - accuracy: 0.9745 - f1_m: 1.0274 - val_loss: 1.0352 - val_accuracy: 0.8398 - val_f1_m: 1.0557\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 134us/sample - loss: 0.0777 - accuracy: 0.9775 - f1_m: 0.9994 - val_loss: 1.0371 - val_accuracy: 0.8608 - val_f1_m: 1.0230\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 100us/sample - loss: 0.0681 - accuracy: 0.9798 - f1_m: 0.9939 - val_loss: 1.0595 - val_accuracy: 0.8510 - val_f1_m: 1.0356\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 1s 100us/sample - loss: 0.0621 - accuracy: 0.9812 - f1_m: 0.9995 - val_loss: 1.0933 - val_accuracy: 0.8550 - val_f1_m: 1.0333\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 1s 100us/sample - loss: 0.0582 - accuracy: 0.9827 - f1_m: 0.9933 - val_loss: 1.0284 - val_accuracy: 0.8624 - val_f1_m: 1.0299\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 100us/sample - loss: 0.0509 - accuracy: 0.9837 - f1_m: 0.9925 - val_loss: 1.0335 - val_accuracy: 0.8582 - val_f1_m: 1.0257\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 1s 98us/sample - loss: 0.0519 - accuracy: 0.9827 - f1_m: 0.9944 - val_loss: 1.0226 - val_accuracy: 0.8582 - val_f1_m: 1.0230\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 1s 100us/sample - loss: 0.0465 - accuracy: 0.9841 - f1_m: 0.9919 - val_loss: 1.0497 - val_accuracy: 0.8496 - val_f1_m: 1.0241\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 1s 100us/sample - loss: 0.0534 - accuracy: 0.9813 - f1_m: 0.9944 - val_loss: 1.0493 - val_accuracy: 0.8554 - val_f1_m: 1.0281\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.0475 - accuracy: 0.9835 - f1_m: 0.9942 - val_loss: 1.0801 - val_accuracy: 0.8576 - val_f1_m: 1.0261\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 100us/sample - loss: 0.0504 - accuracy: 0.9837 - f1_m: 0.9906 - val_loss: 1.1184 - val_accuracy: 0.8570 - val_f1_m: 1.0218\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0715 - accuracy: 0.9818 - f1_m: 0.9785 - val_loss: 1.1933 - val_accuracy: 0.8544 - val_f1_m: 1.0145\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 123us/sample - loss: 0.0461 - accuracy: 0.9873 - f1_m: 0.9745 - val_loss: 1.1278 - val_accuracy: 0.8594 - val_f1_m: 1.0195\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 122us/sample - loss: 0.0374 - accuracy: 0.9882 - f1_m: 0.9738 - val_loss: 1.2277 - val_accuracy: 0.8514 - val_f1_m: 1.0192\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 123us/sample - loss: 0.0374 - accuracy: 0.9886 - f1_m: 0.9755 - val_loss: 1.2459 - val_accuracy: 0.8582 - val_f1_m: 1.0158\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 123us/sample - loss: 0.0508 - accuracy: 0.9835 - f1_m: 0.9799 - val_loss: 1.1466 - val_accuracy: 0.8564 - val_f1_m: 1.0187\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 123us/sample - loss: 0.0397 - accuracy: 0.9859 - f1_m: 0.9759 - val_loss: 1.1540 - val_accuracy: 0.8542 - val_f1_m: 1.0219\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 123us/sample - loss: 0.0294 - accuracy: 0.9907 - f1_m: 0.9711 - val_loss: 1.2533 - val_accuracy: 0.8542 - val_f1_m: 1.0118\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 122us/sample - loss: 0.0338 - accuracy: 0.9889 - f1_m: 0.9717 - val_loss: 1.2888 - val_accuracy: 0.8554 - val_f1_m: 1.0072\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 122us/sample - loss: 0.0328 - accuracy: 0.9890 - f1_m: 0.9737 - val_loss: 1.3152 - val_accuracy: 0.8582 - val_f1_m: 1.0013\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 123us/sample - loss: 0.0296 - accuracy: 0.9899 - f1_m: 0.9688 - val_loss: 1.3647 - val_accuracy: 0.8546 - val_f1_m: 1.0066\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 3s 214us/sample - loss: 0.0990 - accuracy: 0.9684 - f1_m: 1.0089 - val_loss: 0.8419 - val_accuracy: 0.8400 - val_f1_m: 1.0783\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 163us/sample - loss: 0.0805 - accuracy: 0.9733 - f1_m: 1.0075 - val_loss: 0.7864 - val_accuracy: 0.8508 - val_f1_m: 1.0699\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 159us/sample - loss: 0.0765 - accuracy: 0.9727 - f1_m: 1.0071 - val_loss: 0.8901 - val_accuracy: 0.8528 - val_f1_m: 1.0434\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 159us/sample - loss: 0.0779 - accuracy: 0.9723 - f1_m: 1.0061 - val_loss: 0.8999 - val_accuracy: 0.8544 - val_f1_m: 1.0520\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 160us/sample - loss: 0.0798 - accuracy: 0.9723 - f1_m: 1.0071 - val_loss: 0.8570 - val_accuracy: 0.8492 - val_f1_m: 1.0551\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 159us/sample - loss: 0.0692 - accuracy: 0.9750 - f1_m: 1.0037 - val_loss: 0.9677 - val_accuracy: 0.8462 - val_f1_m: 1.0425\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 158us/sample - loss: 0.0847 - accuracy: 0.9693 - f1_m: 1.0077 - val_loss: 0.7827 - val_accuracy: 0.8482 - val_f1_m: 1.0627\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 159us/sample - loss: 0.0740 - accuracy: 0.9739 - f1_m: 1.0072 - val_loss: 0.9715 - val_accuracy: 0.8452 - val_f1_m: 1.0286\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 159us/sample - loss: 0.0755 - accuracy: 0.9743 - f1_m: 1.0026 - val_loss: 0.9038 - val_accuracy: 0.8452 - val_f1_m: 1.0485\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 158us/sample - loss: 0.0625 - accuracy: 0.9766 - f1_m: 1.0004 - val_loss: 0.8267 - val_accuracy: 0.8546 - val_f1_m: 1.0523\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 121us/sample - loss: 0.0436 - accuracy: 0.9927 - f1_m: 0.9588 - val_loss: 1.1182 - val_accuracy: 0.8650 - val_f1_m: 1.0068\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.0213 - accuracy: 0.9959 - f1_m: 0.9568 - val_loss: 1.0599 - val_accuracy: 0.8662 - val_f1_m: 1.0071\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.0102 - accuracy: 0.9977 - f1_m: 0.9538 - val_loss: 1.0803 - val_accuracy: 0.8694 - val_f1_m: 1.0063\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0088 - accuracy: 0.9968 - f1_m: 0.9546 - val_loss: 1.1532 - val_accuracy: 0.8730 - val_f1_m: 1.0041\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0054 - accuracy: 0.9987 - f1_m: 0.9517 - val_loss: 1.1376 - val_accuracy: 0.8678 - val_f1_m: 1.0070\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0130 - accuracy: 0.9959 - f1_m: 0.9561 - val_loss: 1.2869 - val_accuracy: 0.8640 - val_f1_m: 1.0061\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0097 - accuracy: 0.9972 - f1_m: 0.9558 - val_loss: 1.1442 - val_accuracy: 0.8726 - val_f1_m: 0.9959\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0021 - accuracy: 0.9997 - f1_m: 0.9493 - val_loss: 1.1791 - val_accuracy: 0.8720 - val_f1_m: 1.0023\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9491 - val_loss: 1.1619 - val_accuracy: 0.8758 - val_f1_m: 1.0048\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 5.3952e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 1.1726 - val_accuracy: 0.8758 - val_f1_m: 0.9956\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 142us/sample - loss: 0.0367 - accuracy: 0.9943 - f1_m: 0.9566 - val_loss: 1.1252 - val_accuracy: 0.8708 - val_f1_m: 1.0064\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 0.0174 - accuracy: 0.9963 - f1_m: 0.9548 - val_loss: 1.1136 - val_accuracy: 0.8686 - val_f1_m: 1.0045\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 0.0125 - accuracy: 0.9968 - f1_m: 0.9554 - val_loss: 1.2049 - val_accuracy: 0.8660 - val_f1_m: 0.9971\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 0.0056 - accuracy: 0.9983 - f1_m: 0.9517 - val_loss: 1.2468 - val_accuracy: 0.8714 - val_f1_m: 0.9899\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 0.0078 - accuracy: 0.9980 - f1_m: 0.9518 - val_loss: 1.2803 - val_accuracy: 0.8624 - val_f1_m: 0.9874\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 0.0191 - accuracy: 0.9943 - f1_m: 0.9585 - val_loss: 1.1869 - val_accuracy: 0.8706 - val_f1_m: 1.0010\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 0.0034 - accuracy: 0.9987 - f1_m: 0.9506 - val_loss: 1.2063 - val_accuracy: 0.8728 - val_f1_m: 0.9923\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 0.0055 - accuracy: 0.9985 - f1_m: 0.9494 - val_loss: 1.2862 - val_accuracy: 0.8668 - val_f1_m: 0.9934\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 0.0135 - accuracy: 0.9953 - f1_m: 0.9546 - val_loss: 1.1702 - val_accuracy: 0.8666 - val_f1_m: 0.9898\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 0.0014 - accuracy: 0.9995 - f1_m: 0.9486 - val_loss: 1.1711 - val_accuracy: 0.8726 - val_f1_m: 0.9941\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 5s 347us/sample - loss: 0.0488 - accuracy: 0.9912 - f1_m: 0.9589 - val_loss: 1.0036 - val_accuracy: 0.8688 - val_f1_m: 1.0142\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0183 - accuracy: 0.9953 - f1_m: 0.9565 - val_loss: 1.1336 - val_accuracy: 0.8706 - val_f1_m: 1.0094\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0066 - accuracy: 0.9982 - f1_m: 0.9531 - val_loss: 1.2070 - val_accuracy: 0.8758 - val_f1_m: 0.9953\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0030 - accuracy: 0.9989 - f1_m: 0.9499 - val_loss: 1.4505 - val_accuracy: 0.8734 - val_f1_m: 0.9870\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 129us/sample - loss: 0.0171 - accuracy: 0.9953 - f1_m: 0.9548 - val_loss: 1.3462 - val_accuracy: 0.8700 - val_f1_m: 0.9945\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0166 - accuracy: 0.9940 - f1_m: 0.9572 - val_loss: 1.4005 - val_accuracy: 0.8702 - val_f1_m: 0.9866\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0181 - accuracy: 0.9947 - f1_m: 0.9540 - val_loss: 1.3265 - val_accuracy: 0.8738 - val_f1_m: 0.9948\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0143 - accuracy: 0.9953 - f1_m: 0.9536 - val_loss: 1.4329 - val_accuracy: 0.8696 - val_f1_m: 0.9968\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 129us/sample - loss: 0.0209 - accuracy: 0.9942 - f1_m: 0.9547 - val_loss: 1.2653 - val_accuracy: 0.8712 - val_f1_m: 1.0013\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0144 - accuracy: 0.9959 - f1_m: 0.9536 - val_loss: 1.4037 - val_accuracy: 0.8646 - val_f1_m: 0.9917\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 3s 229us/sample - loss: 0.0594 - accuracy: 0.9841 - f1_m: 0.9716 - val_loss: 0.9611 - val_accuracy: 0.8596 - val_f1_m: 1.0273\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0365 - accuracy: 0.9887 - f1_m: 0.9703 - val_loss: 1.1642 - val_accuracy: 0.8620 - val_f1_m: 1.0130\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0384 - accuracy: 0.9879 - f1_m: 0.9662 - val_loss: 1.0730 - val_accuracy: 0.8580 - val_f1_m: 1.0229\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0382 - accuracy: 0.9883 - f1_m: 0.9682 - val_loss: 1.0825 - val_accuracy: 0.8590 - val_f1_m: 1.0161\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0305 - accuracy: 0.9903 - f1_m: 0.9652 - val_loss: 1.3019 - val_accuracy: 0.8634 - val_f1_m: 1.0024\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 3s 174us/sample - loss: 0.0619 - accuracy: 0.9806 - f1_m: 0.9749 - val_loss: 1.1143 - val_accuracy: 0.8552 - val_f1_m: 1.0180\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0237 - accuracy: 0.9919 - f1_m: 0.9626 - val_loss: 1.4836 - val_accuracy: 0.8560 - val_f1_m: 1.0021\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 3s 174us/sample - loss: 0.0202 - accuracy: 0.9941 - f1_m: 0.9595 - val_loss: 1.2434 - val_accuracy: 0.8632 - val_f1_m: 1.0077\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 3s 172us/sample - loss: 0.0262 - accuracy: 0.9912 - f1_m: 0.9613 - val_loss: 1.4710 - val_accuracy: 0.8458 - val_f1_m: 1.0018\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 3s 173us/sample - loss: 0.0490 - accuracy: 0.9857 - f1_m: 0.9706 - val_loss: 1.1154 - val_accuracy: 0.8614 - val_f1_m: 1.0111\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 118us/sample - loss: 0.0951 - accuracy: 0.9717 - f1_m: 1.0304 - val_loss: 1.0873 - val_accuracy: 0.8378 - val_f1_m: 1.0558\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0952 - accuracy: 0.9710 - f1_m: 1.0297 - val_loss: 1.0902 - val_accuracy: 0.8393 - val_f1_m: 1.0569\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0867 - accuracy: 0.9726 - f1_m: 1.0314 - val_loss: 1.0808 - val_accuracy: 0.8400 - val_f1_m: 1.0598\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 1s 87us/sample - loss: 0.0848 - accuracy: 0.9730 - f1_m: 1.0264 - val_loss: 1.0649 - val_accuracy: 0.8449 - val_f1_m: 1.0578\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0822 - accuracy: 0.9737 - f1_m: 1.0306 - val_loss: 1.0868 - val_accuracy: 0.8402 - val_f1_m: 1.0496\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0799 - accuracy: 0.9748 - f1_m: 1.0299 - val_loss: 1.1089 - val_accuracy: 0.8367 - val_f1_m: 1.0558\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 1s 87us/sample - loss: 0.0746 - accuracy: 0.9753 - f1_m: 1.0239 - val_loss: 1.0990 - val_accuracy: 0.8404 - val_f1_m: 1.0587\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0789 - accuracy: 0.9741 - f1_m: 1.0270 - val_loss: 1.0817 - val_accuracy: 0.8404 - val_f1_m: 1.0569\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 1s 87us/sample - loss: 0.0762 - accuracy: 0.9752 - f1_m: 1.0261 - val_loss: 1.0997 - val_accuracy: 0.8418 - val_f1_m: 1.0518\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 1s 86us/sample - loss: 0.0779 - accuracy: 0.9731 - f1_m: 1.0248 - val_loss: 1.1075 - val_accuracy: 0.8393 - val_f1_m: 1.0548\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 130us/sample - loss: 0.0725 - accuracy: 0.9786 - f1_m: 0.9962 - val_loss: 1.1131 - val_accuracy: 0.8596 - val_f1_m: 1.0255\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 97us/sample - loss: 0.0710 - accuracy: 0.9785 - f1_m: 0.9983 - val_loss: 1.0540 - val_accuracy: 0.8549 - val_f1_m: 1.0247\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 98us/sample - loss: 0.0631 - accuracy: 0.9812 - f1_m: 0.9941 - val_loss: 1.0662 - val_accuracy: 0.8609 - val_f1_m: 1.0200\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 97us/sample - loss: 0.0552 - accuracy: 0.9831 - f1_m: 0.9916 - val_loss: 1.0889 - val_accuracy: 0.8518 - val_f1_m: 1.0268\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 98us/sample - loss: 0.0537 - accuracy: 0.9821 - f1_m: 0.9933 - val_loss: 1.0895 - val_accuracy: 0.8547 - val_f1_m: 1.0251\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 97us/sample - loss: 0.0503 - accuracy: 0.9832 - f1_m: 0.9931 - val_loss: 1.0776 - val_accuracy: 0.8564 - val_f1_m: 1.0271\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 97us/sample - loss: 0.0537 - accuracy: 0.9821 - f1_m: 0.9942 - val_loss: 1.1525 - val_accuracy: 0.8551 - val_f1_m: 1.0264\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 98us/sample - loss: 0.0582 - accuracy: 0.9790 - f1_m: 0.9962 - val_loss: 1.1355 - val_accuracy: 0.8562 - val_f1_m: 1.0303\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 97us/sample - loss: 0.0461 - accuracy: 0.9848 - f1_m: 0.9921 - val_loss: 1.1043 - val_accuracy: 0.8549 - val_f1_m: 1.0266\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 97us/sample - loss: 0.0494 - accuracy: 0.9821 - f1_m: 0.9908 - val_loss: 1.1344 - val_accuracy: 0.8591 - val_f1_m: 1.0228\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 160us/sample - loss: 0.0721 - accuracy: 0.9804 - f1_m: 0.9799 - val_loss: 1.1169 - val_accuracy: 0.8498 - val_f1_m: 1.0296\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 119us/sample - loss: 0.0459 - accuracy: 0.9874 - f1_m: 0.9763 - val_loss: 1.2299 - val_accuracy: 0.8520 - val_f1_m: 1.0132\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 120us/sample - loss: 0.0386 - accuracy: 0.9902 - f1_m: 0.9703 - val_loss: 1.2185 - val_accuracy: 0.8511 - val_f1_m: 1.0132\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 121us/sample - loss: 0.0492 - accuracy: 0.9848 - f1_m: 0.9785 - val_loss: 1.2104 - val_accuracy: 0.8498 - val_f1_m: 1.0040\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 119us/sample - loss: 0.0411 - accuracy: 0.9862 - f1_m: 0.9766 - val_loss: 1.2106 - val_accuracy: 0.8553 - val_f1_m: 1.0149\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 120us/sample - loss: 0.0463 - accuracy: 0.9843 - f1_m: 0.9789 - val_loss: 1.1716 - val_accuracy: 0.8587 - val_f1_m: 1.0162\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 119us/sample - loss: 0.0326 - accuracy: 0.9888 - f1_m: 0.9751 - val_loss: 1.2013 - val_accuracy: 0.8571 - val_f1_m: 1.0180\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 119us/sample - loss: 0.0276 - accuracy: 0.9908 - f1_m: 0.9725 - val_loss: 1.2666 - val_accuracy: 0.8613 - val_f1_m: 0.9972\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 119us/sample - loss: 0.0370 - accuracy: 0.9875 - f1_m: 0.9731 - val_loss: 1.2075 - val_accuracy: 0.8567 - val_f1_m: 1.0185\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 120us/sample - loss: 0.0321 - accuracy: 0.9888 - f1_m: 0.9732 - val_loss: 1.3169 - val_accuracy: 0.8531 - val_f1_m: 1.0053\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 3s 209us/sample - loss: 0.0936 - accuracy: 0.9706 - f1_m: 1.0110 - val_loss: 0.8629 - val_accuracy: 0.8529 - val_f1_m: 1.0500\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 155us/sample - loss: 0.0927 - accuracy: 0.9692 - f1_m: 1.0139 - val_loss: 0.7984 - val_accuracy: 0.8476 - val_f1_m: 1.0658\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 155us/sample - loss: 0.0807 - accuracy: 0.9729 - f1_m: 1.0085 - val_loss: 0.8528 - val_accuracy: 0.8533 - val_f1_m: 1.0483\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 158us/sample - loss: 0.0857 - accuracy: 0.9712 - f1_m: 1.0126 - val_loss: 0.8807 - val_accuracy: 0.8513 - val_f1_m: 1.0498\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 3s 163us/sample - loss: 0.0644 - accuracy: 0.9769 - f1_m: 1.0020 - val_loss: 0.8974 - val_accuracy: 0.8433 - val_f1_m: 1.0628\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 156us/sample - loss: 0.0890 - accuracy: 0.9691 - f1_m: 1.0105 - val_loss: 0.8316 - val_accuracy: 0.8424 - val_f1_m: 1.0767\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 157us/sample - loss: 0.0601 - accuracy: 0.9789 - f1_m: 1.0007 - val_loss: 0.9443 - val_accuracy: 0.8509 - val_f1_m: 1.0523\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 157us/sample - loss: 0.0689 - accuracy: 0.9751 - f1_m: 1.0034 - val_loss: 1.0008 - val_accuracy: 0.8520 - val_f1_m: 1.0407\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 156us/sample - loss: 0.0859 - accuracy: 0.9716 - f1_m: 1.0068 - val_loss: 0.8991 - val_accuracy: 0.8456 - val_f1_m: 1.0509\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 155us/sample - loss: 0.0714 - accuracy: 0.9759 - f1_m: 1.0036 - val_loss: 0.8709 - val_accuracy: 0.8480 - val_f1_m: 1.0522\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 117us/sample - loss: 0.0351 - accuracy: 0.9938 - f1_m: 0.9577 - val_loss: 1.2309 - val_accuracy: 0.8649 - val_f1_m: 0.9971\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 1s 87us/sample - loss: 0.0171 - accuracy: 0.9961 - f1_m: 0.9564 - val_loss: 1.2315 - val_accuracy: 0.8658 - val_f1_m: 1.0108\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 1s 87us/sample - loss: 0.0142 - accuracy: 0.9963 - f1_m: 0.9568 - val_loss: 1.1908 - val_accuracy: 0.8644 - val_f1_m: 1.0078\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 1s 89us/sample - loss: 0.0089 - accuracy: 0.9974 - f1_m: 0.9534 - val_loss: 1.1744 - val_accuracy: 0.8727 - val_f1_m: 0.9997\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0036 - accuracy: 0.9994 - f1_m: 0.9506 - val_loss: 1.1804 - val_accuracy: 0.8740 - val_f1_m: 0.9974\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0058 - accuracy: 0.9985 - f1_m: 0.9525 - val_loss: 1.2280 - val_accuracy: 0.8716 - val_f1_m: 1.0014\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 1s 87us/sample - loss: 0.0154 - accuracy: 0.9945 - f1_m: 0.9584 - val_loss: 1.1824 - val_accuracy: 0.8753 - val_f1_m: 1.0029\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 0.0045 - accuracy: 0.9989 - f1_m: 0.9517 - val_loss: 1.1979 - val_accuracy: 0.8749 - val_f1_m: 0.9916\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 7.3329e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 1.1904 - val_accuracy: 0.8776 - val_f1_m: 0.9908\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 1s 88us/sample - loss: 3.6633e-04 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 1.1942 - val_accuracy: 0.8782 - val_f1_m: 0.9878\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 137us/sample - loss: 0.0402 - accuracy: 0.9939 - f1_m: 0.9551 - val_loss: 1.1471 - val_accuracy: 0.8684 - val_f1_m: 1.0025\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 103us/sample - loss: 0.0220 - accuracy: 0.9957 - f1_m: 0.9576 - val_loss: 1.1498 - val_accuracy: 0.8687 - val_f1_m: 1.0021\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 0.0101 - accuracy: 0.9973 - f1_m: 0.9533 - val_loss: 1.2745 - val_accuracy: 0.8616 - val_f1_m: 1.0017\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 0.0120 - accuracy: 0.9962 - f1_m: 0.9552 - val_loss: 1.2119 - val_accuracy: 0.8736 - val_f1_m: 0.9960\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 105us/sample - loss: 0.0089 - accuracy: 0.9971 - f1_m: 0.9518 - val_loss: 1.2067 - val_accuracy: 0.8709 - val_f1_m: 1.0000\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 0.0071 - accuracy: 0.9976 - f1_m: 0.9521 - val_loss: 1.1875 - val_accuracy: 0.8780 - val_f1_m: 0.9970\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 0.0022 - accuracy: 0.9993 - f1_m: 0.9487 - val_loss: 1.2493 - val_accuracy: 0.8760 - val_f1_m: 0.9848\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 103us/sample - loss: 4.1715e-04 - accuracy: 0.9999 - f1_m: 0.9472 - val_loss: 1.2586 - val_accuracy: 0.8769 - val_f1_m: 0.9862\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 1.0821e-04 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 1.2689 - val_accuracy: 0.8762 - val_f1_m: 0.9857\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 7.5253e-05 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 1.2875 - val_accuracy: 0.8778 - val_f1_m: 0.9849\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 3s 168us/sample - loss: 0.0435 - accuracy: 0.9915 - f1_m: 0.9586 - val_loss: 1.1267 - val_accuracy: 0.8704 - val_f1_m: 1.0066\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 128us/sample - loss: 0.0168 - accuracy: 0.9952 - f1_m: 0.9555 - val_loss: 1.1406 - val_accuracy: 0.8696 - val_f1_m: 1.0043\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0165 - accuracy: 0.9956 - f1_m: 0.9551 - val_loss: 1.2170 - val_accuracy: 0.8667 - val_f1_m: 0.9977\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 126us/sample - loss: 0.0082 - accuracy: 0.9972 - f1_m: 0.9527 - val_loss: 1.3447 - val_accuracy: 0.8689 - val_f1_m: 0.9952\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0238 - accuracy: 0.9938 - f1_m: 0.9561 - val_loss: 1.2155 - val_accuracy: 0.8689 - val_f1_m: 1.0003\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0204 - accuracy: 0.9932 - f1_m: 0.9571 - val_loss: 1.4464 - val_accuracy: 0.8713 - val_f1_m: 0.9928\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0174 - accuracy: 0.9954 - f1_m: 0.9535 - val_loss: 1.3595 - val_accuracy: 0.8764 - val_f1_m: 0.9912\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 128us/sample - loss: 0.0097 - accuracy: 0.9972 - f1_m: 0.9523 - val_loss: 1.4226 - val_accuracy: 0.8724 - val_f1_m: 0.9923\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0081 - accuracy: 0.9970 - f1_m: 0.9524 - val_loss: 1.4851 - val_accuracy: 0.8707 - val_f1_m: 0.9863\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 128us/sample - loss: 0.0217 - accuracy: 0.9938 - f1_m: 0.9554 - val_loss: 1.5249 - val_accuracy: 0.8673 - val_f1_m: 0.9908\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 3s 223us/sample - loss: 0.0530 - accuracy: 0.9852 - f1_m: 0.9709 - val_loss: 1.2450 - val_accuracy: 0.8527 - val_f1_m: 1.0135\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 3s 168us/sample - loss: 0.0325 - accuracy: 0.9903 - f1_m: 0.9664 - val_loss: 1.0573 - val_accuracy: 0.8600 - val_f1_m: 1.0229\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 3s 170us/sample - loss: 0.0143 - accuracy: 0.9959 - f1_m: 0.9569 - val_loss: 1.2018 - val_accuracy: 0.8696 - val_f1_m: 1.0096\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 3s 169us/sample - loss: 0.0347 - accuracy: 0.9887 - f1_m: 0.9655 - val_loss: 1.2753 - val_accuracy: 0.8473 - val_f1_m: 1.0182\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 3s 169us/sample - loss: 0.0493 - accuracy: 0.9843 - f1_m: 0.9746 - val_loss: 1.0249 - val_accuracy: 0.8469 - val_f1_m: 1.0414\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 3s 170us/sample - loss: 0.0333 - accuracy: 0.9896 - f1_m: 0.9662 - val_loss: 1.4043 - val_accuracy: 0.8484 - val_f1_m: 1.0145\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 3s 170us/sample - loss: 0.0399 - accuracy: 0.9872 - f1_m: 0.9679 - val_loss: 1.2445 - val_accuracy: 0.8607 - val_f1_m: 1.0108\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 3s 169us/sample - loss: 0.0248 - accuracy: 0.9921 - f1_m: 0.9632 - val_loss: 1.1307 - val_accuracy: 0.8578 - val_f1_m: 1.0110\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 3s 170us/sample - loss: 0.0322 - accuracy: 0.9900 - f1_m: 0.9657 - val_loss: 1.2316 - val_accuracy: 0.8482 - val_f1_m: 1.0109\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 3s 168us/sample - loss: 0.0414 - accuracy: 0.9870 - f1_m: 0.9689 - val_loss: 1.3098 - val_accuracy: 0.8556 - val_f1_m: 1.0171\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 104us/sample - loss: 0.0971 - accuracy: 0.9719 - f1_m: 1.0256 - val_loss: 1.0831 - val_accuracy: 0.8388 - val_f1_m: 1.0561\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 78us/sample - loss: 0.0898 - accuracy: 0.9729 - f1_m: 1.0268 - val_loss: 1.1076 - val_accuracy: 0.8418 - val_f1_m: 1.0555\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0889 - accuracy: 0.9718 - f1_m: 1.0303 - val_loss: 1.1054 - val_accuracy: 0.8428 - val_f1_m: 1.0545\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0853 - accuracy: 0.9728 - f1_m: 1.0301 - val_loss: 1.0829 - val_accuracy: 0.8432 - val_f1_m: 1.0460\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0800 - accuracy: 0.9746 - f1_m: 1.0283 - val_loss: 1.1261 - val_accuracy: 0.8405 - val_f1_m: 1.0558\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0759 - accuracy: 0.9741 - f1_m: 1.0279 - val_loss: 1.1058 - val_accuracy: 0.8425 - val_f1_m: 1.0518\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0771 - accuracy: 0.9753 - f1_m: 1.0277 - val_loss: 1.0931 - val_accuracy: 0.8422 - val_f1_m: 1.0478\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0752 - accuracy: 0.9751 - f1_m: 1.0243 - val_loss: 1.1268 - val_accuracy: 0.8413 - val_f1_m: 1.0503\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0741 - accuracy: 0.9759 - f1_m: 1.0244 - val_loss: 1.1488 - val_accuracy: 0.8403 - val_f1_m: 1.0581\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 76us/sample - loss: 0.0728 - accuracy: 0.9769 - f1_m: 1.0234 - val_loss: 1.1214 - val_accuracy: 0.8438 - val_f1_m: 1.0410\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 117us/sample - loss: 0.0773 - accuracy: 0.9794 - f1_m: 0.9959 - val_loss: 1.0959 - val_accuracy: 0.8648 - val_f1_m: 1.0193\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0717 - accuracy: 0.9772 - f1_m: 0.9959 - val_loss: 1.1248 - val_accuracy: 0.8560 - val_f1_m: 1.0233\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0609 - accuracy: 0.9808 - f1_m: 0.9955 - val_loss: 1.0919 - val_accuracy: 0.8575 - val_f1_m: 1.0256\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 85us/sample - loss: 0.0565 - accuracy: 0.9823 - f1_m: 0.9926 - val_loss: 1.1595 - val_accuracy: 0.8540 - val_f1_m: 1.0195\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0557 - accuracy: 0.9810 - f1_m: 0.9967 - val_loss: 1.0994 - val_accuracy: 0.8553 - val_f1_m: 1.0290\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0457 - accuracy: 0.9861 - f1_m: 0.9902 - val_loss: 1.1092 - val_accuracy: 0.8543 - val_f1_m: 1.0180\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0520 - accuracy: 0.9823 - f1_m: 0.9948 - val_loss: 1.1213 - val_accuracy: 0.8580 - val_f1_m: 1.0246\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0520 - accuracy: 0.9813 - f1_m: 0.9949 - val_loss: 1.1004 - val_accuracy: 0.8530 - val_f1_m: 1.0251\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0483 - accuracy: 0.9856 - f1_m: 0.9913 - val_loss: 1.1364 - val_accuracy: 0.8522 - val_f1_m: 1.0207\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 0.0399 - accuracy: 0.9877 - f1_m: 0.9908 - val_loss: 1.1934 - val_accuracy: 0.8528 - val_f1_m: 1.0222\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 148us/sample - loss: 0.0713 - accuracy: 0.9836 - f1_m: 0.9791 - val_loss: 1.1925 - val_accuracy: 0.8547 - val_f1_m: 1.0165\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 111us/sample - loss: 0.0526 - accuracy: 0.9860 - f1_m: 0.9798 - val_loss: 1.1582 - val_accuracy: 0.8543 - val_f1_m: 1.0149\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 109us/sample - loss: 0.0430 - accuracy: 0.9864 - f1_m: 0.9772 - val_loss: 1.2883 - val_accuracy: 0.8585 - val_f1_m: 1.0075\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 111us/sample - loss: 0.0425 - accuracy: 0.9868 - f1_m: 0.9761 - val_loss: 1.1756 - val_accuracy: 0.8543 - val_f1_m: 1.0162\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 111us/sample - loss: 0.0418 - accuracy: 0.9867 - f1_m: 0.9772 - val_loss: 1.2226 - val_accuracy: 0.8660 - val_f1_m: 1.0110\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 109us/sample - loss: 0.0413 - accuracy: 0.9858 - f1_m: 0.9766 - val_loss: 1.1684 - val_accuracy: 0.8593 - val_f1_m: 1.0055\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 109us/sample - loss: 0.0337 - accuracy: 0.9884 - f1_m: 0.9743 - val_loss: 1.1605 - val_accuracy: 0.8577 - val_f1_m: 1.0096\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 109us/sample - loss: 0.0326 - accuracy: 0.9889 - f1_m: 0.9728 - val_loss: 1.2603 - val_accuracy: 0.8570 - val_f1_m: 1.0141\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 110us/sample - loss: 0.0380 - accuracy: 0.9872 - f1_m: 0.9747 - val_loss: 1.2709 - val_accuracy: 0.8610 - val_f1_m: 1.0034\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 109us/sample - loss: 0.0287 - accuracy: 0.9898 - f1_m: 0.9704 - val_loss: 1.2821 - val_accuracy: 0.8522 - val_f1_m: 1.0009\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 3s 198us/sample - loss: 0.0924 - accuracy: 0.9686 - f1_m: 1.0103 - val_loss: 0.7859 - val_accuracy: 0.8553 - val_f1_m: 1.0616\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0867 - accuracy: 0.9700 - f1_m: 1.0095 - val_loss: 0.7701 - val_accuracy: 0.8525 - val_f1_m: 1.0782\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0748 - accuracy: 0.9761 - f1_m: 1.0068 - val_loss: 0.8310 - val_accuracy: 0.8535 - val_f1_m: 1.0585\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0777 - accuracy: 0.9724 - f1_m: 1.0079 - val_loss: 0.8176 - val_accuracy: 0.8317 - val_f1_m: 1.0733\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0835 - accuracy: 0.9711 - f1_m: 1.0088 - val_loss: 0.8232 - val_accuracy: 0.8618 - val_f1_m: 1.0408\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0689 - accuracy: 0.9754 - f1_m: 1.0052 - val_loss: 0.8390 - val_accuracy: 0.8497 - val_f1_m: 1.0547\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0682 - accuracy: 0.9757 - f1_m: 1.0014 - val_loss: 0.8115 - val_accuracy: 0.8550 - val_f1_m: 1.0459\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 144us/sample - loss: 0.0604 - accuracy: 0.9789 - f1_m: 0.9968 - val_loss: 0.7697 - val_accuracy: 0.8580 - val_f1_m: 1.0540\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0671 - accuracy: 0.9769 - f1_m: 1.0003 - val_loss: 0.9013 - val_accuracy: 0.8453 - val_f1_m: 1.0532\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 146us/sample - loss: 0.0810 - accuracy: 0.9715 - f1_m: 1.0062 - val_loss: 0.7565 - val_accuracy: 0.8475 - val_f1_m: 1.0642\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 106us/sample - loss: 0.0369 - accuracy: 0.9936 - f1_m: 0.9563 - val_loss: 1.1604 - val_accuracy: 0.8725 - val_f1_m: 1.0066\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 79us/sample - loss: 0.0204 - accuracy: 0.9966 - f1_m: 0.9550 - val_loss: 1.2018 - val_accuracy: 0.8698 - val_f1_m: 1.0010\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 76us/sample - loss: 0.0145 - accuracy: 0.9968 - f1_m: 0.9540 - val_loss: 1.1934 - val_accuracy: 0.8712 - val_f1_m: 1.0011\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0125 - accuracy: 0.9964 - f1_m: 0.9550 - val_loss: 1.0887 - val_accuracy: 0.8733 - val_f1_m: 1.0065\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0087 - accuracy: 0.9971 - f1_m: 0.9544 - val_loss: 1.1496 - val_accuracy: 0.8783 - val_f1_m: 1.0003\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 76us/sample - loss: 0.0087 - accuracy: 0.9973 - f1_m: 0.9532 - val_loss: 1.1532 - val_accuracy: 0.8673 - val_f1_m: 1.0060\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 76us/sample - loss: 0.0066 - accuracy: 0.9983 - f1_m: 0.9526 - val_loss: 1.1496 - val_accuracy: 0.8723 - val_f1_m: 1.0071\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0030 - accuracy: 0.9994 - f1_m: 0.9503 - val_loss: 1.1708 - val_accuracy: 0.8752 - val_f1_m: 0.9990\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 77us/sample - loss: 0.0044 - accuracy: 0.9989 - f1_m: 0.9508 - val_loss: 1.1776 - val_accuracy: 0.8717 - val_f1_m: 1.0021\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 78us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_m: 0.9501 - val_loss: 1.2291 - val_accuracy: 0.8748 - val_f1_m: 1.0023\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 2s 120us/sample - loss: 0.0367 - accuracy: 0.9934 - f1_m: 0.9557 - val_loss: 1.1935 - val_accuracy: 0.8692 - val_f1_m: 0.9958\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 89us/sample - loss: 0.0139 - accuracy: 0.9962 - f1_m: 0.9532 - val_loss: 1.2938 - val_accuracy: 0.8685 - val_f1_m: 0.9916\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 88us/sample - loss: 0.0077 - accuracy: 0.9979 - f1_m: 0.9527 - val_loss: 1.1945 - val_accuracy: 0.8775 - val_f1_m: 0.9851\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 90us/sample - loss: 0.0034 - accuracy: 0.9992 - f1_m: 0.9500 - val_loss: 1.2323 - val_accuracy: 0.8760 - val_f1_m: 0.9932\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 89us/sample - loss: 0.0163 - accuracy: 0.9946 - f1_m: 0.9567 - val_loss: 1.2253 - val_accuracy: 0.8648 - val_f1_m: 1.0007\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 91us/sample - loss: 0.0124 - accuracy: 0.9955 - f1_m: 0.9550 - val_loss: 1.2440 - val_accuracy: 0.8712 - val_f1_m: 0.9900\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 88us/sample - loss: 0.0098 - accuracy: 0.9969 - f1_m: 0.9533 - val_loss: 1.3056 - val_accuracy: 0.8692 - val_f1_m: 0.9930\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 89us/sample - loss: 0.0063 - accuracy: 0.9981 - f1_m: 0.9531 - val_loss: 1.2136 - val_accuracy: 0.8752 - val_f1_m: 0.9897\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 87us/sample - loss: 6.7579e-04 - accuracy: 0.9999 - f1_m: 0.9481 - val_loss: 1.2411 - val_accuracy: 0.8785 - val_f1_m: 0.9909\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 88us/sample - loss: 3.1266e-04 - accuracy: 0.9999 - f1_m: 0.9471 - val_loss: 1.2376 - val_accuracy: 0.8813 - val_f1_m: 0.9835\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 155us/sample - loss: 0.0456 - accuracy: 0.9921 - f1_m: 0.9564 - val_loss: 1.1831 - val_accuracy: 0.8700 - val_f1_m: 0.9977\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 115us/sample - loss: 0.0186 - accuracy: 0.9952 - f1_m: 0.9542 - val_loss: 1.1644 - val_accuracy: 0.8708 - val_f1_m: 0.9988\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 115us/sample - loss: 0.0122 - accuracy: 0.9964 - f1_m: 0.9547 - val_loss: 1.2692 - val_accuracy: 0.8788 - val_f1_m: 0.9982\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 116us/sample - loss: 0.0084 - accuracy: 0.9974 - f1_m: 0.9535 - val_loss: 1.2937 - val_accuracy: 0.8773 - val_f1_m: 0.9898\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 115us/sample - loss: 0.0288 - accuracy: 0.9922 - f1_m: 0.9569 - val_loss: 1.2382 - val_accuracy: 0.8690 - val_f1_m: 1.0004\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 115us/sample - loss: 0.0184 - accuracy: 0.9946 - f1_m: 0.9560 - val_loss: 1.3779 - val_accuracy: 0.8698 - val_f1_m: 0.9992\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 116us/sample - loss: 0.0185 - accuracy: 0.9951 - f1_m: 0.9548 - val_loss: 1.3138 - val_accuracy: 0.8700 - val_f1_m: 0.9946\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 114us/sample - loss: 0.0103 - accuracy: 0.9965 - f1_m: 0.9534 - val_loss: 1.4245 - val_accuracy: 0.8760 - val_f1_m: 0.9863\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 116us/sample - loss: 0.0051 - accuracy: 0.9983 - f1_m: 0.9509 - val_loss: 1.4806 - val_accuracy: 0.8717 - val_f1_m: 0.9859\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 115us/sample - loss: 0.0203 - accuracy: 0.9942 - f1_m: 0.9551 - val_loss: 1.5227 - val_accuracy: 0.8687 - val_f1_m: 0.9864\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 3s 212us/sample - loss: 0.0642 - accuracy: 0.9828 - f1_m: 0.9755 - val_loss: 0.9842 - val_accuracy: 0.8583 - val_f1_m: 1.0179\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 3s 161us/sample - loss: 0.0306 - accuracy: 0.9907 - f1_m: 0.9671 - val_loss: 1.0426 - val_accuracy: 0.8590 - val_f1_m: 1.0120\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 3s 158us/sample - loss: 0.0326 - accuracy: 0.9899 - f1_m: 0.9666 - val_loss: 1.1087 - val_accuracy: 0.8615 - val_f1_m: 1.0186\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 3s 160us/sample - loss: 0.0257 - accuracy: 0.9914 - f1_m: 0.9640 - val_loss: 1.1524 - val_accuracy: 0.8650 - val_f1_m: 1.0061\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 3s 158us/sample - loss: 0.0536 - accuracy: 0.9831 - f1_m: 0.9739 - val_loss: 1.0887 - val_accuracy: 0.8535 - val_f1_m: 1.0226\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 3s 160us/sample - loss: 0.0363 - accuracy: 0.9891 - f1_m: 0.9678 - val_loss: 1.1389 - val_accuracy: 0.8633 - val_f1_m: 1.0100\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 3s 157us/sample - loss: 0.0306 - accuracy: 0.9905 - f1_m: 0.9642 - val_loss: 1.1848 - val_accuracy: 0.8595 - val_f1_m: 1.0088\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 3s 159us/sample - loss: 0.0354 - accuracy: 0.9886 - f1_m: 0.9670 - val_loss: 1.0510 - val_accuracy: 0.8620 - val_f1_m: 1.0172\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 3s 159us/sample - loss: 0.0268 - accuracy: 0.9906 - f1_m: 0.9630 - val_loss: 1.1843 - val_accuracy: 0.8633 - val_f1_m: 1.0067\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 3s 159us/sample - loss: 0.0313 - accuracy: 0.9894 - f1_m: 0.9651 - val_loss: 1.1434 - val_accuracy: 0.8670 - val_f1_m: 1.0046\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 112us/sample - loss: 0.0982 - accuracy: 0.9733 - f1_m: 1.0268 - val_loss: 1.1305 - val_accuracy: 0.8409 - val_f1_m: 1.0465\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 1s 85us/sample - loss: 0.0925 - accuracy: 0.9738 - f1_m: 1.0247 - val_loss: 1.1245 - val_accuracy: 0.8403 - val_f1_m: 1.0504\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 1s 85us/sample - loss: 0.0903 - accuracy: 0.9724 - f1_m: 1.0267 - val_loss: 1.1271 - val_accuracy: 0.8391 - val_f1_m: 1.0620\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 1s 83us/sample - loss: 0.0833 - accuracy: 0.9747 - f1_m: 1.0256 - val_loss: 1.1115 - val_accuracy: 0.8420 - val_f1_m: 1.0541\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0821 - accuracy: 0.9734 - f1_m: 1.0291 - val_loss: 1.1238 - val_accuracy: 0.8423 - val_f1_m: 1.0471\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0773 - accuracy: 0.9753 - f1_m: 1.0226 - val_loss: 1.1254 - val_accuracy: 0.8437 - val_f1_m: 1.0432\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0770 - accuracy: 0.9761 - f1_m: 1.0253 - val_loss: 1.1267 - val_accuracy: 0.8411 - val_f1_m: 1.0580\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 1s 83us/sample - loss: 0.0756 - accuracy: 0.9756 - f1_m: 1.0249 - val_loss: 1.1279 - val_accuracy: 0.8443 - val_f1_m: 1.0460\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 1s 83us/sample - loss: 0.0745 - accuracy: 0.9764 - f1_m: 1.0270 - val_loss: 1.1271 - val_accuracy: 0.8466 - val_f1_m: 1.0438\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0722 - accuracy: 0.9765 - f1_m: 1.0237 - val_loss: 1.1314 - val_accuracy: 0.8483 - val_f1_m: 1.0467\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 125us/sample - loss: 0.0767 - accuracy: 0.9799 - f1_m: 0.9951 - val_loss: 1.1413 - val_accuracy: 0.8497 - val_f1_m: 1.0297\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 0.0633 - accuracy: 0.9834 - f1_m: 0.9949 - val_loss: 1.1524 - val_accuracy: 0.8546 - val_f1_m: 1.0169\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 0.0623 - accuracy: 0.9816 - f1_m: 0.9940 - val_loss: 1.1660 - val_accuracy: 0.8460 - val_f1_m: 1.0361\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16500/16500 [==============================] - 2s 92us/sample - loss: 0.0579 - accuracy: 0.9825 - f1_m: 0.9941 - val_loss: 1.1026 - val_accuracy: 0.8509 - val_f1_m: 1.0373\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 0.0528 - accuracy: 0.9845 - f1_m: 0.9918 - val_loss: 1.1302 - val_accuracy: 0.8534 - val_f1_m: 1.0320\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 0.0556 - accuracy: 0.9835 - f1_m: 0.9940 - val_loss: 1.2016 - val_accuracy: 0.8446 - val_f1_m: 1.0343\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 0.0590 - accuracy: 0.9811 - f1_m: 0.9936 - val_loss: 1.0586 - val_accuracy: 0.8560 - val_f1_m: 1.0291\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 92us/sample - loss: 0.0504 - accuracy: 0.9830 - f1_m: 0.9925 - val_loss: 1.1107 - val_accuracy: 0.8563 - val_f1_m: 1.0294\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 0.0555 - accuracy: 0.9817 - f1_m: 0.9955 - val_loss: 1.1639 - val_accuracy: 0.8449 - val_f1_m: 1.0296\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 93us/sample - loss: 0.0508 - accuracy: 0.9842 - f1_m: 0.9932 - val_loss: 1.1254 - val_accuracy: 0.8520 - val_f1_m: 1.0301\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 3s 154us/sample - loss: 0.0621 - accuracy: 0.9828 - f1_m: 0.9785 - val_loss: 1.1257 - val_accuracy: 0.8643 - val_f1_m: 1.0150\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 114us/sample - loss: 0.0487 - accuracy: 0.9859 - f1_m: 0.9772 - val_loss: 1.1914 - val_accuracy: 0.8494 - val_f1_m: 1.0084\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 0.0400 - accuracy: 0.9872 - f1_m: 0.9749 - val_loss: 1.2495 - val_accuracy: 0.8617 - val_f1_m: 0.9949\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 114us/sample - loss: 0.0416 - accuracy: 0.9868 - f1_m: 0.9744 - val_loss: 1.2325 - val_accuracy: 0.8620 - val_f1_m: 1.0022\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 114us/sample - loss: 0.0339 - accuracy: 0.9886 - f1_m: 0.9724 - val_loss: 1.2386 - val_accuracy: 0.8637 - val_f1_m: 1.0015\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 0.0437 - accuracy: 0.9850 - f1_m: 0.9757 - val_loss: 1.2404 - val_accuracy: 0.8506 - val_f1_m: 1.0107\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 0.0327 - accuracy: 0.9889 - f1_m: 0.9716 - val_loss: 1.2595 - val_accuracy: 0.8594 - val_f1_m: 0.9959\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 0.0383 - accuracy: 0.9862 - f1_m: 0.9762 - val_loss: 1.2071 - val_accuracy: 0.8654 - val_f1_m: 1.0061\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 113us/sample - loss: 0.0239 - accuracy: 0.9918 - f1_m: 0.9697 - val_loss: 1.2746 - val_accuracy: 0.8609 - val_f1_m: 1.0094\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 115us/sample - loss: 0.0485 - accuracy: 0.9838 - f1_m: 0.9788 - val_loss: 1.2613 - val_accuracy: 0.8651 - val_f1_m: 1.0070\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 3s 200us/sample - loss: 0.0975 - accuracy: 0.9684 - f1_m: 1.0141 - val_loss: 0.7742 - val_accuracy: 0.8560 - val_f1_m: 1.0486\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 3s 152us/sample - loss: 0.0763 - accuracy: 0.9732 - f1_m: 1.0070 - val_loss: 0.7962 - val_accuracy: 0.8549 - val_f1_m: 1.0527\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 149us/sample - loss: 0.0732 - accuracy: 0.9748 - f1_m: 1.0020 - val_loss: 0.8679 - val_accuracy: 0.8394 - val_f1_m: 1.0663\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 149us/sample - loss: 0.0789 - accuracy: 0.9722 - f1_m: 1.0096 - val_loss: 0.7842 - val_accuracy: 0.8523 - val_f1_m: 1.0592\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 150us/sample - loss: 0.0775 - accuracy: 0.9716 - f1_m: 1.0077 - val_loss: 0.7935 - val_accuracy: 0.8531 - val_f1_m: 1.0720\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 149us/sample - loss: 0.0758 - accuracy: 0.9728 - f1_m: 1.0070 - val_loss: 0.8364 - val_accuracy: 0.8537 - val_f1_m: 1.0491\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 150us/sample - loss: 0.0720 - accuracy: 0.9751 - f1_m: 1.0019 - val_loss: 0.8660 - val_accuracy: 0.8449 - val_f1_m: 1.0427\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 151us/sample - loss: 0.0777 - accuracy: 0.9731 - f1_m: 1.0049 - val_loss: 0.8503 - val_accuracy: 0.8626 - val_f1_m: 1.0430\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 150us/sample - loss: 0.0705 - accuracy: 0.9753 - f1_m: 1.0014 - val_loss: 0.8429 - val_accuracy: 0.8454 - val_f1_m: 1.0585\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 150us/sample - loss: 0.0774 - accuracy: 0.9718 - f1_m: 1.0084 - val_loss: 0.8176 - val_accuracy: 0.8594 - val_f1_m: 1.0479\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 5s 279us/sample - loss: 0.0378 - accuracy: 0.9940 - f1_m: 0.9572 - val_loss: 1.1995 - val_accuracy: 0.8646 - val_f1_m: 0.9981\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 1s 85us/sample - loss: 0.0191 - accuracy: 0.9957 - f1_m: 0.9582 - val_loss: 1.2073 - val_accuracy: 0.8694 - val_f1_m: 0.9984\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 1s 83us/sample - loss: 0.0098 - accuracy: 0.9973 - f1_m: 0.9552 - val_loss: 1.1731 - val_accuracy: 0.8703 - val_f1_m: 1.0079\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 1s 83us/sample - loss: 0.0056 - accuracy: 0.9983 - f1_m: 0.9528 - val_loss: 1.2209 - val_accuracy: 0.8700 - val_f1_m: 0.9979\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0060 - accuracy: 0.9982 - f1_m: 0.9533 - val_loss: 1.2087 - val_accuracy: 0.8734 - val_f1_m: 1.0027\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 1s 83us/sample - loss: 0.0036 - accuracy: 0.9992 - f1_m: 0.9495 - val_loss: 1.2135 - val_accuracy: 0.8654 - val_f1_m: 0.9964\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0092 - accuracy: 0.9972 - f1_m: 0.9540 - val_loss: 1.2314 - val_accuracy: 0.8674 - val_f1_m: 1.0061\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0063 - accuracy: 0.9976 - f1_m: 0.9536 - val_loss: 1.2310 - val_accuracy: 0.8683 - val_f1_m: 0.9960\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 0.0015 - accuracy: 0.9998 - f1_m: 0.9490 - val_loss: 1.1827 - val_accuracy: 0.8720 - val_f1_m: 1.0043\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 1s 84us/sample - loss: 4.3583e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 1.1956 - val_accuracy: 0.8749 - val_f1_m: 1.0021\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 132us/sample - loss: 0.0375 - accuracy: 0.9938 - f1_m: 0.9556 - val_loss: 1.1101 - val_accuracy: 0.8757 - val_f1_m: 0.9868\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 0.0172 - accuracy: 0.9954 - f1_m: 0.9549 - val_loss: 1.1210 - val_accuracy: 0.8786 - val_f1_m: 0.9890\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 0.0119 - accuracy: 0.9959 - f1_m: 0.9542 - val_loss: 1.1470 - val_accuracy: 0.8794 - val_f1_m: 0.9920\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 0.0045 - accuracy: 0.9985 - f1_m: 0.9516 - val_loss: 1.1973 - val_accuracy: 0.8769 - val_f1_m: 0.9860\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 0.0040 - accuracy: 0.9985 - f1_m: 0.9502 - val_loss: 1.1394 - val_accuracy: 0.8803 - val_f1_m: 0.9934\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 0.0010 - accuracy: 0.9998 - f1_m: 0.9482 - val_loss: 1.1623 - val_accuracy: 0.8803 - val_f1_m: 0.9865\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16500/16500 [==============================] - 2s 100us/sample - loss: 0.0162 - accuracy: 0.9942 - f1_m: 0.9571 - val_loss: 1.3165 - val_accuracy: 0.8740 - val_f1_m: 0.9871\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 0.0121 - accuracy: 0.9958 - f1_m: 0.9545 - val_loss: 1.2399 - val_accuracy: 0.8740 - val_f1_m: 0.9921\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 99us/sample - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9498 - val_loss: 1.2124 - val_accuracy: 0.8854 - val_f1_m: 0.9837\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 100us/sample - loss: 0.0097 - accuracy: 0.9971 - f1_m: 0.9516 - val_loss: 1.2849 - val_accuracy: 0.8717 - val_f1_m: 0.9973\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 0.0443 - accuracy: 0.9920 - f1_m: 0.9570 - val_loss: 1.1103 - val_accuracy: 0.8754 - val_f1_m: 0.9992\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 0.0183 - accuracy: 0.9950 - f1_m: 0.9579 - val_loss: 1.1892 - val_accuracy: 0.8766 - val_f1_m: 0.9937\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 124us/sample - loss: 0.0074 - accuracy: 0.9977 - f1_m: 0.9526 - val_loss: 1.2109 - val_accuracy: 0.8774 - val_f1_m: 0.9967\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 0.0065 - accuracy: 0.9981 - f1_m: 0.9513 - val_loss: 1.3110 - val_accuracy: 0.8740 - val_f1_m: 0.9879\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 124us/sample - loss: 0.0158 - accuracy: 0.9950 - f1_m: 0.9554 - val_loss: 1.3117 - val_accuracy: 0.8734 - val_f1_m: 0.9912\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 126us/sample - loss: 0.0358 - accuracy: 0.9890 - f1_m: 0.9606 - val_loss: 1.1854 - val_accuracy: 0.8751 - val_f1_m: 0.9943\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 132us/sample - loss: 0.0118 - accuracy: 0.9970 - f1_m: 0.9550 - val_loss: 1.1093 - val_accuracy: 0.8820 - val_f1_m: 0.9986\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 0.0055 - accuracy: 0.9981 - f1_m: 0.9506 - val_loss: 1.4227 - val_accuracy: 0.8786 - val_f1_m: 0.9821\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 0.0113 - accuracy: 0.9969 - f1_m: 0.9532 - val_loss: 1.3285 - val_accuracy: 0.8809 - val_f1_m: 0.9837\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 0.0133 - accuracy: 0.9959 - f1_m: 0.9536 - val_loss: 1.2999 - val_accuracy: 0.8806 - val_f1_m: 0.9910\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 4s 215us/sample - loss: 0.0613 - accuracy: 0.9848 - f1_m: 0.9733 - val_loss: 0.9114 - val_accuracy: 0.8629 - val_f1_m: 1.0273\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 0.0322 - accuracy: 0.9895 - f1_m: 0.9694 - val_loss: 1.1000 - val_accuracy: 0.8569 - val_f1_m: 1.0137\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 0.0420 - accuracy: 0.9868 - f1_m: 0.9710 - val_loss: 1.1240 - val_accuracy: 0.8577 - val_f1_m: 1.0230\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 0.0334 - accuracy: 0.9889 - f1_m: 0.9689 - val_loss: 1.1677 - val_accuracy: 0.8597 - val_f1_m: 1.0220\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 3s 164us/sample - loss: 0.0426 - accuracy: 0.9863 - f1_m: 0.9709 - val_loss: 1.0873 - val_accuracy: 0.8680 - val_f1_m: 1.0174\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 0.0317 - accuracy: 0.9896 - f1_m: 0.9655 - val_loss: 1.1741 - val_accuracy: 0.8491 - val_f1_m: 1.0178\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 0.0350 - accuracy: 0.9876 - f1_m: 0.9685 - val_loss: 1.1861 - val_accuracy: 0.8591 - val_f1_m: 1.0069\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 0.0293 - accuracy: 0.9904 - f1_m: 0.9641 - val_loss: 1.3736 - val_accuracy: 0.8637 - val_f1_m: 0.9974\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 3s 165us/sample - loss: 0.0422 - accuracy: 0.9865 - f1_m: 0.9673 - val_loss: 1.1444 - val_accuracy: 0.8597 - val_f1_m: 1.0161\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 3s 164us/sample - loss: 0.0249 - accuracy: 0.9922 - f1_m: 0.9643 - val_loss: 1.2591 - val_accuracy: 0.8594 - val_f1_m: 0.9999\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 111us/sample - loss: 0.0923 - accuracy: 0.9719 - f1_m: 1.0265 - val_loss: 1.1440 - val_accuracy: 0.8357 - val_f1_m: 1.0475\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 1s 81us/sample - loss: 0.0866 - accuracy: 0.9737 - f1_m: 1.0262 - val_loss: 1.0998 - val_accuracy: 0.8460 - val_f1_m: 1.0473\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 1s 83us/sample - loss: 0.0806 - accuracy: 0.9755 - f1_m: 1.0226 - val_loss: 1.1296 - val_accuracy: 0.8400 - val_f1_m: 1.0469\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0783 - accuracy: 0.9755 - f1_m: 1.0231 - val_loss: 1.1373 - val_accuracy: 0.8433 - val_f1_m: 1.0470\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0793 - accuracy: 0.9755 - f1_m: 1.0265 - val_loss: 1.1505 - val_accuracy: 0.8470 - val_f1_m: 1.0451\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0762 - accuracy: 0.9751 - f1_m: 1.0253 - val_loss: 1.1252 - val_accuracy: 0.8423 - val_f1_m: 1.0472\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 1s 81us/sample - loss: 0.0722 - accuracy: 0.9776 - f1_m: 1.0225 - val_loss: 1.1231 - val_accuracy: 0.8467 - val_f1_m: 1.0407\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0715 - accuracy: 0.9781 - f1_m: 1.0234 - val_loss: 1.1549 - val_accuracy: 0.8447 - val_f1_m: 1.0470\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 1s 83us/sample - loss: 0.0724 - accuracy: 0.9775 - f1_m: 1.0195 - val_loss: 1.1801 - val_accuracy: 0.8350 - val_f1_m: 1.0502\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0741 - accuracy: 0.9759 - f1_m: 1.0232 - val_loss: 1.1771 - val_accuracy: 0.8427 - val_f1_m: 1.0361\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 123us/sample - loss: 0.0724 - accuracy: 0.9804 - f1_m: 0.9978 - val_loss: 1.1263 - val_accuracy: 0.8483 - val_f1_m: 1.0322\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 92us/sample - loss: 0.0639 - accuracy: 0.9815 - f1_m: 0.9928 - val_loss: 1.1215 - val_accuracy: 0.8527 - val_f1_m: 1.0188\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 2s 92us/sample - loss: 0.0665 - accuracy: 0.9801 - f1_m: 0.9951 - val_loss: 1.1343 - val_accuracy: 0.8493 - val_f1_m: 1.0463\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 91us/sample - loss: 0.0588 - accuracy: 0.9824 - f1_m: 0.9945 - val_loss: 1.0899 - val_accuracy: 0.8513 - val_f1_m: 1.0287\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 94us/sample - loss: 0.0511 - accuracy: 0.9845 - f1_m: 0.9911 - val_loss: 1.1512 - val_accuracy: 0.8483 - val_f1_m: 1.0288\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 91us/sample - loss: 0.0562 - accuracy: 0.9827 - f1_m: 0.9955 - val_loss: 1.1760 - val_accuracy: 0.8533 - val_f1_m: 1.0269\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 93us/sample - loss: 0.0506 - accuracy: 0.9842 - f1_m: 0.9946 - val_loss: 1.1755 - val_accuracy: 0.8493 - val_f1_m: 1.0378\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 92us/sample - loss: 0.0544 - accuracy: 0.9826 - f1_m: 0.9958 - val_loss: 1.1884 - val_accuracy: 0.8483 - val_f1_m: 1.0280\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 92us/sample - loss: 0.0509 - accuracy: 0.9841 - f1_m: 0.9929 - val_loss: 1.1350 - val_accuracy: 0.8467 - val_f1_m: 1.0333\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 2s 91us/sample - loss: 0.0454 - accuracy: 0.9862 - f1_m: 0.9903 - val_loss: 1.1760 - val_accuracy: 0.8447 - val_f1_m: 1.0256\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 3s 151us/sample - loss: 0.0578 - accuracy: 0.9862 - f1_m: 0.9762 - val_loss: 1.1471 - val_accuracy: 0.8500 - val_f1_m: 1.0163\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 113us/sample - loss: 0.0490 - accuracy: 0.9858 - f1_m: 0.9781 - val_loss: 1.1779 - val_accuracy: 0.8657 - val_f1_m: 1.0080\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 2s 112us/sample - loss: 0.0407 - accuracy: 0.9877 - f1_m: 0.9752 - val_loss: 1.2080 - val_accuracy: 0.8567 - val_f1_m: 1.0140\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 113us/sample - loss: 0.0356 - accuracy: 0.9885 - f1_m: 0.9753 - val_loss: 1.2220 - val_accuracy: 0.8543 - val_f1_m: 1.0007\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 113us/sample - loss: 0.0464 - accuracy: 0.9859 - f1_m: 0.9761 - val_loss: 1.1987 - val_accuracy: 0.8500 - val_f1_m: 1.0116\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 112us/sample - loss: 0.0388 - accuracy: 0.9865 - f1_m: 0.9756 - val_loss: 1.2051 - val_accuracy: 0.8567 - val_f1_m: 1.0054\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 113us/sample - loss: 0.0441 - accuracy: 0.9859 - f1_m: 0.9775 - val_loss: 1.2388 - val_accuracy: 0.8567 - val_f1_m: 1.0091\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 113us/sample - loss: 0.0278 - accuracy: 0.9905 - f1_m: 0.9699 - val_loss: 1.4151 - val_accuracy: 0.8527 - val_f1_m: 1.0023\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 114us/sample - loss: 0.0350 - accuracy: 0.9882 - f1_m: 0.9734 - val_loss: 1.2671 - val_accuracy: 0.8603 - val_f1_m: 1.0136\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 2s 113us/sample - loss: 0.0281 - accuracy: 0.9908 - f1_m: 0.9693 - val_loss: 1.3078 - val_accuracy: 0.8593 - val_f1_m: 1.0011\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 3s 197us/sample - loss: 0.0915 - accuracy: 0.9708 - f1_m: 1.0050 - val_loss: 0.8129 - val_accuracy: 0.8520 - val_f1_m: 1.0546\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 3s 148us/sample - loss: 0.0856 - accuracy: 0.9709 - f1_m: 1.0079 - val_loss: 0.7993 - val_accuracy: 0.8553 - val_f1_m: 1.0630\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 3s 149us/sample - loss: 0.0748 - accuracy: 0.9745 - f1_m: 1.0067 - val_loss: 0.7900 - val_accuracy: 0.8523 - val_f1_m: 1.0567\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 3s 149us/sample - loss: 0.0725 - accuracy: 0.9738 - f1_m: 1.0067 - val_loss: 0.7051 - val_accuracy: 0.8473 - val_f1_m: 1.0843\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 3s 149us/sample - loss: 0.0626 - accuracy: 0.9772 - f1_m: 1.0013 - val_loss: 0.8199 - val_accuracy: 0.8537 - val_f1_m: 1.0409\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 3s 148us/sample - loss: 0.1004 - accuracy: 0.9650 - f1_m: 1.0186 - val_loss: 0.8268 - val_accuracy: 0.8553 - val_f1_m: 1.0533\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 3s 148us/sample - loss: 0.0780 - accuracy: 0.9741 - f1_m: 1.0033 - val_loss: 0.9034 - val_accuracy: 0.8497 - val_f1_m: 1.0371\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 3s 149us/sample - loss: 0.0665 - accuracy: 0.9772 - f1_m: 1.0036 - val_loss: 0.9219 - val_accuracy: 0.8480 - val_f1_m: 1.0369\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 3s 148us/sample - loss: 0.0712 - accuracy: 0.9754 - f1_m: 1.0027 - val_loss: 0.7892 - val_accuracy: 0.8493 - val_f1_m: 1.0663\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 3s 148us/sample - loss: 0.0744 - accuracy: 0.9741 - f1_m: 1.0014 - val_loss: 0.8087 - val_accuracy: 0.8527 - val_f1_m: 1.0524\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 110us/sample - loss: 0.0371 - accuracy: 0.9936 - f1_m: 0.9565 - val_loss: 1.1320 - val_accuracy: 0.8667 - val_f1_m: 1.0027\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0173 - accuracy: 0.9969 - f1_m: 0.9539 - val_loss: 1.1223 - val_accuracy: 0.8710 - val_f1_m: 1.0030\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0123 - accuracy: 0.9974 - f1_m: 0.9530 - val_loss: 1.1192 - val_accuracy: 0.8697 - val_f1_m: 1.0075\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0083 - accuracy: 0.9979 - f1_m: 0.9533 - val_loss: 1.1059 - val_accuracy: 0.8737 - val_f1_m: 1.0061\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 0.0033 - accuracy: 0.9995 - f1_m: 0.9493 - val_loss: 1.1212 - val_accuracy: 0.8700 - val_f1_m: 0.9968\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 1s 81us/sample - loss: 0.0167 - accuracy: 0.9944 - f1_m: 0.9580 - val_loss: 1.1206 - val_accuracy: 0.8763 - val_f1_m: 0.9997\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 1s 83us/sample - loss: 0.0077 - accuracy: 0.9974 - f1_m: 0.9538 - val_loss: 1.1844 - val_accuracy: 0.8780 - val_f1_m: 1.0055\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 1s 83us/sample - loss: 0.0045 - accuracy: 0.9986 - f1_m: 0.9511 - val_loss: 1.1067 - val_accuracy: 0.8787 - val_f1_m: 1.0012\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 6.2125e-04 - accuracy: 0.9999 - f1_m: 0.9479 - val_loss: 1.1295 - val_accuracy: 0.8790 - val_f1_m: 1.0049\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 1s 82us/sample - loss: 3.0199e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 1.1365 - val_accuracy: 0.8813 - val_f1_m: 1.0060\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 128us/sample - loss: 0.0383 - accuracy: 0.9942 - f1_m: 0.9566 - val_loss: 1.1482 - val_accuracy: 0.8743 - val_f1_m: 1.0018\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0177 - accuracy: 0.9963 - f1_m: 0.9542 - val_loss: 1.1330 - val_accuracy: 0.8730 - val_f1_m: 0.9962\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0116 - accuracy: 0.9968 - f1_m: 0.9539 - val_loss: 1.1264 - val_accuracy: 0.8717 - val_f1_m: 1.0006\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0083 - accuracy: 0.9976 - f1_m: 0.9540 - val_loss: 1.1484 - val_accuracy: 0.8763 - val_f1_m: 0.9872\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 97us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9529 - val_loss: 1.2586 - val_accuracy: 0.8817 - val_f1_m: 0.9900\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0076 - accuracy: 0.9976 - f1_m: 0.9532 - val_loss: 1.2732 - val_accuracy: 0.8807 - val_f1_m: 0.9904\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0133 - accuracy: 0.9962 - f1_m: 0.9540 - val_loss: 1.2890 - val_accuracy: 0.8753 - val_f1_m: 0.9903\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0029 - accuracy: 0.9992 - f1_m: 0.9506 - val_loss: 1.2025 - val_accuracy: 0.8810 - val_f1_m: 0.9872\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 9.1874e-04 - accuracy: 0.9999 - f1_m: 0.9480 - val_loss: 1.1529 - val_accuracy: 0.8773 - val_f1_m: 0.9919\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0128 - accuracy: 0.9960 - f1_m: 0.9565 - val_loss: 1.1888 - val_accuracy: 0.8793 - val_f1_m: 0.9852\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 3s 158us/sample - loss: 0.0432 - accuracy: 0.9911 - f1_m: 0.9587 - val_loss: 1.1183 - val_accuracy: 0.8633 - val_f1_m: 1.0133\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0163 - accuracy: 0.9958 - f1_m: 0.9552 - val_loss: 1.0740 - val_accuracy: 0.8717 - val_f1_m: 0.9962\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0126 - accuracy: 0.9964 - f1_m: 0.9548 - val_loss: 1.2214 - val_accuracy: 0.8773 - val_f1_m: 0.9902\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0084 - accuracy: 0.9975 - f1_m: 0.9527 - val_loss: 1.1801 - val_accuracy: 0.8730 - val_f1_m: 0.9976\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0089 - accuracy: 0.9972 - f1_m: 0.9534 - val_loss: 1.3193 - val_accuracy: 0.8727 - val_f1_m: 0.9894\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 119us/sample - loss: 0.0254 - accuracy: 0.9926 - f1_m: 0.9560 - val_loss: 1.4811 - val_accuracy: 0.8667 - val_f1_m: 0.9854\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 119us/sample - loss: 0.0206 - accuracy: 0.9941 - f1_m: 0.9560 - val_loss: 1.6136 - val_accuracy: 0.8727 - val_f1_m: 0.9795\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0145 - accuracy: 0.9954 - f1_m: 0.9535 - val_loss: 1.3140 - val_accuracy: 0.8737 - val_f1_m: 0.9879\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0135 - accuracy: 0.9956 - f1_m: 0.9538 - val_loss: 1.5383 - val_accuracy: 0.8750 - val_f1_m: 0.9813\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0060 - accuracy: 0.9981 - f1_m: 0.9508 - val_loss: 1.6495 - val_accuracy: 0.8707 - val_f1_m: 0.9784\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 4s 210us/sample - loss: 0.0557 - accuracy: 0.9868 - f1_m: 0.9713 - val_loss: 1.0621 - val_accuracy: 0.8547 - val_f1_m: 1.0200\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 3s 161us/sample - loss: 0.0393 - accuracy: 0.9873 - f1_m: 0.9698 - val_loss: 1.1996 - val_accuracy: 0.8530 - val_f1_m: 1.0082\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 3s 161us/sample - loss: 0.0304 - accuracy: 0.9897 - f1_m: 0.9660 - val_loss: 1.2638 - val_accuracy: 0.8580 - val_f1_m: 1.0027\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 3s 161us/sample - loss: 0.0465 - accuracy: 0.9854 - f1_m: 0.9711 - val_loss: 1.2743 - val_accuracy: 0.8667 - val_f1_m: 1.0003\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 3s 162us/sample - loss: 0.0414 - accuracy: 0.9865 - f1_m: 0.9703 - val_loss: 1.1305 - val_accuracy: 0.8683 - val_f1_m: 1.0181\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 3s 161us/sample - loss: 0.0296 - accuracy: 0.9912 - f1_m: 0.9659 - val_loss: 1.2253 - val_accuracy: 0.8633 - val_f1_m: 1.0021\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 3s 162us/sample - loss: 0.0326 - accuracy: 0.9902 - f1_m: 0.9648 - val_loss: 1.1787 - val_accuracy: 0.8590 - val_f1_m: 1.0075\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 3s 162us/sample - loss: 0.0582 - accuracy: 0.9832 - f1_m: 0.9734 - val_loss: 1.1149 - val_accuracy: 0.8583 - val_f1_m: 1.0185\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 3s 162us/sample - loss: 0.0345 - accuracy: 0.9891 - f1_m: 0.9664 - val_loss: 1.1781 - val_accuracy: 0.8650 - val_f1_m: 1.0119\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 3s 162us/sample - loss: 0.0276 - accuracy: 0.9901 - f1_m: 0.9662 - val_loss: 1.4401 - val_accuracy: 0.8623 - val_f1_m: 0.9926\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 2s 106us/sample - loss: 0.0984 - accuracy: 0.9726 - f1_m: 1.0240 - val_loss: 1.2099 - val_accuracy: 0.8408 - val_f1_m: 1.0449\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 1s 80us/sample - loss: 0.0924 - accuracy: 0.9741 - f1_m: 1.0249 - val_loss: 1.2325 - val_accuracy: 0.8344 - val_f1_m: 1.0640\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 1s 78us/sample - loss: 0.0875 - accuracy: 0.9739 - f1_m: 1.0234 - val_loss: 1.2281 - val_accuracy: 0.8360 - val_f1_m: 1.0489\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0857 - accuracy: 0.9733 - f1_m: 1.0214 - val_loss: 1.1835 - val_accuracy: 0.8440 - val_f1_m: 1.0515\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0791 - accuracy: 0.9759 - f1_m: 1.0215 - val_loss: 1.1847 - val_accuracy: 0.8400 - val_f1_m: 1.0534\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0765 - accuracy: 0.9753 - f1_m: 1.0235 - val_loss: 1.2137 - val_accuracy: 0.8356 - val_f1_m: 1.0600\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0768 - accuracy: 0.9763 - f1_m: 1.0205 - val_loss: 1.1883 - val_accuracy: 0.8412 - val_f1_m: 1.0519\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0745 - accuracy: 0.9776 - f1_m: 1.0199 - val_loss: 1.2185 - val_accuracy: 0.8456 - val_f1_m: 1.0517\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0730 - accuracy: 0.9783 - f1_m: 1.0210 - val_loss: 1.1950 - val_accuracy: 0.8412 - val_f1_m: 1.0546\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0723 - accuracy: 0.9774 - f1_m: 1.0206 - val_loss: 1.2102 - val_accuracy: 0.8376 - val_f1_m: 1.0507\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 2s 119us/sample - loss: 0.0783 - accuracy: 0.9797 - f1_m: 0.9927 - val_loss: 1.0802 - val_accuracy: 0.8432 - val_f1_m: 1.0447\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 89us/sample - loss: 0.0692 - accuracy: 0.9803 - f1_m: 0.9966 - val_loss: 1.1473 - val_accuracy: 0.8484 - val_f1_m: 1.0265\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 2s 89us/sample - loss: 0.0617 - accuracy: 0.9825 - f1_m: 0.9933 - val_loss: 1.1364 - val_accuracy: 0.8424 - val_f1_m: 1.0423\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 89us/sample - loss: 0.0534 - accuracy: 0.9849 - f1_m: 0.9912 - val_loss: 1.1186 - val_accuracy: 0.8532 - val_f1_m: 1.0239\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 90us/sample - loss: 0.0581 - accuracy: 0.9814 - f1_m: 0.9938 - val_loss: 1.1301 - val_accuracy: 0.8548 - val_f1_m: 1.0265\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 2s 89us/sample - loss: 0.0559 - accuracy: 0.9827 - f1_m: 0.9946 - val_loss: 1.1397 - val_accuracy: 0.8484 - val_f1_m: 1.0290\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 89us/sample - loss: 0.0542 - accuracy: 0.9837 - f1_m: 0.9957 - val_loss: 1.1703 - val_accuracy: 0.8484 - val_f1_m: 1.0239\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 88us/sample - loss: 0.0499 - accuracy: 0.9845 - f1_m: 0.9938 - val_loss: 1.1910 - val_accuracy: 0.8500 - val_f1_m: 1.0254\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 2s 89us/sample - loss: 0.0529 - accuracy: 0.9837 - f1_m: 0.9924 - val_loss: 1.1829 - val_accuracy: 0.8492 - val_f1_m: 1.0190\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 89us/sample - loss: 0.0474 - accuracy: 0.9844 - f1_m: 0.9902 - val_loss: 1.1929 - val_accuracy: 0.8460 - val_f1_m: 1.0267\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 3s 147us/sample - loss: 0.0644 - accuracy: 0.9851 - f1_m: 0.9771 - val_loss: 1.2662 - val_accuracy: 0.8504 - val_f1_m: 1.0143\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 112us/sample - loss: 0.0451 - accuracy: 0.9865 - f1_m: 0.9755 - val_loss: 1.2162 - val_accuracy: 0.8608 - val_f1_m: 1.0118\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 2s 111us/sample - loss: 0.0403 - accuracy: 0.9874 - f1_m: 0.9742 - val_loss: 1.1646 - val_accuracy: 0.8464 - val_f1_m: 1.0209\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 111us/sample - loss: 0.0391 - accuracy: 0.9875 - f1_m: 0.9733 - val_loss: 1.2816 - val_accuracy: 0.8648 - val_f1_m: 1.0000\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 111us/sample - loss: 0.0380 - accuracy: 0.9867 - f1_m: 0.9763 - val_loss: 1.3070 - val_accuracy: 0.8576 - val_f1_m: 1.0080\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 2s 110us/sample - loss: 0.0433 - accuracy: 0.9854 - f1_m: 0.9773 - val_loss: 1.3022 - val_accuracy: 0.8544 - val_f1_m: 1.0099\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 110us/sample - loss: 0.0205 - accuracy: 0.9934 - f1_m: 0.9663 - val_loss: 1.3957 - val_accuracy: 0.8588 - val_f1_m: 0.9964\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 112us/sample - loss: 0.0361 - accuracy: 0.9882 - f1_m: 0.9704 - val_loss: 1.2723 - val_accuracy: 0.8428 - val_f1_m: 1.0133\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 2s 111us/sample - loss: 0.0455 - accuracy: 0.9851 - f1_m: 0.9761 - val_loss: 1.3237 - val_accuracy: 0.8488 - val_f1_m: 1.0192\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 110us/sample - loss: 0.0443 - accuracy: 0.9854 - f1_m: 0.9746 - val_loss: 1.3106 - val_accuracy: 0.8588 - val_f1_m: 0.9907\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 3s 193us/sample - loss: 0.0980 - accuracy: 0.9691 - f1_m: 1.0120 - val_loss: 0.8172 - val_accuracy: 0.8516 - val_f1_m: 1.0492\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 3s 145us/sample - loss: 0.0888 - accuracy: 0.9703 - f1_m: 1.0086 - val_loss: 0.7531 - val_accuracy: 0.8448 - val_f1_m: 1.0589\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 3s 145us/sample - loss: 0.0827 - accuracy: 0.9727 - f1_m: 1.0067 - val_loss: 0.8072 - val_accuracy: 0.8448 - val_f1_m: 1.0445\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 3s 145us/sample - loss: 0.0815 - accuracy: 0.9729 - f1_m: 1.0077 - val_loss: 0.7837 - val_accuracy: 0.8520 - val_f1_m: 1.0641\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 3s 146us/sample - loss: 0.0725 - accuracy: 0.9757 - f1_m: 1.0061 - val_loss: 0.8078 - val_accuracy: 0.8484 - val_f1_m: 1.0485\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 3s 146us/sample - loss: 0.0751 - accuracy: 0.9735 - f1_m: 1.0036 - val_loss: 0.8766 - val_accuracy: 0.8380 - val_f1_m: 1.0529\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 3s 146us/sample - loss: 0.0754 - accuracy: 0.9734 - f1_m: 1.0053 - val_loss: 0.8473 - val_accuracy: 0.8432 - val_f1_m: 1.0504\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 3s 145us/sample - loss: 0.0670 - accuracy: 0.9773 - f1_m: 1.0026 - val_loss: 0.7628 - val_accuracy: 0.8616 - val_f1_m: 1.0417\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 3s 145us/sample - loss: 0.0893 - accuracy: 0.9693 - f1_m: 1.0087 - val_loss: 0.7658 - val_accuracy: 0.8528 - val_f1_m: 1.0577\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 3s 145us/sample - loss: 0.0706 - accuracy: 0.9742 - f1_m: 1.0072 - val_loss: 0.8115 - val_accuracy: 0.8588 - val_f1_m: 1.0459\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 2s 107us/sample - loss: 0.0391 - accuracy: 0.9948 - f1_m: 0.9567 - val_loss: 1.2066 - val_accuracy: 0.8600 - val_f1_m: 0.9877\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0164 - accuracy: 0.9966 - f1_m: 0.9546 - val_loss: 1.1477 - val_accuracy: 0.8736 - val_f1_m: 0.9918\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 1s 80us/sample - loss: 0.0132 - accuracy: 0.9966 - f1_m: 0.9540 - val_loss: 1.1310 - val_accuracy: 0.8708 - val_f1_m: 0.9955\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 1s 80us/sample - loss: 0.0102 - accuracy: 0.9969 - f1_m: 0.9545 - val_loss: 1.1211 - val_accuracy: 0.8700 - val_f1_m: 1.0013\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0038 - accuracy: 0.9987 - f1_m: 0.9514 - val_loss: 1.1376 - val_accuracy: 0.8700 - val_f1_m: 0.9982\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 1s 81us/sample - loss: 0.0034 - accuracy: 0.9991 - f1_m: 0.9503 - val_loss: 1.1642 - val_accuracy: 0.8704 - val_f1_m: 0.9990\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 1s 81us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9491 - val_loss: 1.1574 - val_accuracy: 0.8712 - val_f1_m: 1.0037\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 1s 80us/sample - loss: 0.0124 - accuracy: 0.9959 - f1_m: 0.9579 - val_loss: 1.1665 - val_accuracy: 0.8624 - val_f1_m: 0.9991\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 1s 79us/sample - loss: 0.0053 - accuracy: 0.9982 - f1_m: 0.9519 - val_loss: 1.1491 - val_accuracy: 0.8720 - val_f1_m: 1.0039\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 1s 81us/sample - loss: 6.2690e-04 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 1.1425 - val_accuracy: 0.8752 - val_f1_m: 0.9958\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 2s 128us/sample - loss: 0.0397 - accuracy: 0.9934 - f1_m: 0.9551 - val_loss: 1.1485 - val_accuracy: 0.8800 - val_f1_m: 0.9885\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 95us/sample - loss: 0.0139 - accuracy: 0.9966 - f1_m: 0.9531 - val_loss: 1.1081 - val_accuracy: 0.8808 - val_f1_m: 0.9893\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 2s 95us/sample - loss: 0.0041 - accuracy: 0.9986 - f1_m: 0.9508 - val_loss: 1.2179 - val_accuracy: 0.8800 - val_f1_m: 0.9883\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 95us/sample - loss: 0.0039 - accuracy: 0.9990 - f1_m: 0.9501 - val_loss: 1.2624 - val_accuracy: 0.8808 - val_f1_m: 0.9874\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 95us/sample - loss: 0.0088 - accuracy: 0.9974 - f1_m: 0.9527 - val_loss: 1.2699 - val_accuracy: 0.8840 - val_f1_m: 0.9799\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 2s 95us/sample - loss: 0.0036 - accuracy: 0.9990 - f1_m: 0.9508 - val_loss: 1.2636 - val_accuracy: 0.8836 - val_f1_m: 0.9880\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 96us/sample - loss: 0.0102 - accuracy: 0.9965 - f1_m: 0.9543 - val_loss: 1.2551 - val_accuracy: 0.8780 - val_f1_m: 0.9944\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 94us/sample - loss: 0.0113 - accuracy: 0.9965 - f1_m: 0.9539 - val_loss: 1.1802 - val_accuracy: 0.8844 - val_f1_m: 0.9934\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 2s 95us/sample - loss: 0.0045 - accuracy: 0.9987 - f1_m: 0.9510 - val_loss: 1.2471 - val_accuracy: 0.8788 - val_f1_m: 0.9877\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 94us/sample - loss: 0.0027 - accuracy: 0.9993 - f1_m: 0.9500 - val_loss: 1.3425 - val_accuracy: 0.8828 - val_f1_m: 0.9832\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 3s 154us/sample - loss: 0.0484 - accuracy: 0.9922 - f1_m: 0.9558 - val_loss: 1.1973 - val_accuracy: 0.8680 - val_f1_m: 1.0000\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 118us/sample - loss: 0.0132 - accuracy: 0.9958 - f1_m: 0.9551 - val_loss: 1.3216 - val_accuracy: 0.8680 - val_f1_m: 0.9964\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 2s 118us/sample - loss: 0.0124 - accuracy: 0.9962 - f1_m: 0.9548 - val_loss: 1.4338 - val_accuracy: 0.8664 - val_f1_m: 0.9855\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 117us/sample - loss: 0.0179 - accuracy: 0.9946 - f1_m: 0.9551 - val_loss: 1.4068 - val_accuracy: 0.8748 - val_f1_m: 0.9954\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 118us/sample - loss: 0.0106 - accuracy: 0.9966 - f1_m: 0.9533 - val_loss: 1.5703 - val_accuracy: 0.8720 - val_f1_m: 0.9925\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 2s 119us/sample - loss: 0.0162 - accuracy: 0.9953 - f1_m: 0.9551 - val_loss: 1.4637 - val_accuracy: 0.8740 - val_f1_m: 0.9921\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 118us/sample - loss: 0.0135 - accuracy: 0.9958 - f1_m: 0.9547 - val_loss: 1.5805 - val_accuracy: 0.8696 - val_f1_m: 0.9788\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 118us/sample - loss: 0.0127 - accuracy: 0.9962 - f1_m: 0.9524 - val_loss: 1.7556 - val_accuracy: 0.8672 - val_f1_m: 0.9829\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 2s 117us/sample - loss: 0.0152 - accuracy: 0.9951 - f1_m: 0.9544 - val_loss: 1.5040 - val_accuracy: 0.8780 - val_f1_m: 0.9896\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 117us/sample - loss: 0.0103 - accuracy: 0.9963 - f1_m: 0.9524 - val_loss: 1.4704 - val_accuracy: 0.8748 - val_f1_m: 0.9732\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 4s 208us/sample - loss: 0.0575 - accuracy: 0.9859 - f1_m: 0.9686 - val_loss: 1.1728 - val_accuracy: 0.8600 - val_f1_m: 1.0065\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 3s 158us/sample - loss: 0.0402 - accuracy: 0.9879 - f1_m: 0.9694 - val_loss: 1.1268 - val_accuracy: 0.8636 - val_f1_m: 1.0083\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 3s 158us/sample - loss: 0.0236 - accuracy: 0.9929 - f1_m: 0.9635 - val_loss: 1.0987 - val_accuracy: 0.8640 - val_f1_m: 0.9986\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 3s 159us/sample - loss: 0.0369 - accuracy: 0.9877 - f1_m: 0.9666 - val_loss: 1.2156 - val_accuracy: 0.8600 - val_f1_m: 1.0216\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 3s 159us/sample - loss: 0.0314 - accuracy: 0.9901 - f1_m: 0.9678 - val_loss: 1.2446 - val_accuracy: 0.8620 - val_f1_m: 1.0100\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 3s 159us/sample - loss: 0.0411 - accuracy: 0.9879 - f1_m: 0.9690 - val_loss: 1.4430 - val_accuracy: 0.8480 - val_f1_m: 1.0100\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 3s 159us/sample - loss: 0.0407 - accuracy: 0.9867 - f1_m: 0.9706 - val_loss: 1.2913 - val_accuracy: 0.8592 - val_f1_m: 1.0101\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 3s 160us/sample - loss: 0.0345 - accuracy: 0.9897 - f1_m: 0.9658 - val_loss: 1.2553 - val_accuracy: 0.8628 - val_f1_m: 1.0099\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 3s 161us/sample - loss: 0.0260 - accuracy: 0.9919 - f1_m: 0.9640 - val_loss: 1.4674 - val_accuracy: 0.8480 - val_f1_m: 0.9965\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 3s 159us/sample - loss: 0.0332 - accuracy: 0.9895 - f1_m: 0.9651 - val_loss: 1.3223 - val_accuracy: 0.8628 - val_f1_m: 0.9924\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 2s 105us/sample - loss: 0.0889 - accuracy: 0.9743 - f1_m: 1.0220 - val_loss: 1.2045 - val_accuracy: 0.8470 - val_f1_m: 1.0324\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 1s 79us/sample - loss: 0.0804 - accuracy: 0.9764 - f1_m: 1.0209 - val_loss: 1.2178 - val_accuracy: 0.8420 - val_f1_m: 1.0361\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0805 - accuracy: 0.9743 - f1_m: 1.0201 - val_loss: 1.2408 - val_accuracy: 0.8400 - val_f1_m: 1.0498\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 1s 79us/sample - loss: 0.0760 - accuracy: 0.9767 - f1_m: 1.0214 - val_loss: 1.2178 - val_accuracy: 0.8455 - val_f1_m: 1.0358\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0729 - accuracy: 0.9787 - f1_m: 1.0187 - val_loss: 1.2229 - val_accuracy: 0.8475 - val_f1_m: 1.0453\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 1s 79us/sample - loss: 0.0735 - accuracy: 0.9773 - f1_m: 1.0212 - val_loss: 1.2418 - val_accuracy: 0.8435 - val_f1_m: 1.0352\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0736 - accuracy: 0.9765 - f1_m: 1.0193 - val_loss: 1.2672 - val_accuracy: 0.8520 - val_f1_m: 1.0372\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0758 - accuracy: 0.9756 - f1_m: 1.0191 - val_loss: 1.2736 - val_accuracy: 0.8360 - val_f1_m: 1.0365\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0695 - accuracy: 0.9784 - f1_m: 1.0169 - val_loss: 1.2539 - val_accuracy: 0.8460 - val_f1_m: 1.0390\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 1s 77us/sample - loss: 0.0657 - accuracy: 0.9806 - f1_m: 1.0152 - val_loss: 1.2311 - val_accuracy: 0.8520 - val_f1_m: 1.0286\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 2s 116us/sample - loss: 0.0799 - accuracy: 0.9776 - f1_m: 0.9968 - val_loss: 1.1238 - val_accuracy: 0.8600 - val_f1_m: 1.0172\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 87us/sample - loss: 0.0632 - accuracy: 0.9817 - f1_m: 0.9927 - val_loss: 1.1311 - val_accuracy: 0.8600 - val_f1_m: 1.0186\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 87us/sample - loss: 0.0624 - accuracy: 0.9810 - f1_m: 0.9947 - val_loss: 1.1833 - val_accuracy: 0.8540 - val_f1_m: 1.0317\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 88us/sample - loss: 0.0620 - accuracy: 0.9806 - f1_m: 0.9968 - val_loss: 1.1389 - val_accuracy: 0.8510 - val_f1_m: 1.0359\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 87us/sample - loss: 0.0574 - accuracy: 0.9817 - f1_m: 0.9960 - val_loss: 1.1607 - val_accuracy: 0.8510 - val_f1_m: 1.0130\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 87us/sample - loss: 0.0536 - accuracy: 0.9820 - f1_m: 0.9936 - val_loss: 1.1372 - val_accuracy: 0.8515 - val_f1_m: 1.0236\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 2s 89us/sample - loss: 0.0491 - accuracy: 0.9844 - f1_m: 0.9914 - val_loss: 1.1374 - val_accuracy: 0.8625 - val_f1_m: 1.0231\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 87us/sample - loss: 0.0457 - accuracy: 0.9851 - f1_m: 0.9888 - val_loss: 1.1133 - val_accuracy: 0.8600 - val_f1_m: 1.0295\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 87us/sample - loss: 0.0475 - accuracy: 0.9834 - f1_m: 0.9937 - val_loss: 1.1725 - val_accuracy: 0.8660 - val_f1_m: 1.0195\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 88us/sample - loss: 0.0451 - accuracy: 0.9851 - f1_m: 0.9903 - val_loss: 1.1455 - val_accuracy: 0.8635 - val_f1_m: 1.0149\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 3s 144us/sample - loss: 0.0584 - accuracy: 0.9852 - f1_m: 0.9760 - val_loss: 1.2290 - val_accuracy: 0.8615 - val_f1_m: 1.0033\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 110us/sample - loss: 0.0491 - accuracy: 0.9857 - f1_m: 0.9758 - val_loss: 1.2123 - val_accuracy: 0.8515 - val_f1_m: 1.0128\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0379 - accuracy: 0.9878 - f1_m: 0.9751 - val_loss: 1.2238 - val_accuracy: 0.8500 - val_f1_m: 1.0110\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0396 - accuracy: 0.9868 - f1_m: 0.9754 - val_loss: 1.2503 - val_accuracy: 0.8585 - val_f1_m: 1.0084\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 108us/sample - loss: 0.0295 - accuracy: 0.9913 - f1_m: 0.9696 - val_loss: 1.2206 - val_accuracy: 0.8515 - val_f1_m: 1.0098\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0345 - accuracy: 0.9889 - f1_m: 0.9736 - val_loss: 1.3029 - val_accuracy: 0.8615 - val_f1_m: 1.0120\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0432 - accuracy: 0.9857 - f1_m: 0.9740 - val_loss: 1.4073 - val_accuracy: 0.8505 - val_f1_m: 1.0065\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0394 - accuracy: 0.9882 - f1_m: 0.9705 - val_loss: 1.3608 - val_accuracy: 0.8565 - val_f1_m: 1.0059\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0313 - accuracy: 0.9899 - f1_m: 0.9720 - val_loss: 1.3599 - val_accuracy: 0.8570 - val_f1_m: 1.0020\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0319 - accuracy: 0.9894 - f1_m: 0.9699 - val_loss: 1.3511 - val_accuracy: 0.8565 - val_f1_m: 0.9946\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 3s 190us/sample - loss: 0.0913 - accuracy: 0.9683 - f1_m: 1.0151 - val_loss: 0.7936 - val_accuracy: 0.8655 - val_f1_m: 1.0293\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0888 - accuracy: 0.9708 - f1_m: 1.0105 - val_loss: 0.8368 - val_accuracy: 0.8545 - val_f1_m: 1.0381\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0770 - accuracy: 0.9736 - f1_m: 1.0052 - val_loss: 0.7271 - val_accuracy: 0.8570 - val_f1_m: 1.0487\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0805 - accuracy: 0.9712 - f1_m: 1.0114 - val_loss: 0.7810 - val_accuracy: 0.8560 - val_f1_m: 1.0422\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 3s 144us/sample - loss: 0.0680 - accuracy: 0.9756 - f1_m: 1.0044 - val_loss: 0.8035 - val_accuracy: 0.8575 - val_f1_m: 1.0419\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0763 - accuracy: 0.9730 - f1_m: 1.0023 - val_loss: 0.7445 - val_accuracy: 0.8495 - val_f1_m: 1.0538\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0786 - accuracy: 0.9724 - f1_m: 1.0042 - val_loss: 0.7797 - val_accuracy: 0.8605 - val_f1_m: 1.0414\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0710 - accuracy: 0.9748 - f1_m: 1.0069 - val_loss: 0.7765 - val_accuracy: 0.8605 - val_f1_m: 1.0441\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0672 - accuracy: 0.9758 - f1_m: 1.0011 - val_loss: 0.7692 - val_accuracy: 0.8625 - val_f1_m: 1.0518\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 3s 143us/sample - loss: 0.0875 - accuracy: 0.9687 - f1_m: 1.0103 - val_loss: 0.9030 - val_accuracy: 0.8485 - val_f1_m: 1.0421\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 5s 273us/sample - loss: 0.0311 - accuracy: 0.9942 - f1_m: 0.9561 - val_loss: 1.0408 - val_accuracy: 0.8700 - val_f1_m: 0.9926\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0151 - accuracy: 0.9966 - f1_m: 0.9531 - val_loss: 1.1655 - val_accuracy: 0.8690 - val_f1_m: 0.9968\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 1s 79us/sample - loss: 0.0083 - accuracy: 0.9978 - f1_m: 0.9527 - val_loss: 1.0973 - val_accuracy: 0.8675 - val_f1_m: 0.9927\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 1s 77us/sample - loss: 0.0059 - accuracy: 0.9986 - f1_m: 0.9505 - val_loss: 1.1328 - val_accuracy: 0.8735 - val_f1_m: 1.0004\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0046 - accuracy: 0.9991 - f1_m: 0.9505 - val_loss: 1.1040 - val_accuracy: 0.8725 - val_f1_m: 0.9930\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 1s 79us/sample - loss: 0.0074 - accuracy: 0.9976 - f1_m: 0.9528 - val_loss: 1.1367 - val_accuracy: 0.8675 - val_f1_m: 0.9956\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0140 - accuracy: 0.9956 - f1_m: 0.9562 - val_loss: 1.1955 - val_accuracy: 0.8735 - val_f1_m: 0.9944\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 1s 79us/sample - loss: 0.0070 - accuracy: 0.9982 - f1_m: 0.9524 - val_loss: 1.1961 - val_accuracy: 0.8705 - val_f1_m: 0.9938\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 1s 79us/sample - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9498 - val_loss: 1.1579 - val_accuracy: 0.8665 - val_f1_m: 0.9869\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 1s 78us/sample - loss: 0.0051 - accuracy: 0.9984 - f1_m: 0.9499 - val_loss: 1.1368 - val_accuracy: 0.8700 - val_f1_m: 0.9954\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 2s 122us/sample - loss: 0.0299 - accuracy: 0.9961 - f1_m: 0.9521 - val_loss: 1.0841 - val_accuracy: 0.8845 - val_f1_m: 0.9922\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 94us/sample - loss: 0.0122 - accuracy: 0.9970 - f1_m: 0.9536 - val_loss: 1.0989 - val_accuracy: 0.8750 - val_f1_m: 0.9979\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 93us/sample - loss: 0.0060 - accuracy: 0.9981 - f1_m: 0.9521 - val_loss: 1.0569 - val_accuracy: 0.8930 - val_f1_m: 0.9987\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 94us/sample - loss: 0.0077 - accuracy: 0.9981 - f1_m: 0.9516 - val_loss: 1.1253 - val_accuracy: 0.8795 - val_f1_m: 0.9885\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 93us/sample - loss: 0.0032 - accuracy: 0.9987 - f1_m: 0.9504 - val_loss: 1.2205 - val_accuracy: 0.8815 - val_f1_m: 0.9829\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 94us/sample - loss: 0.0145 - accuracy: 0.9948 - f1_m: 0.9548 - val_loss: 1.1125 - val_accuracy: 0.8755 - val_f1_m: 0.9989\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 2s 93us/sample - loss: 0.0089 - accuracy: 0.9968 - f1_m: 0.9527 - val_loss: 1.1255 - val_accuracy: 0.8870 - val_f1_m: 0.9872\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 93us/sample - loss: 0.0034 - accuracy: 0.9991 - f1_m: 0.9496 - val_loss: 1.1095 - val_accuracy: 0.8920 - val_f1_m: 0.9855\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 93us/sample - loss: 0.0017 - accuracy: 0.9996 - f1_m: 0.9482 - val_loss: 1.1369 - val_accuracy: 0.8935 - val_f1_m: 0.9798\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 94us/sample - loss: 2.7905e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 1.1606 - val_accuracy: 0.8930 - val_f1_m: 0.9746\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 3s 152us/sample - loss: 0.0455 - accuracy: 0.9917 - f1_m: 0.9580 - val_loss: 1.1477 - val_accuracy: 0.8775 - val_f1_m: 0.9853\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 116us/sample - loss: 0.0165 - accuracy: 0.9958 - f1_m: 0.9537 - val_loss: 1.3492 - val_accuracy: 0.8790 - val_f1_m: 0.9852\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 117us/sample - loss: 0.0132 - accuracy: 0.9963 - f1_m: 0.9533 - val_loss: 1.3157 - val_accuracy: 0.8835 - val_f1_m: 0.9792\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 118us/sample - loss: 0.0131 - accuracy: 0.9959 - f1_m: 0.9543 - val_loss: 1.4172 - val_accuracy: 0.8845 - val_f1_m: 0.9835\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 116us/sample - loss: 0.0185 - accuracy: 0.9946 - f1_m: 0.9543 - val_loss: 1.2964 - val_accuracy: 0.8750 - val_f1_m: 0.9853\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 117us/sample - loss: 0.0090 - accuracy: 0.9970 - f1_m: 0.9523 - val_loss: 1.3283 - val_accuracy: 0.8800 - val_f1_m: 0.9829\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 2s 117us/sample - loss: 0.0128 - accuracy: 0.9954 - f1_m: 0.9541 - val_loss: 1.5128 - val_accuracy: 0.8790 - val_f1_m: 0.9823\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 117us/sample - loss: 0.0211 - accuracy: 0.9938 - f1_m: 0.9536 - val_loss: 1.3631 - val_accuracy: 0.8795 - val_f1_m: 0.9846\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 116us/sample - loss: 0.0094 - accuracy: 0.9967 - f1_m: 0.9518 - val_loss: 1.5596 - val_accuracy: 0.8705 - val_f1_m: 0.9771\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 117us/sample - loss: 0.0076 - accuracy: 0.9976 - f1_m: 0.9509 - val_loss: 1.4586 - val_accuracy: 0.8795 - val_f1_m: 0.9892\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 4s 203us/sample - loss: 0.0536 - accuracy: 0.9850 - f1_m: 0.9714 - val_loss: 0.9162 - val_accuracy: 0.8605 - val_f1_m: 1.0213\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 3s 158us/sample - loss: 0.0307 - accuracy: 0.9902 - f1_m: 0.9657 - val_loss: 1.0188 - val_accuracy: 0.8675 - val_f1_m: 1.0095\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 3s 157us/sample - loss: 0.0204 - accuracy: 0.9936 - f1_m: 0.9598 - val_loss: 1.0912 - val_accuracy: 0.8605 - val_f1_m: 1.0046\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 3s 157us/sample - loss: 0.0534 - accuracy: 0.9844 - f1_m: 0.9738 - val_loss: 1.0368 - val_accuracy: 0.8560 - val_f1_m: 1.0172\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 3s 157us/sample - loss: 0.0532 - accuracy: 0.9830 - f1_m: 0.9734 - val_loss: 1.0629 - val_accuracy: 0.8565 - val_f1_m: 1.0097\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 3s 156us/sample - loss: 0.0186 - accuracy: 0.9933 - f1_m: 0.9617 - val_loss: 1.2327 - val_accuracy: 0.8695 - val_f1_m: 0.9822\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 3s 157us/sample - loss: 0.0315 - accuracy: 0.9904 - f1_m: 0.9631 - val_loss: 1.1474 - val_accuracy: 0.8605 - val_f1_m: 1.0105\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 3s 157us/sample - loss: 0.0450 - accuracy: 0.9854 - f1_m: 0.9714 - val_loss: 0.9891 - val_accuracy: 0.8605 - val_f1_m: 1.0150\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 3s 157us/sample - loss: 0.0369 - accuracy: 0.9877 - f1_m: 0.9687 - val_loss: 1.1091 - val_accuracy: 0.8605 - val_f1_m: 1.0061\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 3s 157us/sample - loss: 0.0308 - accuracy: 0.9902 - f1_m: 0.9657 - val_loss: 1.2252 - val_accuracy: 0.8605 - val_f1_m: 0.9961\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 102us/sample - loss: 0.0915 - accuracy: 0.9755 - f1_m: 1.0193 - val_loss: 1.2113 - val_accuracy: 0.8467 - val_f1_m: 1.0381\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0869 - accuracy: 0.9742 - f1_m: 1.0193 - val_loss: 1.1946 - val_accuracy: 0.8507 - val_f1_m: 1.0443\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0791 - accuracy: 0.9776 - f1_m: 1.0198 - val_loss: 1.2157 - val_accuracy: 0.8527 - val_f1_m: 1.0351\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0779 - accuracy: 0.9771 - f1_m: 1.0219 - val_loss: 1.1987 - val_accuracy: 0.8440 - val_f1_m: 1.0415\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0754 - accuracy: 0.9769 - f1_m: 1.0178 - val_loss: 1.1844 - val_accuracy: 0.8460 - val_f1_m: 1.0428\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0753 - accuracy: 0.9759 - f1_m: 1.0221 - val_loss: 1.2234 - val_accuracy: 0.8440 - val_f1_m: 1.0274\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 1s 76us/sample - loss: 0.0729 - accuracy: 0.9764 - f1_m: 1.0181 - val_loss: 1.2070 - val_accuracy: 0.8447 - val_f1_m: 1.0372\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 1s 78us/sample - loss: 0.0693 - accuracy: 0.9781 - f1_m: 1.0172 - val_loss: 1.2273 - val_accuracy: 0.8493 - val_f1_m: 1.0315\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0679 - accuracy: 0.9782 - f1_m: 1.0163 - val_loss: 1.2172 - val_accuracy: 0.8427 - val_f1_m: 1.0285\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0664 - accuracy: 0.9795 - f1_m: 1.0169 - val_loss: 1.2542 - val_accuracy: 0.8447 - val_f1_m: 1.0419\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 114us/sample - loss: 0.0777 - accuracy: 0.9795 - f1_m: 0.9919 - val_loss: 1.1658 - val_accuracy: 0.8607 - val_f1_m: 1.0234\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 87us/sample - loss: 0.0626 - accuracy: 0.9835 - f1_m: 0.9936 - val_loss: 1.0997 - val_accuracy: 0.8600 - val_f1_m: 1.0410\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 2s 85us/sample - loss: 0.0612 - accuracy: 0.9835 - f1_m: 0.9928 - val_loss: 1.1616 - val_accuracy: 0.8633 - val_f1_m: 1.0176\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 86us/sample - loss: 0.0754 - accuracy: 0.9795 - f1_m: 0.9957 - val_loss: 1.0899 - val_accuracy: 0.8620 - val_f1_m: 1.0325\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 86us/sample - loss: 0.0512 - accuracy: 0.9852 - f1_m: 0.9894 - val_loss: 1.1677 - val_accuracy: 0.8527 - val_f1_m: 1.0280\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 86us/sample - loss: 0.0484 - accuracy: 0.9857 - f1_m: 0.9914 - val_loss: 1.1690 - val_accuracy: 0.8560 - val_f1_m: 1.0362\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 2s 85us/sample - loss: 0.0529 - accuracy: 0.9833 - f1_m: 0.9944 - val_loss: 1.1098 - val_accuracy: 0.8587 - val_f1_m: 1.0286\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 85us/sample - loss: 0.0520 - accuracy: 0.9838 - f1_m: 0.9900 - val_loss: 1.1433 - val_accuracy: 0.8553 - val_f1_m: 1.0294\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 86us/sample - loss: 0.0520 - accuracy: 0.9841 - f1_m: 0.9910 - val_loss: 1.1413 - val_accuracy: 0.8627 - val_f1_m: 1.0346\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 85us/sample - loss: 0.0453 - accuracy: 0.9862 - f1_m: 0.9888 - val_loss: 1.1703 - val_accuracy: 0.8580 - val_f1_m: 1.0133\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0684 - accuracy: 0.9849 - f1_m: 0.9753 - val_loss: 1.1614 - val_accuracy: 0.8640 - val_f1_m: 1.0136\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 108us/sample - loss: 0.0513 - accuracy: 0.9870 - f1_m: 0.9776 - val_loss: 1.1650 - val_accuracy: 0.8613 - val_f1_m: 1.0054\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 2s 106us/sample - loss: 0.0369 - accuracy: 0.9890 - f1_m: 0.9734 - val_loss: 1.2409 - val_accuracy: 0.8627 - val_f1_m: 1.0063\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 106us/sample - loss: 0.0404 - accuracy: 0.9865 - f1_m: 0.9751 - val_loss: 1.2341 - val_accuracy: 0.8540 - val_f1_m: 1.0019\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 107us/sample - loss: 0.0461 - accuracy: 0.9841 - f1_m: 0.9784 - val_loss: 1.2294 - val_accuracy: 0.8560 - val_f1_m: 1.0126\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 107us/sample - loss: 0.0363 - accuracy: 0.9895 - f1_m: 0.9719 - val_loss: 1.1864 - val_accuracy: 0.8507 - val_f1_m: 1.0171\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 2s 107us/sample - loss: 0.0390 - accuracy: 0.9869 - f1_m: 0.9767 - val_loss: 1.3158 - val_accuracy: 0.8587 - val_f1_m: 1.0133\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 107us/sample - loss: 0.0212 - accuracy: 0.9934 - f1_m: 0.9657 - val_loss: 1.3603 - val_accuracy: 0.8640 - val_f1_m: 1.0048\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 107us/sample - loss: 0.0458 - accuracy: 0.9844 - f1_m: 0.9747 - val_loss: 1.2983 - val_accuracy: 0.8600 - val_f1_m: 0.9980\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 106us/sample - loss: 0.0308 - accuracy: 0.9897 - f1_m: 0.9707 - val_loss: 1.2867 - val_accuracy: 0.8513 - val_f1_m: 1.0073\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 3s 187us/sample - loss: 0.0946 - accuracy: 0.9686 - f1_m: 1.0087 - val_loss: 0.6716 - val_accuracy: 0.8647 - val_f1_m: 1.0563\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0800 - accuracy: 0.9737 - f1_m: 1.0079 - val_loss: 0.6893 - val_accuracy: 0.8660 - val_f1_m: 1.0598\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0809 - accuracy: 0.9710 - f1_m: 1.0093 - val_loss: 0.7214 - val_accuracy: 0.8620 - val_f1_m: 1.0525\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 3s 143us/sample - loss: 0.0743 - accuracy: 0.9743 - f1_m: 1.0039 - val_loss: 0.7059 - val_accuracy: 0.8507 - val_f1_m: 1.0670\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0821 - accuracy: 0.9709 - f1_m: 1.0084 - val_loss: 0.7331 - val_accuracy: 0.8620 - val_f1_m: 1.0405\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0854 - accuracy: 0.9695 - f1_m: 1.0084 - val_loss: 0.7804 - val_accuracy: 0.8660 - val_f1_m: 1.0284\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0828 - accuracy: 0.9722 - f1_m: 1.0059 - val_loss: 0.7195 - val_accuracy: 0.8613 - val_f1_m: 1.0473\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0662 - accuracy: 0.9761 - f1_m: 1.0008 - val_loss: 0.8052 - val_accuracy: 0.8513 - val_f1_m: 1.0541\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0690 - accuracy: 0.9759 - f1_m: 1.0000 - val_loss: 0.8267 - val_accuracy: 0.8593 - val_f1_m: 1.0466\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 3s 142us/sample - loss: 0.0836 - accuracy: 0.9698 - f1_m: 1.0090 - val_loss: 0.7411 - val_accuracy: 0.8620 - val_f1_m: 1.0417\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 101us/sample - loss: 0.0372 - accuracy: 0.9943 - f1_m: 0.9560 - val_loss: 1.1342 - val_accuracy: 0.8793 - val_f1_m: 1.0078\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 1s 76us/sample - loss: 0.0160 - accuracy: 0.9968 - f1_m: 0.9542 - val_loss: 1.1312 - val_accuracy: 0.8753 - val_f1_m: 0.9966\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 1s 76us/sample - loss: 0.0094 - accuracy: 0.9976 - f1_m: 0.9525 - val_loss: 1.1043 - val_accuracy: 0.8747 - val_f1_m: 1.0077\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0049 - accuracy: 0.9988 - f1_m: 0.9508 - val_loss: 1.1645 - val_accuracy: 0.8773 - val_f1_m: 1.0051\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 1s 76us/sample - loss: 0.0076 - accuracy: 0.9976 - f1_m: 0.9523 - val_loss: 1.1817 - val_accuracy: 0.8707 - val_f1_m: 1.0006\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 7.6082e-04 - accuracy: 0.9998 - f1_m: 0.9478 - val_loss: 1.2772 - val_accuracy: 0.8713 - val_f1_m: 0.9993\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 1s 76us/sample - loss: 0.0092 - accuracy: 0.9965 - f1_m: 0.9549 - val_loss: 1.2372 - val_accuracy: 0.8687 - val_f1_m: 1.0054\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 1s 76us/sample - loss: 0.0084 - accuracy: 0.9975 - f1_m: 0.9533 - val_loss: 1.1657 - val_accuracy: 0.8807 - val_f1_m: 0.9997\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 1s 77us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9476 - val_loss: 1.2024 - val_accuracy: 0.8713 - val_f1_m: 0.9975\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 1s 76us/sample - loss: 0.0069 - accuracy: 0.9976 - f1_m: 0.9523 - val_loss: 1.2970 - val_accuracy: 0.8787 - val_f1_m: 0.9971\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 0.0334 - accuracy: 0.9946 - f1_m: 0.9536 - val_loss: 1.0391 - val_accuracy: 0.8860 - val_f1_m: 0.9924\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 92us/sample - loss: 0.0121 - accuracy: 0.9969 - f1_m: 0.9523 - val_loss: 1.0932 - val_accuracy: 0.8907 - val_f1_m: 0.9917\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 2s 91us/sample - loss: 0.0030 - accuracy: 0.9994 - f1_m: 0.9494 - val_loss: 1.0905 - val_accuracy: 0.8907 - val_f1_m: 0.9894\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 92us/sample - loss: 0.0018 - accuracy: 0.9996 - f1_m: 0.9482 - val_loss: 1.1200 - val_accuracy: 0.8873 - val_f1_m: 0.9861\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 91us/sample - loss: 0.0087 - accuracy: 0.9973 - f1_m: 0.9526 - val_loss: 1.1678 - val_accuracy: 0.8913 - val_f1_m: 0.9903\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 92us/sample - loss: 0.0112 - accuracy: 0.9962 - f1_m: 0.9548 - val_loss: 1.2152 - val_accuracy: 0.8880 - val_f1_m: 0.9966\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 2s 91us/sample - loss: 0.0042 - accuracy: 0.9982 - f1_m: 0.9502 - val_loss: 1.1329 - val_accuracy: 0.8873 - val_f1_m: 0.9825\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 91us/sample - loss: 0.0066 - accuracy: 0.9980 - f1_m: 0.9515 - val_loss: 1.2689 - val_accuracy: 0.8933 - val_f1_m: 0.9838\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 92us/sample - loss: 0.0027 - accuracy: 0.9990 - f1_m: 0.9495 - val_loss: 1.2602 - val_accuracy: 0.8900 - val_f1_m: 0.9759\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 91us/sample - loss: 0.0128 - accuracy: 0.9958 - f1_m: 0.9530 - val_loss: 1.2727 - val_accuracy: 0.8800 - val_f1_m: 0.9820\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 3s 149us/sample - loss: 0.0419 - accuracy: 0.9924 - f1_m: 0.9562 - val_loss: 1.2716 - val_accuracy: 0.8767 - val_f1_m: 0.9894\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 113us/sample - loss: 0.0109 - accuracy: 0.9976 - f1_m: 0.9515 - val_loss: 1.4242 - val_accuracy: 0.8793 - val_f1_m: 0.9820\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 2s 113us/sample - loss: 0.0124 - accuracy: 0.9965 - f1_m: 0.9518 - val_loss: 1.4479 - val_accuracy: 0.8787 - val_f1_m: 0.9790\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 115us/sample - loss: 0.0155 - accuracy: 0.9958 - f1_m: 0.9530 - val_loss: 1.2694 - val_accuracy: 0.8900 - val_f1_m: 0.9798\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 113us/sample - loss: 0.0136 - accuracy: 0.9961 - f1_m: 0.9528 - val_loss: 1.4394 - val_accuracy: 0.8787 - val_f1_m: 0.9893\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 116us/sample - loss: 0.0208 - accuracy: 0.9942 - f1_m: 0.9543 - val_loss: 1.3983 - val_accuracy: 0.8800 - val_f1_m: 0.9849\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9975 - f1_m: 0.951 - 2s 114us/sample - loss: 0.0077 - accuracy: 0.9975 - f1_m: 0.9509 - val_loss: 1.4182 - val_accuracy: 0.8747 - val_f1_m: 0.9865\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 114us/sample - loss: 0.0117 - accuracy: 0.9959 - f1_m: 0.9532 - val_loss: 1.6471 - val_accuracy: 0.8767 - val_f1_m: 0.9809\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 115us/sample - loss: 0.0151 - accuracy: 0.9955 - f1_m: 0.9533 - val_loss: 1.6682 - val_accuracy: 0.8687 - val_f1_m: 0.9829\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 114us/sample - loss: 0.0180 - accuracy: 0.9950 - f1_m: 0.9530 - val_loss: 1.6627 - val_accuracy: 0.8787 - val_f1_m: 0.9797\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 4s 199us/sample - loss: 0.0518 - accuracy: 0.9865 - f1_m: 0.9685 - val_loss: 1.2499 - val_accuracy: 0.8613 - val_f1_m: 1.0035\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 3s 155us/sample - loss: 0.0450 - accuracy: 0.9869 - f1_m: 0.9674 - val_loss: 1.0875 - val_accuracy: 0.8567 - val_f1_m: 1.0148\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 3s 154us/sample - loss: 0.0303 - accuracy: 0.9901 - f1_m: 0.9649 - val_loss: 1.2835 - val_accuracy: 0.8527 - val_f1_m: 1.0150\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 3s 154us/sample - loss: 0.0414 - accuracy: 0.9865 - f1_m: 0.9701 - val_loss: 1.0731 - val_accuracy: 0.8620 - val_f1_m: 1.0124\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 3s 156us/sample - loss: 0.0414 - accuracy: 0.9870 - f1_m: 0.9683 - val_loss: 1.1179 - val_accuracy: 0.8633 - val_f1_m: 1.0073\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 3s 155us/sample - loss: 0.0282 - accuracy: 0.9910 - f1_m: 0.9628 - val_loss: 1.3405 - val_accuracy: 0.8633 - val_f1_m: 1.0063\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 3s 155us/sample - loss: 0.0312 - accuracy: 0.9904 - f1_m: 0.9628 - val_loss: 1.1491 - val_accuracy: 0.8533 - val_f1_m: 1.0084\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 3s 155us/sample - loss: 0.0476 - accuracy: 0.9853 - f1_m: 0.9710 - val_loss: 1.2112 - val_accuracy: 0.8607 - val_f1_m: 1.0036\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 3s 155us/sample - loss: 0.0304 - accuracy: 0.9898 - f1_m: 0.9640 - val_loss: 1.1482 - val_accuracy: 0.8693 - val_f1_m: 1.0130\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 3s 156us/sample - loss: 0.0220 - accuracy: 0.9932 - f1_m: 0.9590 - val_loss: 1.5024 - val_accuracy: 0.8687 - val_f1_m: 1.0084\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000/19000 [==============================] - 2s 100us/sample - loss: 0.0958 - accuracy: 0.9736 - f1_m: 1.0218 - val_loss: 1.3750 - val_accuracy: 0.8270 - val_f1_m: 1.0342\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 1s 74us/sample - loss: 0.0894 - accuracy: 0.9758 - f1_m: 1.0207 - val_loss: 1.3442 - val_accuracy: 0.8400 - val_f1_m: 1.0291\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0857 - accuracy: 0.9759 - f1_m: 1.0199 - val_loss: 1.3261 - val_accuracy: 0.8340 - val_f1_m: 1.0297\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 1s 77us/sample - loss: 0.0823 - accuracy: 0.9769 - f1_m: 1.0183 - val_loss: 1.3648 - val_accuracy: 0.8380 - val_f1_m: 1.0330\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 1s 78us/sample - loss: 0.0782 - accuracy: 0.9779 - f1_m: 1.0165 - val_loss: 1.3642 - val_accuracy: 0.8350 - val_f1_m: 1.0385\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 1s 77us/sample - loss: 0.0826 - accuracy: 0.9751 - f1_m: 1.0181 - val_loss: 1.3697 - val_accuracy: 0.8360 - val_f1_m: 1.0358\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 1s 74us/sample - loss: 0.0780 - accuracy: 0.9761 - f1_m: 1.0208 - val_loss: 1.3435 - val_accuracy: 0.8320 - val_f1_m: 1.0208\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 1s 74us/sample - loss: 0.0742 - accuracy: 0.9786 - f1_m: 1.0164 - val_loss: 1.3671 - val_accuracy: 0.8370 - val_f1_m: 1.0261\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 1s 74us/sample - loss: 0.0788 - accuracy: 0.9759 - f1_m: 1.0184 - val_loss: 1.3855 - val_accuracy: 0.8320 - val_f1_m: 1.0298\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0710 - accuracy: 0.9786 - f1_m: 1.0175 - val_loss: 1.3893 - val_accuracy: 0.8270 - val_f1_m: 1.0263\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 2s 111us/sample - loss: 0.0706 - accuracy: 0.9824 - f1_m: 0.9953 - val_loss: 1.2271 - val_accuracy: 0.8560 - val_f1_m: 1.0176\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 84us/sample - loss: 0.0617 - accuracy: 0.9835 - f1_m: 0.9909 - val_loss: 1.1665 - val_accuracy: 0.8620 - val_f1_m: 1.0197\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 0.0598 - accuracy: 0.9839 - f1_m: 0.9912 - val_loss: 1.2409 - val_accuracy: 0.8550 - val_f1_m: 1.0102\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 0.0597 - accuracy: 0.9822 - f1_m: 0.9965 - val_loss: 1.1974 - val_accuracy: 0.8590 - val_f1_m: 1.0201\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 84us/sample - loss: 0.0495 - accuracy: 0.9854 - f1_m: 0.9894 - val_loss: 1.2334 - val_accuracy: 0.8610 - val_f1_m: 1.0122\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 0.0526 - accuracy: 0.9828 - f1_m: 0.9906 - val_loss: 1.2638 - val_accuracy: 0.8670 - val_f1_m: 1.0060\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 85us/sample - loss: 0.0540 - accuracy: 0.9826 - f1_m: 0.9931 - val_loss: 1.2826 - val_accuracy: 0.8600 - val_f1_m: 0.9928\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 0.0508 - accuracy: 0.9836 - f1_m: 0.9900 - val_loss: 1.2541 - val_accuracy: 0.8620 - val_f1_m: 1.0263\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 84us/sample - loss: 0.0484 - accuracy: 0.9837 - f1_m: 0.9918 - val_loss: 1.2203 - val_accuracy: 0.8630 - val_f1_m: 0.9940\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 2s 84us/sample - loss: 0.0431 - accuracy: 0.9867 - f1_m: 0.9888 - val_loss: 1.2378 - val_accuracy: 0.8640 - val_f1_m: 1.0029\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 3s 138us/sample - loss: 0.0636 - accuracy: 0.9844 - f1_m: 0.9760 - val_loss: 1.2802 - val_accuracy: 0.8490 - val_f1_m: 1.0127\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 105us/sample - loss: 0.0474 - accuracy: 0.9877 - f1_m: 0.9747 - val_loss: 1.2851 - val_accuracy: 0.8570 - val_f1_m: 1.0146\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 104us/sample - loss: 0.0502 - accuracy: 0.9846 - f1_m: 0.9757 - val_loss: 1.2438 - val_accuracy: 0.8560 - val_f1_m: 1.0069\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 105us/sample - loss: 0.0433 - accuracy: 0.9867 - f1_m: 0.9751 - val_loss: 1.2525 - val_accuracy: 0.8580 - val_f1_m: 1.0120\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 107us/sample - loss: 0.0425 - accuracy: 0.9867 - f1_m: 0.9763 - val_loss: 1.2677 - val_accuracy: 0.8510 - val_f1_m: 1.0107\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 106us/sample - loss: 0.0319 - accuracy: 0.9893 - f1_m: 0.9710 - val_loss: 1.3115 - val_accuracy: 0.8590 - val_f1_m: 1.0022\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 106us/sample - loss: 0.0388 - accuracy: 0.9871 - f1_m: 0.9744 - val_loss: 1.3630 - val_accuracy: 0.8560 - val_f1_m: 0.9983\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 107us/sample - loss: 0.0447 - accuracy: 0.9850 - f1_m: 0.9762 - val_loss: 1.3526 - val_accuracy: 0.8570 - val_f1_m: 0.9992\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 106us/sample - loss: 0.0353 - accuracy: 0.9883 - f1_m: 0.9701 - val_loss: 1.3470 - val_accuracy: 0.8470 - val_f1_m: 0.9967\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 2s 107us/sample - loss: 0.0299 - accuracy: 0.9894 - f1_m: 0.9699 - val_loss: 1.4277 - val_accuracy: 0.8490 - val_f1_m: 1.0026\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 4s 184us/sample - loss: 0.0996 - accuracy: 0.9668 - f1_m: 1.0178 - val_loss: 0.7886 - val_accuracy: 0.8510 - val_f1_m: 1.0568\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 3s 140us/sample - loss: 0.0762 - accuracy: 0.9741 - f1_m: 1.0043 - val_loss: 0.7349 - val_accuracy: 0.8590 - val_f1_m: 1.0278\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 3s 139us/sample - loss: 0.0801 - accuracy: 0.9714 - f1_m: 1.0094 - val_loss: 0.7791 - val_accuracy: 0.8510 - val_f1_m: 1.0601\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 3s 140us/sample - loss: 0.0809 - accuracy: 0.9731 - f1_m: 1.0086 - val_loss: 0.7566 - val_accuracy: 0.8580 - val_f1_m: 1.0397\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 3s 139us/sample - loss: 0.0882 - accuracy: 0.9696 - f1_m: 1.0111 - val_loss: 0.7497 - val_accuracy: 0.8660 - val_f1_m: 1.0293\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 3s 139us/sample - loss: 0.0751 - accuracy: 0.9733 - f1_m: 1.0052 - val_loss: 0.7105 - val_accuracy: 0.8640 - val_f1_m: 1.0454\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 3s 141us/sample - loss: 0.0645 - accuracy: 0.9775 - f1_m: 1.0009 - val_loss: 0.8473 - val_accuracy: 0.8540 - val_f1_m: 1.0414\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 3s 139us/sample - loss: 0.0899 - accuracy: 0.9693 - f1_m: 1.0091 - val_loss: 0.7789 - val_accuracy: 0.8630 - val_f1_m: 1.0277\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 3s 139us/sample - loss: 0.0772 - accuracy: 0.9725 - f1_m: 1.0067 - val_loss: 0.7469 - val_accuracy: 0.8600 - val_f1_m: 1.0383\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 3s 139us/sample - loss: 0.0696 - accuracy: 0.9764 - f1_m: 1.0001 - val_loss: 0.9036 - val_accuracy: 0.8650 - val_f1_m: 1.0045\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 2s 99us/sample - loss: 0.0338 - accuracy: 0.9940 - f1_m: 0.9560 - val_loss: 1.3322 - val_accuracy: 0.8700 - val_f1_m: 0.9928\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0193 - accuracy: 0.9958 - f1_m: 0.9532 - val_loss: 1.2915 - val_accuracy: 0.8680 - val_f1_m: 0.9891\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0127 - accuracy: 0.9973 - f1_m: 0.9533 - val_loss: 1.2573 - val_accuracy: 0.8660 - val_f1_m: 0.9818\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0071 - accuracy: 0.9982 - f1_m: 0.9524 - val_loss: 1.2457 - val_accuracy: 0.8710 - val_f1_m: 0.9963\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 1s 74us/sample - loss: 0.0028 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 1.2891 - val_accuracy: 0.8690 - val_f1_m: 0.9945\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0046 - accuracy: 0.9989 - f1_m: 0.9496 - val_loss: 1.2069 - val_accuracy: 0.8650 - val_f1_m: 0.9957\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0146 - accuracy: 0.9958 - f1_m: 0.9562 - val_loss: 1.2806 - val_accuracy: 0.8540 - val_f1_m: 0.9951\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 1s 74us/sample - loss: 0.0079 - accuracy: 0.9971 - f1_m: 0.9543 - val_loss: 1.2862 - val_accuracy: 0.8710 - val_f1_m: 0.9948\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 0.0032 - accuracy: 0.9992 - f1_m: 0.9499 - val_loss: 1.2346 - val_accuracy: 0.8700 - val_f1_m: 0.9926\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 1s 75us/sample - loss: 4.1966e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 1.2610 - val_accuracy: 0.8690 - val_f1_m: 0.9937\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 2s 116us/sample - loss: 0.0393 - accuracy: 0.9944 - f1_m: 0.9542 - val_loss: 1.2801 - val_accuracy: 0.8800 - val_f1_m: 0.9789\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 90us/sample - loss: 0.0167 - accuracy: 0.9957 - f1_m: 0.9539 - val_loss: 1.2717 - val_accuracy: 0.8770 - val_f1_m: 0.9858\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 90us/sample - loss: 0.0116 - accuracy: 0.9971 - f1_m: 0.9532 - val_loss: 1.2926 - val_accuracy: 0.8780 - val_f1_m: 0.9881\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 89us/sample - loss: 0.0086 - accuracy: 0.9979 - f1_m: 0.9516 - val_loss: 1.2482 - val_accuracy: 0.8740 - val_f1_m: 0.9829\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 89us/sample - loss: 0.0048 - accuracy: 0.9988 - f1_m: 0.9500 - val_loss: 1.3010 - val_accuracy: 0.8810 - val_f1_m: 0.9881\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 89us/sample - loss: 0.0041 - accuracy: 0.9988 - f1_m: 0.9503 - val_loss: 1.3404 - val_accuracy: 0.8720 - val_f1_m: 0.9777\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 89us/sample - loss: 0.0211 - accuracy: 0.9944 - f1_m: 0.9550 - val_loss: 1.2355 - val_accuracy: 0.8820 - val_f1_m: 0.9891\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 89us/sample - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9499 - val_loss: 1.2058 - val_accuracy: 0.8900 - val_f1_m: 0.9798\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 89us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_m: 0.9493 - val_loss: 1.2136 - val_accuracy: 0.8920 - val_f1_m: 0.9804\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 2s 90us/sample - loss: 0.0048 - accuracy: 0.9985 - f1_m: 0.9503 - val_loss: 1.3692 - val_accuracy: 0.8820 - val_f1_m: 0.9808\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 3s 145us/sample - loss: 0.0443 - accuracy: 0.9919 - f1_m: 0.9564 - val_loss: 1.2891 - val_accuracy: 0.8770 - val_f1_m: 0.9905\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 113us/sample - loss: 0.0161 - accuracy: 0.9961 - f1_m: 0.9533 - val_loss: 1.3783 - val_accuracy: 0.8840 - val_f1_m: 0.9781\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 112us/sample - loss: 0.0142 - accuracy: 0.9962 - f1_m: 0.9520 - val_loss: 1.3584 - val_accuracy: 0.8800 - val_f1_m: 0.9865\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 112us/sample - loss: 0.0197 - accuracy: 0.9950 - f1_m: 0.9549 - val_loss: 1.4759 - val_accuracy: 0.8800 - val_f1_m: 0.9656\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 112us/sample - loss: 0.0133 - accuracy: 0.9959 - f1_m: 0.9533 - val_loss: 1.4572 - val_accuracy: 0.8750 - val_f1_m: 0.9764\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 112us/sample - loss: 0.0117 - accuracy: 0.9965 - f1_m: 0.9532 - val_loss: 1.7218 - val_accuracy: 0.8670 - val_f1_m: 0.9791\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 112us/sample - loss: 0.0202 - accuracy: 0.9950 - f1_m: 0.9534 - val_loss: 1.4997 - val_accuracy: 0.8850 - val_f1_m: 0.9892\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 111us/sample - loss: 0.0202 - accuracy: 0.9939 - f1_m: 0.9555 - val_loss: 1.7163 - val_accuracy: 0.8670 - val_f1_m: 0.9741\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 112us/sample - loss: 0.0141 - accuracy: 0.9964 - f1_m: 0.9531 - val_loss: 1.7021 - val_accuracy: 0.8860 - val_f1_m: 0.9769\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 2s 113us/sample - loss: 0.0157 - accuracy: 0.9955 - f1_m: 0.9528 - val_loss: 1.7328 - val_accuracy: 0.8650 - val_f1_m: 0.9735\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 4s 195us/sample - loss: 0.0621 - accuracy: 0.9866 - f1_m: 0.9706 - val_loss: 1.1694 - val_accuracy: 0.8550 - val_f1_m: 1.0171\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 3s 153us/sample - loss: 0.0350 - accuracy: 0.9907 - f1_m: 0.9667 - val_loss: 1.1524 - val_accuracy: 0.8470 - val_f1_m: 1.0191\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 3s 152us/sample - loss: 0.0261 - accuracy: 0.9928 - f1_m: 0.9661 - val_loss: 1.0395 - val_accuracy: 0.8650 - val_f1_m: 1.0185\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 3s 152us/sample - loss: 0.0429 - accuracy: 0.9878 - f1_m: 0.9687 - val_loss: 1.3386 - val_accuracy: 0.8530 - val_f1_m: 0.9934\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 3s 151us/sample - loss: 0.0478 - accuracy: 0.9857 - f1_m: 0.9709 - val_loss: 1.0632 - val_accuracy: 0.8650 - val_f1_m: 1.0237\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 3s 152us/sample - loss: 0.0308 - accuracy: 0.9907 - f1_m: 0.9660 - val_loss: 1.0004 - val_accuracy: 0.8510 - val_f1_m: 1.0364\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 3s 152us/sample - loss: 0.0298 - accuracy: 0.9906 - f1_m: 0.9651 - val_loss: 1.1845 - val_accuracy: 0.8550 - val_f1_m: 1.0158\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 3s 152us/sample - loss: 0.0360 - accuracy: 0.9884 - f1_m: 0.9699 - val_loss: 1.2658 - val_accuracy: 0.8580 - val_f1_m: 1.0156\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 3s 151us/sample - loss: 0.0388 - accuracy: 0.9880 - f1_m: 0.9671 - val_loss: 1.1570 - val_accuracy: 0.8490 - val_f1_m: 1.0048\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 3s 151us/sample - loss: 0.0373 - accuracy: 0.9894 - f1_m: 0.9666 - val_loss: 1.2862 - val_accuracy: 0.8570 - val_f1_m: 0.9855\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 2s 99us/sample - loss: 0.0905 - accuracy: 0.9744 - f1_m: 1.0214 - val_loss: 1.5018 - val_accuracy: 0.8220 - val_f1_m: 1.0503\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0831 - accuracy: 0.9769 - f1_m: 1.0200 - val_loss: 1.4659 - val_accuracy: 0.8400 - val_f1_m: 1.0359\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0838 - accuracy: 0.9747 - f1_m: 1.0193 - val_loss: 1.5223 - val_accuracy: 0.8240 - val_f1_m: 1.0356\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0774 - accuracy: 0.9782 - f1_m: 1.0191 - val_loss: 1.5337 - val_accuracy: 0.8240 - val_f1_m: 1.0545\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0769 - accuracy: 0.9769 - f1_m: 1.0182 - val_loss: 1.4500 - val_accuracy: 0.8360 - val_f1_m: 1.0347\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0761 - accuracy: 0.9762 - f1_m: 1.0175 - val_loss: 1.4864 - val_accuracy: 0.8300 - val_f1_m: 1.0366\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0743 - accuracy: 0.9774 - f1_m: 1.0173 - val_loss: 1.5431 - val_accuracy: 0.8220 - val_f1_m: 1.0436\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 1s 74us/sample - loss: 0.0699 - accuracy: 0.9793 - f1_m: 1.0197 - val_loss: 1.4983 - val_accuracy: 0.8240 - val_f1_m: 1.0432\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 1s 72us/sample - loss: 0.0702 - accuracy: 0.9776 - f1_m: 1.0173 - val_loss: 1.4883 - val_accuracy: 0.8240 - val_f1_m: 1.0483\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 1s 77us/sample - loss: 0.0715 - accuracy: 0.9772 - f1_m: 1.0183 - val_loss: 1.5407 - val_accuracy: 0.8300 - val_f1_m: 1.0399\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 2s 108us/sample - loss: 0.0649 - accuracy: 0.9833 - f1_m: 0.9904 - val_loss: 1.4151 - val_accuracy: 0.8380 - val_f1_m: 1.0448\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0582 - accuracy: 0.9826 - f1_m: 0.9907 - val_loss: 1.3371 - val_accuracy: 0.8500 - val_f1_m: 1.0254\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0616 - accuracy: 0.9810 - f1_m: 0.9947 - val_loss: 1.3361 - val_accuracy: 0.8620 - val_f1_m: 1.0423\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0536 - accuracy: 0.9835 - f1_m: 0.9928 - val_loss: 1.3949 - val_accuracy: 0.8500 - val_f1_m: 1.0253\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0439 - accuracy: 0.9864 - f1_m: 0.9891 - val_loss: 1.3580 - val_accuracy: 0.8520 - val_f1_m: 1.0347\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 83us/sample - loss: 0.0501 - accuracy: 0.9841 - f1_m: 0.9895 - val_loss: 1.3401 - val_accuracy: 0.8660 - val_f1_m: 1.0255\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0507 - accuracy: 0.9844 - f1_m: 0.9877 - val_loss: 1.4231 - val_accuracy: 0.8640 - val_f1_m: 1.0129\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0425 - accuracy: 0.9851 - f1_m: 0.9884 - val_loss: 1.2677 - val_accuracy: 0.8600 - val_f1_m: 1.0409\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 83us/sample - loss: 0.0436 - accuracy: 0.9856 - f1_m: 0.9878 - val_loss: 1.3407 - val_accuracy: 0.8620 - val_f1_m: 1.0417\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0440 - accuracy: 0.9853 - f1_m: 0.9900 - val_loss: 1.3852 - val_accuracy: 0.8560 - val_f1_m: 1.0254\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 3s 139us/sample - loss: 0.0622 - accuracy: 0.9846 - f1_m: 0.9772 - val_loss: 1.3056 - val_accuracy: 0.8560 - val_f1_m: 1.0101\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0471 - accuracy: 0.9862 - f1_m: 0.9727 - val_loss: 1.2595 - val_accuracy: 0.8480 - val_f1_m: 1.0282\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0371 - accuracy: 0.9888 - f1_m: 0.9709 - val_loss: 1.4523 - val_accuracy: 0.8680 - val_f1_m: 1.0031\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0355 - accuracy: 0.9880 - f1_m: 0.9743 - val_loss: 1.5091 - val_accuracy: 0.8580 - val_f1_m: 1.0140\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0432 - accuracy: 0.9864 - f1_m: 0.9738 - val_loss: 1.4414 - val_accuracy: 0.8580 - val_f1_m: 1.0170\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0359 - accuracy: 0.9870 - f1_m: 0.9722 - val_loss: 1.4177 - val_accuracy: 0.8620 - val_f1_m: 1.0066\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 102us/sample - loss: 0.0433 - accuracy: 0.9859 - f1_m: 0.9731 - val_loss: 1.4809 - val_accuracy: 0.8500 - val_f1_m: 1.0134\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0346 - accuracy: 0.9886 - f1_m: 0.9716 - val_loss: 1.6502 - val_accuracy: 0.8580 - val_f1_m: 0.9999\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0312 - accuracy: 0.9889 - f1_m: 0.9706 - val_loss: 1.5024 - val_accuracy: 0.8640 - val_f1_m: 1.0046\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 0.0389 - accuracy: 0.9869 - f1_m: 0.9718 - val_loss: 1.4772 - val_accuracy: 0.8580 - val_f1_m: 0.9978\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 4s 181us/sample - loss: 0.0921 - accuracy: 0.9714 - f1_m: 1.0075 - val_loss: 0.8015 - val_accuracy: 0.8720 - val_f1_m: 1.0270\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 3s 137us/sample - loss: 0.0782 - accuracy: 0.9732 - f1_m: 1.0067 - val_loss: 0.7320 - val_accuracy: 0.8720 - val_f1_m: 1.0266\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 3s 136us/sample - loss: 0.0832 - accuracy: 0.9707 - f1_m: 1.0092 - val_loss: 0.7963 - val_accuracy: 0.8760 - val_f1_m: 1.0495\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 3s 137us/sample - loss: 0.0692 - accuracy: 0.9752 - f1_m: 1.0011 - val_loss: 0.8108 - val_accuracy: 0.8700 - val_f1_m: 1.0282\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 3s 137us/sample - loss: 0.0840 - accuracy: 0.9698 - f1_m: 1.0066 - val_loss: 0.7130 - val_accuracy: 0.8800 - val_f1_m: 1.0401\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 3s 136us/sample - loss: 0.0689 - accuracy: 0.9761 - f1_m: 1.0050 - val_loss: 0.7886 - val_accuracy: 0.8760 - val_f1_m: 1.0315\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 3s 137us/sample - loss: 0.0783 - accuracy: 0.9718 - f1_m: 1.0076 - val_loss: 0.8995 - val_accuracy: 0.8600 - val_f1_m: 1.0168\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 3s 137us/sample - loss: 0.0768 - accuracy: 0.9746 - f1_m: 1.0031 - val_loss: 0.8307 - val_accuracy: 0.8720 - val_f1_m: 1.0449\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 3s 137us/sample - loss: 0.0787 - accuracy: 0.9732 - f1_m: 1.0081 - val_loss: 0.8670 - val_accuracy: 0.8820 - val_f1_m: 1.0263\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 3s 137us/sample - loss: 0.0622 - accuracy: 0.9770 - f1_m: 0.9996 - val_loss: 0.9205 - val_accuracy: 0.8760 - val_f1_m: 1.0124\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 2s 97us/sample - loss: 0.0252 - accuracy: 0.9953 - f1_m: 0.9549 - val_loss: 1.3278 - val_accuracy: 0.8620 - val_f1_m: 0.9853\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0123 - accuracy: 0.9970 - f1_m: 0.9536 - val_loss: 1.3074 - val_accuracy: 0.8600 - val_f1_m: 0.9917\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 1s 75us/sample - loss: 0.0068 - accuracy: 0.9981 - f1_m: 0.9529 - val_loss: 1.4209 - val_accuracy: 0.8700 - val_f1_m: 0.9956\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 1s 74us/sample - loss: 0.0081 - accuracy: 0.9976 - f1_m: 0.9524 - val_loss: 1.3085 - val_accuracy: 0.8860 - val_f1_m: 0.9956\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 1s 74us/sample - loss: 0.0029 - accuracy: 0.9992 - f1_m: 0.9502 - val_loss: 1.3055 - val_accuracy: 0.8920 - val_f1_m: 0.9956\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 77us/sample - loss: 8.8533e-04 - accuracy: 0.9998 - f1_m: 0.9477 - val_loss: 1.3077 - val_accuracy: 0.8740 - val_f1_m: 0.9977\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 1s 74us/sample - loss: 2.5184e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 1.3238 - val_accuracy: 0.8780 - val_f1_m: 0.9936\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 1s 74us/sample - loss: 8.8236e-04 - accuracy: 0.9997 - f1_m: 0.9480 - val_loss: 1.3169 - val_accuracy: 0.8680 - val_f1_m: 0.9958\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 1s 74us/sample - loss: 0.0292 - accuracy: 0.9909 - f1_m: 0.9631 - val_loss: 1.4314 - val_accuracy: 0.8700 - val_f1_m: 0.9945\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19500/19500 [==============================] - 1s 73us/sample - loss: 0.0035 - accuracy: 0.9991 - f1_m: 0.9508 - val_loss: 1.3440 - val_accuracy: 0.8740 - val_f1_m: 0.9904\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 2s 116us/sample - loss: 0.0283 - accuracy: 0.9946 - f1_m: 0.9543 - val_loss: 1.4983 - val_accuracy: 0.8800 - val_f1_m: 0.9877\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0125 - accuracy: 0.9969 - f1_m: 0.9526 - val_loss: 1.4386 - val_accuracy: 0.8740 - val_f1_m: 0.9922\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0055 - accuracy: 0.9981 - f1_m: 0.9513 - val_loss: 1.4309 - val_accuracy: 0.8720 - val_f1_m: 0.9890\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0048 - accuracy: 0.9979 - f1_m: 0.9506 - val_loss: 1.5666 - val_accuracy: 0.8880 - val_f1_m: 0.9767\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0031 - accuracy: 0.9989 - f1_m: 0.9495 - val_loss: 1.5832 - val_accuracy: 0.8720 - val_f1_m: 0.9913\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0172 - accuracy: 0.9954 - f1_m: 0.9549 - val_loss: 1.5745 - val_accuracy: 0.8820 - val_f1_m: 0.9766\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0053 - accuracy: 0.9986 - f1_m: 0.9504 - val_loss: 1.5823 - val_accuracy: 0.8740 - val_f1_m: 0.9941\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0055 - accuracy: 0.9981 - f1_m: 0.9511 - val_loss: 1.6673 - val_accuracy: 0.8720 - val_f1_m: 0.9826\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0073 - accuracy: 0.9976 - f1_m: 0.9511 - val_loss: 1.6677 - val_accuracy: 0.8860 - val_f1_m: 1.0014\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 88us/sample - loss: 0.0085 - accuracy: 0.9971 - f1_m: 0.9518 - val_loss: 1.6566 - val_accuracy: 0.8740 - val_f1_m: 0.9854\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 6s 313us/sample - loss: 0.0380 - accuracy: 0.9936 - f1_m: 0.9550 - val_loss: 1.5348 - val_accuracy: 0.8780 - val_f1_m: 0.9869\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 112us/sample - loss: 0.0166 - accuracy: 0.9960 - f1_m: 0.9531 - val_loss: 1.7779 - val_accuracy: 0.8700 - val_f1_m: 0.9825\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 112us/sample - loss: 0.0147 - accuracy: 0.9956 - f1_m: 0.9531 - val_loss: 1.4220 - val_accuracy: 0.8780 - val_f1_m: 0.9770\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 111us/sample - loss: 0.0144 - accuracy: 0.9953 - f1_m: 0.9544 - val_loss: 1.5918 - val_accuracy: 0.8900 - val_f1_m: 0.9880\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 110us/sample - loss: 0.0075 - accuracy: 0.9973 - f1_m: 0.9510 - val_loss: 1.6725 - val_accuracy: 0.8780 - val_f1_m: 0.9925\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 111us/sample - loss: 0.0104 - accuracy: 0.9971 - f1_m: 0.9518 - val_loss: 1.7453 - val_accuracy: 0.8680 - val_f1_m: 0.9946\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 112us/sample - loss: 0.0235 - accuracy: 0.9936 - f1_m: 0.9554 - val_loss: 1.6009 - val_accuracy: 0.8780 - val_f1_m: 0.9840\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 111us/sample - loss: 0.0235 - accuracy: 0.9937 - f1_m: 0.9541 - val_loss: 1.7507 - val_accuracy: 0.8760 - val_f1_m: 0.9810\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 111us/sample - loss: 0.0113 - accuracy: 0.9967 - f1_m: 0.9525 - val_loss: 1.7515 - val_accuracy: 0.8740 - val_f1_m: 0.9863\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 111us/sample - loss: 0.0209 - accuracy: 0.9946 - f1_m: 0.9537 - val_loss: 2.0325 - val_accuracy: 0.8760 - val_f1_m: 0.9868\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 4s 195us/sample - loss: 0.0501 - accuracy: 0.9849 - f1_m: 0.9701 - val_loss: 1.2822 - val_accuracy: 0.8540 - val_f1_m: 1.0306\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0440 - accuracy: 0.9878 - f1_m: 0.9692 - val_loss: 1.1241 - val_accuracy: 0.8700 - val_f1_m: 1.0207\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0415 - accuracy: 0.9863 - f1_m: 0.9690 - val_loss: 1.3197 - val_accuracy: 0.8600 - val_f1_m: 1.0160\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0350 - accuracy: 0.9887 - f1_m: 0.9649 - val_loss: 1.3573 - val_accuracy: 0.8740 - val_f1_m: 1.0164\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0166 - accuracy: 0.9947 - f1_m: 0.9589 - val_loss: 1.4550 - val_accuracy: 0.8640 - val_f1_m: 0.9982\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 3s 151us/sample - loss: 0.0376 - accuracy: 0.9888 - f1_m: 0.9666 - val_loss: 1.4458 - val_accuracy: 0.8680 - val_f1_m: 1.0080\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 3s 151us/sample - loss: 0.0425 - accuracy: 0.9866 - f1_m: 0.9674 - val_loss: 1.4662 - val_accuracy: 0.8580 - val_f1_m: 1.0158\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 3s 151us/sample - loss: 0.0314 - accuracy: 0.9901 - f1_m: 0.9672 - val_loss: 1.6424 - val_accuracy: 0.8580 - val_f1_m: 1.0100\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 3s 151us/sample - loss: 0.0479 - accuracy: 0.9860 - f1_m: 0.9692 - val_loss: 1.4538 - val_accuracy: 0.8540 - val_f1_m: 1.0109\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0320 - accuracy: 0.9908 - f1_m: 0.9635 - val_loss: 1.5873 - val_accuracy: 0.8680 - val_f1_m: 1.0206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>ratio</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN 1 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.746584</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>2.286928</td>\n",
       "      <td>0.874241</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>2.385068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN 2 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.667575</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>2.003256</td>\n",
       "      <td>0.759935</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>2.085379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN 5 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.789632</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>2.102995</td>\n",
       "      <td>0.878646</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>2.180627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.753168</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>1.887009</td>\n",
       "      <td>0.908910</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>1.813461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.494028</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>1.716723</td>\n",
       "      <td>0.692759</td>\n",
       "      <td>0.7567</td>\n",
       "      <td>1.874901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.062159</td>\n",
       "      <td>0.977026</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.920527</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>1.012420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.950832</td>\n",
       "      <td>1.343985</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.990404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>CNN 2 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>0.951785</td>\n",
       "      <td>1.656552</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.985435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>CNN 5 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.994615</td>\n",
       "      <td>0.953735</td>\n",
       "      <td>2.032515</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.986837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>CNN 10 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.963524</td>\n",
       "      <td>1.587301</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>1.020637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  train_samples  test_samples  ratio      loss  accuracy  \\\n",
       "0     CNN 1 S            500         19500  0.025  0.746584  0.736000   \n",
       "1     CNN 2 S            500         19500  0.025  0.667575  0.744000   \n",
       "2     CNN 5 S            500         19500  0.025  0.789632  0.706000   \n",
       "3    CNN 10 S            500         19500  0.025  0.753168  0.738000   \n",
       "4     CNN 1 L            500         19500  0.025  0.494028  0.834000   \n",
       "..        ...            ...           ...    ...       ...       ...   \n",
       "307  CNN 10 S          19500           500  0.975  0.062159  0.977026   \n",
       "308   CNN 1 L          19500           500  0.975  0.003482  0.999077   \n",
       "309   CNN 2 L          19500           500  0.975  0.008462  0.997128   \n",
       "310   CNN 5 L          19500           500  0.975  0.020927  0.994615   \n",
       "311  CNN 10 L          19500           500  0.975  0.032007  0.990769   \n",
       "\n",
       "           f1  val_loss  val_accuracy    val_f1  \n",
       "0    2.286928  0.874241        0.6861  2.385068  \n",
       "1    2.003256  0.759935        0.7256  2.085379  \n",
       "2    2.102995  0.878646        0.6742  2.180627  \n",
       "3    1.887009  0.908910        0.6930  1.813461  \n",
       "4    1.716723  0.692759        0.7567  1.874901  \n",
       "..        ...       ...           ...       ...  \n",
       "307  0.999597  0.920527        0.8760  1.012420  \n",
       "308  0.950832  1.343985        0.8740  0.990404  \n",
       "309  0.951785  1.656552        0.8740  0.985435  \n",
       "310  0.953735  2.032515        0.8760  0.986837  \n",
       "311  0.963524  1.587301        0.8680  1.020637  \n",
       "\n",
       "[312 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_3a_cnn():\n",
    "    total_samples = 20000\n",
    "    epochs = 10\n",
    "    ratios = np.arange(0.025, 1.0, 0.025)\n",
    "    \n",
    "#     total_samples = 300\n",
    "#     epochs = 1\n",
    "#     ratios = [0.2, 0.8]\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        train_samples, test_samples = calc_train_test_samples(total_samples, ratio)\n",
    "        \n",
    "        for name, layers in cnns.items():   \n",
    "            loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm = evaluate_cnn(layers, train_samples, test_samples, epochs)\n",
    "            \n",
    "            yield name, train_samples, test_samples, ratio, loss, accuracy, f1, val_loss, val_accuracy, val_f1\n",
    "            \n",
    "            codename = name.lower().replace(' ', '_')\n",
    "            roc.savefig(f'plots/3a/{codename}_r{ratio}_roc.svg')\n",
    "            pr.savefig(f'plots/3a/{codename}_r{ratio}_pr.svg')\n",
    "            cm.savefig(f'plots/3a/{codename}_r{ratio}_cm.svg')             \n",
    "            plt.close('all')\n",
    "            \n",
    "results_3a_cnn = pd.DataFrame(gen_3a_cnn(), columns=[    \n",
    "    'model',\n",
    "    'train_samples', 'test_samples', 'ratio',\n",
    "    'loss', 'accuracy', 'f1', 'val_loss', 'val_accuracy', 'val_f1'\n",
    "])\n",
    "results_3a_cnn.to_csv('results/3a_cnn.csv')\n",
    "results_3a_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.4465 - accuracy: 0.9152 - f1_m: 1.0506 - val_loss: 0.9015 - val_accuracy: 0.8469 - val_f1_m: 1.0758\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.4015 - accuracy: 0.9161 - f1_m: 1.0573 - val_loss: 0.6898 - val_accuracy: 0.8521 - val_f1_m: 1.0996\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.3215 - accuracy: 0.9159 - f1_m: 1.1012 - val_loss: 0.4932 - val_accuracy: 0.8554 - val_f1_m: 1.1757\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.2650 - accuracy: 0.9157 - f1_m: 1.1336 - val_loss: 0.4046 - val_accuracy: 0.8633 - val_f1_m: 1.1928\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.3635 - accuracy: 0.9350 - f1_m: 1.0183 - val_loss: 0.6807 - val_accuracy: 0.8629 - val_f1_m: 1.0808\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.2850 - accuracy: 0.9386 - f1_m: 1.0461 - val_loss: 0.4719 - val_accuracy: 0.8743 - val_f1_m: 1.1259\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.2460 - accuracy: 0.9404 - f1_m: 1.0642 - val_loss: 0.4261 - val_accuracy: 0.8800 - val_f1_m: 1.1282\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.2294 - accuracy: 0.9349 - f1_m: 1.0969 - val_loss: 0.4250 - val_accuracy: 0.8683 - val_f1_m: 1.1511\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.3500 - accuracy: 0.9174 - f1_m: 1.0753 - val_loss: 0.7836 - val_accuracy: 0.8526 - val_f1_m: 1.0891\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.2980 - accuracy: 0.9196 - f1_m: 1.0942 - val_loss: 0.7448 - val_accuracy: 0.8495 - val_f1_m: 1.0967\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2883 - accuracy: 0.9201 - f1_m: 1.0864 - val_loss: 0.5792 - val_accuracy: 0.8576 - val_f1_m: 1.1293\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.2372 - accuracy: 0.9271 - f1_m: 1.0961 - val_loss: 0.5455 - val_accuracy: 0.8613 - val_f1_m: 1.1180\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.2332 - accuracy: 0.9259 - f1_m: 1.1171 - val_loss: 0.4691 - val_accuracy: 0.8598 - val_f1_m: 1.1626\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.2001 - accuracy: 0.9337 - f1_m: 1.1081 - val_loss: 0.4642 - val_accuracy: 0.8631 - val_f1_m: 1.1264\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.2291 - accuracy: 0.9205 - f1_m: 1.1402 - val_loss: 0.3793 - val_accuracy: 0.8776 - val_f1_m: 1.1550\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.2113 - accuracy: 0.9251 - f1_m: 1.1339 - val_loss: 0.4083 - val_accuracy: 0.8720 - val_f1_m: 1.1633\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.2240 - accuracy: 0.9451 - f1_m: 1.0376 - val_loss: 0.5903 - val_accuracy: 0.8740 - val_f1_m: 1.0949\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1645 - accuracy: 0.9539 - f1_m: 1.0370 - val_loss: 0.5760 - val_accuracy: 0.8775 - val_f1_m: 1.0814\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.1648 - accuracy: 0.9544 - f1_m: 1.0520 - val_loss: 0.4354 - val_accuracy: 0.8804 - val_f1_m: 1.1276\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.1175 - accuracy: 0.9645 - f1_m: 1.0356 - val_loss: 0.4455 - val_accuracy: 0.8869 - val_f1_m: 1.0796\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.1460 - accuracy: 0.9563 - f1_m: 1.0544 - val_loss: 0.4251 - val_accuracy: 0.8842 - val_f1_m: 1.1005\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1047 - accuracy: 0.9671 - f1_m: 1.0284 - val_loss: 0.4194 - val_accuracy: 0.8917 - val_f1_m: 1.0818\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.1697 - accuracy: 0.9448 - f1_m: 1.0817 - val_loss: 0.4040 - val_accuracy: 0.8774 - val_f1_m: 1.1252\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.1443 - accuracy: 0.9512 - f1_m: 1.0661 - val_loss: 0.4253 - val_accuracy: 0.8756 - val_f1_m: 1.1245\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.2699 - accuracy: 0.9223 - f1_m: 1.1056 - val_loss: 0.6643 - val_accuracy: 0.8558 - val_f1_m: 1.1204\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.2469 - accuracy: 0.9242 - f1_m: 1.1136 - val_loss: 0.6539 - val_accuracy: 0.8535 - val_f1_m: 1.1153\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.2326 - accuracy: 0.9275 - f1_m: 1.1173 - val_loss: 0.6023 - val_accuracy: 0.8585 - val_f1_m: 1.1276\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2147 - accuracy: 0.9311 - f1_m: 1.1028 - val_loss: 0.4899 - val_accuracy: 0.8675 - val_f1_m: 1.1354\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.1971 - accuracy: 0.9341 - f1_m: 1.1032 - val_loss: 0.4915 - val_accuracy: 0.8673 - val_f1_m: 1.1198\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1885 - accuracy: 0.9375 - f1_m: 1.1025 - val_loss: 0.4837 - val_accuracy: 0.8678 - val_f1_m: 1.1199\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.1834 - accuracy: 0.9385 - f1_m: 1.1004 - val_loss: 0.4564 - val_accuracy: 0.8675 - val_f1_m: 1.1559\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1689 - accuracy: 0.9423 - f1_m: 1.0952 - val_loss: 0.4827 - val_accuracy: 0.8606 - val_f1_m: 1.1214\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1645 - accuracy: 0.9434 - f1_m: 1.0890 - val_loss: 0.4826 - val_accuracy: 0.8672 - val_f1_m: 1.1152\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.2017 - accuracy: 0.9290 - f1_m: 1.1249 - val_loss: 0.3813 - val_accuracy: 0.8817 - val_f1_m: 1.1579\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1929 - accuracy: 0.9298 - f1_m: 1.1203 - val_loss: 0.3836 - val_accuracy: 0.8756 - val_f1_m: 1.1621\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1868 - accuracy: 0.9328 - f1_m: 1.1140 - val_loss: 0.4084 - val_accuracy: 0.8803 - val_f1_m: 1.1180\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1301 - accuracy: 0.9625 - f1_m: 1.0305 - val_loss: 0.5565 - val_accuracy: 0.8767 - val_f1_m: 1.0782\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1044 - accuracy: 0.9686 - f1_m: 1.0263 - val_loss: 0.5774 - val_accuracy: 0.8741 - val_f1_m: 1.0748\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0882 - accuracy: 0.9737 - f1_m: 1.0181 - val_loss: 0.5550 - val_accuracy: 0.8755 - val_f1_m: 1.0720\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0881 - accuracy: 0.9733 - f1_m: 1.0178 - val_loss: 0.4771 - val_accuracy: 0.8867 - val_f1_m: 1.0736\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0654 - accuracy: 0.9796 - f1_m: 1.0058 - val_loss: 0.5043 - val_accuracy: 0.8907 - val_f1_m: 1.0543\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0526 - accuracy: 0.9835 - f1_m: 0.9959 - val_loss: 0.5583 - val_accuracy: 0.8849 - val_f1_m: 1.0491\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0842 - accuracy: 0.9729 - f1_m: 1.0142 - val_loss: 0.4914 - val_accuracy: 0.8880 - val_f1_m: 1.0569\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0632 - accuracy: 0.9803 - f1_m: 0.9981 - val_loss: 0.5100 - val_accuracy: 0.8897 - val_f1_m: 1.0664\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0543 - accuracy: 0.9814 - f1_m: 0.9921 - val_loss: 0.5837 - val_accuracy: 0.8832 - val_f1_m: 1.0379\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.1269 - accuracy: 0.9569 - f1_m: 1.0512 - val_loss: 0.4559 - val_accuracy: 0.8702 - val_f1_m: 1.0955\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.1101 - accuracy: 0.9625 - f1_m: 1.0392 - val_loss: 0.4636 - val_accuracy: 0.8737 - val_f1_m: 1.0972\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.1009 - accuracy: 0.9655 - f1_m: 1.0290 - val_loss: 0.4801 - val_accuracy: 0.8771 - val_f1_m: 1.0962\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.2235 - accuracy: 0.9277 - f1_m: 1.1226 - val_loss: 0.5846 - val_accuracy: 0.8629 - val_f1_m: 1.1304\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.2130 - accuracy: 0.9299 - f1_m: 1.1247 - val_loss: 0.5979 - val_accuracy: 0.8571 - val_f1_m: 1.1259\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.2068 - accuracy: 0.9312 - f1_m: 1.1249 - val_loss: 0.5660 - val_accuracy: 0.8609 - val_f1_m: 1.1330\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.2016 - accuracy: 0.9323 - f1_m: 1.1243 - val_loss: 0.5439 - val_accuracy: 0.8605 - val_f1_m: 1.1448\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.1812 - accuracy: 0.9386 - f1_m: 1.1018 - val_loss: 0.4604 - val_accuracy: 0.8696 - val_f1_m: 1.1377\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.1727 - accuracy: 0.9409 - f1_m: 1.0988 - val_loss: 0.4762 - val_accuracy: 0.8728 - val_f1_m: 1.1126\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1673 - accuracy: 0.9439 - f1_m: 1.0960 - val_loss: 0.4760 - val_accuracy: 0.8703 - val_f1_m: 1.1186\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1632 - accuracy: 0.9442 - f1_m: 1.0931 - val_loss: 0.4604 - val_accuracy: 0.8754 - val_f1_m: 1.1153\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 14s 298us/sample - loss: 0.1549 - accuracy: 0.9460 - f1_m: 1.0841 - val_loss: 0.4693 - val_accuracy: 0.8664 - val_f1_m: 1.1347\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1461 - accuracy: 0.9498 - f1_m: 1.0770 - val_loss: 0.4907 - val_accuracy: 0.8663 - val_f1_m: 1.1086\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1413 - accuracy: 0.9512 - f1_m: 1.0738 - val_loss: 0.4907 - val_accuracy: 0.8688 - val_f1_m: 1.1057\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1347 - accuracy: 0.9529 - f1_m: 1.0700 - val_loss: 0.4814 - val_accuracy: 0.8687 - val_f1_m: 1.1101\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.1813 - accuracy: 0.9341 - f1_m: 1.1073 - val_loss: 0.3776 - val_accuracy: 0.8828 - val_f1_m: 1.1514\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.1738 - accuracy: 0.9360 - f1_m: 1.1049 - val_loss: 0.4096 - val_accuracy: 0.8738 - val_f1_m: 1.1443\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.1693 - accuracy: 0.9392 - f1_m: 1.0993 - val_loss: 0.4164 - val_accuracy: 0.8782 - val_f1_m: 1.1151\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.1662 - accuracy: 0.9392 - f1_m: 1.0970 - val_loss: 0.3926 - val_accuracy: 0.8769 - val_f1_m: 1.1443\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0778 - accuracy: 0.9755 - f1_m: 1.0131 - val_loss: 0.5790 - val_accuracy: 0.8817 - val_f1_m: 1.0697\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.0638 - accuracy: 0.9805 - f1_m: 1.0067 - val_loss: 0.6123 - val_accuracy: 0.8742 - val_f1_m: 1.0589\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.0555 - accuracy: 0.9833 - f1_m: 0.9995 - val_loss: 0.5965 - val_accuracy: 0.8807 - val_f1_m: 1.0515\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.0503 - accuracy: 0.9839 - f1_m: 0.9966 - val_loss: 0.6312 - val_accuracy: 0.8818 - val_f1_m: 1.0540\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0425 - accuracy: 0.9869 - f1_m: 0.9862 - val_loss: 0.5759 - val_accuracy: 0.8888 - val_f1_m: 1.0364\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0359 - accuracy: 0.9879 - f1_m: 0.9818 - val_loss: 0.5960 - val_accuracy: 0.8956 - val_f1_m: 1.0311\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0256 - accuracy: 0.9919 - f1_m: 0.9731 - val_loss: 0.6676 - val_accuracy: 0.8874 - val_f1_m: 1.0222\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0244 - accuracy: 0.9919 - f1_m: 0.9716 - val_loss: 0.6628 - val_accuracy: 0.8913 - val_f1_m: 1.0306\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0457 - accuracy: 0.9846 - f1_m: 0.9827 - val_loss: 0.6159 - val_accuracy: 0.8889 - val_f1_m: 1.0357\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0362 - accuracy: 0.9877 - f1_m: 0.9776 - val_loss: 0.7542 - val_accuracy: 0.8848 - val_f1_m: 1.0214\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0359 - accuracy: 0.9876 - f1_m: 0.9751 - val_loss: 0.8120 - val_accuracy: 0.8854 - val_f1_m: 1.0143\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0323 - accuracy: 0.9886 - f1_m: 0.9708 - val_loss: 0.8074 - val_accuracy: 0.8827 - val_f1_m: 1.0142\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 9s 181us/sample - loss: 0.0965 - accuracy: 0.9671 - f1_m: 1.0228 - val_loss: 0.5067 - val_accuracy: 0.8788 - val_f1_m: 1.0674\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.0842 - accuracy: 0.9700 - f1_m: 1.0160 - val_loss: 0.5785 - val_accuracy: 0.8726 - val_f1_m: 1.0672\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.0850 - accuracy: 0.9711 - f1_m: 1.0141 - val_loss: 0.5913 - val_accuracy: 0.8766 - val_f1_m: 1.0489\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.0775 - accuracy: 0.9731 - f1_m: 1.0081 - val_loss: 0.6269 - val_accuracy: 0.8741 - val_f1_m: 1.0591\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.1983 - accuracy: 0.9328 - f1_m: 1.1239 - val_loss: 0.5467 - val_accuracy: 0.8622 - val_f1_m: 1.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.1931 - accuracy: 0.9341 - f1_m: 1.1236 - val_loss: 0.5688 - val_accuracy: 0.8570 - val_f1_m: 1.1334\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.1892 - accuracy: 0.9359 - f1_m: 1.1241 - val_loss: 0.5485 - val_accuracy: 0.8632 - val_f1_m: 1.1307\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.1858 - accuracy: 0.9364 - f1_m: 1.1218 - val_loss: 0.5374 - val_accuracy: 0.8630 - val_f1_m: 1.1462\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.1836 - accuracy: 0.9365 - f1_m: 1.1189 - val_loss: 0.5540 - val_accuracy: 0.8613 - val_f1_m: 1.1358\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.1607 - accuracy: 0.9448 - f1_m: 1.0916 - val_loss: 0.4519 - val_accuracy: 0.8728 - val_f1_m: 1.1206\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.1536 - accuracy: 0.9470 - f1_m: 1.0885 - val_loss: 0.4794 - val_accuracy: 0.8743 - val_f1_m: 1.1084\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.1508 - accuracy: 0.9492 - f1_m: 1.0877 - val_loss: 0.4866 - val_accuracy: 0.8719 - val_f1_m: 1.1055\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.1472 - accuracy: 0.9494 - f1_m: 1.0814 - val_loss: 0.4787 - val_accuracy: 0.8757 - val_f1_m: 1.1077\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.1445 - accuracy: 0.9501 - f1_m: 1.0794 - val_loss: 0.4788 - val_accuracy: 0.8767 - val_f1_m: 1.0980\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.1308 - accuracy: 0.9545 - f1_m: 1.0615 - val_loss: 0.5032 - val_accuracy: 0.8695 - val_f1_m: 1.0976\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1251 - accuracy: 0.9562 - f1_m: 1.0593 - val_loss: 0.5587 - val_accuracy: 0.8614 - val_f1_m: 1.0917\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1230 - accuracy: 0.9573 - f1_m: 1.0565 - val_loss: 0.5493 - val_accuracy: 0.8674 - val_f1_m: 1.0837\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1192 - accuracy: 0.9587 - f1_m: 1.0541 - val_loss: 0.5531 - val_accuracy: 0.8637 - val_f1_m: 1.0928\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1186 - accuracy: 0.9582 - f1_m: 1.0533 - val_loss: 0.5343 - val_accuracy: 0.8691 - val_f1_m: 1.0859\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1660 - accuracy: 0.9399 - f1_m: 1.0944 - val_loss: 0.4097 - val_accuracy: 0.8767 - val_f1_m: 1.1248\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1592 - accuracy: 0.9414 - f1_m: 1.0891 - val_loss: 0.4059 - val_accuracy: 0.8827 - val_f1_m: 1.1071\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1583 - accuracy: 0.9427 - f1_m: 1.0873 - val_loss: 0.4143 - val_accuracy: 0.8770 - val_f1_m: 1.1163\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1557 - accuracy: 0.9439 - f1_m: 1.0861 - val_loss: 0.3859 - val_accuracy: 0.8865 - val_f1_m: 1.1200\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1530 - accuracy: 0.9434 - f1_m: 1.0856 - val_loss: 0.4274 - val_accuracy: 0.8800 - val_f1_m: 1.1134\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0449 - accuracy: 0.9860 - f1_m: 0.9914 - val_loss: 0.6541 - val_accuracy: 0.8791 - val_f1_m: 1.0481\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0378 - accuracy: 0.9882 - f1_m: 0.9858 - val_loss: 0.7215 - val_accuracy: 0.8737 - val_f1_m: 1.0409\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0326 - accuracy: 0.9904 - f1_m: 0.9819 - val_loss: 0.6815 - val_accuracy: 0.8802 - val_f1_m: 1.0415\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0294 - accuracy: 0.9914 - f1_m: 0.9788 - val_loss: 0.7003 - val_accuracy: 0.8808 - val_f1_m: 1.0345\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.0274 - accuracy: 0.9916 - f1_m: 0.9764 - val_loss: 0.7331 - val_accuracy: 0.8764 - val_f1_m: 1.0362\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0219 - accuracy: 0.9926 - f1_m: 0.9693 - val_loss: 0.7453 - val_accuracy: 0.8867 - val_f1_m: 1.0138\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0175 - accuracy: 0.9944 - f1_m: 0.9641 - val_loss: 0.7794 - val_accuracy: 0.8927 - val_f1_m: 1.0116\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0155 - accuracy: 0.9947 - f1_m: 0.9628 - val_loss: 0.7981 - val_accuracy: 0.8879 - val_f1_m: 1.0047\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0162 - accuracy: 0.9946 - f1_m: 0.9621 - val_loss: 0.8398 - val_accuracy: 0.8915 - val_f1_m: 1.0064\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0139 - accuracy: 0.9952 - f1_m: 0.9609 - val_loss: 0.8644 - val_accuracy: 0.8893 - val_f1_m: 0.9986\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0308 - accuracy: 0.9897 - f1_m: 0.9696 - val_loss: 0.8762 - val_accuracy: 0.8797 - val_f1_m: 1.0092\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0283 - accuracy: 0.9901 - f1_m: 0.9676 - val_loss: 0.9754 - val_accuracy: 0.8812 - val_f1_m: 1.0031\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0243 - accuracy: 0.9913 - f1_m: 0.9646 - val_loss: 0.9518 - val_accuracy: 0.8811 - val_f1_m: 1.0111\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0255 - accuracy: 0.9909 - f1_m: 0.9654 - val_loss: 0.9242 - val_accuracy: 0.8781 - val_f1_m: 1.0032\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0245 - accuracy: 0.9916 - f1_m: 0.9639 - val_loss: 0.9814 - val_accuracy: 0.8877 - val_f1_m: 0.9981\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 9s 177us/sample - loss: 0.0848 - accuracy: 0.9710 - f1_m: 1.0080 - val_loss: 0.5886 - val_accuracy: 0.8741 - val_f1_m: 1.0570\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0717 - accuracy: 0.9747 - f1_m: 1.0055 - val_loss: 0.6282 - val_accuracy: 0.8760 - val_f1_m: 1.0458\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0768 - accuracy: 0.9742 - f1_m: 1.0035 - val_loss: 0.6184 - val_accuracy: 0.8756 - val_f1_m: 1.0500\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0685 - accuracy: 0.9762 - f1_m: 0.9953 - val_loss: 0.6974 - val_accuracy: 0.8736 - val_f1_m: 1.0485\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0637 - accuracy: 0.9778 - f1_m: 0.9939 - val_loss: 0.6265 - val_accuracy: 0.8793 - val_f1_m: 1.0491\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1832 - accuracy: 0.9364 - f1_m: 1.1174 - val_loss: 0.5414 - val_accuracy: 0.8646 - val_f1_m: 1.1382\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1789 - accuracy: 0.9377 - f1_m: 1.1157 - val_loss: 0.5696 - val_accuracy: 0.8586 - val_f1_m: 1.1322\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1757 - accuracy: 0.9397 - f1_m: 1.1167 - val_loss: 0.5485 - val_accuracy: 0.8648 - val_f1_m: 1.1275\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1736 - accuracy: 0.9404 - f1_m: 1.1155 - val_loss: 0.5436 - val_accuracy: 0.8643 - val_f1_m: 1.1383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1717 - accuracy: 0.9407 - f1_m: 1.1123 - val_loss: 0.5591 - val_accuracy: 0.8633 - val_f1_m: 1.1337\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1712 - accuracy: 0.9405 - f1_m: 1.1124 - val_loss: 0.5694 - val_accuracy: 0.8626 - val_f1_m: 1.1267\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.1438 - accuracy: 0.9493 - f1_m: 1.0789 - val_loss: 0.4665 - val_accuracy: 0.8759 - val_f1_m: 1.1070\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1380 - accuracy: 0.9521 - f1_m: 1.0760 - val_loss: 0.5016 - val_accuracy: 0.8740 - val_f1_m: 1.0973\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1355 - accuracy: 0.9539 - f1_m: 1.0740 - val_loss: 0.5114 - val_accuracy: 0.8724 - val_f1_m: 1.0868\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1321 - accuracy: 0.9538 - f1_m: 1.0702 - val_loss: 0.5040 - val_accuracy: 0.8738 - val_f1_m: 1.0925\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1302 - accuracy: 0.9551 - f1_m: 1.0666 - val_loss: 0.5057 - val_accuracy: 0.8770 - val_f1_m: 1.0835\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.1301 - accuracy: 0.9547 - f1_m: 1.0664 - val_loss: 0.5013 - val_accuracy: 0.8730 - val_f1_m: 1.0843\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.1135 - accuracy: 0.9601 - f1_m: 1.0467 - val_loss: 0.5740 - val_accuracy: 0.8634 - val_f1_m: 1.0910\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1089 - accuracy: 0.9619 - f1_m: 1.0441 - val_loss: 0.6088 - val_accuracy: 0.8603 - val_f1_m: 1.0772\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1076 - accuracy: 0.9623 - f1_m: 1.0423 - val_loss: 0.5956 - val_accuracy: 0.8656 - val_f1_m: 1.0816\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1036 - accuracy: 0.9638 - f1_m: 1.0389 - val_loss: 0.5816 - val_accuracy: 0.8714 - val_f1_m: 1.0792\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1057 - accuracy: 0.9620 - f1_m: 1.0403 - val_loss: 0.5776 - val_accuracy: 0.8716 - val_f1_m: 1.0776\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1036 - accuracy: 0.9630 - f1_m: 1.0371 - val_loss: 0.5985 - val_accuracy: 0.8647 - val_f1_m: 1.0810\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.1557 - accuracy: 0.9429 - f1_m: 1.0826 - val_loss: 0.4024 - val_accuracy: 0.8812 - val_f1_m: 1.1210\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1482 - accuracy: 0.9456 - f1_m: 1.0807 - val_loss: 0.4387 - val_accuracy: 0.8794 - val_f1_m: 1.1063\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1476 - accuracy: 0.9457 - f1_m: 1.0767 - val_loss: 0.4337 - val_accuracy: 0.8785 - val_f1_m: 1.1164\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1442 - accuracy: 0.9477 - f1_m: 1.0767 - val_loss: 0.4274 - val_accuracy: 0.8804 - val_f1_m: 1.1127\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1411 - accuracy: 0.9473 - f1_m: 1.0741 - val_loss: 0.4231 - val_accuracy: 0.8777 - val_f1_m: 1.1160\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.1401 - accuracy: 0.9484 - f1_m: 1.0734 - val_loss: 0.4346 - val_accuracy: 0.8869 - val_f1_m: 1.0902\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0252 - accuracy: 0.9920 - f1_m: 0.9742 - val_loss: 0.7723 - val_accuracy: 0.8755 - val_f1_m: 1.0317\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0221 - accuracy: 0.9933 - f1_m: 0.9714 - val_loss: 0.8411 - val_accuracy: 0.8760 - val_f1_m: 1.0245\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0183 - accuracy: 0.9945 - f1_m: 0.9677 - val_loss: 0.8113 - val_accuracy: 0.8824 - val_f1_m: 1.0161\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0153 - accuracy: 0.9956 - f1_m: 0.9659 - val_loss: 0.8479 - val_accuracy: 0.8795 - val_f1_m: 1.0202\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0169 - accuracy: 0.9948 - f1_m: 0.9657 - val_loss: 0.8631 - val_accuracy: 0.8764 - val_f1_m: 1.0182\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0154 - accuracy: 0.9952 - f1_m: 0.9647 - val_loss: 0.9044 - val_accuracy: 0.8809 - val_f1_m: 1.0166\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0132 - accuracy: 0.9958 - f1_m: 0.9593 - val_loss: 0.9929 - val_accuracy: 0.8831 - val_f1_m: 0.9962\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0091 - accuracy: 0.9971 - f1_m: 0.9565 - val_loss: 0.9519 - val_accuracy: 0.8856 - val_f1_m: 1.0016\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0148 - accuracy: 0.9950 - f1_m: 0.9594 - val_loss: 0.9365 - val_accuracy: 0.8924 - val_f1_m: 0.9961\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0101 - accuracy: 0.9966 - f1_m: 0.9570 - val_loss: 1.0503 - val_accuracy: 0.8844 - val_f1_m: 1.0015\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0097 - accuracy: 0.9968 - f1_m: 0.9567 - val_loss: 1.0303 - val_accuracy: 0.8849 - val_f1_m: 0.9951\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0115 - accuracy: 0.9959 - f1_m: 0.9572 - val_loss: 1.0399 - val_accuracy: 0.8894 - val_f1_m: 0.9895\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0254 - accuracy: 0.9920 - f1_m: 0.9616 - val_loss: 1.0943 - val_accuracy: 0.8858 - val_f1_m: 0.9973\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0310 - accuracy: 0.9896 - f1_m: 0.9632 - val_loss: 1.1168 - val_accuracy: 0.8837 - val_f1_m: 0.9971\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0255 - accuracy: 0.9920 - f1_m: 0.9617 - val_loss: 0.9938 - val_accuracy: 0.8883 - val_f1_m: 1.0039\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0210 - accuracy: 0.9928 - f1_m: 0.9583 - val_loss: 1.2020 - val_accuracy: 0.8820 - val_f1_m: 0.9924\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0251 - accuracy: 0.9916 - f1_m: 0.9611 - val_loss: 1.1690 - val_accuracy: 0.8848 - val_f1_m: 0.9953\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0239 - accuracy: 0.9925 - f1_m: 0.9601 - val_loss: 1.1630 - val_accuracy: 0.8845 - val_f1_m: 0.9913\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 9s 195us/sample - loss: 0.0655 - accuracy: 0.9775 - f1_m: 0.9938 - val_loss: 0.6731 - val_accuracy: 0.8740 - val_f1_m: 1.0414\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0626 - accuracy: 0.9775 - f1_m: 0.9918 - val_loss: 0.7177 - val_accuracy: 0.8790 - val_f1_m: 1.0223\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0607 - accuracy: 0.9783 - f1_m: 0.9903 - val_loss: 0.6955 - val_accuracy: 0.8673 - val_f1_m: 1.0393\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0608 - accuracy: 0.9789 - f1_m: 0.9893 - val_loss: 0.6924 - val_accuracy: 0.8754 - val_f1_m: 1.0432\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0648 - accuracy: 0.9785 - f1_m: 0.9922 - val_loss: 0.7157 - val_accuracy: 0.8752 - val_f1_m: 1.0418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0640 - accuracy: 0.9780 - f1_m: 0.9907 - val_loss: 0.7004 - val_accuracy: 0.8691 - val_f1_m: 1.0372\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1706 - accuracy: 0.9405 - f1_m: 1.1092 - val_loss: 0.5565 - val_accuracy: 0.8643 - val_f1_m: 1.1338\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1673 - accuracy: 0.9416 - f1_m: 1.1076 - val_loss: 0.5909 - val_accuracy: 0.8618 - val_f1_m: 1.1227\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1646 - accuracy: 0.9427 - f1_m: 1.1078 - val_loss: 0.5635 - val_accuracy: 0.8675 - val_f1_m: 1.1233\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1630 - accuracy: 0.9447 - f1_m: 1.1068 - val_loss: 0.5610 - val_accuracy: 0.8633 - val_f1_m: 1.1299\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1618 - accuracy: 0.9439 - f1_m: 1.1048 - val_loss: 0.5782 - val_accuracy: 0.8621 - val_f1_m: 1.1302\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1612 - accuracy: 0.9439 - f1_m: 1.1031 - val_loss: 0.5933 - val_accuracy: 0.8622 - val_f1_m: 1.1151\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1597 - accuracy: 0.9454 - f1_m: 1.1005 - val_loss: 0.5855 - val_accuracy: 0.8617 - val_f1_m: 1.1182\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.1289 - accuracy: 0.9543 - f1_m: 1.0649 - val_loss: 0.5056 - val_accuracy: 0.8754 - val_f1_m: 1.0903\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1237 - accuracy: 0.9568 - f1_m: 1.0620 - val_loss: 0.5348 - val_accuracy: 0.8741 - val_f1_m: 1.0878\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1218 - accuracy: 0.9578 - f1_m: 1.0618 - val_loss: 0.5451 - val_accuracy: 0.8721 - val_f1_m: 1.0776\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1193 - accuracy: 0.9584 - f1_m: 1.0586 - val_loss: 0.5382 - val_accuracy: 0.8734 - val_f1_m: 1.0809\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1190 - accuracy: 0.9574 - f1_m: 1.0583 - val_loss: 0.5388 - val_accuracy: 0.8776 - val_f1_m: 1.0709\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1174 - accuracy: 0.9590 - f1_m: 1.0561 - val_loss: 0.5388 - val_accuracy: 0.8742 - val_f1_m: 1.0695\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1173 - accuracy: 0.9583 - f1_m: 1.0531 - val_loss: 0.5605 - val_accuracy: 0.8756 - val_f1_m: 1.0702\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.1022 - accuracy: 0.9638 - f1_m: 1.0328 - val_loss: 0.5997 - val_accuracy: 0.8687 - val_f1_m: 1.0766\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0923 - accuracy: 0.9666 - f1_m: 1.0307 - val_loss: 0.6566 - val_accuracy: 0.8609 - val_f1_m: 1.0667\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0968 - accuracy: 0.9650 - f1_m: 1.0296 - val_loss: 0.6535 - val_accuracy: 0.8633 - val_f1_m: 1.0772\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0924 - accuracy: 0.9671 - f1_m: 1.0299 - val_loss: 0.6443 - val_accuracy: 0.8656 - val_f1_m: 1.0723\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0916 - accuracy: 0.9677 - f1_m: 1.0275 - val_loss: 0.6510 - val_accuracy: 0.8686 - val_f1_m: 1.0554\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0928 - accuracy: 0.9668 - f1_m: 1.0263 - val_loss: 0.6508 - val_accuracy: 0.8681 - val_f1_m: 1.0666\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0894 - accuracy: 0.9684 - f1_m: 1.0233 - val_loss: 0.7049 - val_accuracy: 0.8643 - val_f1_m: 1.0623\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.1429 - accuracy: 0.9476 - f1_m: 1.0726 - val_loss: 0.4314 - val_accuracy: 0.8853 - val_f1_m: 1.0955\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1367 - accuracy: 0.9485 - f1_m: 1.0689 - val_loss: 0.4551 - val_accuracy: 0.8845 - val_f1_m: 1.0743\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1383 - accuracy: 0.9492 - f1_m: 1.0719 - val_loss: 0.4390 - val_accuracy: 0.8854 - val_f1_m: 1.0828\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1363 - accuracy: 0.9501 - f1_m: 1.0669 - val_loss: 0.4166 - val_accuracy: 0.8833 - val_f1_m: 1.1088\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1358 - accuracy: 0.9500 - f1_m: 1.0676 - val_loss: 0.4783 - val_accuracy: 0.8769 - val_f1_m: 1.0888\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1336 - accuracy: 0.9515 - f1_m: 1.0640 - val_loss: 0.4248 - val_accuracy: 0.8864 - val_f1_m: 1.1013\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1330 - accuracy: 0.9514 - f1_m: 1.0631 - val_loss: 0.4926 - val_accuracy: 0.8800 - val_f1_m: 1.0775\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0137 - accuracy: 0.9959 - f1_m: 0.9630 - val_loss: 0.9245 - val_accuracy: 0.8749 - val_f1_m: 1.0179\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0138 - accuracy: 0.9957 - f1_m: 0.9615 - val_loss: 1.0060 - val_accuracy: 0.8786 - val_f1_m: 1.0136\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0124 - accuracy: 0.9960 - f1_m: 0.9592 - val_loss: 0.9262 - val_accuracy: 0.8756 - val_f1_m: 1.0137\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.0122 - accuracy: 0.9964 - f1_m: 0.9601 - val_loss: 0.9407 - val_accuracy: 0.8779 - val_f1_m: 1.0157\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0099 - accuracy: 0.9973 - f1_m: 0.9576 - val_loss: 1.0331 - val_accuracy: 0.8750 - val_f1_m: 1.0048\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0106 - accuracy: 0.9965 - f1_m: 0.9584 - val_loss: 1.0299 - val_accuracy: 0.8728 - val_f1_m: 1.0094\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0118 - accuracy: 0.9963 - f1_m: 0.9592 - val_loss: 1.0337 - val_accuracy: 0.8761 - val_f1_m: 1.0048\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0116 - accuracy: 0.9964 - f1_m: 0.9558 - val_loss: 1.0301 - val_accuracy: 0.8925 - val_f1_m: 0.9937\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0098 - accuracy: 0.9966 - f1_m: 0.9548 - val_loss: 1.0975 - val_accuracy: 0.8905 - val_f1_m: 0.9933\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0102 - accuracy: 0.9962 - f1_m: 0.9550 - val_loss: 1.0989 - val_accuracy: 0.8842 - val_f1_m: 0.9919\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0105 - accuracy: 0.9966 - f1_m: 0.9552 - val_loss: 1.1263 - val_accuracy: 0.8886 - val_f1_m: 0.9847\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0087 - accuracy: 0.9973 - f1_m: 0.9537 - val_loss: 1.1750 - val_accuracy: 0.8834 - val_f1_m: 0.9843\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0116 - accuracy: 0.9964 - f1_m: 0.9546 - val_loss: 1.2018 - val_accuracy: 0.8848 - val_f1_m: 0.9878\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0107 - accuracy: 0.9964 - f1_m: 0.9550 - val_loss: 1.1860 - val_accuracy: 0.8872 - val_f1_m: 0.9860\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0243 - accuracy: 0.9923 - f1_m: 0.9592 - val_loss: 1.2159 - val_accuracy: 0.8859 - val_f1_m: 0.9867\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0225 - accuracy: 0.9931 - f1_m: 0.9578 - val_loss: 1.1645 - val_accuracy: 0.8847 - val_f1_m: 0.9934\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0252 - accuracy: 0.9922 - f1_m: 0.9593 - val_loss: 1.1914 - val_accuracy: 0.8870 - val_f1_m: 0.9911\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0221 - accuracy: 0.9932 - f1_m: 0.9585 - val_loss: 1.2927 - val_accuracy: 0.8833 - val_f1_m: 0.9893\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0248 - accuracy: 0.9927 - f1_m: 0.9580 - val_loss: 1.1744 - val_accuracy: 0.8823 - val_f1_m: 0.9930\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0271 - accuracy: 0.9923 - f1_m: 0.9592 - val_loss: 1.1432 - val_accuracy: 0.8856 - val_f1_m: 1.0015\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0217 - accuracy: 0.9934 - f1_m: 0.9575 - val_loss: 1.1853 - val_accuracy: 0.8879 - val_f1_m: 0.9879\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0690 - accuracy: 0.9771 - f1_m: 0.9915 - val_loss: 0.7191 - val_accuracy: 0.8756 - val_f1_m: 1.0303\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0622 - accuracy: 0.9790 - f1_m: 0.9900 - val_loss: 0.7964 - val_accuracy: 0.8739 - val_f1_m: 1.0261\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0562 - accuracy: 0.9804 - f1_m: 0.9847 - val_loss: 0.7510 - val_accuracy: 0.8766 - val_f1_m: 1.0269\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0530 - accuracy: 0.9824 - f1_m: 0.9841 - val_loss: 0.7483 - val_accuracy: 0.8760 - val_f1_m: 1.0259\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0623 - accuracy: 0.9788 - f1_m: 0.9890 - val_loss: 0.7700 - val_accuracy: 0.8718 - val_f1_m: 1.0358\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0605 - accuracy: 0.9802 - f1_m: 0.9868 - val_loss: 0.8226 - val_accuracy: 0.8713 - val_f1_m: 1.0362\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0552 - accuracy: 0.9811 - f1_m: 0.9839 - val_loss: 0.8233 - val_accuracy: 0.8715 - val_f1_m: 1.0270\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1596 - accuracy: 0.9450 - f1_m: 1.0993 - val_loss: 0.5874 - val_accuracy: 0.8616 - val_f1_m: 1.1262\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1572 - accuracy: 0.9457 - f1_m: 1.1001 - val_loss: 0.6143 - val_accuracy: 0.8605 - val_f1_m: 1.1210\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1548 - accuracy: 0.9465 - f1_m: 1.0974 - val_loss: 0.5865 - val_accuracy: 0.8677 - val_f1_m: 1.1166\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1539 - accuracy: 0.9474 - f1_m: 1.0978 - val_loss: 0.5944 - val_accuracy: 0.8605 - val_f1_m: 1.1220\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1526 - accuracy: 0.9473 - f1_m: 1.0972 - val_loss: 0.6051 - val_accuracy: 0.8612 - val_f1_m: 1.1253\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1523 - accuracy: 0.9476 - f1_m: 1.0931 - val_loss: 0.6269 - val_accuracy: 0.8613 - val_f1_m: 1.1072\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1511 - accuracy: 0.9484 - f1_m: 1.0931 - val_loss: 0.6146 - val_accuracy: 0.8588 - val_f1_m: 1.1075\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1514 - accuracy: 0.9480 - f1_m: 1.0914 - val_loss: 0.6254 - val_accuracy: 0.8638 - val_f1_m: 1.1073\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.1154 - accuracy: 0.9586 - f1_m: 1.0518 - val_loss: 0.5573 - val_accuracy: 0.8711 - val_f1_m: 1.0732\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1111 - accuracy: 0.9613 - f1_m: 1.0510 - val_loss: 0.5801 - val_accuracy: 0.8711 - val_f1_m: 1.0737\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1100 - accuracy: 0.9621 - f1_m: 1.0489 - val_loss: 0.5994 - val_accuracy: 0.8685 - val_f1_m: 1.0668\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1088 - accuracy: 0.9613 - f1_m: 1.0471 - val_loss: 0.5953 - val_accuracy: 0.8730 - val_f1_m: 1.0589\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1061 - accuracy: 0.9622 - f1_m: 1.0467 - val_loss: 0.5814 - val_accuracy: 0.8743 - val_f1_m: 1.0675\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1072 - accuracy: 0.9624 - f1_m: 1.0457 - val_loss: 0.5857 - val_accuracy: 0.8720 - val_f1_m: 1.0611\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1060 - accuracy: 0.9627 - f1_m: 1.0438 - val_loss: 0.5985 - val_accuracy: 0.8742 - val_f1_m: 1.0565\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1052 - accuracy: 0.9629 - f1_m: 1.0441 - val_loss: 0.5962 - val_accuracy: 0.8745 - val_f1_m: 1.0625\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0909 - accuracy: 0.9676 - f1_m: 1.0207 - val_loss: 0.6704 - val_accuracy: 0.8659 - val_f1_m: 1.0600\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0837 - accuracy: 0.9701 - f1_m: 1.0214 - val_loss: 0.7205 - val_accuracy: 0.8604 - val_f1_m: 1.0595\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0867 - accuracy: 0.9686 - f1_m: 1.0196 - val_loss: 0.7175 - val_accuracy: 0.8627 - val_f1_m: 1.0512\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0807 - accuracy: 0.9714 - f1_m: 1.0158 - val_loss: 0.7149 - val_accuracy: 0.8628 - val_f1_m: 1.0572\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0855 - accuracy: 0.9700 - f1_m: 1.0183 - val_loss: 0.6989 - val_accuracy: 0.8714 - val_f1_m: 1.0482\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0844 - accuracy: 0.9703 - f1_m: 1.0157 - val_loss: 0.7150 - val_accuracy: 0.8682 - val_f1_m: 1.0585\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0805 - accuracy: 0.9709 - f1_m: 1.0150 - val_loss: 0.7707 - val_accuracy: 0.8656 - val_f1_m: 1.0498\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0814 - accuracy: 0.9712 - f1_m: 1.0131 - val_loss: 0.7585 - val_accuracy: 0.8696 - val_f1_m: 1.0434\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.1352 - accuracy: 0.9503 - f1_m: 1.0628 - val_loss: 0.4502 - val_accuracy: 0.8816 - val_f1_m: 1.1029\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1293 - accuracy: 0.9524 - f1_m: 1.0605 - val_loss: 0.4585 - val_accuracy: 0.8727 - val_f1_m: 1.0969\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1276 - accuracy: 0.9532 - f1_m: 1.0577 - val_loss: 0.4662 - val_accuracy: 0.8853 - val_f1_m: 1.0802\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1259 - accuracy: 0.9535 - f1_m: 1.0553 - val_loss: 0.4457 - val_accuracy: 0.8817 - val_f1_m: 1.1053\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1295 - accuracy: 0.9535 - f1_m: 1.0597 - val_loss: 0.4865 - val_accuracy: 0.8803 - val_f1_m: 1.0822\n",
      "Epoch 6/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1281 - accuracy: 0.9533 - f1_m: 1.0588 - val_loss: 0.4632 - val_accuracy: 0.8828 - val_f1_m: 1.0840\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1267 - accuracy: 0.9536 - f1_m: 1.0558 - val_loss: 0.4953 - val_accuracy: 0.8804 - val_f1_m: 1.0692\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1220 - accuracy: 0.9555 - f1_m: 1.0528 - val_loss: 0.4885 - val_accuracy: 0.8811 - val_f1_m: 1.0762\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0115 - accuracy: 0.9962 - f1_m: 0.9583 - val_loss: 1.0410 - val_accuracy: 0.8735 - val_f1_m: 1.0086\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0087 - accuracy: 0.9974 - f1_m: 0.9563 - val_loss: 1.1062 - val_accuracy: 0.8778 - val_f1_m: 1.0026\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0094 - accuracy: 0.9971 - f1_m: 0.9557 - val_loss: 1.0721 - val_accuracy: 0.8766 - val_f1_m: 0.9990\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0092 - accuracy: 0.9972 - f1_m: 0.9564 - val_loss: 1.1380 - val_accuracy: 0.8765 - val_f1_m: 1.0002\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0083 - accuracy: 0.9975 - f1_m: 0.9550 - val_loss: 1.1096 - val_accuracy: 0.8752 - val_f1_m: 1.0004\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0051 - accuracy: 0.9987 - f1_m: 0.9532 - val_loss: 1.2407 - val_accuracy: 0.8694 - val_f1_m: 1.0007\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0110 - accuracy: 0.9964 - f1_m: 0.9565 - val_loss: 1.1741 - val_accuracy: 0.8826 - val_f1_m: 0.9930\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0074 - accuracy: 0.9976 - f1_m: 0.9539 - val_loss: 1.2057 - val_accuracy: 0.8763 - val_f1_m: 0.9932\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0122 - accuracy: 0.9959 - f1_m: 0.9549 - val_loss: 1.2273 - val_accuracy: 0.8907 - val_f1_m: 0.9837\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0090 - accuracy: 0.9973 - f1_m: 0.9524 - val_loss: 1.2181 - val_accuracy: 0.8855 - val_f1_m: 0.9882\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0092 - accuracy: 0.9968 - f1_m: 0.9539 - val_loss: 1.2784 - val_accuracy: 0.8862 - val_f1_m: 0.9856\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0085 - accuracy: 0.9974 - f1_m: 0.9528 - val_loss: 1.2659 - val_accuracy: 0.8873 - val_f1_m: 0.9851\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0104 - accuracy: 0.9966 - f1_m: 0.9536 - val_loss: 1.3074 - val_accuracy: 0.8929 - val_f1_m: 0.9872\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0080 - accuracy: 0.9973 - f1_m: 0.9522 - val_loss: 1.3396 - val_accuracy: 0.8868 - val_f1_m: 0.9783\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0119 - accuracy: 0.9961 - f1_m: 0.9542 - val_loss: 1.2701 - val_accuracy: 0.8880 - val_f1_m: 0.9843\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0041 - accuracy: 0.9986 - f1_m: 0.9503 - val_loss: 1.3269 - val_accuracy: 0.8837 - val_f1_m: 0.9818\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0276 - accuracy: 0.9917 - f1_m: 0.9597 - val_loss: 1.3691 - val_accuracy: 0.8876 - val_f1_m: 0.9791\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0229 - accuracy: 0.9934 - f1_m: 0.9563 - val_loss: 1.2929 - val_accuracy: 0.8807 - val_f1_m: 0.9867\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0199 - accuracy: 0.9942 - f1_m: 0.9562 - val_loss: 1.3039 - val_accuracy: 0.8830 - val_f1_m: 0.9925\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0224 - accuracy: 0.9933 - f1_m: 0.9578 - val_loss: 1.3706 - val_accuracy: 0.8844 - val_f1_m: 0.9879\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0199 - accuracy: 0.9939 - f1_m: 0.9559 - val_loss: 1.3020 - val_accuracy: 0.8859 - val_f1_m: 0.9884\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0241 - accuracy: 0.9933 - f1_m: 0.9571 - val_loss: 1.3790 - val_accuracy: 0.8815 - val_f1_m: 0.9898\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0202 - accuracy: 0.9936 - f1_m: 0.9561 - val_loss: 1.4086 - val_accuracy: 0.8882 - val_f1_m: 0.9793\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0207 - accuracy: 0.9935 - f1_m: 0.9554 - val_loss: 1.3571 - val_accuracy: 0.8833 - val_f1_m: 0.9853\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0611 - accuracy: 0.9797 - f1_m: 0.9845 - val_loss: 0.7444 - val_accuracy: 0.8807 - val_f1_m: 1.0251\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0514 - accuracy: 0.9826 - f1_m: 0.9806 - val_loss: 0.7618 - val_accuracy: 0.8739 - val_f1_m: 1.0235\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0599 - accuracy: 0.9798 - f1_m: 0.9847 - val_loss: 0.7338 - val_accuracy: 0.8754 - val_f1_m: 1.0348\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0545 - accuracy: 0.9809 - f1_m: 0.9828 - val_loss: 0.7554 - val_accuracy: 0.8759 - val_f1_m: 1.0304\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0542 - accuracy: 0.9815 - f1_m: 0.9829 - val_loss: 0.7935 - val_accuracy: 0.8689 - val_f1_m: 1.0263\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0538 - accuracy: 0.9815 - f1_m: 0.9842 - val_loss: 0.7964 - val_accuracy: 0.8799 - val_f1_m: 1.0174\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0548 - accuracy: 0.9816 - f1_m: 0.9827 - val_loss: 0.7914 - val_accuracy: 0.8744 - val_f1_m: 1.0236\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0580 - accuracy: 0.9809 - f1_m: 0.9824 - val_loss: 0.8492 - val_accuracy: 0.8769 - val_f1_m: 1.0145\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.1502 - accuracy: 0.9479 - f1_m: 1.0905 - val_loss: 0.6242 - val_accuracy: 0.8602 - val_f1_m: 1.1170\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1484 - accuracy: 0.9483 - f1_m: 1.0909 - val_loss: 0.6542 - val_accuracy: 0.8585 - val_f1_m: 1.1116\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1465 - accuracy: 0.9493 - f1_m: 1.0881 - val_loss: 0.6240 - val_accuracy: 0.8667 - val_f1_m: 1.1111\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1453 - accuracy: 0.9502 - f1_m: 1.0894 - val_loss: 0.6335 - val_accuracy: 0.8612 - val_f1_m: 1.1133\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1445 - accuracy: 0.9497 - f1_m: 1.0884 - val_loss: 0.6450 - val_accuracy: 0.8589 - val_f1_m: 1.1153\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1444 - accuracy: 0.9496 - f1_m: 1.0863 - val_loss: 0.6763 - val_accuracy: 0.8599 - val_f1_m: 1.0997\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1432 - accuracy: 0.9508 - f1_m: 1.0845 - val_loss: 0.6560 - val_accuracy: 0.8585 - val_f1_m: 1.0993\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1434 - accuracy: 0.9509 - f1_m: 1.0843 - val_loss: 0.6807 - val_accuracy: 0.8632 - val_f1_m: 1.1000\n",
      "Epoch 9/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1422 - accuracy: 0.9500 - f1_m: 1.0825 - val_loss: 0.6599 - val_accuracy: 0.8597 - val_f1_m: 1.1099\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1048 - accuracy: 0.9621 - f1_m: 1.0419 - val_loss: 0.6114 - val_accuracy: 0.8710 - val_f1_m: 1.0572\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1007 - accuracy: 0.9647 - f1_m: 1.0392 - val_loss: 0.6505 - val_accuracy: 0.8722 - val_f1_m: 1.0636\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0994 - accuracy: 0.9646 - f1_m: 1.0375 - val_loss: 0.6574 - val_accuracy: 0.8660 - val_f1_m: 1.0534\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0985 - accuracy: 0.9651 - f1_m: 1.0367 - val_loss: 0.6451 - val_accuracy: 0.8718 - val_f1_m: 1.0545\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0966 - accuracy: 0.9655 - f1_m: 1.0370 - val_loss: 0.6442 - val_accuracy: 0.8735 - val_f1_m: 1.0537\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0963 - accuracy: 0.9663 - f1_m: 1.0371 - val_loss: 0.6435 - val_accuracy: 0.8721 - val_f1_m: 1.0465\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0964 - accuracy: 0.9653 - f1_m: 1.0346 - val_loss: 0.6664 - val_accuracy: 0.8736 - val_f1_m: 1.0485\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0936 - accuracy: 0.9665 - f1_m: 1.0348 - val_loss: 0.6517 - val_accuracy: 0.8735 - val_f1_m: 1.0584\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0959 - accuracy: 0.9664 - f1_m: 1.0324 - val_loss: 0.6656 - val_accuracy: 0.8712 - val_f1_m: 1.0571\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0842 - accuracy: 0.9698 - f1_m: 1.0116 - val_loss: 0.7237 - val_accuracy: 0.8623 - val_f1_m: 1.0599\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0719 - accuracy: 0.9742 - f1_m: 1.0100 - val_loss: 0.8012 - val_accuracy: 0.8626 - val_f1_m: 1.0488\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0810 - accuracy: 0.9705 - f1_m: 1.0113 - val_loss: 0.7693 - val_accuracy: 0.8652 - val_f1_m: 1.0455\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0750 - accuracy: 0.9729 - f1_m: 1.0095 - val_loss: 0.8188 - val_accuracy: 0.8640 - val_f1_m: 1.0507\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0761 - accuracy: 0.9721 - f1_m: 1.0093 - val_loss: 0.7569 - val_accuracy: 0.8628 - val_f1_m: 1.0579\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0765 - accuracy: 0.9720 - f1_m: 1.0089 - val_loss: 0.7901 - val_accuracy: 0.8656 - val_f1_m: 1.0535\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0765 - accuracy: 0.9733 - f1_m: 1.0079 - val_loss: 0.8328 - val_accuracy: 0.8634 - val_f1_m: 1.0415\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0738 - accuracy: 0.9739 - f1_m: 1.0091 - val_loss: 0.8239 - val_accuracy: 0.8683 - val_f1_m: 1.0394\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0768 - accuracy: 0.9731 - f1_m: 1.0071 - val_loss: 0.8084 - val_accuracy: 0.8599 - val_f1_m: 1.0485\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.1270 - accuracy: 0.9537 - f1_m: 1.0541 - val_loss: 0.4435 - val_accuracy: 0.8886 - val_f1_m: 1.0946\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1251 - accuracy: 0.9540 - f1_m: 1.0549 - val_loss: 0.4542 - val_accuracy: 0.8830 - val_f1_m: 1.0758\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.1210 - accuracy: 0.9556 - f1_m: 1.0530 - val_loss: 0.4796 - val_accuracy: 0.8855 - val_f1_m: 1.0715\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1203 - accuracy: 0.9557 - f1_m: 1.0485 - val_loss: 0.4902 - val_accuracy: 0.8841 - val_f1_m: 1.0824\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1205 - accuracy: 0.9564 - f1_m: 1.0487 - val_loss: 0.5063 - val_accuracy: 0.8791 - val_f1_m: 1.0664\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1190 - accuracy: 0.9563 - f1_m: 1.0503 - val_loss: 0.4740 - val_accuracy: 0.8847 - val_f1_m: 1.0781\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1152 - accuracy: 0.9578 - f1_m: 1.0463 - val_loss: 0.5470 - val_accuracy: 0.8819 - val_f1_m: 1.0633\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1189 - accuracy: 0.9573 - f1_m: 1.0486 - val_loss: 0.5195 - val_accuracy: 0.8816 - val_f1_m: 1.0763\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1187 - accuracy: 0.9574 - f1_m: 1.0499 - val_loss: 0.4939 - val_accuracy: 0.8761 - val_f1_m: 1.0801\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0088 - accuracy: 0.9974 - f1_m: 0.9547 - val_loss: 1.1880 - val_accuracy: 0.8773 - val_f1_m: 0.9938\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0070 - accuracy: 0.9979 - f1_m: 0.9533 - val_loss: 1.2815 - val_accuracy: 0.8710 - val_f1_m: 0.9944\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0083 - accuracy: 0.9974 - f1_m: 0.9549 - val_loss: 1.2712 - val_accuracy: 0.8724 - val_f1_m: 0.9956\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0081 - accuracy: 0.9975 - f1_m: 0.9546 - val_loss: 1.2388 - val_accuracy: 0.8770 - val_f1_m: 0.9947\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0086 - accuracy: 0.9973 - f1_m: 0.9543 - val_loss: 1.2559 - val_accuracy: 0.8709 - val_f1_m: 0.9968\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0071 - accuracy: 0.9978 - f1_m: 0.9533 - val_loss: 1.2680 - val_accuracy: 0.8747 - val_f1_m: 0.9918\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0066 - accuracy: 0.9978 - f1_m: 0.9531 - val_loss: 1.2150 - val_accuracy: 0.8783 - val_f1_m: 0.9889\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0080 - accuracy: 0.9972 - f1_m: 0.9535 - val_loss: 1.2707 - val_accuracy: 0.8736 - val_f1_m: 0.9957\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0077 - accuracy: 0.9976 - f1_m: 0.9545 - val_loss: 1.2682 - val_accuracy: 0.8754 - val_f1_m: 0.9921\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0093 - accuracy: 0.9967 - f1_m: 0.9526 - val_loss: 1.3820 - val_accuracy: 0.8897 - val_f1_m: 0.9771\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0091 - accuracy: 0.9971 - f1_m: 0.9523 - val_loss: 1.3296 - val_accuracy: 0.8884 - val_f1_m: 0.9838\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0109 - accuracy: 0.9968 - f1_m: 0.9520 - val_loss: 1.3511 - val_accuracy: 0.8889 - val_f1_m: 0.9801\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0112 - accuracy: 0.9965 - f1_m: 0.9530 - val_loss: 1.3030 - val_accuracy: 0.8879 - val_f1_m: 0.9792\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0058 - accuracy: 0.9982 - f1_m: 0.9512 - val_loss: 1.2687 - val_accuracy: 0.8898 - val_f1_m: 0.9829\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0068 - accuracy: 0.9978 - f1_m: 0.9520 - val_loss: 1.3226 - val_accuracy: 0.8913 - val_f1_m: 0.9807\n",
      "Epoch 7/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0082 - accuracy: 0.9976 - f1_m: 0.9523 - val_loss: 1.3688 - val_accuracy: 0.8961 - val_f1_m: 0.9755\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0116 - accuracy: 0.9962 - f1_m: 0.9529 - val_loss: 1.4458 - val_accuracy: 0.8914 - val_f1_m: 0.9800\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0069 - accuracy: 0.9979 - f1_m: 0.9509 - val_loss: 1.4043 - val_accuracy: 0.8948 - val_f1_m: 0.9795\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0231 - accuracy: 0.9933 - f1_m: 0.9567 - val_loss: 1.3832 - val_accuracy: 0.8872 - val_f1_m: 0.9880\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0227 - accuracy: 0.9936 - f1_m: 0.9560 - val_loss: 1.3342 - val_accuracy: 0.8852 - val_f1_m: 0.9873\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0233 - accuracy: 0.9931 - f1_m: 0.9564 - val_loss: 1.3018 - val_accuracy: 0.8796 - val_f1_m: 0.9881\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 5s 115us/sample - loss: 0.0186 - accuracy: 0.9944 - f1_m: 0.9556 - val_loss: 1.3024 - val_accuracy: 0.8805 - val_f1_m: 0.9875\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 5s 115us/sample - loss: 0.0187 - accuracy: 0.9949 - f1_m: 0.9549 - val_loss: 1.2663 - val_accuracy: 0.8821 - val_f1_m: 0.9922\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0229 - accuracy: 0.9931 - f1_m: 0.9568 - val_loss: 1.3770 - val_accuracy: 0.8822 - val_f1_m: 0.9864\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 5s 115us/sample - loss: 0.0229 - accuracy: 0.9938 - f1_m: 0.9556 - val_loss: 1.3273 - val_accuracy: 0.8875 - val_f1_m: 0.9869\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0208 - accuracy: 0.9941 - f1_m: 0.9561 - val_loss: 1.4114 - val_accuracy: 0.8851 - val_f1_m: 0.9884\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0251 - accuracy: 0.9932 - f1_m: 0.9567 - val_loss: 1.4014 - val_accuracy: 0.8901 - val_f1_m: 0.9845\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0592 - accuracy: 0.9807 - f1_m: 0.9810 - val_loss: 0.7939 - val_accuracy: 0.8753 - val_f1_m: 1.0204\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 8s 156us/sample - loss: 0.0547 - accuracy: 0.9817 - f1_m: 0.9824 - val_loss: 0.7773 - val_accuracy: 0.8756 - val_f1_m: 1.0237\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0544 - accuracy: 0.9819 - f1_m: 0.9815 - val_loss: 0.8344 - val_accuracy: 0.8781 - val_f1_m: 1.0154\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0555 - accuracy: 0.9810 - f1_m: 0.9805 - val_loss: 0.8285 - val_accuracy: 0.8720 - val_f1_m: 1.0248\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0507 - accuracy: 0.9833 - f1_m: 0.9784 - val_loss: 0.8234 - val_accuracy: 0.8742 - val_f1_m: 1.0233\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0471 - accuracy: 0.9836 - f1_m: 0.9782 - val_loss: 0.9031 - val_accuracy: 0.8759 - val_f1_m: 1.0197\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0580 - accuracy: 0.9809 - f1_m: 0.9826 - val_loss: 0.7805 - val_accuracy: 0.8725 - val_f1_m: 1.0330\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0511 - accuracy: 0.9830 - f1_m: 0.9791 - val_loss: 0.8134 - val_accuracy: 0.8751 - val_f1_m: 1.0235\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0517 - accuracy: 0.9827 - f1_m: 0.9803 - val_loss: 0.7660 - val_accuracy: 0.8743 - val_f1_m: 1.0273\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1426 - accuracy: 0.9508 - f1_m: 1.0832 - val_loss: 0.6595 - val_accuracy: 0.8600 - val_f1_m: 1.1110\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1404 - accuracy: 0.9510 - f1_m: 1.0830 - val_loss: 0.6990 - val_accuracy: 0.8534 - val_f1_m: 1.1063\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1384 - accuracy: 0.9517 - f1_m: 1.0802 - val_loss: 0.6763 - val_accuracy: 0.8653 - val_f1_m: 1.0995\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1375 - accuracy: 0.9532 - f1_m: 1.0818 - val_loss: 0.6811 - val_accuracy: 0.8584 - val_f1_m: 1.1023\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1364 - accuracy: 0.9525 - f1_m: 1.0803 - val_loss: 0.6932 - val_accuracy: 0.8568 - val_f1_m: 1.1113\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1371 - accuracy: 0.9526 - f1_m: 1.0784 - val_loss: 0.7115 - val_accuracy: 0.8598 - val_f1_m: 1.0953\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1356 - accuracy: 0.9534 - f1_m: 1.0765 - val_loss: 0.6963 - val_accuracy: 0.8586 - val_f1_m: 1.0962\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1360 - accuracy: 0.9532 - f1_m: 1.0764 - val_loss: 0.7253 - val_accuracy: 0.8601 - val_f1_m: 1.0917\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1352 - accuracy: 0.9527 - f1_m: 1.0752 - val_loss: 0.7170 - val_accuracy: 0.8560 - val_f1_m: 1.0959\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1352 - accuracy: 0.9544 - f1_m: 1.0756 - val_loss: 0.7141 - val_accuracy: 0.8573 - val_f1_m: 1.0947\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0940 - accuracy: 0.9667 - f1_m: 1.0314 - val_loss: 0.6806 - val_accuracy: 0.8672 - val_f1_m: 1.0513\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0911 - accuracy: 0.9680 - f1_m: 1.0289 - val_loss: 0.7070 - val_accuracy: 0.8691 - val_f1_m: 1.0530\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0896 - accuracy: 0.9686 - f1_m: 1.0281 - val_loss: 0.7322 - val_accuracy: 0.8655 - val_f1_m: 1.0408\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0893 - accuracy: 0.9677 - f1_m: 1.0283 - val_loss: 0.7097 - val_accuracy: 0.8715 - val_f1_m: 1.0475\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0871 - accuracy: 0.9689 - f1_m: 1.0296 - val_loss: 0.7211 - val_accuracy: 0.8685 - val_f1_m: 1.0486\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0884 - accuracy: 0.9696 - f1_m: 1.0266 - val_loss: 0.7153 - val_accuracy: 0.8692 - val_f1_m: 1.0398\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0873 - accuracy: 0.9685 - f1_m: 1.0267 - val_loss: 0.7365 - val_accuracy: 0.8700 - val_f1_m: 1.0418\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0859 - accuracy: 0.9691 - f1_m: 1.0254 - val_loss: 0.7203 - val_accuracy: 0.8686 - val_f1_m: 1.0472\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0877 - accuracy: 0.9698 - f1_m: 1.0242 - val_loss: 0.7223 - val_accuracy: 0.8673 - val_f1_m: 1.0542\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0857 - accuracy: 0.9699 - f1_m: 1.0255 - val_loss: 0.7097 - val_accuracy: 0.8707 - val_f1_m: 1.0502\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0741 - accuracy: 0.9734 - f1_m: 1.0044 - val_loss: 0.8358 - val_accuracy: 0.8644 - val_f1_m: 1.0393\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0695 - accuracy: 0.9746 - f1_m: 1.0060 - val_loss: 0.8328 - val_accuracy: 0.8591 - val_f1_m: 1.0474\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0704 - accuracy: 0.9751 - f1_m: 1.0043 - val_loss: 0.8450 - val_accuracy: 0.8639 - val_f1_m: 1.0391\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0712 - accuracy: 0.9746 - f1_m: 1.0022 - val_loss: 0.8321 - val_accuracy: 0.8674 - val_f1_m: 1.0427\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0705 - accuracy: 0.9749 - f1_m: 1.0042 - val_loss: 0.9023 - val_accuracy: 0.8672 - val_f1_m: 1.0303\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0721 - accuracy: 0.9749 - f1_m: 1.0027 - val_loss: 0.8554 - val_accuracy: 0.8667 - val_f1_m: 1.0430\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0686 - accuracy: 0.9758 - f1_m: 1.0007 - val_loss: 0.8977 - val_accuracy: 0.8633 - val_f1_m: 1.0312\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0674 - accuracy: 0.9758 - f1_m: 1.0028 - val_loss: 0.9442 - val_accuracy: 0.8688 - val_f1_m: 1.0278\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0689 - accuracy: 0.9753 - f1_m: 0.9988 - val_loss: 0.8998 - val_accuracy: 0.8687 - val_f1_m: 1.0264\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0658 - accuracy: 0.9768 - f1_m: 0.9986 - val_loss: 0.8508 - val_accuracy: 0.8610 - val_f1_m: 1.0416\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.1200 - accuracy: 0.9566 - f1_m: 1.0472 - val_loss: 0.5013 - val_accuracy: 0.8785 - val_f1_m: 1.0856\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.1188 - accuracy: 0.9562 - f1_m: 1.0471 - val_loss: 0.4906 - val_accuracy: 0.8754 - val_f1_m: 1.1076\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1154 - accuracy: 0.9574 - f1_m: 1.0482 - val_loss: 0.5079 - val_accuracy: 0.8821 - val_f1_m: 1.0636\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1130 - accuracy: 0.9596 - f1_m: 1.0432 - val_loss: 0.4981 - val_accuracy: 0.8800 - val_f1_m: 1.0739\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.1195 - accuracy: 0.9570 - f1_m: 1.0466 - val_loss: 0.4810 - val_accuracy: 0.8787 - val_f1_m: 1.0830\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1127 - accuracy: 0.9581 - f1_m: 1.0458 - val_loss: 0.4770 - val_accuracy: 0.8843 - val_f1_m: 1.0854\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.1154 - accuracy: 0.9574 - f1_m: 1.0434 - val_loss: 0.5355 - val_accuracy: 0.8830 - val_f1_m: 1.0661\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.1110 - accuracy: 0.9588 - f1_m: 1.0425 - val_loss: 0.5113 - val_accuracy: 0.8766 - val_f1_m: 1.0631\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1162 - accuracy: 0.9586 - f1_m: 1.0439 - val_loss: 0.4784 - val_accuracy: 0.8833 - val_f1_m: 1.0846\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1142 - accuracy: 0.9580 - f1_m: 1.0442 - val_loss: 0.4562 - val_accuracy: 0.8822 - val_f1_m: 1.0765\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0062 - accuracy: 0.9980 - f1_m: 0.9526 - val_loss: 1.3517 - val_accuracy: 0.8754 - val_f1_m: 0.9876\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0086 - accuracy: 0.9974 - f1_m: 0.9532 - val_loss: 1.2878 - val_accuracy: 0.8741 - val_f1_m: 0.9943\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0088 - accuracy: 0.9971 - f1_m: 0.9534 - val_loss: 1.3450 - val_accuracy: 0.8761 - val_f1_m: 0.9939\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0050 - accuracy: 0.9984 - f1_m: 0.9519 - val_loss: 1.3905 - val_accuracy: 0.8763 - val_f1_m: 0.9909\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0058 - accuracy: 0.9983 - f1_m: 0.9519 - val_loss: 1.4312 - val_accuracy: 0.8670 - val_f1_m: 0.9960\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0089 - accuracy: 0.9969 - f1_m: 0.9540 - val_loss: 1.3289 - val_accuracy: 0.8779 - val_f1_m: 0.9931\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0054 - accuracy: 0.9984 - f1_m: 0.9516 - val_loss: 1.3821 - val_accuracy: 0.8771 - val_f1_m: 0.9906\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0046 - accuracy: 0.9985 - f1_m: 0.9514 - val_loss: 1.3473 - val_accuracy: 0.8830 - val_f1_m: 0.9877\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0098 - accuracy: 0.9974 - f1_m: 0.9510 - val_loss: 1.3868 - val_accuracy: 0.8754 - val_f1_m: 0.9947\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0054 - accuracy: 0.9986 - f1_m: 0.9516 - val_loss: 1.3550 - val_accuracy: 0.8828 - val_f1_m: 0.9871\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0097 - accuracy: 0.9971 - f1_m: 0.9516 - val_loss: 1.5484 - val_accuracy: 0.8920 - val_f1_m: 0.9807\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0089 - accuracy: 0.9971 - f1_m: 0.9513 - val_loss: 1.4765 - val_accuracy: 0.8892 - val_f1_m: 0.9780\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0090 - accuracy: 0.9975 - f1_m: 0.9519 - val_loss: 1.3903 - val_accuracy: 0.8886 - val_f1_m: 0.9803\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0093 - accuracy: 0.9973 - f1_m: 0.9509 - val_loss: 1.4838 - val_accuracy: 0.8848 - val_f1_m: 0.9819\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0096 - accuracy: 0.9973 - f1_m: 0.9509 - val_loss: 1.4750 - val_accuracy: 0.8917 - val_f1_m: 0.9776\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0058 - accuracy: 0.9979 - f1_m: 0.9512 - val_loss: 1.4248 - val_accuracy: 0.8862 - val_f1_m: 0.9761\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0137 - accuracy: 0.9964 - f1_m: 0.9523 - val_loss: 1.4260 - val_accuracy: 0.8868 - val_f1_m: 0.9782\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0047 - accuracy: 0.9985 - f1_m: 0.9499 - val_loss: 1.4961 - val_accuracy: 0.8934 - val_f1_m: 0.9802\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0096 - accuracy: 0.9970 - f1_m: 0.9515 - val_loss: 1.4722 - val_accuracy: 0.8909 - val_f1_m: 0.9771\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0084 - accuracy: 0.9974 - f1_m: 0.9508 - val_loss: 1.4280 - val_accuracy: 0.8902 - val_f1_m: 0.9766\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0182 - accuracy: 0.9945 - f1_m: 0.9546 - val_loss: 1.5881 - val_accuracy: 0.8874 - val_f1_m: 0.9809\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0218 - accuracy: 0.9939 - f1_m: 0.9542 - val_loss: 1.5518 - val_accuracy: 0.8844 - val_f1_m: 0.9824\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0210 - accuracy: 0.9939 - f1_m: 0.9549 - val_loss: 1.5216 - val_accuracy: 0.8842 - val_f1_m: 0.9827\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s 115us/sample - loss: 0.0207 - accuracy: 0.9942 - f1_m: 0.9553 - val_loss: 1.5802 - val_accuracy: 0.8864 - val_f1_m: 0.9807\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0211 - accuracy: 0.9941 - f1_m: 0.9546 - val_loss: 1.4577 - val_accuracy: 0.8817 - val_f1_m: 0.9879\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0184 - accuracy: 0.9948 - f1_m: 0.9541 - val_loss: 1.5639 - val_accuracy: 0.8846 - val_f1_m: 0.9789\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0217 - accuracy: 0.9945 - f1_m: 0.9542 - val_loss: 1.5375 - val_accuracy: 0.8885 - val_f1_m: 0.9825\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0242 - accuracy: 0.9933 - f1_m: 0.9552 - val_loss: 1.5887 - val_accuracy: 0.8865 - val_f1_m: 0.9805\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0136 - accuracy: 0.9960 - f1_m: 0.9527 - val_loss: 1.6470 - val_accuracy: 0.8853 - val_f1_m: 0.9789\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0246 - accuracy: 0.9937 - f1_m: 0.9544 - val_loss: 1.6134 - val_accuracy: 0.8909 - val_f1_m: 0.9789\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.0537 - accuracy: 0.9823 - f1_m: 0.9786 - val_loss: 0.8961 - val_accuracy: 0.8794 - val_f1_m: 1.0108\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0480 - accuracy: 0.9841 - f1_m: 0.9767 - val_loss: 0.9039 - val_accuracy: 0.8766 - val_f1_m: 1.0151\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0522 - accuracy: 0.9838 - f1_m: 0.9790 - val_loss: 0.8229 - val_accuracy: 0.8800 - val_f1_m: 1.0241\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0546 - accuracy: 0.9827 - f1_m: 0.9790 - val_loss: 0.7810 - val_accuracy: 0.8769 - val_f1_m: 1.0275\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0428 - accuracy: 0.9853 - f1_m: 0.9747 - val_loss: 0.8632 - val_accuracy: 0.8763 - val_f1_m: 1.0216\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.0526 - accuracy: 0.9824 - f1_m: 0.9795 - val_loss: 0.8517 - val_accuracy: 0.8818 - val_f1_m: 1.0178\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0509 - accuracy: 0.9833 - f1_m: 0.9779 - val_loss: 0.8597 - val_accuracy: 0.8762 - val_f1_m: 1.0209\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0414 - accuracy: 0.9860 - f1_m: 0.9762 - val_loss: 0.9665 - val_accuracy: 0.8753 - val_f1_m: 1.0226\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0605 - accuracy: 0.9813 - f1_m: 0.9806 - val_loss: 0.8424 - val_accuracy: 0.8734 - val_f1_m: 1.0256\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0435 - accuracy: 0.9853 - f1_m: 0.9749 - val_loss: 0.8505 - val_accuracy: 0.8829 - val_f1_m: 1.0225\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1354 - accuracy: 0.9535 - f1_m: 1.0743 - val_loss: 0.7111 - val_accuracy: 0.8605 - val_f1_m: 1.1057\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1331 - accuracy: 0.9539 - f1_m: 1.0735 - val_loss: 0.7542 - val_accuracy: 0.8529 - val_f1_m: 1.0986\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1302 - accuracy: 0.9548 - f1_m: 1.0728 - val_loss: 0.7264 - val_accuracy: 0.8634 - val_f1_m: 1.0965\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1300 - accuracy: 0.9559 - f1_m: 1.0736 - val_loss: 0.7270 - val_accuracy: 0.8600 - val_f1_m: 1.0948\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1294 - accuracy: 0.9546 - f1_m: 1.0714 - val_loss: 0.7369 - val_accuracy: 0.8569 - val_f1_m: 1.1053\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1301 - accuracy: 0.9554 - f1_m: 1.0702 - val_loss: 0.7671 - val_accuracy: 0.8598 - val_f1_m: 1.0881\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1288 - accuracy: 0.9562 - f1_m: 1.0703 - val_loss: 0.7526 - val_accuracy: 0.8581 - val_f1_m: 1.0872\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1297 - accuracy: 0.9556 - f1_m: 1.0700 - val_loss: 0.7759 - val_accuracy: 0.8595 - val_f1_m: 1.0855\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.1295 - accuracy: 0.9546 - f1_m: 1.0681 - val_loss: 0.7617 - val_accuracy: 0.8550 - val_f1_m: 1.0902\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1284 - accuracy: 0.9568 - f1_m: 1.0688 - val_loss: 0.7609 - val_accuracy: 0.8575 - val_f1_m: 1.0869\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1270 - accuracy: 0.9559 - f1_m: 1.0673 - val_loss: 0.7731 - val_accuracy: 0.8560 - val_f1_m: 1.0884\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0862 - accuracy: 0.9691 - f1_m: 1.0243 - val_loss: 0.7597 - val_accuracy: 0.8638 - val_f1_m: 1.0420\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0819 - accuracy: 0.9708 - f1_m: 1.0220 - val_loss: 0.8044 - val_accuracy: 0.8659 - val_f1_m: 1.0445\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0815 - accuracy: 0.9714 - f1_m: 1.0208 - val_loss: 0.7939 - val_accuracy: 0.8641 - val_f1_m: 1.0404\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0817 - accuracy: 0.9709 - f1_m: 1.0206 - val_loss: 0.7794 - val_accuracy: 0.8676 - val_f1_m: 1.0392\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0791 - accuracy: 0.9719 - f1_m: 1.0185 - val_loss: 0.7876 - val_accuracy: 0.8692 - val_f1_m: 1.0387\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0816 - accuracy: 0.9714 - f1_m: 1.0199 - val_loss: 0.7888 - val_accuracy: 0.8654 - val_f1_m: 1.0357\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0805 - accuracy: 0.9718 - f1_m: 1.0181 - val_loss: 0.8112 - val_accuracy: 0.8676 - val_f1_m: 1.0274\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0784 - accuracy: 0.9726 - f1_m: 1.0175 - val_loss: 0.8036 - val_accuracy: 0.8663 - val_f1_m: 1.0399\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0818 - accuracy: 0.9717 - f1_m: 1.0203 - val_loss: 0.8237 - val_accuracy: 0.8671 - val_f1_m: 1.0478\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0750 - accuracy: 0.9729 - f1_m: 1.0172 - val_loss: 0.7945 - val_accuracy: 0.8672 - val_f1_m: 1.0405\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0800 - accuracy: 0.9724 - f1_m: 1.0159 - val_loss: 0.8077 - val_accuracy: 0.8703 - val_f1_m: 1.0338\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0718 - accuracy: 0.9753 - f1_m: 1.0004 - val_loss: 0.8966 - val_accuracy: 0.8655 - val_f1_m: 1.0420\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0627 - accuracy: 0.9772 - f1_m: 0.9980 - val_loss: 0.8993 - val_accuracy: 0.8625 - val_f1_m: 1.0358\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0701 - accuracy: 0.9752 - f1_m: 0.9985 - val_loss: 0.9028 - val_accuracy: 0.8603 - val_f1_m: 1.0405\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0671 - accuracy: 0.9765 - f1_m: 0.9977 - val_loss: 0.9176 - val_accuracy: 0.8603 - val_f1_m: 1.0443\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0659 - accuracy: 0.9765 - f1_m: 0.9987 - val_loss: 0.9219 - val_accuracy: 0.8630 - val_f1_m: 1.0289\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0634 - accuracy: 0.9775 - f1_m: 0.9973 - val_loss: 0.9387 - val_accuracy: 0.8649 - val_f1_m: 1.0404\n",
      "Epoch 7/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0658 - accuracy: 0.9769 - f1_m: 0.9953 - val_loss: 0.9793 - val_accuracy: 0.8610 - val_f1_m: 1.0386\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0648 - accuracy: 0.9772 - f1_m: 0.9984 - val_loss: 0.9737 - val_accuracy: 0.8622 - val_f1_m: 1.0273\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0653 - accuracy: 0.9765 - f1_m: 0.9952 - val_loss: 0.9387 - val_accuracy: 0.8670 - val_f1_m: 1.0222\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0633 - accuracy: 0.9770 - f1_m: 0.9953 - val_loss: 0.9728 - val_accuracy: 0.8661 - val_f1_m: 1.0194\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0640 - accuracy: 0.9778 - f1_m: 0.9937 - val_loss: 0.9733 - val_accuracy: 0.8664 - val_f1_m: 1.0255\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.1177 - accuracy: 0.9556 - f1_m: 1.0457 - val_loss: 0.5261 - val_accuracy: 0.8813 - val_f1_m: 1.0607\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1179 - accuracy: 0.9561 - f1_m: 1.0467 - val_loss: 0.4855 - val_accuracy: 0.8874 - val_f1_m: 1.0664\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.1092 - accuracy: 0.9605 - f1_m: 1.0380 - val_loss: 0.5382 - val_accuracy: 0.8828 - val_f1_m: 1.0602\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1091 - accuracy: 0.9591 - f1_m: 1.0409 - val_loss: 0.4990 - val_accuracy: 0.8822 - val_f1_m: 1.0817\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1106 - accuracy: 0.9598 - f1_m: 1.0390 - val_loss: 0.5098 - val_accuracy: 0.8802 - val_f1_m: 1.0755\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1116 - accuracy: 0.9590 - f1_m: 1.0385 - val_loss: 0.4561 - val_accuracy: 0.8812 - val_f1_m: 1.0907\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1080 - accuracy: 0.9609 - f1_m: 1.0390 - val_loss: 0.5345 - val_accuracy: 0.8795 - val_f1_m: 1.0850\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1093 - accuracy: 0.9606 - f1_m: 1.0364 - val_loss: 0.5196 - val_accuracy: 0.8789 - val_f1_m: 1.0636\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1091 - accuracy: 0.9610 - f1_m: 1.0368 - val_loss: 0.5180 - val_accuracy: 0.8804 - val_f1_m: 1.0764\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.1053 - accuracy: 0.9618 - f1_m: 1.0379 - val_loss: 0.5239 - val_accuracy: 0.8800 - val_f1_m: 1.0658\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.1070 - accuracy: 0.9611 - f1_m: 1.0367 - val_loss: 0.5054 - val_accuracy: 0.8809 - val_f1_m: 1.0792\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0071 - accuracy: 0.9977 - f1_m: 0.9523 - val_loss: 1.4171 - val_accuracy: 0.8754 - val_f1_m: 0.9849\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0052 - accuracy: 0.9982 - f1_m: 0.9521 - val_loss: 1.4046 - val_accuracy: 0.8803 - val_f1_m: 0.9885\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0043 - accuracy: 0.9987 - f1_m: 0.9505 - val_loss: 1.4726 - val_accuracy: 0.8757 - val_f1_m: 0.9856\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0067 - accuracy: 0.9979 - f1_m: 0.9528 - val_loss: 1.4122 - val_accuracy: 0.8765 - val_f1_m: 0.9887\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0059 - accuracy: 0.9980 - f1_m: 0.9514 - val_loss: 1.4255 - val_accuracy: 0.8729 - val_f1_m: 0.9920\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0077 - accuracy: 0.9973 - f1_m: 0.9531 - val_loss: 1.5071 - val_accuracy: 0.8737 - val_f1_m: 0.9900\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0031 - accuracy: 0.9991 - f1_m: 0.9500 - val_loss: 1.4769 - val_accuracy: 0.8736 - val_f1_m: 0.9851\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0089 - accuracy: 0.9971 - f1_m: 0.9517 - val_loss: 1.4873 - val_accuracy: 0.8771 - val_f1_m: 0.9852\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0043 - accuracy: 0.9986 - f1_m: 0.9505 - val_loss: 1.4376 - val_accuracy: 0.8830 - val_f1_m: 0.9842\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0073 - accuracy: 0.9978 - f1_m: 0.9520 - val_loss: 1.5007 - val_accuracy: 0.8785 - val_f1_m: 0.9885\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0056 - accuracy: 0.9981 - f1_m: 0.9510 - val_loss: 1.4079 - val_accuracy: 0.8791 - val_f1_m: 0.9826\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0084 - accuracy: 0.9973 - f1_m: 0.9511 - val_loss: 1.5788 - val_accuracy: 0.8859 - val_f1_m: 0.9805\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0075 - accuracy: 0.9977 - f1_m: 0.9512 - val_loss: 1.5490 - val_accuracy: 0.8876 - val_f1_m: 0.9757\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0093 - accuracy: 0.9973 - f1_m: 0.9509 - val_loss: 1.6503 - val_accuracy: 0.8881 - val_f1_m: 0.9772\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0083 - accuracy: 0.9976 - f1_m: 0.9510 - val_loss: 1.5544 - val_accuracy: 0.8924 - val_f1_m: 0.9787\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0073 - accuracy: 0.9978 - f1_m: 0.9508 - val_loss: 1.6728 - val_accuracy: 0.8908 - val_f1_m: 0.9725\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0088 - accuracy: 0.9973 - f1_m: 0.9514 - val_loss: 1.6609 - val_accuracy: 0.8903 - val_f1_m: 0.9740\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0039 - accuracy: 0.9988 - f1_m: 0.9497 - val_loss: 1.6293 - val_accuracy: 0.8831 - val_f1_m: 0.9789\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0116 - accuracy: 0.9967 - f1_m: 0.9513 - val_loss: 1.6376 - val_accuracy: 0.8888 - val_f1_m: 0.9763\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0063 - accuracy: 0.9983 - f1_m: 0.9496 - val_loss: 1.6164 - val_accuracy: 0.8878 - val_f1_m: 0.9750\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0115 - accuracy: 0.9970 - f1_m: 0.9509 - val_loss: 1.6468 - val_accuracy: 0.8902 - val_f1_m: 0.9725\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0063 - accuracy: 0.9982 - f1_m: 0.9501 - val_loss: 1.6064 - val_accuracy: 0.8869 - val_f1_m: 0.9758\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0218 - accuracy: 0.9946 - f1_m: 0.9535 - val_loss: 1.5703 - val_accuracy: 0.8888 - val_f1_m: 0.9811\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0189 - accuracy: 0.9946 - f1_m: 0.9538 - val_loss: 1.5750 - val_accuracy: 0.8868 - val_f1_m: 0.9808\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0210 - accuracy: 0.9948 - f1_m: 0.9542 - val_loss: 1.6118 - val_accuracy: 0.8888 - val_f1_m: 0.9797\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0219 - accuracy: 0.9946 - f1_m: 0.9537 - val_loss: 1.6077 - val_accuracy: 0.8919 - val_f1_m: 0.9800\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0170 - accuracy: 0.9954 - f1_m: 0.9536 - val_loss: 1.7395 - val_accuracy: 0.8852 - val_f1_m: 0.9738\n",
      "Epoch 6/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0194 - accuracy: 0.9948 - f1_m: 0.9531 - val_loss: 1.7111 - val_accuracy: 0.8880 - val_f1_m: 0.9810\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0251 - accuracy: 0.9938 - f1_m: 0.9544 - val_loss: 1.4714 - val_accuracy: 0.8901 - val_f1_m: 0.9842\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0164 - accuracy: 0.9954 - f1_m: 0.9530 - val_loss: 1.7234 - val_accuracy: 0.8878 - val_f1_m: 0.9780\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0195 - accuracy: 0.9949 - f1_m: 0.9534 - val_loss: 1.6826 - val_accuracy: 0.8867 - val_f1_m: 0.9767\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0186 - accuracy: 0.9946 - f1_m: 0.9541 - val_loss: 1.7560 - val_accuracy: 0.8900 - val_f1_m: 0.9760\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0222 - accuracy: 0.9947 - f1_m: 0.9534 - val_loss: 1.6232 - val_accuracy: 0.8949 - val_f1_m: 0.9766\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.0518 - accuracy: 0.9837 - f1_m: 0.9749 - val_loss: 0.9664 - val_accuracy: 0.8777 - val_f1_m: 1.0136\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0520 - accuracy: 0.9833 - f1_m: 0.9764 - val_loss: 0.8300 - val_accuracy: 0.8787 - val_f1_m: 1.0143\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0468 - accuracy: 0.9853 - f1_m: 0.9754 - val_loss: 0.8576 - val_accuracy: 0.8776 - val_f1_m: 1.0201\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0530 - accuracy: 0.9819 - f1_m: 0.9784 - val_loss: 0.9383 - val_accuracy: 0.8756 - val_f1_m: 1.0164\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0541 - accuracy: 0.9830 - f1_m: 0.9764 - val_loss: 0.9025 - val_accuracy: 0.8757 - val_f1_m: 1.0140\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0501 - accuracy: 0.9836 - f1_m: 0.9786 - val_loss: 0.7307 - val_accuracy: 0.8774 - val_f1_m: 1.0326\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0484 - accuracy: 0.9840 - f1_m: 0.9764 - val_loss: 0.8656 - val_accuracy: 0.8791 - val_f1_m: 1.0238\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0557 - accuracy: 0.9822 - f1_m: 0.9779 - val_loss: 0.8469 - val_accuracy: 0.8727 - val_f1_m: 1.0323\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0467 - accuracy: 0.9851 - f1_m: 0.9771 - val_loss: 0.9617 - val_accuracy: 0.8803 - val_f1_m: 1.0068\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0466 - accuracy: 0.9854 - f1_m: 0.9747 - val_loss: 0.8564 - val_accuracy: 0.8782 - val_f1_m: 1.0234\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0653 - accuracy: 0.9800 - f1_m: 0.9806 - val_loss: 0.8515 - val_accuracy: 0.8728 - val_f1_m: 1.0232\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.1282 - accuracy: 0.9559 - f1_m: 1.0677 - val_loss: 0.7652 - val_accuracy: 0.8574 - val_f1_m: 1.0955\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.1260 - accuracy: 0.9570 - f1_m: 1.0662 - val_loss: 0.8057 - val_accuracy: 0.8520 - val_f1_m: 1.0875\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1239 - accuracy: 0.9572 - f1_m: 1.0673 - val_loss: 0.7917 - val_accuracy: 0.8593 - val_f1_m: 1.0879\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1243 - accuracy: 0.9578 - f1_m: 1.0656 - val_loss: 0.7981 - val_accuracy: 0.8591 - val_f1_m: 1.0863\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1231 - accuracy: 0.9572 - f1_m: 1.0642 - val_loss: 0.7909 - val_accuracy: 0.8560 - val_f1_m: 1.0978\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1234 - accuracy: 0.9569 - f1_m: 1.0630 - val_loss: 0.8178 - val_accuracy: 0.8582 - val_f1_m: 1.0848\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1226 - accuracy: 0.9579 - f1_m: 1.0639 - val_loss: 0.7995 - val_accuracy: 0.8577 - val_f1_m: 1.0792\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1234 - accuracy: 0.9579 - f1_m: 1.0633 - val_loss: 0.8265 - val_accuracy: 0.8593 - val_f1_m: 1.0804\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1232 - accuracy: 0.9569 - f1_m: 1.0629 - val_loss: 0.8246 - val_accuracy: 0.8540 - val_f1_m: 1.0845\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1225 - accuracy: 0.9588 - f1_m: 1.0635 - val_loss: 0.8159 - val_accuracy: 0.8550 - val_f1_m: 1.0815\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.1216 - accuracy: 0.9585 - f1_m: 1.0617 - val_loss: 0.8355 - val_accuracy: 0.8558 - val_f1_m: 1.0776\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1212 - accuracy: 0.9585 - f1_m: 1.0625 - val_loss: 0.8207 - val_accuracy: 0.8597 - val_f1_m: 1.0809\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0768 - accuracy: 0.9732 - f1_m: 1.0168 - val_loss: 0.8401 - val_accuracy: 0.8655 - val_f1_m: 1.0381\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0736 - accuracy: 0.9735 - f1_m: 1.0137 - val_loss: 0.8611 - val_accuracy: 0.8621 - val_f1_m: 1.0372\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0735 - accuracy: 0.9750 - f1_m: 1.0132 - val_loss: 0.8653 - val_accuracy: 0.8633 - val_f1_m: 1.0277\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0740 - accuracy: 0.9737 - f1_m: 1.0142 - val_loss: 0.8501 - val_accuracy: 0.8678 - val_f1_m: 1.0313\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0701 - accuracy: 0.9751 - f1_m: 1.0119 - val_loss: 0.8797 - val_accuracy: 0.8679 - val_f1_m: 1.0231\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0734 - accuracy: 0.9750 - f1_m: 1.0126 - val_loss: 0.8729 - val_accuracy: 0.8664 - val_f1_m: 1.0285\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0732 - accuracy: 0.9743 - f1_m: 1.0127 - val_loss: 0.8918 - val_accuracy: 0.8673 - val_f1_m: 1.0236\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0699 - accuracy: 0.9759 - f1_m: 1.0113 - val_loss: 0.8689 - val_accuracy: 0.8681 - val_f1_m: 1.0326\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0740 - accuracy: 0.9745 - f1_m: 1.0122 - val_loss: 0.8953 - val_accuracy: 0.8633 - val_f1_m: 1.0326\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0685 - accuracy: 0.9758 - f1_m: 1.0096 - val_loss: 0.8787 - val_accuracy: 0.8657 - val_f1_m: 1.0287\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0742 - accuracy: 0.9744 - f1_m: 1.0097 - val_loss: 0.8873 - val_accuracy: 0.8699 - val_f1_m: 1.0268\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0700 - accuracy: 0.9756 - f1_m: 1.0100 - val_loss: 0.8989 - val_accuracy: 0.8652 - val_f1_m: 1.0363\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0678 - accuracy: 0.9763 - f1_m: 0.9959 - val_loss: 0.9895 - val_accuracy: 0.8618 - val_f1_m: 1.0265\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0609 - accuracy: 0.9787 - f1_m: 0.9923 - val_loss: 0.9790 - val_accuracy: 0.8594 - val_f1_m: 1.0262\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0618 - accuracy: 0.9782 - f1_m: 0.9922 - val_loss: 0.9922 - val_accuracy: 0.8650 - val_f1_m: 1.0221\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0661 - accuracy: 0.9770 - f1_m: 0.9943 - val_loss: 1.0178 - val_accuracy: 0.8668 - val_f1_m: 1.0339\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0624 - accuracy: 0.9779 - f1_m: 0.9946 - val_loss: 0.9836 - val_accuracy: 0.8657 - val_f1_m: 1.0196\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0615 - accuracy: 0.9786 - f1_m: 0.9928 - val_loss: 1.0250 - val_accuracy: 0.8639 - val_f1_m: 1.0211\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0604 - accuracy: 0.9785 - f1_m: 0.9899 - val_loss: 1.0279 - val_accuracy: 0.8653 - val_f1_m: 1.0234\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0650 - accuracy: 0.9768 - f1_m: 0.9947 - val_loss: 1.0350 - val_accuracy: 0.8592 - val_f1_m: 1.0278\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0575 - accuracy: 0.9791 - f1_m: 0.9901 - val_loss: 1.0363 - val_accuracy: 0.8628 - val_f1_m: 1.0244\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0597 - accuracy: 0.9794 - f1_m: 0.9909 - val_loss: 1.0076 - val_accuracy: 0.8679 - val_f1_m: 1.0219\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0651 - accuracy: 0.9777 - f1_m: 0.9908 - val_loss: 1.0139 - val_accuracy: 0.8582 - val_f1_m: 1.0349\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0605 - accuracy: 0.9786 - f1_m: 0.9920 - val_loss: 1.0419 - val_accuracy: 0.8686 - val_f1_m: 1.0191\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.1113 - accuracy: 0.9588 - f1_m: 1.0355 - val_loss: 0.5111 - val_accuracy: 0.8830 - val_f1_m: 1.0710\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1078 - accuracy: 0.9603 - f1_m: 1.0382 - val_loss: 0.5313 - val_accuracy: 0.8767 - val_f1_m: 1.0724\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1078 - accuracy: 0.9604 - f1_m: 1.0379 - val_loss: 0.4955 - val_accuracy: 0.8823 - val_f1_m: 1.0770\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1068 - accuracy: 0.9606 - f1_m: 1.0340 - val_loss: 0.4931 - val_accuracy: 0.8831 - val_f1_m: 1.0714\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1046 - accuracy: 0.9614 - f1_m: 1.0350 - val_loss: 0.4942 - val_accuracy: 0.8847 - val_f1_m: 1.0735\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1045 - accuracy: 0.9622 - f1_m: 1.0318 - val_loss: 0.4775 - val_accuracy: 0.8775 - val_f1_m: 1.0950\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1055 - accuracy: 0.9619 - f1_m: 1.0343 - val_loss: 0.5940 - val_accuracy: 0.8796 - val_f1_m: 1.0590\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.1053 - accuracy: 0.9628 - f1_m: 1.0343 - val_loss: 0.5177 - val_accuracy: 0.8859 - val_f1_m: 1.0582\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1070 - accuracy: 0.9613 - f1_m: 1.0359 - val_loss: 0.5289 - val_accuracy: 0.8836 - val_f1_m: 1.0571\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1073 - accuracy: 0.9621 - f1_m: 1.0344 - val_loss: 0.5502 - val_accuracy: 0.8813 - val_f1_m: 1.0556\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 7s 144us/sample - loss: 0.1058 - accuracy: 0.9611 - f1_m: 1.0347 - val_loss: 0.5230 - val_accuracy: 0.8803 - val_f1_m: 1.0746\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.1021 - accuracy: 0.9628 - f1_m: 1.0319 - val_loss: 0.5160 - val_accuracy: 0.8818 - val_f1_m: 1.0629\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0072 - accuracy: 0.9974 - f1_m: 0.9526 - val_loss: 1.4820 - val_accuracy: 0.8720 - val_f1_m: 0.9902\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9506 - val_loss: 1.5236 - val_accuracy: 0.8781 - val_f1_m: 0.9863\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0061 - accuracy: 0.9982 - f1_m: 0.9513 - val_loss: 1.4990 - val_accuracy: 0.8740 - val_f1_m: 0.9861\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9496 - val_loss: 1.5358 - val_accuracy: 0.8794 - val_f1_m: 0.9859\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0076 - accuracy: 0.9976 - f1_m: 0.9515 - val_loss: 1.5642 - val_accuracy: 0.8772 - val_f1_m: 0.9783\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0045 - accuracy: 0.9988 - f1_m: 0.9502 - val_loss: 1.6117 - val_accuracy: 0.8749 - val_f1_m: 0.9868\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0060 - accuracy: 0.9981 - f1_m: 0.9514 - val_loss: 1.5910 - val_accuracy: 0.8798 - val_f1_m: 0.9849\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0068 - accuracy: 0.9978 - f1_m: 0.9515 - val_loss: 1.5493 - val_accuracy: 0.8824 - val_f1_m: 0.9818\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0056 - accuracy: 0.9983 - f1_m: 0.9509 - val_loss: 1.5324 - val_accuracy: 0.8799 - val_f1_m: 0.9876\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9486 - val_loss: 1.5512 - val_accuracy: 0.8819 - val_f1_m: 0.9800\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0079 - accuracy: 0.9976 - f1_m: 0.9513 - val_loss: 1.5613 - val_accuracy: 0.8810 - val_f1_m: 0.9842\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9504 - val_loss: 1.5253 - val_accuracy: 0.8818 - val_f1_m: 0.9828\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0081 - accuracy: 0.9978 - f1_m: 0.9499 - val_loss: 1.6600 - val_accuracy: 0.8906 - val_f1_m: 0.9732\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0070 - accuracy: 0.9979 - f1_m: 0.9508 - val_loss: 1.7181 - val_accuracy: 0.8875 - val_f1_m: 0.9691\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0107 - accuracy: 0.9971 - f1_m: 0.9508 - val_loss: 1.6794 - val_accuracy: 0.8917 - val_f1_m: 0.9746\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0082 - accuracy: 0.9976 - f1_m: 0.9501 - val_loss: 1.6667 - val_accuracy: 0.8933 - val_f1_m: 0.9742\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0053 - accuracy: 0.9983 - f1_m: 0.9496 - val_loss: 1.6847 - val_accuracy: 0.8941 - val_f1_m: 0.9739\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0086 - accuracy: 0.9975 - f1_m: 0.9502 - val_loss: 1.8312 - val_accuracy: 0.8875 - val_f1_m: 0.9700\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0064 - accuracy: 0.9980 - f1_m: 0.9503 - val_loss: 1.6807 - val_accuracy: 0.8902 - val_f1_m: 0.9733\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0101 - accuracy: 0.9971 - f1_m: 0.9507 - val_loss: 1.7129 - val_accuracy: 0.8903 - val_f1_m: 0.9741\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0094 - accuracy: 0.9975 - f1_m: 0.9503 - val_loss: 1.6713 - val_accuracy: 0.8936 - val_f1_m: 0.9757\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9499 - val_loss: 1.7302 - val_accuracy: 0.8852 - val_f1_m: 0.9715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0087 - accuracy: 0.9977 - f1_m: 0.9500 - val_loss: 1.7670 - val_accuracy: 0.8918 - val_f1_m: 0.9745\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0088 - accuracy: 0.9978 - f1_m: 0.9504 - val_loss: 1.8491 - val_accuracy: 0.8876 - val_f1_m: 0.9730\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0220 - accuracy: 0.9945 - f1_m: 0.9532 - val_loss: 1.7269 - val_accuracy: 0.8868 - val_f1_m: 0.9783\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0232 - accuracy: 0.9942 - f1_m: 0.9537 - val_loss: 1.6606 - val_accuracy: 0.8887 - val_f1_m: 0.9747\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0175 - accuracy: 0.9952 - f1_m: 0.9528 - val_loss: 1.6466 - val_accuracy: 0.8904 - val_f1_m: 0.9791\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0184 - accuracy: 0.9955 - f1_m: 0.9528 - val_loss: 1.5802 - val_accuracy: 0.8888 - val_f1_m: 0.9781\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0229 - accuracy: 0.9941 - f1_m: 0.9539 - val_loss: 1.7087 - val_accuracy: 0.8882 - val_f1_m: 0.9709\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0118 - accuracy: 0.9967 - f1_m: 0.9516 - val_loss: 1.8866 - val_accuracy: 0.8925 - val_f1_m: 0.9686\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0222 - accuracy: 0.9944 - f1_m: 0.9539 - val_loss: 1.7325 - val_accuracy: 0.8861 - val_f1_m: 0.9776\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0226 - accuracy: 0.9947 - f1_m: 0.9534 - val_loss: 1.8182 - val_accuracy: 0.8906 - val_f1_m: 0.9767\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0205 - accuracy: 0.9951 - f1_m: 0.9531 - val_loss: 1.8637 - val_accuracy: 0.8863 - val_f1_m: 0.9768\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0249 - accuracy: 0.9943 - f1_m: 0.9529 - val_loss: 1.8163 - val_accuracy: 0.8874 - val_f1_m: 0.9779\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0236 - accuracy: 0.9941 - f1_m: 0.9531 - val_loss: 1.8053 - val_accuracy: 0.8896 - val_f1_m: 0.9781\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0221 - accuracy: 0.9946 - f1_m: 0.9523 - val_loss: 1.8830 - val_accuracy: 0.8962 - val_f1_m: 0.9707\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 8s 177us/sample - loss: 0.0526 - accuracy: 0.9825 - f1_m: 0.9779 - val_loss: 0.8653 - val_accuracy: 0.8762 - val_f1_m: 1.0151\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0536 - accuracy: 0.9824 - f1_m: 0.9766 - val_loss: 0.8643 - val_accuracy: 0.8851 - val_f1_m: 1.0186\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0494 - accuracy: 0.9841 - f1_m: 0.9771 - val_loss: 0.9048 - val_accuracy: 0.8796 - val_f1_m: 1.0155\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0468 - accuracy: 0.9847 - f1_m: 0.9729 - val_loss: 0.8924 - val_accuracy: 0.8746 - val_f1_m: 1.0209\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0558 - accuracy: 0.9823 - f1_m: 0.9771 - val_loss: 0.8112 - val_accuracy: 0.8753 - val_f1_m: 1.0210\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0485 - accuracy: 0.9843 - f1_m: 0.9775 - val_loss: 0.8921 - val_accuracy: 0.8819 - val_f1_m: 1.0118\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0485 - accuracy: 0.9849 - f1_m: 0.9741 - val_loss: 1.0107 - val_accuracy: 0.8731 - val_f1_m: 1.0177\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0467 - accuracy: 0.9837 - f1_m: 0.9757 - val_loss: 0.9728 - val_accuracy: 0.8814 - val_f1_m: 1.0096\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0518 - accuracy: 0.9832 - f1_m: 0.9763 - val_loss: 0.9134 - val_accuracy: 0.8767 - val_f1_m: 1.0182\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0505 - accuracy: 0.9835 - f1_m: 0.9757 - val_loss: 0.8856 - val_accuracy: 0.8748 - val_f1_m: 1.0216\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0447 - accuracy: 0.9852 - f1_m: 0.9748 - val_loss: 0.8968 - val_accuracy: 0.8718 - val_f1_m: 1.0214\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0445 - accuracy: 0.9847 - f1_m: 0.9729 - val_loss: 0.9104 - val_accuracy: 0.8696 - val_f1_m: 1.0171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN 1 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.446459</td>\n",
       "      <td>0.915187</td>\n",
       "      <td>1.050566</td>\n",
       "      <td>0.901519</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>1.075829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN 2 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.401480</td>\n",
       "      <td>0.916083</td>\n",
       "      <td>1.057271</td>\n",
       "      <td>0.689809</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>1.099597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN 5 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.321478</td>\n",
       "      <td>0.915937</td>\n",
       "      <td>1.101213</td>\n",
       "      <td>0.493196</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>1.175676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>0.915688</td>\n",
       "      <td>1.133611</td>\n",
       "      <td>0.404555</td>\n",
       "      <td>0.8633</td>\n",
       "      <td>1.192783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363455</td>\n",
       "      <td>0.935021</td>\n",
       "      <td>1.018314</td>\n",
       "      <td>0.680653</td>\n",
       "      <td>0.8629</td>\n",
       "      <td>1.080836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.102068</td>\n",
       "      <td>0.962771</td>\n",
       "      <td>1.031878</td>\n",
       "      <td>0.515951</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>1.062896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.998708</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>1.525287</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.982822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CNN 2 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>0.997771</td>\n",
       "      <td>0.950433</td>\n",
       "      <td>1.849088</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.973010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CNN 5 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.022113</td>\n",
       "      <td>0.994604</td>\n",
       "      <td>0.952280</td>\n",
       "      <td>1.882990</td>\n",
       "      <td>0.8962</td>\n",
       "      <td>0.970679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CNN 10 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.044450</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>0.972941</td>\n",
       "      <td>0.910362</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>1.017146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  train_samples  test_samples  epochs      loss  accuracy  \\\n",
       "0    CNN 1 S          48000         12000       1  0.446459  0.915187   \n",
       "1    CNN 2 S          48000         12000       1  0.401480  0.916083   \n",
       "2    CNN 5 S          48000         12000       1  0.321478  0.915937   \n",
       "3   CNN 10 S          48000         12000       1  0.264992  0.915688   \n",
       "4    CNN 1 L          48000         12000       1  0.363455  0.935021   \n",
       "..       ...            ...           ...     ...       ...       ...   \n",
       "91  CNN 10 S          48000         12000      12  0.102068  0.962771   \n",
       "92   CNN 1 L          48000         12000      12  0.003873  0.998708   \n",
       "93   CNN 2 L          48000         12000      12  0.008804  0.997771   \n",
       "94   CNN 5 L          48000         12000      12  0.022113  0.994604   \n",
       "95  CNN 10 L          48000         12000      12  0.044450  0.984729   \n",
       "\n",
       "          f1  val_loss  val_accuracy    val_f1  \n",
       "0   1.050566  0.901519        0.8469  1.075829  \n",
       "1   1.057271  0.689809        0.8521  1.099597  \n",
       "2   1.101213  0.493196        0.8554  1.175676  \n",
       "3   1.133611  0.404555        0.8633  1.192783  \n",
       "4   1.018314  0.680653        0.8629  1.080836  \n",
       "..       ...       ...           ...       ...  \n",
       "91  1.031878  0.515951        0.8818  1.062896  \n",
       "92  0.950355  1.525287        0.8818  0.982822  \n",
       "93  0.950433  1.849088        0.8876  0.973010  \n",
       "94  0.952280  1.882990        0.8962  0.970679  \n",
       "95  0.972941  0.910362        0.8696  1.017146  \n",
       "\n",
       "[96 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_3b_cnn():\n",
    "    total_samples = 60000\n",
    "    epochses = range(1, 13)\n",
    "    ratio = 0.8\n",
    "    \n",
    "#     total_samples = 2000\n",
    "#     epochses = [1, 2]\n",
    "#     ratio = 0.8\n",
    "    \n",
    "    train_samples, test_samples = calc_train_test_samples(total_samples, ratio)\n",
    "    \n",
    "    for epochs in epochses:        \n",
    "        for name, layers in cnns.items():   \n",
    "            loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm = evaluate_cnn(layers, train_samples, test_samples, epochs)\n",
    "            \n",
    "            yield name, train_samples, test_samples, epochs, loss, accuracy, f1, val_loss, val_accuracy, val_f1\n",
    "            \n",
    "            codename = name.lower().replace(' ', '_')            \n",
    "            roc.savefig(f'plots/3b/{codename}_e{epochs}_roc.svg')\n",
    "            pr.savefig(f'plots/3b/{codename}_e{epochs}_pr.svg')\n",
    "            cm.savefig(f'plots/3b/{codename}_e{epochs}_cm.svg')            \n",
    "            plt.close('all')\n",
    "            \n",
    "results_3b_cnn = pd.DataFrame(gen_3b_cnn(), columns=[    \n",
    "    'model',\n",
    "    'train_samples', 'test_samples', 'epochs',\n",
    "    'loss', 'accuracy', 'f1', 'val_loss', 'val_accuracy', 'val_f1'\n",
    "])\n",
    "results_3b_cnn.to_csv('results/3b_cnn.csv')\n",
    "results_3b_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1c5eace0388>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAFgCAYAAADn4k1jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAADEUUlEQVR4nOz9d5Rl133fC372PunmUDl3bqATMkgQBDMIkZQpURRlSZ5le2w/jS1btsdv7LdsL4+91sia0XhpnmZpNJL9ZD3Jz3ojSpREiko0CDGZAAEipwbQubuqK9fN4aS99/xxbqXuAtCkgGY6n7VqVdWtE/Y599b+nl/Yv58wxhhSUlJSUlK+y5Hf6QGkpKSkpKTcCKlgpaSkpKR8T5AKVkpKSkrK9wSpYKWkpKSkfE+QClZKSkpKyvcE9nd6AG8ni4uL1702NDRErVb7DowmHUc6jnQc38/jmJqausmj+cHjB87CkvK745LTcewmHcdu0nHsJh1HCvwAClZKSkpKyvcmqWClpKSkpHxPkApWSkpKSsr3BKlgpaSkpKR8T5AKVkpKSkrK9wSpYKWkpKSkfE+QClZKSkpKyvcEqWClpKSkpHxPkApWSkpKSsr3BKlgpaSkpKR8T5AKVkpKSkrK9wSpYKWkpKSkfE+QClZKSkpKyvcEqWClpKSkpHxPcNP6YT333HP81m/9FlprPvShD/GJT3xi1987nQ6//uu/zsrKCo7j8LM/+7PMzc3d0L4pKSkpKd//3BQLS2vNb/7mb/Kv//W/5pd/+Zd59NFHWVhY2LXNZz/7Wfbv388v/dIv8XM/93P89m//9g3vm5KSkpLy/c9NEaxz584xMTHB+Pg4tm1z//338+STT+7aZmFhgVOnTgEwPT3N2toajUbjhvZNSUlJSfn+56a4BGu1GsPDw1u/Dw8Pc/bs2V3b7Nu3jyeeeIJbb72Vc+fOsba2Rq1Wu6F9N3nkkUd45JFHAPjFX/xFRkZGrtvGtu09X7/ZpONIx5GOIx1HyrfGTREsY8x1rwkhdv3+iU98gt/+7d/mX/yLf8Hc3BwHDhxASnlD+27y4IMP8uCDD279vr6+ft02IyMje75+s0nHkY4jHcf3zziUMcxOT38HRvSDxU0RrOHhYTY2NrZ+39jYoFqt7toml8vxD//hPwQSgfu5n/s5xsbGCMPwTfdNSUlJudloY/CVpqcUodbMfqcH9APATYlhHTp0iKWlJVZXV4njmMcee4x77rln1zbdbpc4jgH4y7/8S44dO0Yul7uhfVNSUlJuBsYYfKWohxErfkgjigi1/k4P6weGm2JhWZbF3/27f5df+IVfQGvNBz7wAWZnZ3n44YcBeOihh7h69Sq/+qu/ipSSmZkZ/sE/+AdvuG9KSkrKzSJQmr5SBL0+tTDaet0YiDSEeu8wRcpby01bh3XXXXdx11137XrtoYce2vr56NGj/Mqv/MoN75uSkpLydhJqTX8gVHoQS/eMQRsIFQRaECrB9VH2lLeLmyZYKSkpKd/tRDtESu1I+HqpZvOXiy6NSFO0ctw3HnG4pJI/aiBOLaybQSpYKSkpP9BEWuMPRCreIVLaQKDgxZrDn1/xsIQh60A3EnzxioecDDmY1ZC6A28aqWClpKT8wBFrQ18p+koTm+2kCTUQqVCJrbjU15cdLGFwJLgKslpgYnhpyeHg/jDZMfUL3hRSwUpJSfmBQJltkYoGmX07kyYCBcpcYy0Z6PqSkgBHgS0ESoOR0I4khBEYg4jVd+CKfvBIBSslJeX7lmvXSgHEGkKdWFGRfp2kCUUSl4oFk8LQjwVCAsKAMSgNJUsjovgmXk1KKlgpKSnfdwQDkfKVRhmTWFFKEGjQ11pRm2ggSkSKzW204Y5KyNfXPFAGiSbWiSV2R7F7064nJSEVrJSUlO8LNl1+vVjhK0OgBKGGWMvXDzFtZvjFIkmeMIBWEGuEUmAM+xwQlYjn2jk6SlCwDHcUu8zlEuuqrxUX4z4fvUnX+YNMKlgpKSnfs2hjCLSmFyvakR6sjQJl3qCIz7UipQyoGLRJRGoP5nIxc7kW+VyOdrfLgvL5cr/HuTBgKXIRusj/5e25xJQdpIKVkpLyPcVmXKqv9ECkksw+/UYiZdgWqViAUqDUlhX1ZtRUxLmox5lOkyt9idJ5hBlBmAzWYJvw1z6N+w9/6i25xpS9SQUrJSXlux5lDN04cfe1Y0Ooksy+141HQSJSCoglBLypFbUT3yheC3xeDuBqaOPrPEKPIgbytFMaJYbJoI1udf4ql5hyA6SClZKS8l2JGhSabUea9UaP1U48yOp7k4W6iiR5IgQihVDRm1pRShteCWNe9gVXI5ueKiDM2NbfdwqUJ2Km3ZgDrmKf7HPixRcY6jcRVefbvtaUGyMVrJSUlO8alDH0Y0Ur0nRis7U2quyYNy4wG5O4+gKTJEzEb5xuHmp4LRCcDmAxdOipLDunw+0zGQpWwKwTc8TVnLIDxlfnqazWKNVr5Dvt7W2r49/2dafcGKlgpaSkfEdRxtCLNY1Q0YnNjoKyN+DuC4FAg3p9V58x0FCSi6HkNV+yFDn0tfc6x4/JWT4HvZiTdsyp3gajjQ3K9RqlRg0n2q7UrpF0rDGaziR1Z5rbePrbvQUpN0gqWCkpKTcdYwztWNMINe0oWSeV8CYiFYmkNIVvXjdhIjKwHNnMhzbnAsly5BCZ66c6g0GIPhYhWQP7wpjb2hsc6qxxW7BMtdPcNZpYuNSdOeruNA1vhj7DmK2UCzDh49/WvUi5cVLBSklJuSkYA+1I04wUzdAQ30D9vXMNi2eWHYLAUJZZ7iz0mMtFu7ZpKclCaHM1srkUWKzFzp5xLoMC0SFn9TnsRtwfdcgs9Jhrr3Owt0YxDnZt78sCLXuSWnYfLWuCkBJ7Cap2ImK7hcwWvqX7kfKtkwpWSkrK24Y20Io0rcjQDBXqRorExkCouVyz+OZqUiW9YGn6MXytnud43Ce2BAuhzUJo09bWnocxoo8RHaTsUtZdTnWbvLPW4NZ2m339LnKHdWYQdKwR1t0ZVr05+nIMC2+vo2LooGkQVCP8aoiyYuphhn8+8VH27uiX8laRClZKSspbSqigG2uakaEd6V19pV5/J50kTIQaMTC9XqjlMMLQF4KGFvSEhQ9c7l5vySTWUxcjOzh0OWJ87g677F9a4856k8o11pPCpmGPs5g5QM2dRlNF7nDvbf0kNcI0MdpH6iyWkWjRp28vIPoNvLFx1sMcZ7vDbPQ1KW8vqWClpKT8ldjsG9WJEpHqqxsQKWUgirlQ93mu0aMTa4rS4mCmiBI5FiKHV5VNLK5xwQ1+NQQY2cbIDkK0ORBE3NWKeGd9g9vrKzjsFo9Q5Fh3p1nwDtC1J7ApIHa49zbT1ntSU3MV5UKPcqmDyvg4L64j9K0gFBAhjUMhPI5SLxDZcLE5xJgvOXk27Yv1dpMKVkpKyrdMrMFX0B5YUYF+E5EyQKwgMIhQQSQ40wt5pOESmFFCLK4KwSvRjkl/S5z0lvW0KVJjOuKujs+7lhrc26iR03rXqXqyynp+H5ftfURyBNdktv7ubG1nELmITjbmgjGsCY1rx5wsdai4fWIiYiJc5oAYgUYIwChAI81hpLdGtpvhjqZLM5MK1ttNKlgpKd9FPFNv8rmra6xHrzLi2HxiepS7quXv+Dh+dGqUE+UywUCkurEi1OaNRUoNaiZFBgLDemhzNXJYCLNcjWzWYzsRpetaUIW7xAnRJaMNJ9o+792o8Y5Gm8lgZ3q5Rd2eYT1ziKY9RSDLW9l7AnAHQ4wxrLgxi25M3TN86sA6jjGMKJg2iehqE6FMjCbEluBJgZQF0P3B2cTWWZEFsGvc0rHRGKI3qAyV8taQClZKyncJz9Sb/MaFq9hCUHId6mHEb1y4ys8c5KaK1uY4LCR5x2Xd1/zHs2t8fBr253Po1xMppZMafZEh7BqebcMLPUlLZYjIoNkrOcJgRG9LnIxogwiRGI51A+6rNbmn0eGWTn9r70h4LOVvYSO3jy7jRKrIXtl7wlEsupp5R7HgRiw7MRkDZS2ZEIZsDBpDiCKSEcgYIwxSCqRwQSTrwXROI/seqDAx3wRge+isRuuQQgxBalzdFFLBSkn5LuFzV9ewhSBjScTgu680n7u6dlMEazMW9QdX6qA9pBREyhrEdzRfWa3zt/Znt7Y/2+ryjVqdWhBTIcucNUSocyyENmuxtWdquUWMsDoEoo2RbRBdEIk7b7ofcG+jwz2NDne2uuSVxgBdu8rC0Elq7hR9M4yOBmO4dp2wMAhbYY91cSe7yGyM1fM4t5onr+GYlphBL6t3jAeEGY1vQi71fE63Yrox5G04XrKZye4Q15k65vwYWBbCAR0lLYfj8Uvo2Cdw+9iRx7azMeXtIhWslJTvElaDkIK126/kScFqEL5t54wGsahgUEw21poVPyYjxVYKugEcKahHEcQxUah5qqb4RgOMniHSWRaxWbzu6AYLHyM7RLKFkW1iEWwZQ/lYcXczEah7Gx0mgwiNZMmbYWHoTtr2BP24glADIdh5G4TBKoRY5YDVTJtHqbEqAoYsm/eXC5zI57CNy0ReMDkc8Y0Ni4aSFF3NrZUWhWyHjlYs9BVXFjLc3RohH3l0nYDXSusw4zOTtTAYdLkB+3ys5RFEmMU4IWpiGV1tA5pcfoXZS0P0snun16e8daSClZLyXcKY57LUyeCHYyjtYcmAjLvKZMF/y86xaUU9WWvz50s1NoKYIcfmPWMV9uVyKGMoOza1vkcUjxArF0tESNnFlRa/dabASmij93LBoXBEj5LTZ81soGSXWGybQdIYjrd7WwJ1S6dPLDKczx3i5fw+niuNklV5bERiPaltR18oY1azHZYzHQ6OGg4MCxzbcD4I+ZPVDewwphJrlLD4WldTnchyuJgBG2bLEeV8m17so0wS+9pM0VhdynBnbQqDJpIx2djmztoUr8irjO9rgYlAaMxwm3hkjWwhg2r0qKxmGHquQHUxhxNagM8zB9KFw283qWClpHyXcKowzZm1LEIYpFDE2qHdn+Ghif6b7/w6GJNYUZs9o0ItON1s8/sXF7HCiIzWNKTks32fj0yPczCTYZgxFoLNuJAkNi6oPKGCnQ00HAJs08GIDspq0rf7RAJ6O7aZ6gfcO7Ci7mx26VslOuUjNCvTPFUcIgoyCAQZILPDxScyMZfdFlczLeq5Hr1MhEYTGs2S5XDP0AzCtvj66fPkezGlGFxtIwxEIuKxpTWmsg6tuEu0toq1sILdD7CzHvHMKKpaAmCuPoIRmliaJF6FQmrDdGMYc8vVrfF4HZuhqzlGl4vkl0aQ17Q16ZYD/sY/Tovfvt2kgpWSchNxLl4l883TyGYHXS7gv+M40YFpAE7XilRdQ1dFxMbgSMhbNqdrRdj/xtXHd/L06Yt8brnOqrAYNoIHR4e49dAsShsCHfMXV5aIfI8u+4nxkFohfZ8/vuChyKH26DEljCEnDIdzHbRpMe+vUHci+nL3tvlYcdemQDV69KxprmaOU7fGeaxaIqetxHoaqFqyt0EWQuxygF0O8aohTk7wW5cXyUuJtCxsy0YpRcZI6kohpI3wDbIWU4pLdMQoGhcpQrKsseF3WfHXsOot7HMLIE0SYgo7OOebmFtniIZy5JVDIOJE2Y0BIVBCU4pdimseQ1dzDF3Nk2u5u65TS0NzrE9tukd9ukeQj/kwd934ByHl2yIVrJSUt4jNVPDVIGTMc69LSXcuXiX3yJMYS2IyLqLbJ/fIk/QehOjANKu+4Fbf4uR6lmIkaTual0Yizojdi2A/c6nPn83b+LGDZ0V8dCbmr81mCTU8f2aeT691cHDIG2gCn16r88NKMzs7wWoXlrpjxAyzaUEl3rcc7Ej+c7QmqxWejsiaNbDWWM7EPL3Z4sMDEEhjONbuc0+zw20NRVmNEoyc5ArjnC9kcYzEA7ydCRKWxiom4uQMRWSqGjcjcRyJbXubB2fU82j1fTKdPkZrbCExtschO4PVTu5JLsyybk0h0GhiImHRFZMUuQiZGHvxIsIKwJZJPMqK0SZCXzmHqhxCOl1kmEVLhWVguBcx2lOM9kOcK9O77nvoKdpzIavjTZoTfZRjiI3hbNznpV6XD//VP0Ipb0IqWCkpbwE7U9ILltwzJT3zzdMYS4Iz+LdzbAwxmW+eJjowzalAcsdVB20MgYjI+pJ3XnXwZrfXHP3+xT7PvVzkJ1ou1VhStzWPtkJ6cZePzGT44loDm+QfO8QiooBPgT+o5dH1PJGRQHH34I3BNgZPxzxU7TC/tEZoNVjKxCwVdk4RiVhN+iH3NjqcamYYCafwrRNEskzPceg7Ajq7z9CTig0nYt0JuZqz+Tt39fA8iWPZSLFXvb6EhyzJ7/VDRAxFbSOUIBYx76tKhDQICYGs0pEKLTQIBm49SU6PYqwN8LtETGF6J8EUkrR55wWEugJAKX6BUus2Sn5MxY+5dilVtxxSm+7yyojPl+2YtpbkrJhq2GM5avNK1CPgDdaipbylpIKV8rby7Lrg81csVn3BWMbwI3OKO0du/j/4cy/b1F/2yAaSvqepngi448SNu9nejM9dXeNAq8Jd61MUA4+2F/DMyOKulHTZ7PDN8gx/UDzKsp1nIu7yqfYZ3tFcAOCBDUPDGJQ0SASRMFga3r1uaIVJub2XX83xsVoGjaEvDMVY8LFahv92XnGupJhnBEGBiDyK7O5BDm67NAbbKBytGAs7zAWLaKvJSkbxucAlGtmctpPpIRcrbm/2ub3lcigzg2SMfqMCwqI7SOCTO04i8xEXdMyio2g5AX2ZVIiIkJTpUcrn3/yGRoZ7X16gpOFL5RxrNlRFzA83mhxvLrF0yKMRd6lnJsmFPl1poxBYGAo6ILBzRMF5pDWF6L1zkDofIHSWfPudlONJSn9eIt/0gO2kFg10sm0aucus3l8iKMRc6Uu+Vhf06NHyOjRkBx1vW70C2G9lrr2ClLeBVLBS3jaeXRf85hkbR0LBhkaY/P73iL8l0Wov2Gy86BK1JU5RM3wqpDhz42Lz3Ms2/WeyuMIQSoMbCvrPZHmO/rckWi+8XOPz8w4rIsO48fmR2YjbTgwBkFnL8p6Fg0TGoi3A7du8Z+EgX+b81v5PjBzg1/IncNAUdUjNyvD/rdyBcRxuBTJtzZDpUhNZYiGxjaakfdyORSdOrJt31HMoDD1Ls+rCsmNYc2HJcfnV0wD7dw/aGBz6FHWf91dtbvXXWV2o0TMd5nOK58pZzg7ZJAGeRH2kMdzajrmzMcSMP0FeDSNwEUIQbNaQ3QpdJZ0UBRECg8wbxj4cof/sBb5ROoltBC6JtRcLwUdrZ4A7dw1RWIm1JLRBxhoZJSu4sq06+90pPr56kJA8Fh0c+xXOy8t0oyYARU/RxaUS+aA1SEHkeBTczRz4u5BaUQpDyn1D2Q9xNMDo1vkjGdIsrNEsrNLMr6NFiHFcuvkMr0V9/lu/Tz3XQYsdn1kDJZPhjkwPT1xkIziH/0sPkfnn19z/lLeUVLBS3jY+f8XCkeANlqdsfv/8FYs7R25MKNoLNsvfyCCkQbqGuCdY/kYG3uVvidabWXH1lz1sDKFIMsGESMr11F/24MTuY2yEHYZd+7pjvPByjf+8UMRBUTQRdRz+80KG/4Eat50Y4h0rc4TGIpIgMIRCYLTFO1bm2Fzh+vsTp3CaERkUCIGnYzQW/7/xU/yfA5Cmg0WOcdVDCIExBm0sLDqs9DOcb8HpgmbR09Rs9ux16BEjTJes6jERtTjWWeVAv4lja15rWvzXcoGLcxkgt2u/2Z7FPZ0KtzBEvjGC0M72CXaW93MUVjUC1xAsOfS0IZTgGZu8BWN3RGQti9vsHrJ+mv9WOsialWVE9flI+xy32S26nkFYBimTuF72m68hGz66UCC47TDxTJJtV8/NcTW8FYPCSJ8Ql358F+Q0UdQHE3OyvMBja/vAy2IJjTISZQT3eUtMnC0xsqAp+gHymuejvmOxcXiDemmNYP1MUp5dSkKjeSUreXYyw2utK4SY7dLtBorGJm/qePIVlH2WC2rgrrXANHf36Up560kFK+VtY9UXFK75hLkyeX2TN6udt/Gim4jV4DjCBh0bNl50Kc7EPLsu+F9PC1y/RzmOaNkO/2snw989zpbgZHxJd5C4IEhsggBD3k8cWTuPUVQRLev6Y3x+3iGWhoYtiYWFbQwFZfj8vMNtJ6AYZGgPxCo5jyESgmKQAboALJsMIidYVYqYZB4sWjY94+KrmFz2Cs3+cXxgyTVc8mzmPcl8Jkfv+cENKOxwRRmoxjAVCGaDgJOTixxsLqOW1umpPmeKLk9WCnx2ephI7ojOGJj0M9zTHGJfb5ShqIhrXm/Rq0KgwAEjLUZ+qIUnBedaNo9FkhNNm3ws6DqGb5ZjHvA0x6UhvvMgd/33Z7g7nEdYAqkihNL0HrwX29MQgPvaEuHXVjlvvYPQKuD2O4w9dhbrXYruZJFV7wi5Zp/xboSrDIElWCnYNHOnMOoVAGbzTe7nMi/Wx6nWHe5q9bmzEVJtVQfj31531claNAo2zayHn1eEd9QAi6g6xdmNdV7IGF7JO0RSsLlKWQJ5rcmwhCufR9irg7uy9S4w15njxMZJhJcWE3y7SQUr5dvmzSybsYyhEYotywqSOMxYJtnmRmrnRW1JYMU0+jGRMThCUHFsvHby0f2TMzFud2C1SEFGRdDV/MkZhztHkhM3nJhcJInNppiAbQQNJ77uGELKPY9xRWZp2wZJ8qUE1G1BHCdxoqalySuJb22Xm8toaFiadR8iLXCsmOVQImUyESpgQwlGnZin1yWXD+zjQt1n0c2hd7XVSK41IzWznTbjYZlpP+Rod5mZcJnhaIVY1Hmml+f3ywWeOlyh7m67vKQRzPTy3NmvciisUm2Vscxek6tBViKMb2EMSFfjODZaG4jBympKg4SRLy9K2gXN1yshShiUhL6GjQ3BHfsN3DpO5N22K4W/f9dx4tFJZE2DAf/JBovWHQgUkpCQDFes2/BefIZ2uU+pcZCZdpgUehfgaMNsK8I4BdYAGQsqy1kOLTp88qqP629a7ckYI1fRGI5pqSFaOQflaNAWGEF39jynww4vRV3OyD7R6Pb9kMCo7JMVFwnNi0hr9zo4oYvY8WFOOWPcIl1mFiKa+Yt73M+Ut5pUsFK+LW4kPvUjc4rfPJN8xFyZiFWkk9fhxmrn+ZmQZkujhMIyBiUEjRjKpcTSWOtCceBiAxJXm1Gsdbfruj05tMAHl/eBhlgYbCOwjODJoQU+yvANHSOyI8DZYUElXWpDO6IT2ZwvtLizWSGrxNY5BHCu0OaUTo6j5SqYMYyxUAg0EpCs+YL/eg6gxM4mt6Oqy3QmYrogOOrXOVxfZfjyFQpBH0HEi8UcD48VeKpS5Hx+bGs/T1kc6ZQ40q1yuDvEcJjD2st/iAE7cc8ZYZBZTfWBDnrdpf1CFmEEEoGOwRhB9ZYQ6RikBVc0ZDJJ7GkTS8Lqjiqw0YFpon1TiMAgfJNUrvC3H2jW/TmQCiNilDBoEhdpFBwmCC8w3u6ihURLEAgUBksZZmtdRr46QXklg6V2C+96vs76VIdozqI14oMEudHFnp8liCSnqxd4buQ8r8kWcX97LBJDRTaxzGs44jxShMSAFCCxGDITuGGF4UAyqRsUeRlhniUCLm6uF67vcYtT3lJSwUp5Xd7IgrqR+NSdI4a/R/y6x7iR2nlfL1zkzsZ+JJJYaBwtkQi+XrjIKaaZCNrUnCwZs+2kCaTNRNAGKgAY5zxfG464o7WfcmTTdGKeK13COFeAYSaCNlfdHB0LYiEG7j6YHhwj1oC7CsEsCoEQGmMkAgnuCq1ohlsP9PjKRZe7OxlKStKyNE8XfE7u6/P8usOltmC9VwXjXGM9JbhCM+VFTHsxB+hxR9hkaOkqpSt1is06Umsu5jz+slrgqfIkz5fyhJYEA5XY4/ZmmQP9Mge7VapRZldzwk1ENsaqxuAY4mUHLJC2ASWQRjByLKLgOjBl8GRA46yD6oOdNwyfCijNbccdh3ID63nH8besZ2Mggu5FSfNll7grcPKaytGI/ITCGIOvOvStEoYeWmw+BjAohZRUofB0RGxspBLYRmNpgzXYMLuYxOC0MFwqz/Pq6AXOjl5mLbeBNoY7S+9gSk7jG80rxQVeOvIaZ+M+MTtFSpMXa9icISvmkSLciteVTJ5JlWUsihn2m9hcBbYrX2wfxMMTk4wvH8IEacfht5tUsFL25M0sqBuJT0EiWq+XYDHmuRSWPe5enaIQZeg4Pk+PLZKb2G5n/oK9TFjtc7K9n0KUpeP0eal4idfsJjDNj4eX+GX3JCu2hRIGywjyCn4mvATcAcBPLtf4/0xLVvPzeMYQCEEkBf/4ag2Ak8zzgn1iYPNoQiHZsCXvjlZY6lUxwHhBsGaWCaJhlHGxRIjnbDBaTITyliMVtGnwhRWPNZlJ4vS2xTP1kR1P3s72hBgbJkOYDgyWc4kfcdepLtUp12tk+0kZiJpj8WS5wFMHJ3myUqDmOggDE0GBu5ol9vXLHOiVKKjrU6rNwG0ZC5OkxyMY/2ADWwgcS6JWFd2zHnFPYuc1laMhxRmFGIhY9ahm6JaIkZER1teb1x1/L+vZxIYfn46QdU130WLjuUH80THEvmDtWYfOiQ3iyjJ+HKHyRxFdhyTOtBlddBCeT/VqDoEhp/R1ZZC0MGzMdalNdfmTzJ/TsOrYgwxHGwdfKL7cm0cpm7Nxb1dRd4Emw1Uy4uJApJIYl2MkY5HDeBgxHkNed9mMPW6f1yYSNsoukC3dSrZ8C8gswhiMU0ak1drfdlLBStmTN7Og3iw+dSN8qlWmuziFRhPImEzs8p7Fg+Rz23W/J/2Qi4U6S/na1mu+EEwM4hXBsRJq6SIwk1SkEz7KXiA4Vtra/l7L4h8v1/j94TJLtsV4bPjRtTaH7SzrPjw+lqHUuULfTKBEBtv4ZMUyL45YfGBwjAfHh3hio8c961nKoUvTtXh82GVmpMKfXjBc6kqu9EYJnR2T6+BW2MIw6UZM1G2mehG3dlfZ5y9TjVaphuvYDK5FCF4s5XhqbJwnK0XO5zO4WjLTL3F7q8y+XolZv4Sn9/i3tTRWJSboSPqRILQSD6dJ/kSmoBjxXOSmdTdlqM72kXYiUMLa9ojeCJvW859flLS7cNDSfHhCcTxrQEPjNScphyQ12iiM0CgjaJ4tEt5+GYNB7l/Cee0gQgmcOKDsS8pBSCmIkOcndp1PS4OyNNrSnLt3ncZMElfaWN3AxSVCsi6LrMkSNZHHCAlxIvwChccCOXGZzKZIGagqmIhgPIIhlTysbCLcKlZ2ApmZIARWG69ipI1luag4oNW+wJg7Qj6XVMNYn2mS+cn9N34DU74tUsFK2ZNVX3C0Lzm57lAIBR3XJGWCBq3I3yw+dSMMnSmhMNRtF41ECk01jhg6U4L7k21+oh/wq26Sw71lHYnkdYA/VJqjOsPdqy6FyKXjaJ4ezfCZOORoDLGBzl2nOPD1F/gfgw7atiFWCK2p3X+CWAvWkeRzIcX+2aScuRTorMeGGKix1hxslqA2ynlHs5BXrLgODTnNy0vXX1fRUsy4ETNOzOGwya2tZYZWNigvtcipbWvFABdzHk+VyzwxVOLFYg5Pecz1S9zSKfPQWplJv4Dcy73nJenl1lCMNRQhiwohwVl14IUCRieNfl2SHk9TJyIsKRC2QdpJ1qX4dpPaYoMIDHdbhrsPbL+sTUwch8TKJ+hMghOB0WiTNEpEAr6HwYCBrOgxbC8ytFIg7+90pwmMMLRGfPrFiGzDIRM69HIhi8eaNKYSseppRcOeYklkaYhCIlLbgyTDVXLi0kCkYjIaxsNEpMZi8AyARbE/RdGfoxDOUurOUe7Oce6BFhtzPQyapUt/iBEWUthgNFLaaB1Ra57eEqxzQczP/vc/4tff88lv86am3AipYKXsyalAcseii5aGwEq6s75z0cWbSeJLbxafuhFaukDTdrAMOBg0gqZ08WLBZjrybbcd4YeeXuazlWP0ZZas6vNjjVc4cdcRfAXeap73Lu9HCYPvGDImx3tXjvCIvEL90GCin57EfrfEe+Ecst1DF3P4O9b7DLsO5Y0S92yMUwo9Wm7AE8Mr6ILmC+cUl/o2FzsOwfDmpLojo8wYJtyYGTfm1maPB86vMdNZAauBRQNL73aH1h2Lp8pFvjE0zLOlLI7JMdcvs79b4n3rZYaia6pTAElx2HggTjFWNUJk9ZZFJIXAkRJXCtwZge8GNM44xF2JXdAMnwgpzsXIv0q7JpWIFKFBDC5JmxitwuTLREQqIDABoQ4gW6awAWNNHy/SBI5kueSBG1B8coShxRxeb3P6Se5r7Cjqk33q0z3qkz1ib1vEcvk8vW6XnlacDnu8GHU5H/fR1naFdEFMhgWy4hIZsYBNzEi8bUVVI5eSv49Sb47uXJne9BB3P3wH2V4G7eyIbQnY92yVtck1jIoIwxa2dNnO/wQpbKK4DSRi9cV2QCW324WY8taTCtZNZrNqw/lehJXLfctVG24W727ZNEUSBxFAJMAShne3bCCxbt4oPrXJG1UnX3UljhJJHThEkjJuJKuu5Phg/8cLMzw8Oksl8BkN+wS2w1+M3kvOMxwP4L71GSKRuIwAYqHRWvKujUnY4eKJZ8a3BApjknbuUYSINR+LRmmvVrjoGhYrihXHZoMZ6MIXNuegzaaDGmYimI3gcL+TWE/Fiwyt18j4ne1tB6cOheDZ4TKPjQ7zQjaH1iX29UvM9crcVyuR03vEPaTBHdZQ8gcCFSOcnQ8CiUB5lsAVEnuwxkoIg7DB2x9RORz91QQKQBtMXyGaGhGZwULmEB0HKBNitEIbRahDAu2jjCLShtBo8t4KM+tFNGCMIecrjvR7g9u47a7tFyLq0z1qU11aYz57Zdt3teKZ9iJPd9a4ZOSuTsaCiIwYiBRXKes4saK0x7gzy9z8USrt/RTiWbLRKAKJjARBO+aZwwvk21liTw+sPgMkpbGyLRsTJw9njl1kcmWaOy+/n6JfpZ2p8cLcl1mfuELZkjzTi3CFIGunMay3m1SwbiI7qzY4HkR7VG34biETCEQGGlHiVrMFVDLgBTce6Hiz6uRPDGvevwpKC5QAywgk8LUhzYk+KAN/eMkCRyAy+a3FtpaCLy0ajlcVoyrDBgGJ4CU6oUleh96WODVqL7K49EXCYAPpjKOLP8w6B7nY97jYdumNw7WlI4SBMSdm2o3Zv2JzrLnBfn+JcrhCMVjFMYNsxh05CRrBxewQ36xUebFUpOWUmPbL7GuV+NurRew9ZmThKKyhCKuafJflmEq1RLO5vf5HIHAtgSclveZplhe/iB8s4eVKzOz/GCNjd377Lr6dDDL8RGAQocHoEOX30CpE6WAwqUOkI+QVRenFLG7HI8hnWTjWpD3ZI9dw2f+ai6M1lt59Tw2G1qhPfapHbbrHhn2ReuMVYr+NvVSkUrkVz83RDJd4OerworFZFNWBu88a3IttkSrqBSZiyb72BMfXP0g+OMjyoTzZWxJL9fijB+g6ffq6h29qSGGRlTny7SwGQ78Y4nUtlL3tyraUpF9IHsqEEJzsf4ATr96KljGx3aEQ5HngtR/lYuUVYimoa0P2W4j/pXz7pIJ1E9lZtUEIgbymasN3E05RI3qCqR0VfHQMdvHGXX7XVidXjk0kDOrJM7Smp2mPGr5qAu6qORSVpG1pnh4KaY9CNMgM2wgE+T2yETcGwpkpwlDXpWkilDZYQlC2HDJZhWx1MAouNi/wzPJZ1vgQq+yjFoxjgh2z++DHjIbZWDATGg71uxxrrzBSuki5XiPfbu25kim0PeZHhjgXlnmpXKHhFhgOS8z1S3xsbe8ir5GzQeBdQOXXKM1OUBib23LvtVpnWD3/KHHcxLOLzEy+h9HqCRwpkFLQaD1H55kvc2r+AbL+EP1MjQvLjyAfUAyP3AOAfSbEeyxA1jW6Kgnu94iPunuOZXtQZkukVBwhL/pknlXE3RaFvKJ7W0w4HRGakFAHZBccRh6vEEtD6Gicts2RR0fRFrjBbtPOYIgdjXISS+alB5PAX7d7mY21r2MJH9fy6et5vtZe51V3H2tyHER+R3WoiIyYJ8clpqgz7YwynbuV0vJP8s7HDxMLTWhpXCWZXZM8JRbJHI1p5NvQjtGORoikCUkU+DQKIdpvcvG44eA35ujEmr7UZLWkiGDltmWGbIktBIfP3oblGmJ8MBplx9hk2X/mDs4dfY0hS9JSaUr7zSAVrJtI1JZId/eEL6zk9ZvNxvpTXLn0R4ThGq47ytz+T25NeADDp0KWv5FBx0kGmVFgtGD4VPAGR01yFmKdWEeiHRJlcsTSIkYm648sg+hGdGLB+ycVn+lrzmVqSHw0GYRT5Cemtu/HsGdoRQJ3Rz23UBmGHYPo+WT2ReiXyowKB2xDpGHJEiyP+MxfKnDRt2nre4B7rhtrmQYHshn2rdrc0qpzyF+kGqxSCFdx9aCCd2N7e4Og61SpOeM8O1TlQjVHGHtUu3nmVJl3Nq8XBYNGlCKc4Zgwc4XFzmfB9hHCwZiI1rpmJvsxSqWjtFtnWJn/Y1xhKDsucbTM6pXfoZj5KfLjtyMsQ/+/P86Jsz+MlprY7uOFJU68+mOcdb7E8A/fk4jVnzQIVBMl+lirWbw/KcPHK9eL1iAuZXyFjgK0itA6wLkCuUcdjGUwGaBnyH9d0rnPpz/tE2nDxPNV4lgjFORiB7mp+oPnLiU12jLEnkLZhtjq03EWqJcu0aqdIQ6XiKIVIjvD0+4+zjnHqIvxXZkggpCsmKcsFrk1n2HKO8JU9l48uR3nm354PBErOxGM0NYQw6Hnh7l6dIXPH/oiP/7shxGxILQiPOVgG4s/OPgFjnCYL1TP0DlW5ycvHGGin2M52+PXD55luLrKB0XiuvbaHrEX44kqliVRKqnU4XVsbGHzUCnPp2sN1ptX3vB/I+WvTipYNxGnqIl7ArHjrhuVvP5W80aVxTfWn+LMq/8RKWxcr0QY1Djz6n/k6K3/YEu0ijMxF6cvsnGpSibO4ds9hvfXKc6MYkziJhQXF7GfPoNu9whLRTq3HyWc2U5HDitV/E6JDkeJTQ5b9ChwhkyxBcAUL3K3epaXeD8dhihQ46T6Y6a4E9QJ0JoPjsZ85rIg9DsI4yPJYMkCD1ZiTFvT8QwvTy5wuVXiquOx5A6EMdg9OdsmZIRVRlhlNlrheGeVubbPXDRModVix9LVLSLLoTVUpVkd4kxpiMu6gup6lDo5pvpF7u1dHyRSxDiqw0i/SzHss3ZXC3NiDoCFs38Kto8UydiEcLHwaa58ldnh46yvfJGCCLFskK6PtLoY3WNh6fcYnb4dgOmzd6ClRluDGnlWUoFj+uwdAMivrBHELZQdI7BQ+ARxjPxKBEenwRhMoHhheZEvL19hI+wz5Lh8sDrOrfkktpR73kEPUsiNSdLJpYahZ4uYdYvKQo7ihrdrcbLBEMoILMGLHzyP7i2RW6jTzF6klVvAz6xvbbvqZ3nR3celzB20xTjsikmFZLnCtOtzLF9hNnuciv1eiqUinXbnuvs93PXoOLu9E6GlGep6LOiYb448S3RbyIfPPcBIr8JGrsaXDn+F50ef4Z32UZ7ohwRjqzw/vrz9HhqJ1434YClxxYalAKfrYhyNJMn/l7FAlzRVu8IJfYYP9r/JU96x68aX8taSCtZNZKfVYiyTlLy5AavlW+XNKotfufRHSGFjWRmEEFhWBpTPlUt/tCVYz79ygf/k17AnLuMiCRBEvuSnXvQ5emgOe2GF7GOnMVJCNg/9CO+xF9H3i63khtbMbfROl0kiOxGx8WhwO7mZJhawuPAws1aD/c4VLMtCxTFKhSxdWqE6dwCjBVOds7wrOMdZ8276VLBEn4J+la/V9vHp9TINZQFlKOy+B2XpM+fBrB0ysvJljjZXmOxJxrqQjTcnSJudAaiuU6HtTNDKjnB1sshVN4NqOxTbOUbWc5zYwynYdwNMOSDgcYq9BrcszlHwC3QzHV7d/zwbbovD/B0AwqCBbWVwUNjE2MRIoVHBArmMxFdnsT0nSTywbNAaKT38/srW+fL+KKHdGUTsEpQMyPujSSSvFg7EapCIgUSJGGsjJNqoYYKQV1oN/nB1HksIssKiFUf84eo8nxiZ5EDOpdquotzEiiAE27ewIomnBfna9iJljabntqnn51mpvEi7cJFOboG4m2TPMWjYGwOXnRyvuPu4au2nzxi7RSqgyAITrLBfNRmxqhyc/NSbf9CBjXxAse9sWVgArhLU8j5e1KEqHV4Ze4bzE89vuV0jHVG2ktJffe1hby1cTpBo+tpj2B5CCol/Vw/rqzadoIMvfTI6Q4EC/bt9HDvPysbjHKbJbc6ZGxpzyrdPKlg3keJMDO/y2XjRJe6BnUtK3nyr8as3Kzr7+XkHB0VmkKqWIZl8NiuL+/0VbDuZ4RNrySYWZbq9LrUgcen93lIHiYdNksjgkMxfD681OHpoDu+Fc4lY7eyeG8V4L5zbEqz++jhkFDJMehUJCdpx6S2PUJrbIOo2sWQRqSRSeUmBVSNRQYD2LTpK8PhqjQV5hJawWSeHEmVgYjPrHQDLxAyxxigrzMQrHGstcaivmQnKFFpNpDFs94hICKWhWS7RGZmiWR6i7o1R73qYjku+laGw6F3bWQqNoZXtocsB1RFDYRSKueS+n37pq/SLGdbGtyctg0EFPlIIPCmoelmINrCkBzLCiBBlmriFInbOkMmX6Vzdz6FL72O4X2Aj2+H8/q9SmL60fcwhF6tub4mSQWMpGzPkYoyhm1kjE5ZRMpmEhRHYOkPfqaN7SSGlL9VXOLFR5kOXJxjqu9SyIY/MLfKX1jJ/20ygLY3dklhKbrv6BvSzXVZHz3Mp9yjt0gtE7vVWjwGaFly0S5xz5liTs4SM79pGEjBsbXCk1eKnXruPA8130c7UeHbf14hOTV53zNfj/O1r3PONGYgNoaXxlMQ2kqVTS1QtybuKt/Ol5ldQRuMIh9jEGDQfKL+XUW+cvLxCX9vYm2mdIrGw8lZEPptYf6enX+blk8/y4LkPMtwbZiO3wR8e/iwnJu/khHOSIKhj27k3HGfKW0MqWDeZ4kxMcSZ+3ZI38Map4DfSTmNFZCia3b15XDTLIkMvBu0d5C/7p3hRf5DI5HFEjxPyq7wj8yq+GiQ7CEH+Gi+ZC2xsrv1p9zDejjReY8CSyFYX0Q8wSqNaOQJpaLsO2jhYCApS4HUtdNciK/cRRR2kdNDaYc1UWTTjrNuz/NFigZqygI9wzZxJzrQZMUvcWpqksvwFTnRbTHUNY13IRzutoMbWT52sx3IuZCkTUCsWsfP3IcNp4pZD/lIWV1uM7T4NgYzZyHUxJZ/qiGF0VFLO7B1vdL0KcdRGDNx9SYp+l7KXZ8RzEQL2738f5y/8LxipkJaL1gGamLn9fzs5RvAp7nlljFhqOnZIMchyzysf48LI6tZ59PtH8f7E2Y5RmSyuVaTzbhu/u8jq/mc4+sqDCG2hZYzUNkILlva9xAiJu3Z8KcOnXpsjlpquFVHp2/zNlw/SPBsx2cte5+pr5udZHH6SpeGnaOUWruvDJZUL0QjnciHn8oJVa5qWniK85o5KAkbMIncPHeC2wn4mFk5xy9PDhKaHb3XJhWU+cO4neW16g41Cb8/7bDBYOko6JpuY6kHBq1xm4vlxhroZavmAtTtqzN2axZZl7svtZ9ib5KvNL7MRbTDsjvLB6kOcKJwE4ONDE/ze+gaxkVgk/bQMgo9XJxCDeNqX6g/TmmxwefoKtm0TxzGhDlipr3GicJJMZoQwbOw53pS3llSwvst4s1TwN2qnccewhTIwYnzquHhJfQEMggBJ1YQ0QpfnvL/FM53prbYOsXF5Tn2EcubU1vqnYQM1EYHsYwbNx9FZhrUDUYzOZ6AXgGVjTNJ0AwXay6NrydNqYEd0A4ERiX2jMXRjg/EiVAxruQ/zSmuddabZYJxIuNuT4SDLWKKomjVGWGM6XuFYd5VD7TYTPZvhvsTSm66gHVXCpWE9LwnGjtCqDtHKjxAHBVTLQbUcqquZPatHNO2Ahew69dwSI8OC26emGHGdJDPmTRgbfzeL83+CQ4grJNL00SZk3/4fxslphA1jpdsoLP8s2ccivG6BIN+hf79DbuQEACPPjaAkhJYCDKGlEEhGnhtBv0thTER0ICb+qEP2G0NkmqDKhvZdEdFogNUQFA7fytn+F5ldvI9sUKHvNZifepz8sWMYowl1yA9dnkRoQ05ZDCkHZ1DqKR8nDyCx9FmtvMTy0LMsDz1H4La2rlPIHLYzSdtIXtHrrLsRDdumI6r0zX5CRncuf0MQYdEGLDQWs6LN3aUZAPY9O4SxLSyngDXw6ZpIsO+5IWr7fUCCkFgI8paDJcA1BtvysKSDLWxs6TB2ysK+zYCIGMVhTOwu63Rb6S5uK9215/v2Y6N3As/yJ/UVusomb8V8vDo+eD1hI1onJ3dbUI5w2YiSuNzsxEOcu/y7xPHuNiQpbz2pYN1k3qyzbeabp3mkMENL30suztHzepTkk3zwm6eJDkyz1oUCaqvCtRESy2iWu4KlfjIJv3dS85llC20ELpoQSSwkH5xIXI9P1CeQaASbTQ01BsET9Ql+bDCOdxa7/FFP4BoL10i0Scojvdv2MWsRvdlDeKcvYYwAKROXnzaEB2e2ruWp8ionVyYAybqtWXUlSw5cyMX0lspAGeThXfcnJyJmXc2ME3E0bHBg4xXKqxcZ60mK0c7YE2zOjC1Xs5ozrBYEy9mYjlVl3H0PGX8CveDihA42uz/sGsOq12Up16aXrzPvfhPbm6foWvixz5rRjEUfY5939A3fT1skC3iHRk4w4sDi0p/iB1dx8hXmDn6S4ZHbtrc9EzL+9RmMBVTBjUYpfR36pZD4qEul49BzFZZIuv0akxSurXQc/P52UkC0D/pTIEIQkQANYpDmXywfhVPw6tifE4Z1bLdCZexehBwnfHmD/LxDpTWMpXcnpfS8dZaHnmNp6BnWy6+iZZR0+LXy9MU0PZFjXWr2VW/lij7PxWCRLnP0zH4iRtiZs+IKhTG9wWNONLDYksXhr4oZPma5CGGR63jJGqm4izIxlrDJWgUK7Szl7Ci2junVX2Rj5Ss0oyYZp8rc+IcZrd6G/BYWnT3TrvO52iKrUcCY4/GJoSnuKla3/v5jo3fyY6Ovv/+wM0IrbuCK7dr0kQkZdkYAGKqe5DA/zVrrGzc8ppRvj1SwbiI7K6AX3b17SH05rhDF78UVmkBGuMojit/Lnzvf4JgP1bDHhmOB6KCFRhoJpsBI2GWzgsAtRyr8BA2+tGSzLjxGTMAHJ2JuOVIBINAOlokSl8egA7jUYJSL2UiCWOXuy3wozPIah+nJPDnd5RZeIS99MKfQI1Xas3nCq3lU7CFlgJztYqo23VBxJbJ43LV4crJPT3gEOzveDqpaCwzjtmLajTniKQ7XF9jfWKFSr1FsNLD05mLObQsnFtAsFegMT9KqVmmWh2m1e0S1Lm5/hKH6DGN6e2LZ3DMUiquZNgvZJkL0KVcVczN5Hsjk+OOlPyMbt3GkixACR7pEOuSZxqPsK1wrWAJXikGVCQvbJikg6xhylROM7z/xuu+/91iQiJU7qErrGIzRuF/v0p1r08iH5HoS344xGASCTGxTz4eUsBHRQKRCsUsgruWKHOZx9wjVXpc7V4eYeH6M4ebYrkQNgFrhPMtDz7I09ByxCClEM/T2T3G+b2giMMKlb3doyQ36cpWADC/1s/TNYSLu23Us1wTMmXVm1DLvPvrj/D8vnsYm3qrBLkg8u4HJ4LrJ57RR6GJaAdpWSATGxERBh25JMW0EzfpZnl74DKcdn65nyOsWxxd+h/eJ/yND1ZPb11F/ifnlh/H9dTKZEWYnHtr6+zPtOr+xchFbCArSoh6H/MbKRX4GdonWG/HB6kN8Zvm/oPs1HK2JpES5WT44+tcB0H6doh9y+w/9Lzd0vJRvn1SwbiI7K6ALkVQ6NwY+d9niSDkmNlDnnXgCQpk094sFuBoCcxeh1rxLP8+T/jt4R3uGcmzTtGO+Wexwr3gGeM/WuW45UuGWI8nPRjugwQQaExmGo5hYODhGb01hComrQxgUIQ3DFtNWyAxPJxsMOun6YUigDWHNRa8NoT1N3YZ522YhyDO/FLO6s3zODm+aROGJPkXh8yNOwPHWMmMr65TqdXK9veuw+dkszcoQzeoQreoQnWwVuhlEy0WsuYhLLiVzvXuvY4Vczja5nGvRz3Q5WNPc0fb46EaGXJRFaFjMuHT2SdpRA1fubtFhC4d21Bj8lghU5UpM+ekQu61RFUnwbg91y+svyDXGYEyMMQqtY0QtxmQ0JqlXtHV/ZEOglM+52+a587H9uLFFYMW4ysJWgvlbFrmtvm9LpF7ttvhSfYVaFDJiw7vzihE26PSuwLJkdnUf76jdQcHfnegQy4DV6susls9gCPCiYXL9fdx55gFc5fHUkUfp5ar07BqXo5eJRI+IIn2zn75+FxHDu47nmYB91JgzG4zRQugIxyuR8SpkpCLQFlJsO1+1EWSkwhGSrOXwhcN/ysef+jCWgsiKcJSLpSV/cejP+Cif4Jsrf8yTbg8LgYfAF4Yn3R7O8h/x1waCVKu/xLnLv4sQFradIwwbnLv8uxzmpxmqnuRztcWkSeigTlVGWPha8bna4g0L1tEefHwF/ntJ0JZwuGt451LI+Opf0On/7xg/6R/zf3Wf5uffnYrW28lNE6znnnuO3/qt30JrzYc+9CE+8YlP7Pp7r9fjV37lV9jY2EApxcc//nE+8IGkucM/+kf/iEwmg5QSy7L4xV/8xZs17G+ZvTL4bh82xBqW+wIZB6wrRbJKxlC0bJaVS2vg7srHWXpy9+NzKCAfJ6WGCvYqf23VoY+gLw3FWPDXag7dsXVMNJgHY0Nr41VWVh4lClq4ToWx6jsp5w4igPf3Vvhybv8gvqXRg8bv9/uLMMjmcpwyQdwH6aGQSSdYHSPsEU77gsWNHPNVxYIL3Z0P7mZ7hW9FxkSmS1l3OdZb42R7lcPtFod7HRx1fVV3LSXtUoVmtUqrOkSjMkREAdH2kG0XcdHF9veu17bm9hKByja5mltnKK+4uzDBR/IF7viCi93V6EHrD+2AjAyjz8V09jkUnQrduI0jtsVHmYiKU6Tk2HhSkpkPKX7Vx1hgsiA7itxf9OgSEh6SGKMxRmF0IlCbv+9ElT1kB3a2TRJxEocCeGLks7x2+xEePPN+xntFapkef3n4Cdqly9xm/g5R3ObV5ms8V3uZKbPGLWaNYiekfPF2Rmp3crz+Ply1u7pGx21wfvgyZ0c3GD9UQHhDXLm8QLl5gFs3ToCWfGX6cZ6afpyl/DJhXxGZEn0O09f7iRjadbyCZXOiWOGAbLO49jyvilmuisPkTY9jYp53jL8LgHdXh/jLjSbKJGniZvBo9InxfdxS3IdA8Jsj30TfGfC+Mw8w1K1Sy9f56tGv8dzI83yUT/C8WcESYA8ijjYCUDxvVvhrg/HMLz+MEBaWlVjVluWhVMD88sMMVU+yGgUUrimq6AnJavTmS0mMMZjeGsHpP+BoEHO0LZIalMm7ifbPb20bC6j763sfKOUt46YIltaa3/zN3+Tf/Jt/w/DwMP/qX/0r7rnnHmZmtuMdX/jCF5iZmeFf/st/SavV4p/+03/Ke97zHmw7GeK/+3f/jlKp9Hqn+I5jDDy1Jvits4nLLyNh3Rf8p1dtPnUg5ngVPO2zrBg0RjdooK40E9Jn861oOIp8bBGJbdFytKBhK0wMufoDWATkRYe8BoRA4JKvvQc2AoTWNLvnWVj5IkJILJkhitosrDwM4x+mnDvEeyZcxPw5Hi3OEUgPTwfc177CPTNZ2rEixuCU7qO28Rh9XWBDTrFmxliXEzQYRW9IuCaL19MwHcFsAAdGlzjRWWaivk6utkH5daynwMtsWU7h5CSrdgb8DKLtJRbUVRcnuj7hIUZzNdvmSrbF5WyT+Wwd296gImpUZIM506Agi7xjKFn/5La69JyAXthBGYUlLHJWgVwrmeTuqrybL698jihsYpkAhELakgfGP4XndRFWTPZJRZ+Apq6j/CTeUjZVvK+7dGaSye+V9kt8tfYwtWidIWeE9w09xLHituuq846I8heTqt/GTsRKKEHn3hARQdjpE1au8N/u/R1coXHiNq7qUel0eOrc/0QYNwC4vTfBRO0uJms/wVDrSLKYdQeLxQ1eHmny3EiPq8U+RhgCnedvZkZQJmY+4/PV4lf4/f1/RjxYgByZMn1zgr66XqSKtsOJYpmTxQqz2TxSCF7rtHjeuR2j+7g6xJdZnpO3s8+aZNzK8WPT76HiPMcX1i7R00kyw4+MH+KT4/di+g20Chi2h3h5/EXOTm4vBQh1wLCdxIa6FjjXuD4l0LW2LWrfX78upVxKF38gHmOORz0OyexInAmMZszxuBYT9VGNi8lX/SK6cRETvU4F9kF/Fu/WT/KZ4DGuOH1y9l6V9lPeSm6KYJ07d46JiQnGx5On9/vvv58nn3xyl2AJIfB9P2mf7fsUCgWkvPHA6s0i1kmVh83vavO7EXz2soUUMOhcjjNwo31p0eJ4VWGieQxzg1QBTSJbAhNewegDoOGZ8jIfWJ9BqqRbrG0EFoKXS2vc1szhxGNo2QWsrcQ4IyJsPQQqmThX608MxCp5lLekg9IRq/UnyOcOoYYr3GUMd195CRNGRJ5LPDtGo1JiObS4GtkshMeZd07QMQOr4xqv25CC2RDmophbuxsc7S5SCVYohqvY53an1CdXa6jlBK2hUfqj+2hWhgicHKLjIdou9qUsVtNG7OHe68mIK9kWV3IDCyrTZtS1uSWTJ+48wgnLx95hlRqTuPOMMRg0zVwf1emjrSRWoo3CD7qEhZgwCKkGLY75HS7ZLdpOF5eAwzGMUkPTTLIfa5I10SAWGQwSYTShaTBRT9xKr7Rf4nMrv4stLHIyRztu8LmV3wV+eku0goOa5odDCt90sBoCVTJ0buvTzC3SXZjnWD/Cis+R0QHWjj65wkhKtVkmah9lonYXRX93FlwoFa9WW5QOK37Hvcq81SU2PZTRyVoqGeG4i/y5v8TV+CJRISnaG5kyfb2fntlPzG73WEEKZvUKM2qBKSEYy7ybUm77//XR2gqO5eI6uWTxOYJIG55pNvnx6STD7m/s+yA/Pasg9jGxj1EBur/VfpkPVh/iD1Z/F3SAI1wiExIbxQerDwEw4o5T85cRYvN/RSdZsN52uvxmSvmmhQWgdUgmk4jeJ4am+I2Vi/ha4QlJYDSxMXyiOoFqLaAaF9H1RKR0Z5k9g4NC0rayvJCd5pXsBB0rxwf9ee4UEe7+93P2wsPXZRGmvD3cFMGq1WoMD2/7v4eHhzl79uyubT7ykY/wH/7Df+Dv//2/T7/f55/9s3+2S7B+4Rd+AYAPf/jDPPjgg3ue55FHHuGRRx4B4Bd/8RcZGRm5bhvbtvd8fSdKJy68SEOszZZAPb0S8WcXYtZ7mpGc5GMHbG4f2/bvNKIueScR300saWiEUCkVCWhTNmdQeg5jMrgEeFzGQVO0Khg0ztgqT7DEifoYpdiiZSterqyiR3oUnSrtnKbby9AXNopk7UjWxORzFoVikhocxW1WrRlOs58uWXIEHLLmGYpXmXEHAjQ9QXt8gvnQ5nIfrviShRVJvIdgOMIw42nmMprDusPx9jKTq2vk19bJxfU9i8JGXoZaJcdla4W1vKCWszE6S8bPM9o/iLtRxelYbCrhdqchqDn9rfjTlWyTNbdHwbI4ni/yoWKF46V9VFwPg+bTZw2dOESKzffBEJqQklvCdZOJ+eEDT/CR5+9EIoisGFc5WEbyyMHH+PDYx3lh6WHm3CYHXBtBCQMo47O68mUOHHwvAPOZ83i9MsZOUs4NEqkKzOfWma0e4tGrX8K1PLzBxGnjEKiAR1tf4v6594AxKD9g3f0Sl2a+SneiTt+O6bf6mFYiTjv9B06cY7R+O+O1u5mu344T746xNb2QV0abvDza5OVKC9cT/OTMFGPrfc7U2hh7EeyrRM4iyPbg8wkxFXrmOH1zgJjyrmPa+DwwfoiDdgf/yuexLAvL8VA6YHHhL8jn8kyM3YEjXNoXz1By81iWhSD5zGeMYSMKGK6W0WEPHfUwKgJHANnB1zYPVN/DvLH5zPLlrZTyn5jYxwOziVvxU/wt/t9n/5C1+CChKeDSYdS+wP/pwI9TrSYCe+zIJ3n+hV8n9usIrTDSQjg5jh35JNVqlQ9VqxSKBT5/6UUyzQscC2vcHjfInL9CL97DLSgETnkWb+QI7ugRvOEjfGP1Cr+6fBUHg4shRPC/OccoTc7w3mqV8dwEzXQd1k3hpgiWMdc/teyc1AGef/559u3bx7/9t/+WlZUVfv7nf55bb72VXC7Hz//8zzM0NESz2eTf//t/z9TUFMePH7/umA8++OAuMVtfv96nnCzYXd9VpDXe+bNOCgldy+k6/MFFG3vg7qv1NL/9YsynDnQ4XgWjYdiyqGxY3NmwyYeCrmN4uRzTKSk2FlqMxAF9obF5bWt2jpFkTEj76hIYeIfn8BfFOmvFOo4QRMaggI/mSnTaHWrjYF2sIEyMFAphLGI81kYb2I3k6fGKPMJG9w7e35qkGHu07YBnSuM085eorykWIoervkN9r+ZDQNlSzDgxs3bALf0NbmkuMXylRqlew4mvt54MgoZTZb1SIZpKau/52RzL84/j9G4j159hpjGFowo79knQGJYzHS4N4k+Xcy06dogFHHAc7vE8jmSHmXBtpAAIUJ1VNgb7H8uc4rHGl9EixhY2sYlRRnGieAftTjJRP1M5TXTC570XT1HpFWjk6nz16Nd5ZuJp3qPup+tfwLZzqDjGsm1UHGOMRbezTL2eWAT/9cA5fvalexGxIbDUVkWF/3zgHD9bH2K1v0xWCaJwHaNjHCxGyJNRHZ5q/BLd/jz9cPAEL0lWYe/AkjmG49sY2jhBaWUfk805pNnt6usPhVwZb/HZ/BILxR6WFMTGoIzhsNfnv9ef58XoSVSpnfRGYdAtxFTxzQFicZSe3i18jvApWzXyLDPsCj5UvY/zZ/40+XgaCwuBZVwsE9K++AhHK/fjSYtJL08t9Nk6mtH4KmbYtlm9fHrPz9W1PNOu88crPXJyjKqVWD9/vNJjjAvcVayy3i7TNO/GiC6WCTGiRNO8m/V2mTrJ+yJqHabamhUHQgmugvG+wlw5x8r8eVTjIlP1i/z9/sauc29+/oRXwqocQFYOYFUPYJX3IezkqiKSrs2f6Wlct4AbtsFoPGEh3AKf6SpO1eu8t/BB/mD1dxFWug7r7eamCNbw8DAbG9sfmI2Nja0npE2+/OUv84lPfAIhBBMTE4yNjbG4uMjhw4cZGkp86uVymXvvvZdz587tKVjXYsy2CMUDYdI9zWpvb1F6I7581cIDMoBUybNirARPXLK5xU5KH33ECKwVB4UmEBovlNy7ZqNKEaLf56h5hWflncRGYKOIsdBCclS/CuYUAEezyT/LY50ujVhRsS3uL+Q5ms0QA1+WGxRHu5xqjFGIMnSckKcqV2lYfX7MVADwg3u4tz7D1Yzm2bxmxfVYdvcTcQBau6/LMklH1rkA9hfqHNcLzK2vvmFLjchxWC5VeCKT40KxxNV8CR+bYT/HO6MK1ctZ7LbHrL6+HlwkIhayTS7kOlzONlnItghl4iQdl5I7PIcjXomD2Qyu9ebv0Wx+H/fzAV7sPE0rblKyy5wq3M1sfh8SgScEVdfmlcknODP3OEqGIJJYSdVOPldeZoRoD7eSl9m2xJ8Y7aKPP8tfv3iU8V6elVyX3z9whidHOvxdf4P9vsHu1SlrQU4bXEIgsfDW/W/uGnOMRRcbbbIc2zjGgcY9VHt34rV2J5RoaehN+rRn+jSm+nRzMaHWzPZt1jo+DXEJYc+j7Hke1b3kdHJbpAJzmJ7ZR7RZaHEwSxctgW0uUZIbFCwfZSI0mruGfjix2f0GOTtPBkNOGCwipDTE/iL5QZPCH5s4yn+69Cy+UXgIAqMGrrbZN33PNnmzDL7P1RbJWR5DTi6pNanUdRl+4bn/Rkl5lJWLUWHiFlcdwlf+4PoTShtZmk2EqXIAq3IQkR2i3ng5SYu/8rXr0uKBJHHDySLc7XF4xmwlbiRVM36aR4N0HdbbzU0RrEOHDrG0tMTq6ipDQ0M89thj/JN/8k92bTMyMsKLL77IsWPHaDQaLC4uMjY2thXXymaz+L7PCy+8wKc+dWOFMTcX0u7EU3uLlTEkYSWTWEvowVoXnfwedyRVi12r+B2g5Yukc602VOctegREIoMRFpoYz/iUFgViXDPnRRC+sHttkzmXvL7zfmUz7M94KGO2nqA34hgD1OKYXr7LSv7SjrEbOrHDcz2PhdDmsjXEV2cE19bPAyhIzawvme1rbvEbHO8sMhQsUdzZUmPnfQE6hQLNSoVGpUKzUqabzfDIhqbYyzER5LmlmacaZPesHtGzesxnG5zNdbmca7Hiddjs6ZcTgn1WiNQXcbnKkOVyKpOIzbfCidoBHnzxMF5bEBQNG7dp4qrGcwyWo3iXczufWzmNLSwckjVWsVG8byiJlUxNf5iLFz4NKkBaFkoFaKOYmv7w1jkm3TxPja5yceQcI7rJcNxgUjX5e+0Wzz3zexzaY1wGsIxHpXSKrDfF2sITvORkOFQ/xt214xyqHSUX787qi7OKznSf6AislRv4liIwmkhHLIfzXFHnuKBeoZm9xmIw4FgHaapJOnqKiN3HdUXAO6uznChVmPKyXOlmebb+KK3Ip+QMcd/wh7i1fAc5y6OVGUKE6ziWl1itGJQOyGTHklhU1OcOR/AzY3NvuCD3zXizDL69/l7UMcXmVYJz8+jGBXT9HImL9npEdjgRpmoiTrI0g7B2PxS8WVo83FjixonCST5yz9+54WtP+fYQZi9/3dvAM888w3/5L/8FrTUf+MAH+OQnP8nDDz8MwEMPPUStVuPXfu3XtlwwP/qjP8p73/teVlZW+KVf+iUAlFI88MADfPKTn7yhcz51bmnX70ZDpVyhUWtgtNhsTzsQqzd6mjf8zlmLYtPiRMsiH0u6tublYkynFPM3p5JMoo3HPLTpwE53pzFIUWD4/oBmbzt7z7YzxLFPbGBi9EPksgdQxqAG2YOvx2c3GrSVRpkcPhl8k3zpPcRJGMNoBBOhYc73ub2zzsHCqwwt9inEG3u31LBtmuUSjXKJRqVMs1Qitm2E72F1sshODquTQ4Z79X4yrLt9avkWpzN1zueaNOxgy/0pjWZc1TmWLXCiPIGOl/hG88tYwsKxPCIVoIzi/soHdolWaV4y+aK1JUhLpxStWb31t33fsBM3m5N0IxYamh8OCQ5u38k3y+Br1F9k8eoXiaIajjPExOT7cd0q3e4Vet0F1loXifqL2Fyfjp/ca4E0HnVp0RQWmAwHgxJTgaR06O9RmM8SnK0x09qPdY2rbyW/iDyUpzPj0x8KCYzGymWYb11hPj7HFXWOq+oS8cBi27rfRqCYpG8OoORhOmr3Z9gVfYpijbxc4cPj72V/8ZYdf/NwLA9XeHiWTc5yyFo2lpC728+4OYKgi9Ehh/f/FEOVk7xV/NvLLydCsEOUfK2o2i7/t30n+LeXXsLprXIgWGPWX2Wqu8xYUEPuLU9guWB7gEBmh8m/+38C3nhh8fOv/M/XJW0oFeC6FW4/9j8Cuxcf52yHXhwRG8PPjB/YEuho9SXk8uPs/+v/6S27PynXc9ME6zvBN19a3rKQMInFVC6XaDZbe25/rgWPr0gaoaDiKO4bCjmaicEYLi1msS8VUMKgBUiTtHSP93fYP5X4rlce72CpIkZsW0zCOCirzfB9BZQ2NHoXWWk8S6B6WFaRauk2irm5re2Td8Owad4ZbagryUJoczVyuRg6NLTLdWl7QFYopmyf6ZrLwU6LY91FJoNlhqI1Mnpv/3rPLtN0x2g54zRzw9RPNMFIZDeL1d0WKKH2SC8XmpVMl/lsk3O5BpeyiUWwk2GhmY6XmQqvMmtHTI7cSb64H4A/X/kjeqqLLRyklGitiU1EzsrzsfHkoaQ0L5l+FPr08GVIRrtkybH4bgj2aw79mYPdY1dMSESgC7DxUzfWtiWOujx76S853biMp1uM6DpF0+H1yklEePjWOEPZOaby+/HcceJzX0FHPbAcMIJ8d4py/QDl1lEy/u4Ft5FQvFKp8+LwVa5UnqBfXOCTU/8DbdPjUnSB+fgsC+YiTbVx3bktskSM43OAth4nMrtjUsOux6ynCKKXiNQiZbfKndV3s69wC67M4EoHR3i4lk1W2mQtB+eabFyjIr586Sv88foV6sahKiJ+tDLO+ybv5K1kpxB4QiLjHtO9FX7UChnrLRHWL2Kp661+AFmYwKocxNge8dKzYLkI2wMVglZ4J38KZ+zkLgtKShetQ4xRHN6XWFBPPPuvse3crpi6MYY47vHOO//vu8b6udoi6ypixHJ2WZPR6ksEL30aJ1vg8N/5w7f0HqXs5vu60oUJX89qGuSja4XQgNaca0seXvOQGLJC04kED694iBHDkVzMyHoG39Z0jECbpDFqRmgy6xkYCFboPk62/9FEHEUExsFgUfeeQ4Z3J+V2nHEmRn+ITDZDr9fDGE0UtQGT1I4zgpXY42rssRjlWIwz9Mz1YgEGh5C86HNKtrnf3+Bwc4Vqo0mp3Rm01NhNLC2alRLNzAjt3j7WnBI9S+BqD8/kEFmfzGtDyF4GsUdChrZjuvkOV7MtnsvUecVtoq5Z5OwhOOo63OK5HMl5VBwbmASun+xacZPMdRUmbFrxdhX76nMRHQJiSyGRBFaAUhEjL3n4d9i4HYH2do/B2GA193L7GsKwTq87P7Cc5ul25gnDGgC37nGXXbtK1psm603huVN43gTCKu6qaA7gjN5L69U2bvskR+tjFOLdFmicUTw/dJ5HK31OV9cIrDBZsG2VKbhL/E73N1hRV9DX2NdZq8B09lYyzq3U4mGeaSwTX5Nt54keebHCT899hHEvM5h8T2Jj41gejnSxcbClHFhSu0XKqAijAogDjAp5prXBp5s+tjvO2MCi+HTXUGzXvyWX3xthtOJ23eKfq2XW1l5jrLfMaLT9viu2Hdo96XDJG2HdLjKj+hy75SO4U3dvbRuNniA6/zCqv4GVHcY59BDOWGJBzS8/DEohonZSbUTaGCe3tbD4zdLiN7mrWOWuYpVqtbrlBdo6//mHQVpIJ12H9XbzfS1YGA1KI4xO/gOMwggL2b6+dcHj9QzTPYsTLXvb5VeKebzhcTgXoXyJa2uG2XzuNklSR1/QjDoorcGWLBUfZqh3H64qE1pNarnHKQhNFO8+p9ICpSLa2mIxznI1zrAYeawqb88Ymyt0Yj1ZfY6EdU60lpls1ig3WmSDvS2Jnl2kbU/QzA5Tm3ZpTkhAsN5t0F9psq89TSXMbi88bexeTBl6Xa5m5rmYWeNSPmTBsQivye6UGm5puRxpWWS8ixw9XKZY3n9Db0/JLjOzVOX9F++g2i9Qz3b4yoHnWJjcnhCctqHrRCANBgUCIqFxm0k5W1U2yA6Ya6pHxGVFr7dIrzs/EKjkexzvvRDUGOhToiuG6JghmgyhKfM35u7ec/tkbBaFhSyFhSy55RnkNUsCrua79GZ97AMx/kjI/764xnq8DvYixl5E20sgA5pAc6s6vWQ8c4BD1TvQ8QzzgcOz7SbNOCJpNplMip7oUbY2KFsbSN2k4JaYyGR3uPpcpLAQAjLSJm85eFby7260wkQ9TBxgYn/ggthmZzKEGHz/VssZXYvu11GNC6jGpWTdU/My6Igx2N2EREhkaQarcoB4/TWMjsg7OW63HZTyMTokvvzVXYLljJ3cEqhr8XuLyKCXLLAXFhiFCFr4A9fuZqV1pYJdFtjsxEM3fG2qv45w8m++Ycpfme9rwZKdbTeYISk0quMQpcMkTGsGrjdjyLZKvKPmoIQhlJqMgnfUHL6Bpj9SA7eADh2w9JbDDiUxbkgwCBI7owdpbizy1fELdGSGgva5o+sxOjyFJslYXIk9FmOPlV6eK4FDR+/9FgzJkCknYI4Ox7prHG0uMzSwnrZbamwTS0lrR+ypUS4RuS5okL0sspvFu5C49/bF159To2hmV8kUbZZybZ52r/KK6BKKzafG7X2GpcXBVoMfujjB8baFaxSWtrH0MZ7TT8O9+2/o/flQ6z3cerqEkpq+E1AIMvzo6ft5tdgiM2vIOIbV/BKVoEQktl2NrnZZy61RZIbOOyIKj0DLmqeZv0LLuUwzc4VWbh79XLjneYWwybiTZLwpPHeCz69HhJQwwkEgMCJ5GAmuaSvSbV9EXVhmeG2K8catFHu7n8JjoTlfbXN6tMHpkSYrXp+cZXhHqcuF7jnWvFfQuevdfMaUOFm5jensLSg5zZlOjy+stmiEu/uljbkZZjKKjd7XyUofWzrEOkILw7uGP0zVGd2qYu5KaysuJYXAqBAdtJJFvOr6pQk7+auUMwIwKkQ1r6DrF7YqRxi/see2IlPFquzHqh5MUsvLcwgrsU7bX/rXCCe/ewmM5aL619/D18ONYkIB1lbVTIkWCjdK7sFmpfXXi3HdCFZ2BB3s3dsu5a3l+1qwgqg5SGHYdhn5YUSkrrewbm9bxIP4FCS1wTSG21o2jRis8Q3cK5MYJROzQkuEEUQT2/88l7I5nijvx4oVRaXwxRBfKc/xksjTaWZZjl3Utd0IAQfNpB0wbfc5FDU42VpmurlBudEi5+/tw+9lMzTKZRqVEo1ymU4hn3QAjiVWN4dcy5Lp5JDd7J7uvVD6bGQXqeWWWMisc8kLqFlZ+qK0wymViJVlYkqiRcmsM2a1+dTUx5h7DDJh0vkWAcqKwdgcuXyEK/fe0NvDbWeniK2ItojQJnkYqFo295yfpPaORGweOf4kH3vqIUAQWRGCiHb2Cs/c8iWmz5bpdebpn1yG10lVkTJD1p2ib41yPiqzrIdxnRHeWa6wLzcQ47WXCbFwdnxOYgRlEyEiQWExQ+ZizMHFu/GuyeqL3JDubMRnsotcGG7iO5pYNAjlZQLrChtygfneoKP0VplFB8kMWs7gm2kcp0LTFHhspUk7vrLr+ONehhPFCieKFca8xH16uePwbP1R2lGTijvMA6Mf4XDxZNLy3nLIWQ62EKACjN9B7WFFvRHfUjkjYzC9VdSgWoRqXES3FvY+n3SwKvsSYarsTzL3sq9vsW0Jgb3jvCrEyg6/7j7XMhpYLHigjE6qnGAwAkaD7alvqHryWxKoa3EOPUTw0qfRUboO6+3m+1qwzOtkdAFoY1Bme+FwRUFLJM0QNlsiKCGo6mQBoSp3iYbP46yMInQWI7tE42tbhUu1gW/2XHqiROhk8U2GeJAJsHHNA21ZRsxmIqZUi1t76xxrLjPcbFJutva0npSUtErFXdZT6HlgQIQOspPFWRgkR/S96+IrANoNUYUeutDja9bXuWD36cgyLVFEUdm1rQSypkWZNlVRoyhrCJkIvz9IfS8EFQKrz87kDyUjCsHuY71Rhp9sQUMmjSgtKdBGUteKTGMz3tRgbNbiz+NfZqqbJXTXCLwk3pQxsLG2+xoD8nTkKC1GOFTaz/7ifhy7yvm+z8O1BrYA2xa0teELtQYfAQ7nstxXyvNwOyQyGltA0c9yojbG+1ujjH6jirwmg7SdWWal8irLw+dpDvWpzn6YF9afpSMvEVtX0IPKEjsZs2fJ2wd41S+hxRhG2PR0TKA1RvksBdsPJhNelrtHxznsZhhxd8f4XOFxonIvd1YfQAiBEOBtuvyklYhU0ETH/e2K8N8iO8sZ5aTE14M1VkNTmKiHaly6oXp7wivDoAiwzI7gHPlh3Inbd20Trb40iD+tY2VHdsWfNoXAxAFIK/muFc6hG3fXDbnTiHCFVadPIGI8YzMWZqm642++866LESAkwnaThcVCbn15cw8gvCLi8he/tWOmfMt8XwsWJBOfMkkISxmIYk0nun7dhueFFAOX7qAPr4Umj0Z6yZO+bLaxaiso5xxYgp62WeyWuFKb5qpVYin2iPawngQaB5/bMyGH4sR6mm2uM9Rqk+3u3Qa8n/FolMtJenmlTKtYSKwnA7KfgdUIuymxowksXbz+mjEE2RZLmUsseRdpF5q4mRkaFLmoQmrm+n9W1/Q5aHvclq1yOOPx9cZj9HUHW2wHh2ITU7KTcj5hSWC1LZRQMJB4S1uEpe3JPcnws+gQU5OaTEsy/aiN9z6IjygWcl0KfZtQKHx3lV5mnsBd4HzhCsGTC8RxB4CihPY1l+k6I3juJK+EJTZUhb7OERkXtEVs59gIMxx1koXBj7fa2AKcgbvMEUlDwcdbbQ7nshwd2U+1voFaKHKkNsZMb/fJjDSsFy6wUn6JpfIZ2l6TNSdmOdNnLePTaD+J8XY/aAiTQ+pZjpdu486R2/CcApd7HVZqa5zvtlHXpKhPellOlCrcEtcpLz4GKy3wSsRzD5AbOYFrZXCEt+Xys6UkK21yKKSOIOihVfgtWVKvx13FKj8D/PHGAlZ3hXuDde5TLapXP0+ns7z3TnZ2sBh3P1b1ADr2CV/9Y5AWwnIxKiA8/RmEtLYEaTO7DmkhnDw6aCa/DzL8nLGTcPKniM4/jA7qSK+6S9BuBOfQQ5Rf+jRlnUnS3gdZhM6xHwJpJz3h5KBEmJQgrOQ1kfy8KUqbbkmnOIIMrp82vdn7mXrnja0PTfn2+b4WrGZ0vY0lXmeRYTyRuPzKQoOMt1x+4cQGxkBtzedqdoYFr8JVp8yGPXANGSDePo5FREb4lEyHI711TjWXOd5tcajbxt6rpYYQu6ynZrmEnxk8VSuB7Oawl7PJ2qduFqGvzxg0hKhcG11WqEKfBecCj0Yv0xVV2qJMlzlMLIFtl4WLoUCLLDXG6HNv5QgHCpOD8kdwW/EuHmt8GWBXyaNThSTYvXqHw9TXJb7uEcgITzs4IsvyHdurqyvPQYuI0DIIDH07JlR9zOllOqOXefrIy+zrNelmF9DWNfGmwT0VwsJ1x8m4U2TcSTxviow7gZSJm+izV+ZxVXtg5wkwGivq0Nhh+TViRUbutpJy2mJutcjkhSqFhSzH/N0VGmJP0Zn2aU73qE/0efHK/8ai22Hd67PmdYnkbmGQWAzJffjRFB09iZMd5b6RcTwp+WKtwen2Zboq3rXPVCbLiWKFk8UKQ65HtHGG8PwX0JYk4+Sx/B7uK39B5mQFZ+wkUggyArJG4aoQEwZg9v48fzvooIWqX0A3LnFr4yJHGpe2CirDTqerQBansKoHB2WN9iMLE8lEP6D3jf85EaJNd57tYeKA6PzD24I1yK57o202hWuv7LxdbFpA0t4lNJvWT/ja51HdNaz8GN7xH8edumdr13DxKcJX/gjVXcHKj+Me++Suv6d89/B9LViv7xDcY9tyl3BuCXt5mCh0mM/HXKn2WRBFluojBNWD1+0jjWY8ajNZNBxULaabS5TWVznSbTPl7+3PDlyXRqVMd3SItVyeVrGAthIREpGN7GSxFw1WO4MVj1zXJRYgki1WM/MsZy/Tdq8ypmrkZZWro3dzUUWcVZrYOrV7J2Moih53uGMc8DxmXJeMM8VQOU+3e70L641KHgG8PHSRrx07ywcu3slQv0Qt2+LzB77B8NARZtmXyEWvx3rpAv3cPP3MPP3sAr63lKzsPQ9DEtrb5QWRKkOPURreMHdUD5Fxp/DcUc73I/6y1abRVlT6FveVNIcHxbFLUYsOFs5WOxZBbASlaHutXcW2aIc+I13F8Y1hTtTHOdwYwrkmtheUI3oHYlZGm6wPtVnQl5hX57kSnqM2tnLdPcrHDjN+iaNTP85k/jAy4xJbhku9Di+1G/zx8vx1IjU9EKkTA5Ha9RZdfoyssMmIDA4OyhJoE8DZP6MyfBjPxEnGK2/YcPiGMCpCtxYGmXuJe8+8TjJDUm9vP7JycFe9vS133tk/vc6dt2fm3DUJEzeyDTAQtZ2uOJFYQnIgTAORurY+6Sbe7P14s/fv+bdw8Sn8p/4TWDbCLaL9evL7PaSi9V3I97Vg3QjGQEPbXI0yLFoZro4r1pUFWMnq0x0P0jkVMh03mQ3r3NJf40RzldGoTymOcOL4umMroFYo0KuWtxIk/EwGhCCbzeDXDFYti/0m1SOUtYYuBuiq4Er7czxb3EBj0RcVmrJKR04TyDyEncFeyds66gvu2vA41NOsVi9yZuQiDw3/BI7UCJHkOsq9/8eBRLRer0zSi52nWRu2+Fr1ApF2KIoGU5wn2vgmpXaZoD/P/B2vn81l2UWUPcaFqEJfjBHY47R0gRjBR4YqVAYJEed6fb4wiD9lpKCj1K740z3+eb6UPUaExkYTI9FCck//DJgTZDZc/tb5UfLLVWa6u119Wmi6YyH1mR6BFRMvtznnv8YL/ouc6b5GLHYHHx0tGQ5zjARZJsIio9rFy+Sxx45xrtvm5bVlXuk06V1jSc9kcpwsVjheLFN1r09ccIVHxsrid5vg5BDaIInIxD4ZHWF1amT0tgX6RnGfvf5uH/wwdnFyS5iSxIh50Nd/Zq+ttze07w5aoX2dGLyZO+9GEia2txl4FIQAHWLlx5G5ka2eU0KI13XF/VUJX/mjRKw2x2BnMPiEr/xRKljfhfzACVakBfNRhsXYS0QqztDfY2GuwDBihUzZPgd1ixPr8xxZvEI5CsnH0Z5FYQPHoTlIikjKGhW3rCe0SKpHzMfIpg3RBLlrqhQAGCJiZ2nwtUjsLKHpg5WhXn6AL8kCdTlDT5YxYreF4CHYZzkMNdb4P5yeYziASEa4xsFeOsFfnApwZ7ZLGk2+aJHpRvh5Z1cyxBthjCaOVqG7yJSSnDDPUTHrZNhOGmhfY1x6/ihZf5Zid45Sdx/fmLF4x8kkJdzu9Xm81aapDWVbcF+pyOHc9gLMN4s/HZIx9M/wZGaOlswwHIV8dM1wS/N9lE9PYfevSU23I16rrtEuvkZYPcfSoUlWWpe4os5SG69dc7GCcWeWfc6tTAcVhq+cxTia2NGEssclJ8fZkTt47exL9PVukZrN5DhRSiypinP9g4hlBK6wcXGQWkPUxvJKuEGDnJTkkCgTY1SA3DHJv5lQRKsv4b/4u2yWeFHNy6info3gdWyy3fX2DiBLs7vq7dmFKmIPV9ybufN2JUzsjB0d/WGEmwdp4x7/FP4zvwlGgeWBShqQeid+Yvu4bzOqu4JwrwmQWh6qu3pTzp/yrfF9LVjGQEvbLMYei2+yMNcTiik7YEb2OBrUONlcYqJZo9xs4UbXP4kaoJ3L0hiqDqynMv1sZruOYGxhtbM4m9ZTL7tnc0Ituqh8F13R6EKP3uofsuIZzrkBTekQiiE0+1m1y/T9BjgHtvaVBg50BFmzRi+3yKfGfghpW5x6IocIYyI7EdYQhVE2D52/g8untuvvGQnKA6cn2PcNm8vEu0TL6IgwuErgXyYKrhAF88TBVTAht+1xvxWSliixr3SQjDPFhh5m4dIoD87vZ7jvsZEN+OLsEnMHt4X2cC7L4VyWQrFAp9257ph7xZ9sIWjEiUDYU3dyy5lnuHdFUG7to9ieQ5rdBU573gZrlcusVi5wvnqOq5kmC16DNaeD6ZNUMR7sUg4rHG+c5MTGCY76x1j8sETbELuGbnGYs0sv8Qo5zrqj+MIGf1uo5rL5LUuq7LgYrUDrZHGuVggEHhYuNjYWgwYW2FKSlxbD+99D9PLvJUkAMrdnVty1QmEsF6N7BKc/g1p5nujqE4k47IXlDdLJt9c9SW/vLt6bVlovqMMeyQ57u/M8VL+GcLK4s/ch3DzhmT9FddewC9fHhrzZdyEsZxA/WsXKj930+JGVH0f79W0rD0AFWPmx198p5TvG97Vg/cf6HB2z9yUOWyFTls9+0+ZYd5WjjWWGGi2Knc6e1lPobBaFLW9ZT8oeHNuACFzsjR3FYYO9nxBjayOxntwlYnsBJWoIO4M3/gFCY3i2UOFFN0tHDiVuvmsoqJj7VvKcqlscaUElcrBNlT87EVCaNdgyotqx6FkBarDuRCJw0eQ6yT/l5IsWRoJ2QAqBtkHpHt6Zy9SzZ4mCK6hwARWu8HrrmyJsarJMSwzRZjipDmHKOHaFdw0nCQxDwPr+y/y/hr6Brx0yMuKdpQKHczdejb1iW3SUGlhWg3uoDcd7RUaeK1FYuI9s7b279jHC0Br1qU33WJhc4eXOZ1hwNljMtAjkbkvIwuKW2q0ca57gRPMks/4cWifWiBUKzhRqnAvavLTR4NVOgO9t12UXJJbUyUKB47k8JUuANpi4g46SBekSiSs9XOnhiO3PohCQlTZ5aW2XSRo/hRTiDbPiVG8VhJ0sxFUhxAGb1cqj7jVxNukk1o3lgtEUPvT/2EqMiFZfwn/mP///27vz+Krqa+H/nz2d+ZzMcwIBgkyCgIizogi11xaxtrXoUwWt19vWOrT15/jc6tPW0qJ92nptb+2LKtenrba3vdrh1mtVHIpWkUFQkEEIUxJC5uGMe/j9cZJDTgYIGQmu9+vFC3LO3icrAc7K97vXXqvXbcWuqzjdFcDsuoormImi6mi+fOx4C2geOm9tUKwYWrAI1dsxtmXcBbjHXXDMv19X8bxR3XpzTfsM0Xd/jkM0tcrDMnFN61+DbTGyTumE1ZmsUjfmahFmOC1MqTtASXMDGU3NuBO9DSSENr8/dVNuU2YGYZ+X/QmbLRGHdgvG1fuYafrJifqT9z/10j3CURxsXyR1/1O44Tkco2N9p6g4jk2tFmCf5uNApImDdgLLd1raa6iOScBuJJswn8g6k4teVVHCcRKahQIkDBMsm08eOIN9s5NvtBGjCXcigNGlfFG1dCJGEzEziB1poyZjH62efbR6D9Dq3k/E1bEF0stlJ1UL4PYU4fEU4XUV4zFK+O0Rk4Z4O6bTjoWDhoJb9ZPd5ebSA5FK9odfpcRQ0dExMdkftil1L6DMW96vv8NzQkFeqKtDi8WY3hRiamMhpzfkkhlP/4HANCwaiyMcKW5he+FOPlJ3cMDcRYN9mG6DdclMeCiNhCjPPJ/xWeczY30WRiS5kkJTiOkWmwMNvJZ/hH/srSNmd62Pg/FuN9N9XqZ5vYQ6t3ydBE5nZSNKMklpblxK+mqvczXlVTXUXooEulbFNdTXYbceJF75auqmXProGIGiouVOw26rwXEsFFcglZwcM4bqzkhLVsfcVuyyilNUFcXw4VgxEpWv4qn4BADu069JFidY8TH9Ru8qngfzGNVVnui/UzphfdKoZlq4lqlNyRtzg300hU3oWrfVUwjT6PKtMVXqG9zEmnxcHPWTG/Oh99I9wtGsVHKyAmFsXzS5b9epTaPNgf2uTPYZIfYZASJqxxua3ZE4HYfcRIxzan2cXesnNxHljfGH2FpQQ47HQ2ZYJWIo2E47lmOhKRpuw4cv7MJxkuM59pfuYPKes8BWaPMept1TTZv3EFW5HxDf28La03tuvXVS9BwMowS3uwilsZDiXVPIa86j2RfnyPQWQpOSX898vZIXIyYex0DHwUTBVkzma0fvLdvSuhFVUTE63rQNDBIk2NK6MZWwrOa9mFWbiCVawQiiF89By0hue+phlbm74MzKInJbx+HqVtIfCcZpKA6zr7iKLVlb2Ofs4pC5F6vbVGSX4qXMKaWkRaGk1SCk56IXzUYPjcOxbQ7NaqH47SDrM+r5e14db2c0ENE7VmL20SQ1w+tlms9LUOt5zRNAUww8qhuX6kLtWt2pgFfV8Ks6LrXnv5tOdrQxVRRxuPUAsfqPjv676E7Vk6ubjvuF3DOvxVUw82gyshI4Xa8dHWNbMXX9ac/fcJXMx4o2JK/rKCqKZqA4Jihe7PDRO7VPpTf60V7lnQzKy8t59913yc3NHdQxw+2UTljfePu/e328zeejKTNEc0flXpvff/TaU0f3CK3eh9aWvP9JibrxozCu2+u06FEavBGKsiJYgQiO5+jsp04Jx+GAlWCvFWdP1gzqetlwzMBhou6l3HDhPrCbz2ybhqk6mKqFYQe4aucc3K4NZJQliIcMPGEDl56ZuqNMSUCrP0Jj24fY8UPUle7kYOjPWFoLVvf7mzoWC4qj4Y8WE4qNJ9hWRmZ4PC2nZRAvUjAMm+aPFCZtyMVSbCKGiT+qE9qQy0fUkTHJYXzdRi613alih5Ad5azIfsbHYpBXDkCr2YxbSV8J6ei0dnRjt5r3ktj7WrLTte7Fjrejb9tBpjqO0JEifA3p59rYNAeqqcnYxQeF2/hwfIID5i7anObk5aAUhQK1hPHaZMbpkyhUSlAVDXwOFCab6VuGTavewA4zyrZQmJ3nRYkpR3+4UBwo97iZ0bGSCvSRpFRFw92x5ad3m0lmqCo+VcOjamjdVlOpfntdKvecaO/3GSnujKP3PGVNxI61Ylau7bU7edebbXt7Hrpef1JS9y9h6NjRJlRvFnqgCDvaeLRyDnq9riNv9GKkndIJC8DUNJozguwP5PKOUcI2bxG4FGYGmilzR1LdI9Q2H9RbaNEQei/dI2wc6l2tHHa3UOtupcbdTFiP4ah+rs32pY5zHIda22KvFWevFeeAnehyP1jyTcvlWJTFWxhvRZgYKCAnVIpiJN/sZu4/HVONkdBMFBziGjhoLNp3Jh9MbeGjaToV7xo0Gwdo8VfS5j5Aq2c/rb5DUNXl+kzXwjRHQzXy0d0TMPQSDLUU5VAR4z4KkRE1aPLF2D+9mYyJTqqfXt62EJZikVCT88ASqgK2Tt62EPFJzdixZibqHiZGP+jyeRzsLp3jg3oGYasNgy7dMjAJdnTLMKs2AS78bZPJaK4gs2kC7kT6995UYxzJqGRvznY2FWxmd6CGI0Y7jkJakvIrQcarFYzTKijTJuJVfKRzsAybsGGyIxHhg3CEXdEo8c4Vt5JsSVXh9zHF5WLqMZJU55afW/WkXZeC5Pu/T9XxaVqqstFxHOz2zn57e47fby9jPL7CqSS8xckk1Uu/PdcxZlP11b1c0Yzk6/sLsWPN6ZV4VhS1IyF1va7jaP5k0cgY3O471VVWVnL55ZdzwQUX8I9//IMzzjiDFStW8K1vfYva2lp+9atfUVFRwY033siePXvw+Xw88cQTzJo1i/r6epYtW8aRI0eYP38+Xcci/r//9//4yU9+Qjwe5+yzz+anP/0pWh//F0baKZ2wvj/1cmaXRjkQ9/FWcx6q4uADMsIakQY/WDa+iKvX7hGWEiNiHELxxVHzPPxX7ABtioLepTzYRsPjtNFmu9nbsYqqtOO0d9t2VIAiVWeC5iKktNAQ30HE1U676ifiLSChJtCIoisJMsOZhA0byzaxcTD1NqKhI8Rc1YQP76LVPsS+WX3f36SoAVRXMbpRgt6RnAxyU1tUquJQbbWzNngIZd4B3JpGzLIwHbg8nJkqKc8Iu4joncknmWgTqklG2M0RQHVnJHvIdR05bpsdJcLJkupZgTN4s+l1Eg7oiorpWFiOzWxtNt5tGnk7P0lW2wQ0u1tVn6uJw2XtbCvaztuuv3DA20i8e7GEo1CiTWScVsF4rYJsJa/XG0dtzSFimGy3wnwQibCzMUqiy9+PCkzwuJnh9THV66EgI4O2tt63TDVFx6N6em75kX5tSjGjWHW7iPWn354vL7V6SpaVl6Ko2vE7O/SDohmguZOJSXOlrmG5Z3wumZDM3gsNum732dE6VE/umN3uO9Xt3r2b3/3udzzxxBOcddZZ/PrXv+bvf/87f/zjH3n44YcpKytjzpw5PPfcc7zyyitcf/31bN68mYceeogLLriAf/3Xf+Uvf/kLTzzxBADbt2/n2WefZd26dRiGwVe+8hV+9atfcf3114/yV5p0SiesHe4C5iSqaDycy9kRFwVxjay4itrLtlxCbaXROMxer8V+T5SoVk+5uZsip5Wi0CcpObyD7doMrOSgECKqQlh1QI3zWKShx+uFFJUJms54zaDU0HHpKjWJGt5v3YSqKBiKRtSpY2v7y7i0ORRqxTiJBvYXfkhEPUiLbx+tnv3EjS5jC7q1HmxXMmhXCwm6S8n1jsellqI5ITRH5VA0xvbmCG2mRVBv5vSQi4qQga7Z/OlwAygxtFgY07HRFBVH96XubQJodrfjT7hJdEkUhq3R5G7DMaNoeTNIHHgzeQ+NqidvQrVt9KIp2JFkzCVKNvP9Z/Fe24cEm4OcXj+DmQ3TyGnKTPs6HGyaAtV8lLOdDXnr2ZK7lyajZ6eQzmKJsmiAcTkLcPdxU7OjQlg32WaH+SAaZldzzyQ10eNmutfHNK8H33F+enSpLtyqt0cBBQp4FQVPuBateR92414iTXux22rotReF7u0oK0/e96RmTkB1BXoeN0B9JageX08/rj91bvfl5uZSV1c3ZDGKoTVhwgRmzkx2tZkxYwYLFy5EURRmzpxJZWUl+/bt4/e/T05BvvTSS6mvr6e5uZnXX3+dP/zhDwBcccUVZGUlV/Evv/wyGzZs4KyzkiMXIpEI+fknT4n/KZ2wPl/txXfgNM7t9riDQ5tmc9BrMSGvFjsQ5t0ja9numonqWKjY2Bhsc5+OE99KoePgMcBHFQf1HMKqkrzIAUByW8UAyjSNUlVlnK6SoWpgJFvIJG8Httjdvg1NjWJgElTa8JqteK0WnNottNkRcGJsK+r5dSiOiq4W4PiLaSWfrZFM4hRgOH5UE6wEzFMClHiSsRyKxni3rRVHS4DLpE41eSnsoHtCVHjcNMWiuBKtHdcvOvrvxVtpcsCJt+I4NlW5G5lyaBEGkFAtDFtDtVWqc9eRnZiA6s9HLz0Lq3YbdrwN1RVAy58OgRKiDlgm+GsDzK6ex6U1C/FEuk3g1S1qcqv4ILSON4veZU+wFltJf5N346VMm0BZIpfiIxH8sQSKEUDPn44WLOn2TUomqQ+sdt6Ph9nVEsXs8nIaMNHjYYbXyxSvF5/Wd/EDgK64cKuuHqspJdaK0bIfd+t+1OZK7KZ9mFaMnnfqde23l2xrpAYK+kwiA6JqKKkE5U62Kuonuf50anC7j27rqqqa+lhVVUzTRNd7vsV37kT0tiPhOA433HAD3/ve94Yp4sE5pRNWwEz+B7Y6yhNMxSGhOlgd9yYd8cUYl53sObdPn4ziWGgdVQmOYhPWHN7yn8a6SD3t7snpL+44ZNltjNNcTHIHKNA0VE0DXYGONzgFUJwwmnkINXGACbF1BO0IXrsdta9ucIqBmxJyGieQ1Twet1NKY3kWrXmgWgqbGptQLQt/5z82BRTHZns4TInh4NITvBdvJOpKoHfccKvj4NgObzW1MDHLS9BsoV3Ru8x/UjAVlaDZgmMlryEFsnazQ1EoOnIemTEfTe4w1XlvEsjcDSSr+NRACU6gBMuBqOOgRnQyPwpSXB0iqzaIZqW/gYZ9USoL97OxcDPrst6gRW1K/9IdKKCA8a5pjFMrKFBLkt3J3UAfC5GwZvG+3c778XZ2t0TTEocGTPJ4mOFLJinvMSr0kt8FFZ/uRzcMNDSwTdTmA2jNlWjN+9Cb96FEj66mu16BUlzBjlVTer+9IaWoKFpHTz3dnWz0KsQxXHTRRfzqV7/if//v/82rr75Kbm4uoVAo9fgDDzzAX//619T288KFC7nyyiu58847yc/Pp6GhgdbWVsaP7/+9k8PplP4XHyutSZaY7y8kEXdjKUdnXWkOzG0/+oYa1oPEnTBNGkQ0SGh0HKmm5gr5sck3G8k16ygmQU5wPF5fdsd4AsBqJXPvTrLqjhB11dAS2E/EVYelJPsKFnaLL6EYtKk+olomE4LnoauF6OSgWxpmCI6ktrEiKNFk0m0zk1O2uvbotrQE9Uo7IW8UBWgkjrvbD0+6As1W8i12XmQ3r/img+Ok+u9ZisK88G4guXLR8qfjj79DS/l7tHRs+XkdGytvPmHbIeGA5Th4mz3k1ITIqc4g2OhLm8Xl4FCf3cj2gh28WfAmWwKbe1RRBpQMxquTmOybQb5ZgkfxcjxhNZmktsbb2R2LpjU51oCKLknKc5wkBR3l6IoLTzyMr/p99OoP0Vr2obYcRHF6aaHc2W+vo2OEljkBxZvTZ/PVAVMUFM2dTE6aO61lkhD98eCDD7JixQpmzZqFz+djzZo1AHzrW99i2bJlzJ07l4svvphx45I10NOnT+c73/kOixcvxrZtDMPg8ccfP2kSluI4A5zyNgY8/9f1AHi3VBBTHSK2io2Kio1bNWnSo2ydsJ39tskBKzmJtCvFAb+jMdetUKYqZGrJDtGOBtgNED+EkjiIkjgIiYNgtfQMovO1tEwSehYH7QRRJYilZJNIuNAclZmeGeTp/bu34ZXWKBEbFD2BqcQxVRMTh4Cmcl1W8s3+V40R2iwbo0tLo4R99Jj4nr+xBw/r3eW0aF5CVoSzYpVMJIpr4qKj57QeInbkQ+KJKLYRgNzTUN2FZNYFyK4JkVMTwhPudgOvbrIv7yCbCzbzWv6r1LvTC0Q0dErV8lSxRJaSi6Io+Hx+wuHeCxMAwkoySW1JtPNRtySlAxVeDzO8Pk7zevqVpFTLJNB2BE9rNUbLAbTmfajxnl3rARRvdrfCiLJhSx6KZoDuIbeghIam3uMZSSfLNayxEEdxcfEIR/Pxc2qvsIjhOBaGK4qe0MEVZp+vlY/czezxtNKmJ47OsupYerkcFb+j47Y1XI7OXF+CYrUGxT4EsUOQOIiSqEJxeh9dj6PijebjjRTjixQTahuPL5HL7otBtVT0WD17o/uIOVF8iocJ7nLy9P6M/HbQNIvTgwleDrejqclVk9kxnPJs39E30LN9Bi+2xsB2ej1Gy5/OhIPvMCHRgKob2GYC27GxSuYTsZ3khGUHbG8RjCvCiGlk14TI3ppBVm0Q3Uzf6mvztvNh4U7eyn+Ld3PWY2rpV3SylXzGa5MYp1VQoo5PGwp5LGEsttrtbDV7SVJKx0qqP0nKcTDC9bhbD+FtrcHdcgitrQal18IIN0poHEZHrz0tcwKqJ6PncUNI0Yxkl/YuqyhVdwOjn7CEOJmc0gkrYkWpth0OFu/goAk17p4TfgNAmapQpoBuWTQkDuO2qsnhAHnKQYzmGpS+JmspOqpegGoUohqFzHhrGmo8Gw0XiqMkt8cc8JpujHhypZGn55IXyMXjdhPtcs9SV1Vxiw9jCdps8Ooms/wOk/2gKRACNMPN2+EEzZZNhqZyts+gwn30r7Lzz30dowZKoGQ+0SM7sMwIlpGJknsaircAbAcc8LV6yKkOkV0TItTg77HVV5NVy+aC93i94HX2B/elbfV58FKmTWKcNolx6iSCav/f8NudjpWU2c5H8WjadSJDUZjs8TDd5+U0jwd3H0lKTYRxt1Thbj2U/L3lEKrV+/fa8hdgZ4xHy5yAL7uCvHGn09Tc3OuxQ6Zjqy95LcpzQsUSQnycndIJ6xfReHIBpSXobEJg2CrjY35KtDaKXHvItvahJGpQrBqw6pnUZzGEF1PPpg6VRsXA0nKZ6JlNkVaEailoloKTcOM1vVja0QSn2RqN7v7/pFwVt3g7FsZWE6DHiSrwShR0w51KOBVuPS1B9abrMTbJVVbq2hMOTsfqyefzEg5HUGyFjFo/OTUZZFeH8Hbb6ktoJrvzPuLtgrd5u+BtWtxHtz8VVArV0uQqSq0gXy1OjXLvj3bbYmO0ng3RRj5K9J6kZvi8TO4tSdkWrvZa3C2HcLcmk5PRy20GAI7hwwqNx8oox8oYj5o5Hr87mLx3qrNyqh/biQOiaii6J5mkNPfQX+8S4mPglE5YyY0phzxMxiXqGBfZTZG1A00/AnZ7t3Y+XaiZqEYBmlGA6ipE1QupS0TZ1rYdwzbwOC70GOwP78Pn9ZJnJLf0NpXuZMFHZ6IApmqh2xqqrbOpdCf5lB8zVlW1MIwEm2ItJIzO608d84Zth7fDieMmqeRXm9z+Mx0wHQer4/fe6B1bfeP355N1ONRjq6/F08qWgq28WbCObbnbSWhHv2FBJTOVoMq0Cbj7USzRVZtt8b7ZzharnT1mepJyKQqndaykJns8af33tFhLatXkbjmEq60atZdBhI6iYgeKO5LTOKyMchxvLoqq4FU1Qsfp6zcUktejvMlEJQUTQgzaKZ2wFideoSyxGZ/T8RN3xyDhTg4KaHkoehGqUYDuSv5SHS+qraJZCqqloCYUtrVtIGh50CwTiAAqlqazN1aZSlhKSZAXeZtzDk4nIxak2d3KP0q34S452lons9ZLyd4QvqiLsCfO4dPqiZY0YnS8d7Y49jEr/LrrmpzMztVTX2U0Dnhb3eTUZJBTEyJUn77VB3Aw8xBvF7zDhoJ32Rfan9rq0zEYr05mfEexRKZy4lVxbbbFVjO53bfHiqatZd2qymkdN/NWeNy4VBXFSuBqPZRKTu7WQ+ix3lerliuEmTEOJ3MidmgcVqgsOVajg6Yo+DUdXx9d0odE16o+3SNl50IMsVP6f9SU+CtHP3B0sLNR7DwcKwctkYVLyYKKcRh28h4n1VJR27u/hSdFrHZ0K0HyHVwFHFQrTte33TwjhyMl8Ifct4jaETyqN1lU0ZHQMmu9TNqWjaM6OG4Tb1xl4tZ8qowE7YXJdkAZmpqs8OsShOkkH7cgtWIyOx4/XpGnYkNGfYDs6hA5NRl427tv9SXYlruddwreYXPBZpo8R6/f5CoFyetQWgXF6rh+F0t01WqbbDXDbDHb2ds9SSkKp3VU983OycZqOIS7ZTfuQx2rp/ZalF767dmqTjxQRCxUgp05ATVzEqqn98IVt6ri13Q8w3WdqPN6lOFLXo+SrT4hhs0pnbBs7wU4RjH6fnDUTAxHwYONyzLRLQUt4ZBo79+3wGtZxAAtlc6SwxE9VnpBRp6Rk0pQnRTFRtdNxu3LQ9Hs5EwsVcUybEio5H6Yn0pYnRV+jmWjK3Rcc4IZbo0m8/gj7AH0uEb24RDZ1SGya0PoifQ36yZPMxsKNrChYCPbcreltvo8+DhNm8l4rYJx2iT8Ss8mwP3RbJu835GkKrsnKRym+Pyc7taYHqsn0LYHd1UVns1VqImeRTEACW8WsVApsWAxsVAJVqAEj+7DrbrRe/nxQlUU/KqGT9N7dEkfKormOpqkpGhCnGS++93v8utf/xpN01BVlaKiImbPnp3WwWLz5s0sW7aM7du3U15eTllZGW+88Ubq+dmzZ2OaJu+///5ofAm9OqUTFr5/wm07BJyDuCMJNEVFVVVs2wDbBlf/v/yyiMpOrw3YqB3JygbKIn109O5IUoZm4tKTwxY9YRemK/16i63buNoNEiRXTAWGxnk+g81Rk1bLJqipnOHRKTtOrMmtvhDZ1RlkNPhRut1UVpmxL5mkCjeyL5Ss6lNQKdHHU6pMYLxaQb5aNODWQc22mdru22fF0pOUnWBqvI7Z4f3MCh8kqGi4Ys29rmRtzU0sVEwsWEIsVEIsVIxtJDuvu1UPnl46pHcyVJWAquNR1WFZ6aTKz3WvJCkxJKzte7DWvoPd0IyanYF2yXy0aRMH9ZpvvfUWf/7zn9m4cSNut5u6ujo++OADVqxYkZawnnnmGa699trUx62trRw4cICysjK2b98+qBiGyymdsPJiFqrioGaF0KvqcVQbVBVsG8UGM7f/5dZ5SgCiYQ54TCKKjddRKYvq5HUdY6HYGN2SVFdxfxw9omMbNrYDtuOgmCrtvjgtXVZPZa7jJyg6tvqSSSqErz29DVBcTfB+3vtsLNjEpoJNNHmaAAgpWczU5jFOraBUm0CWP+eYN+weS1Nnkkq0s89OLxv34nB6+CBnte1hdvsB3L10jHBQSPjziIVKIG8iLa5cEr6co7PJSM6b8qke3Kq7R4f0Tm5VJaDpuIcjiag6iuFDMbxyTUoMKWv7HhJ/+BtoGnjd2C1t2H/4G3xm0aCSVnV1Nbm5uam+grm5uVx88cVkZmby9ttvc/bZZwPw29/+lv/5n/9Jnff5z3+eZ599lm9+85v85je/YdmyZTz99NOD+yKH2Cn9P1DtaKZqB/2YxaDVNUPCBEPHzM3ADvr7/1qZ5eTWf0hu2E2ycsMCx0HNLUPX47h0E0O3eryldi2K2D/5MBPeK8VJKNhGMlmptsrBybX9ikGPa2QdDpJTEyLrcAgjkf7X1+huYlPBJjYWbuSDnG3E9Tg6BqXqBM7QzmO8VkGGkj2o1UdjR5La2kuS8jsmc8KHmN+yixmRanTStzBNRSOiu4loOvZpnyYWLMLpmMkUCARIdBnrYSguPJoHl5LeNLcrj6oR1HSMoa72U7VkgtJ9Ut0nho219h3QNBRXx78xl4ETTz4+mIS1ePFi/s//+T+cdtppXHbZZVxzzTVcfPHFLFu2jGeeeYazzz6bf/zjH+Tk5DB58tEeqZ/97GdZvnw53/zmN/nTn/7Er371q7GbsB555BEuuugi5s6d22sH4JOR2pKBHUoWEYSNKK0Z1dhWFFXzEDTceDiBhOXLIavhLEr2ZOKN+4i6WqmdUkM8T0cl+cZtA/GOHnudW3xdiyKiBa1Ysw5SuisfX8RN2Bvj4ORaGgv7vk/L0+YipzpZ1ZdRH+ix1bc3VMmmwk1sKNjIvox9OIpDrlLITO0sxmkVFKnj0PvYQuuvBjvBVjPM1kQb++30CcYBK8qZ7fs5q30f0yLVqXlhjqIS0TxEVJ2I20dE95BQdbBMFJcfT1Z571+v6sGjeZPNZ3ujgE/VCGg6+lB1Pu9yI68RKkazug9/FGLo2Q3N4E0vgsLQk48PQiAQYMOGDbzxxhusXbuWa665hpUrV/KFL3yB8847j0cffZRnnnmGZcuWpZ2XnZ1NVlYWzzzzDNOmTcPnO/n+H/T7nWzKlCn8/ve/59///d8599xzueiii5gyZcpwxjZoruoioqFmotF6Gls+REFB011YZozGlg/JYiqeLtVlnSXnnrBO1GdyaEILTfnJuUyZRzxUfFSCo9o4fhuvmU35jhwOeA/RUNiaWkUdT2NhK42FrakbdnuwIdTgTyUpX1v3rb44H+RuY1PHVl+DtxEvfsZpk7hMWzqoYomuGuwEW+MtbE20sL/bc0Erytz2/cxvr2RqpAYdh4Qng2jeNOKhEmLBYuLBQhItB0nsexXQkjOzLBOw0Ivmpr1eZ5d0w+g5GLGTqij4VA3/UBVSKGqy9Nzwpt3Iq2hj44cxMfap2RnYLW3g6rKKT5io2YNvBaZpGgsWLGDBggXMnDmTNWvWsHz5csrLy3nttdf4/e9/z1tvvdXjvGuuuYavfvWrPPXUU4OOYTj0+3/npz/9aT796U9z4MAB3njjDX784x+jaRoXX3wxF1xwAYWF3XuRjz4llnyzbw1XJpNVx6A+TdOwLIvWcGUqYXWWnNsqmIaDK6YzaVs2lfphIiUtlO/LxVHtZGWf42DpFqqpkrMjj6r8vpvedrc/bvJe1KStOUpAgTM8OhMUF1mHk81ks2t6bvU1uZvYVLCZTQWbeD/3AxJ6giJ1HFO0uYzXKshTCgc/Z8mxaYwe4f1YPe85sF9PvxE4aEWY176fs9oqOS3egBksIpY7gfrQ+cRDJVi9DCLUM8uBBZjVG3HiLSiuEHrR3I7Hj07wdatu/LqfFnp+H42uk3wHm6gUJVkw0S1JCTEatEvmY//hbzhxwNCTlyssC+2S+YN63R07dqCqamq7b/Pmzalu68uWLePOO+9k0qRJlJaW9jj3qquuorq6mk984hNUVVUNKo7hcMI/TpaVlXHttdcyZ84cfvnLX/K73/2OP/3pT1RUVPDFL36R8vLyYQhzYJyO5qGmGUHrdsE8OeDs6AqnZG+IhGISJoplJ1AV8Ks+ivdk8kFJA1q7C9Mw0wbJ2pqNJ9z3NZbu9sdN1rXHUYGSmI+ptRmcXp/Fac0hVCc94ewL7WNjwSY2Fmxib+Zegmom47UKFqmfoVSbgEtx9/5J+kkxwxjhQzTV17EhHmWDEWK/Oxu0o4kqw4xwZvs+5lhNjPe4SWSVEBt/Oof8edDPBKlnlqcSVKc+J/h24enY9ht0N4rUfVLeZNcJSVLiJKFNmwifWTTkVYJtbW187Wtfo6mpCV3Xqaio4IknngDgc5/7HLfffjuPPfZYr+cGg0HuvvvuQX3+4XRCCauqqorXX3+ddevWoes6F154IXfffTehUIgXX3yRVatW8fjjjw9XrCfM9uwENHTdi2XGUissANu20TtXEYqNEVZo0ppBcVBQsXBooZ3MthCm4xD1xXFFdWz9aCGBaqlEfenXdDpXUF1L0se5dHCgucbDVbWFzGzIpqg9fX84oSbYlrONjYWb2JS/mRZfa8cYjqlcoH2KTLU/Hd374FjokcMY4YMY4YPUxxrZ6Mpkvb+c/e5C6JJzM8wIs81GZroUSkI5mGUXYOseGgf+2YHktp9b8+BR3X1en+rc9vNp2qCvT0kJuhgLtGkTB52gujvzzDN58803e30uLy+PRKJnT7rKysoej5WXl59U92DBCSSse+65hyNHjnDuuedy2223pVWXAHzqU5/ir3/965AHOBhmURTwE/SV09jyIZZloekqpmVhYxMIFmK521AUmyPeOnxRL2ZH41oFBd3WOOJJdlk/OLmWivdKwUyurFSrZ4Vf1xWUSwE7phCuDlLSnEPZkQwuiqevKJpdzamtvq157xMyshmnVXCxtoQitRRtgMUSaqIFo/1gKkEZ4SqqdR9/95fzjn88B7PmpB2fYSeYqdpMC4UoDhajdqxq4r29+AnSFRcezY1LcfVoA5U6RlXJMtz4jfigVkDSu0+IU1u/3xGXLl3KvHnzjlkheDKtroBU2brhzibim83OuIdWRUN3tzHd10JR0A8do0PWlv2DpTsXoVgKCdXEsHV0R2Nt2T+oYDKNha3sJlnh5wm7iPriPSr83oua5EXcnNGQzYy6LCqaQujdtvr2B/cn740q3MSejGo0q5SAM4EvBm/Dp/QxB/6YX2QCI1KdlqC0RPJa0CEjg/X+8awvmc1BV1baaRnADLefufk55DjWkPfXc6luPKq3z5t8UcCravg7mtAGdIPGAcSgaC4wvLKSEuJjoN8Jy+v1UltbmzZVs6qqirq6OmbNmjUswQ1WxLIxFag1YYOdie2ycOsqcSvExngGnlgrZe7k8vhQfi1/5GUuPDCfrEiQRm8rb5S9w6H8WipIriY7K/zSOBBq8JFdk8Edh/yUtKcnHVMx2Za7jY0Fm9hcsIUGl4FhjcPnzCcYyQZH4cKMEL7+XJNyHLR4QzIxdSQoPXIYpeN+Jwc4ZGSyPusM3vGXU+XKTDs9U9GY4fIzw++hyGugqgqBgI+2Lvc/DYaCkuxGoXn63PbTFQWfpuNVtQFX+0mSEuLjqd8Ja/Xq1Tz00ENpj3k8HlavXs2Pf/zjIQ9sSLiieHSTbc0hHM3CUB0UBXTVwbRhS8RHmTt5z8MUbwWbc7ewO7cSTdGwnOS24Wxvz2SsmipZh4NkVwfJOhzEE09PNi2uFjbnv8fGgo18kLsfRS3kEt8Mrta+RFUcNrS10+Y4BFSFMwN+yt29JyvFimKED6UlKNVKL4V3gANGJm9nTGO9fxw1WnoZfKaiMdPwM93npcino2hDX3SgKlqq2q/XsnQFPIqGX9MG3I1CrkkJIfqdsJqbm8nKSt9WysrKoqmpaahjGjJuI7l6arM0XEp61wVdcWizjr7xFeoFzPbPYkdkN2G7HZ/qZ4q3gkK9IPlaYQMOBgjV+KhoyMZw0t80DwQPJrtM5G9hXyiOyy5DsaZhxM/h4owQ5R0dHcrdUO524/P501siOTZ6tDYtQWmxI71e9bFUN3tDp7E+MJGNRga13VYqWYrOLMPPDI+XQp+OM0yXc3TFwKt5+qxYHHQTWlXv6DjhlWtSQoj+J6yCggLef/99Tj/99NRjH3zwAfn5+cMS2FAKaBZhS0VXjtakm45CQEvvb1eoF1AYTCYoHAg2+sio9pFZEyC7JTPtWFMx2Z7zIZsKNlFZeIBAMIvx2mlMMa8k3B6l1bIIahpnZvS+glLirbibd6auO+nhKlS7Z5mDg4LpySfuK2Gvfzwb3TlsdhzqnfQmutkdSWqmy0eBV8dyOaDS1/zkQXGrbtzHuD7lVtXUtt8JU7XUvVKK1v9bBoQQp75+J6zPfe5zPPLII1x66aUUFBRw+PBh1q5dy1e+8pXhjG9IzPKGebMtiGmDqoBpK9gozPKmj7NQTZXMw378NS7yD+fgj6WXnrcarWwueI/Nedv4MKeFuJJPyJnA53POP3qQDhM93Vqa2CZ6pAYjfBBX+CB6+CB6vKnXWC3dT8JXSsJXStxXwj5PHu/ZCbYm2pNJyj5akprTmaQMP4UuHcvtYBsO1jCkKQUVj5bslt7btp+igFfV8WsaxomWpCsqqjuA6tNQ9MHdXybEx11NTQ133HEH69evx+12U15ezo9+9CNcLhcTJkzgJz/5CV/72tcAuPXWW5k3bx7Lly9n+fLl/O1vf2PPnj2pLu/z5s3rteT9xhtv5M9//jP5+fl9lr7v2LGDW265haamJmKxGBdeeGHqfrCB6nfCOuuss3jggQd45ZVX2LhxIzk5Odx///1UVFQMKoCRUOZOcB6tbIn4aLNVAprNLG+YMncCd9jAX+MmVO2lqK4Aw07/lhwKHGJTwWY25+5nfwa47fFozmxcjoLhOITtbsnBcVATTRjth46WlUeqUXrrVq6oJLxFmL5S4r5SEv5SLD2Dg04i1QW9IVqXdk5uR5KapfspNAwst4Np2CTU/s3KOlGaYuBR3bhVd69l6QOe5Nut64Tuy0YJ1x3/PCFOIa1711G//j9INFdhZBSTc9b1BCecf/wT++A4DldddRU33HADzzzzDJDsdHH48GHKysrIz8/nxz/+MbfccgsuV88dDE3T+OUvf8mXv/zlY36e5cuXc+utt3L99df3ecxtt93GnXfeyZVXXgnA1q1bB/x1dTqhG30qKirGRILqTZk7QZm7GZ/Xi3PIwrNbI78mj4KW9C1NUzH5MGcH7+V/SE1hI0WZBZRqE2lpLMAwrbQbWhOOQ5ZiYbTtTS8rN3sf12G5MjtWTyWo2ZNpUzJANXAchwN2jC2JMFvDh2jstt2XpxrM1H2coQco1Awsl4PlsonpPZPgUHGpbtyqp89uFK6OSb4nuu2X6t8nXSfEx1zr3nXUvPx9FM1A9YQw2+uoefn7sPDuASettWvXYhgG//Iv/5J6bPbs2UDy5uC8vDzOP/981qxZw80339zj/DvuuIP/+3//b6/PdXXRRRf1uvLqqrq6Oq3908yZM/v/hfThhBJWZWUl27dvp7W1Na0L+TXXXDPoQIaTkoDI4VaCVV4q6grIjGWmPd9mtLElfyubcw+wPSuKoxXi2KU4Timldgi34ebMgMprTc0ErDrKErXkx2soiteQbzag9LIFZ6sGpreEhL80laRs42hTWo/Xx762BrZEW9hqttPUbQWWrxrM1DtWUqqBY4DpsokaJn3cfztox+1G0VHtd0Itk7p0QpfpvEIcVb/+P5LJykh23FEML3bH4wNNWO+//z5nnnnmMY+55557+OQnP8mNN97Y47lx48ZxwQUX8PTTT/PpT396QDF0uvPOO7n00ks577zzWLx4MStWrCAzM3NQr9nvhPXSSy+xZs0aZs2axebNm5k9ezZbtmxh3rx5gwpgOOl7THJrMik/Mg6Xnb78rfJXsa3wQ+oKmzDyAvyjNYOwPf7oG7EKqhXmyJEDzNCbmd1+kDPDB9G7zYDqZLpzk4mpI0GZnvwe/fZsx2G/HWNLop332w/QZKevpAq6JinNhaOC6bKIGSbOML7Pq4qGV/X2ue13wp3S0/r3eQbfmFeIU1CiuQrVE0p7TNE9JJqHt+nshAkTmD9/Pr/+9a97ff6+++5jyZIlXHHFFYP6PCtWrOATn/gEL7zwAs8//zw///nPee+991KDJQei3wnr+eef57777mPatGmsWLGCu+66i02bNrFu3boBf/Lhdt57R5OppVjszNrFB/k72JW7jxZ3hIASYmH2J1AUCDfVUGw1UBw/TGG8hsLEYbLMpl5f19a8qVVTMkmV4Gje3o91HPZZMbaY7bxvttPcbSVV2CVJFWguUMAybGKGiW0MR43fUYbiIsPIwq17en1e7+iU7utnp3RFc6EYPllJCdEPRkYxZntd8ge7Do4ZxcgoPsZZxzZjxgz+8z//87jH3XfffXz2s5/loosu6vFcRUUFs2fP5re//e2A4+hUXFzMjTfeyI033sjpp5/erxXgsfQ7YbW0tDBt2jQAFEXBtm3mzJnDT37ykwF/8uHWbrSzM383m7PfZ3/2EWwDNNXAsRWyLI3MWBXB2IsY4YPcEa7C6HbtCMBGwfIWdiSnsmRhhCs7bYx7j3Mch71WNDmZ1wzT2i1JFakuzvRmMhWDfDW58rN1h7hhYbnsYdvy6+TuGJKoo+HSDKJ0uRn5BG/ylRt6hRiYnLOup+bl72OTXFk5ZhTHSpBzVt+FDMdz6aWXct999/GLX/widR1q/fr1hMPh1IgRgKlTpzJ9+nT+/Oc/M39+z3Em999//6BXWC+88AILFy7EMAxqamqor6+npKRkUK/Z74SVnZ1NbW0t+fn5FBUV8e677xIMBk/q6cPvXrETw/BS29BEdqyFwmiM/EQ7ubFW/FZnefi+tHNaVT81rkIOuQqoMgqYnDOJcd7j9/jrTFLJlVTPJFWsupilJ0vQ81QDn89Pe7Qd07AxXdawbvnB8cvST+gm384KP5df7pUSYoCCE86HhXcPaZWgoij813/9F3fccQcrV67E4/Gkytq7u//++5kzZ07PFyG5Ups7dy4bN27s9flly5bx6quvUldXR2lpKQ899BA33XRT2jEvvvgit99+Ox5Pcgdn1apVg56bqDhOP8bkAq+++ioZGRnMmTOHTZs28cMf/hDTNFmxYgWLFy8+7vmbN2/mySefxLZtFi5cyNKlS9OeD4fD/OQnP6G+vh7Lsvj0pz/NJZdc0q9z+/LuU1/u6LdX3XthhKJheotJ+MtI+ErYq+fzVkw7etPvMdomAVhpSaqdNie9tLykS5LKVTuq7RSwdBtPto+WWGsvrzq0km2TvHj6uD6Vk5mF1dbWrwGJiuZCcfmHpcIvNzeXurrRL2uXOCSOgcbRtc+qGB79Wh45jsO0adPIzc0FYM6cOTz55JOYppnKnsdi2zarV6/mgQceICcnh3vvvZd58+allTy+8MILlJaWcs8999DS0sLtt9/OhRdeiKqqxz23L776d9I+btU91Li8NLuy8GfOIjs0E5SjS5ti4OrjLKYsx2FPlyTV3i1JlXZJUjnq0ZJwW0uWopuGDSq4DAd6r98YEpqi49W8uPtom+RSVQKaTqHHS2Mk2ufrpEZ2GF4U9eRdTQshTn39egdSFIVvfvObrFmz5uiJut7v7cDdu3dTWFhIQUGy7dF5553H+vXr05KOoihEo1EcxyEajRIIBFBVtV/n9qXRU4aRMSFVIOHofgp9fkLh3u+T6ovlOHzUkaQ+6CVJjVPdzDT8zNR9ZHdJUo5CMkm5bBxteAsoOmmKge8Y/f36NclX1Tp6+Pmkh58Q4qTR7x+Zy8vLqa6uHtBFs4aGBnJyjk7MzcnJYdeuXWnHXH755fzgBz/glltuIRKJcOedd6Kqar/O7ct/BD7PFwqT9z5VxmJsaG6gra6egHLsLumQTFK7rUhHkgoT7pakxqeSlJ+sriuPji0/02Vj686wF1B0Sjai9fV+o69Cqiy9z7ZJqpa8qVf3SnskIcRJqd8Ja8aMGTz88MNcfPHFqa3BTpdeeukxz+3tMln3ayDvvfce48eP51//9V85fPgw3/72t5k6dWq/zu300ksv8dJLLwGwcuVKwo4Hn8/PR+3tvN7ahgZ4FYWo4/B6axtul5tJfn/qfNOx2RFvZ1O0mS2xVsLdCicmGj7muEPM9oTI6lZs4GgOltvGcjloatrU+V5pukYgMICBjd24VBdezY+rl5WQqigENIOAbvReSKEouLxB8gL5qMbxt3aHk67rPf5dSRwSh8Qhuup3wtqxYwf5+fls3769x3PHS1g5OTnU19enPq6vr+8xqmTt2rUsXboURVEoLCwkPz+fqqqqfp3b6bLLLuOyyy5LfexTooTD7bzZ0ACOjdaxutAAy7F5s6GBPBx2WhG2JtrZZoaJcHQlpQDjNXfympTuJ6NzJRVLECYBCpiGjeWysTUHTJK/+iEQCAxqcGLnRF9FUYkSSStN77x/yqtq2Eqclm7nHm2P5CEvM5OGujpgaIY4DtRYuKgucUgcUnQxuvqdsL71rW8N+JNMmjSJ6upqamtryc7O5s033+S2225LOyY3N5etW7cybdo0mpqaqKqqIj8/H7/ff9xz+zLHnyxdb7Us3OrRFYaNQ1izOKBEea+thWiXCkLFcRgXb+P0eJRZwWKyfD3/EaYKKEbgnqmujjfR193R38/Ty/1Qcr+UEGKs63fCsu2+u4Grx+krp2kaN954I9/97nexbZtLLrmEsrIyXnzxRQAWL17M1VdfzU9/+lO+8Y1vAHDdddcRCiXblvR2bn9MycwGIKhptNomUc2mSTVpUhPYXRKNAkxAYXrTfqZFWgkqgGVCyyGsEgUtmLxuZxk2prvj2tQIOuZE32Ndn+ocgGj4pMJPiI+J4R4vcuDAAa6//npqampQVZV//ud/5vbbb+8Rx6iOF1m2bFmfzz377LPHPX/u3LnMnTs37bGu929lZ2fzwAMP9Pvc/kg4NjvMCA2eOHvNKKbaJdE4yfuk5ruCnK77ce19BScRhs7KR10H0yRx5H2c3KIRubm3Oy010dfV4x6qPm/0lQGIQowZhw6uY/sHa2hrqyIQKGbajBsoKT25x4vous6jjz7K3LlzaW1t5cwzz2TRokVMnz497bhRHS/yb//2b2kfNzY28txzz53UzW8fattPvHO7TwXVgWlNIc6rzWVBXR6tZ7TSUpS89hNNtIJ2tDrOUhOY3iiWU4vXO3xjPHpjKC48mrfXij9dVQl0XJ9KFZ90mS2l9NEXUAhxcjl0cB3vvr0SVTNwuUJEInW8+/ZK4J4BJ62RGC9SVFREUVERAMFgkGnTpnHo0KEeCWtUx4vk5eX1+PjWW2/l3nvvPW7RxWiJ46ACZzRncOHhPM5pziHLdmHbDqqlEPwwI5WwFCOIZbViuixMLQaKA2YCxR069icZQl17/PV8Lnmjb6q/X6ojekezWZktJcSYsv2DNaiaga4nm9/quhez4/GBJqyRHi9SWVnJpk2bOPvss3s8NxzjRQY19yEcDtPS0r0G7eTxWXcu/zswjpWbZ/GJukIyzC6dJ3QHd7ueHOHhtkmUTyDqrsekFbDBTAAWetGJb0WeCFXR8Gl+soxsAlogPVkp4NN08lxucgw3bjU5Ql71ZKIGClF9OclVlSQrIcactrYqNC19R0TTPLS1jf54kVWrVh2zbgGgra2Nq6++mh/96EepeoOuVqxYwfbt2/nc5z7Hq6++yjnnnEMsNrj2Pv1eYT322GNpb4yxWIzt27dz4YUXDiqA4VTitOBXgsT8JkZYTxvXoVoQCSaIhpKVhJp3PIa2ALN6I068BcUVQi+ai55ZPiyxGapBUA/22pFCVRT8moZPTV6fkgo/IU49gUAxkUhdaoUFYFlRAoGTf7xIIpHg6quv5rrrruMzn/lMn8cN9XiRfq+wOtsjdf6aPHkyt912W6/LypNFfF9y9Vc1tRnVAdVMtktSrGSJ+P45DWnH65nleKZ9Bu8Zy/FM+8yQJ6vOsvSQnkmmK6tHstJVlUzdoMBwEzQ86J4gqj8/+csVkGQlxClk2owbsK0EphnBcRxMM4JtJZg244YBv+all15KLBbjF7/4Reqx9evX89prr6Ud13W8SG/uv/9+HnnkkV6fcxyHm266iWnTpvH1r3+9z1heeOEFEonkgmDEx4t87nOfG9QnGg1nVZ5O3WkWjePCmG6L0g+y8LW5CQdi7D+jgcZx4RGJQ1N03KoHt+rqdbSHR+2YP6UZHYUT0h5JiFNd8jrVPUNaJTgS40XWrVvH008/zcyZM1MFHQ8//DD/9E//lHbcqI4X+eUvf8n555/PlClTUo/t2LGDt956i+XLlw8qiOFy8LY32fq/anC65IjBdpg4EW7VjUv19Frtl5GRQaKtDb9u4DJ8yeIJzT3i16PGQgcBiUPiGAtxSKeL4dfvLcF169YxadKktMcmTpzI3//+9yEPaqjEMsy0ZDUS0osogj2SlaJAQDcoCWaTHSzAHSxG9WYn2yVJ8YQQQvSp31uCiqL0qBqxbbvX5rQni9o5I7PlB8nefu4+VlPQkagML35PCN3w4Q4WoMRG/ydGIYQYK/qdsKZOncozzzzD//pf/wtVVbFtm9/97ndMnTp1OOMblK7XqMymSszqjUTjreAKDkkF4DFbJnUeo+n43UGCnhCazJYSQogB63fCWrFiBStXruSWW25J7eNmZWVx9913D2d8g2I2VaJnlmM2VZLY9yqgoRlerHh7x8cLBpS0dMWFV3P3OSQRVUPVPQQ9IQIuH6ps9QkhxKD1O2Hl5OTw/e9/n927d1NfX09OTg4VFRXHbXw7mszqjcmEVb0R0EA3kp1udQPMo8/3l6648Gk+DKWXb5uigu7GMLwE3UF8mi7XpIQQYgj1O2FVVlYSCAQ47bTTUo/V1dXR1tZGeXn5cMQ2aE68peP3Zuh2Rzmannr+eJIrql56+ykK6G4UzY3H5Segu/Bo0hVdCCGGQ7+XR4899hiWld4E1jTNHk1xTyaKK9Txe0ZyXEhXlpl6vi8u1UVIzyRDD6UnK92F4gmh+fMI+fMo8OeQ6/ZJshJCjLqamhq+8IUvMGnSJKZPn84//dM/sXPnTiorK1EUhcceeyx17K233spTTz0FwPLlyykpKUm1T6qrq+tzMVJeXp66D6uvBug7duxgwYIFzJ49m2nTpvHP//zPg/7a+v0OW1dXR0FBQdpjhYWFHDlyZNBBDJfOPoB60dzkNSsTMNzH7BOoouLSPHhUd/qQRE2Hjht6Dc3Arxn4NEOuTwkhBmzD4XU8t3sNteEq8n3FLK24gTMLTu7xIp3Wrl1Lbm5un88Px3iRfq+wsrOz2bNnT9pje/bs6XNc/cmg8/qUnlmOMX4BisuPnYiguPwY49MLLgzFRVAPkmlk4Vd9yWSlauDyo/hyUL05+Dwh8twBCtzJ7T9JVkKIgdpweB2/2LqSxmgdASNEY7SOX2xdyYbD6wb8mn2NF+ns+ZqXl8fChQtZs2ZNr+d3jhcxTbPX50/EqI4XueKKK1i1ahVLliyhoKCAw4cP86c//emYjQ9H285IhNO8Ha37M8vRM8vTOl2oqLi1ZFl6ajWlqGB4kjfyqskVlK9jRaWfxAUmQoix5bnda9AVA09H81uP7iVqJh8f6CprpMaLKIrC4sWLURSFW265pdftvuEYL9LvhHXZZZfh9/t55ZVXUlWC119/Peecc86gAhhO61paUwmrk6IouFRXx02+rs4HkzOlOgooINmIVrb9hBDDpTZcRcBIv47u1jzURkZ/vMiSJUu44oor+nyNdevWUVxcTG1tLYsWLWLq1Kk9Or+vWLGCT3ziE7zwwgs8//zz/PznP+e9997D7R54n9QTqhI499xzOffccwf8yUZaU5cikc7VVLYrh7ZoWzJJaa5kk1ntaFskQ1UJ6C58cpOvEGIY5fuKaYzWpVZYADErSr735B8v0tk3MT8/n6uuuop33nmn19catfEiAE1NTbz77rusXbuWV155JfXrZJWpaWiKQaDj2pRP9aHpHhR3KHldypOZ7IyuKLhUjRyXl3y3X5KVEGLYLa24AdNJEO0YLxI1I5hOgqUVJ/d4kfb2dlpbW1N/fvHFFzn99NN7HDeq40XeeecdHnvsMYqKijhw4ABlZWUcOHCAqVOncumllw4qiOGyOLOQTD0jrcJP9+eixBtTx3g0nYDuOjp6XgghRkDyOtU9ySrBSBX53sFXCY7EeJHDhw9z1VVXAclbm6699louv/zyHseN6niRb3zjG3z2s5/l3HPPZcWKFTz55JOsXbuWAwcOcP311w8qiOHy9vZ3O6b0Hs3LWVlZNDU14lUNArqBMUqJaiyMS5A4JA6Jo/9xyHiR4dfvLcG6uroe168uvvhiXn/99SEPaqiormBaslIVhQyXhwK3nyyXZ9SSlRBCiBPX7y3BUChEU1MTmZmZ5OXlsXPnToLBYI+RIycjl6rh1wy8mk6Gy0NCGZkBjkIIIYZOvxPWwoUL+fDDDznnnHO44ooreOihh1AUhU996lPDGd+g+DQjOdFXVlJCCDHm9TthLV26NPXniy++mBkzZhCNRtPuZO68P+tkkeXyHP8gIYQQY8KAWzfk5uamJSuAr3/964MOSAghhOjNkPYa6mfBoRBCCHHChjRhycBCIYQYXSMxXuTGG28kPz+/xw3DDQ0NLFq0iMmTJ7No0SIaGxt7nGvbNrfddhunn346M2fO5KyzzmLv3r39+tqkm6sQQoySN2sq+fIbf+DK/3mKL7/xB96sqRzU63WOF1mwYAEfffQR27Zt4+GHH+bw4cMAqfEi8Xi81/M7x4scz/Lly3nhhRd6PL5y5UoWLlzIrl27WLhwIStXruxxzLPPPktVVRVbtmxh69at/Nd//Ve/m+JKwhJCiFHwZk0lP3jvVeqi7YQMN3XRdn7w3quDSlojNV7koosuIjs7u8fjzz//PDfckGwtdcMNN/Dcc8/1OKa6upqioiLUjukXpaWl/R5TJdewhBBiFDy9ayOGquHVDRRFwdvReefpXT3bIfVXf8eLPProoz0myEP6eJGBOHz4MEVFRQAUFRVRW1vb45jPf/7z/OlPf2L27Nl84xvfYNOmTf1+/SFNWD/84Q+H8uWEEOKUVRVuwaOl31nk0XSqwi3D+nn7M15k1apVw9YUorS0lB07dvC9730PVVVZuHAhL7/8cr/OPeZ9WP0Zkwzws5/9DOCY45KFEEIcVewLURdtx6sfnQ4RtUyKfaFjnHVsIzVepC8FBQWpLb/q6mry8/N7Pc7tdvPJT36ST37ykxQUFPDcc8+xcOHC477+MRPW1772tRMOWAghxPF9cfJcfvDeq2AmV1ZRyyRhW3xx8twBv+all17Kfffdxy9+8QtuvvlmIDleJBwOM378+NRxXceLzJ8/v8fr3H///ccc4NiXJUuWsGbNGu655x7WrFnDlVde2eOYjRs3UlhYSHFxMbZts2XLFmbNmtWv1z9mwpo+ffoJByyEEOL4ziss5/9jAU/v2khVuIViX4gvTp7LeYXlA37NkRgvArBs2TJeffVV6urqKC0t5aGHHuKmm27innvu4fOf/zyrV69m3Lhx/O53v+txbm1tLTfffHOqfH7+/Pnceuut/fv6+jteBKCyspLt27fT2tqaVmBxzTXX9PclRlRVVc9R02NhTIHEIXFIHGMvDhkvMvz63UvwpZdeYs2aNcyaNYvNmzcze/ZstmzZwrx584YzPiGEEAI4gSrB559/nvvuu4+77roLl8vFXXfdxde//nU0TTqhCyGEGH79TlgtLS1MmzYNSO6T2rbNnDlz2LBhw7AFJ4QQQnTq95ZgdnY2tbW15OfnU1RUxLvvvkswGETX+/0SQgghxID1O9tceeWVHDp0iPz8fD772c/ywx/+ENM0WbFixXDGJ4QQQgAnkLAqKyu54IILAJgzZw5PPvkkpmni8ciQRCGEEMPvhFozrVq1ittuu43f/va31NbWSrISQoiTzGiOF+nqwQcf5JFHHhmyrwtOIGEtX76cn/3sZ3zpS1+irq6O+++/n7vvvps///nPQxqQEEJ8XLxZXctXX/sHV/33Wr762j94s7pns9gTMdrjRYbbCa2wVFVl1qxZfOUrX+HRRx8lGAwOuKuvEEJ8nL1ZXcsjmz+gLhoj5NKpi8Z4ZPMHg0paoz1eZLidUMKKRqO8/vrrfO973+P2229H0zS++tWvDldsQghxyvrVzj0YqopX1zrGi2gYqsqvdu4Z8GuO9niR4dbvoosf/vCHbNq0iYkTJ3L++efz1a9+lVBo4F2FhRDi46yqPULI1X28iEpVe2RYP29/xossWbJkQM1vh1u/E9bEiRO5/vrrZYSIEEIMgWK/l7poDK9+tFtQ1LIp9nsH/JqjPV5kuPV7S3Dp0qWSrIQQYohcd9pEErZNxLRwHIeIaZGwba47beKAX/PSSy8lFovxi1/8IvXY+vXree2119KO6zpepDf333//kFf4DYUhnTgshBCif84ryuebs2eQ63HTEjfJ9bj55uwZnFfU+9DD/ugcL/K3v/2NSZMmMWPGDB588MFeO8nff//9HDx4sNfX6Rwv0pdly5Zx7rnnsmPHDkpLS1m9enWvx33nO9+htLQ09WuwTmi8yFgj40UkDolD4hipOGS8yPAbsUaAmzdv5sknn8S2bRYuXMjSpUvTnv/jH//IG2+8AYBt2xw8eJDVq1cTCAT46le/isfjQVVVNE1j5cqVIxW2EEKIk8SIJCzbtlm9ejUPPPAAOTk53HvvvcybNy9tibhkyRKWLFkCwLvvvstf/vIXAoFA6vlvfetbUpUohBAfYyNyDWv37t0UFhZSUFCAruucd955rF+/vs/j161bx/nnnz8SoQkhhBgjRmSF1dDQQE5OTurjnJwcdu3a1euxsViMzZs3c9NNN6U9/t3vfheARYsWcdlll/V67ksvvcRLL70EwMqVK3utatR1/aSodpQ4JA6JQ+IQJ2ZEElZvdR2KovR67IYNG5gyZUraduC3v/1tsrOzaW5u5jvf+Q7FxcVMnz69x7mXXXZZWjLr7eLoWLh4K3FIHBLH2ItDii6G34hsCebk5FBfX5/6uL6+nqysrF6PXbduXWqMSafOnlUZGRmcddZZ7N69e/iCFUIIcVIakYQ1adIkqqurqa2txTRN3nzzTebNm9fjuHA4zLZt29Kei0ajRCKR1J+3bNnCuHHjRiJsIYQYc4Z7vMiBAwe45JJLmDZtGjNmzODHP/5xr3EMx3iREdkS1DSNG2+8ke9+97vYts0ll1xCWVkZL774IgCLFy8G4J133uGMM85Im7PV3Nyc+qIty+KCCy5g9uzZIxG2EEIMq38civHrbVGq22yKAirXTvdwTol7wK/XOV7khhtu4JlnngGStxQdPnyYsrKy1HiRW265BZfL1eP8zvEiX/7yl/v8HLqu8+ijjzJ37lxaW1s588wzWbRoUa+XaYbaiN2HNXfu3B53Tncmqk4LFixgwYIFaY8VFBSwatWq4Q5PCCFG1D8Oxfjh+jCGCkEX1Edsfrg+zNdhwEmrr/EikJwan5eXx/nnn8+aNWu4+eabe5zfOV6kt+c6FRUVUVRUBEAwGGTatGkcOnRoRBKWtGYSQohR8OttUQwVPLqCoih4dAVDTT4+UCM9XqSyspJNmzZx9tlnDyjeEyUJSwghRkF1m41bS3/MrSUfH079GS+yatUqbPvYcbS1tXH11Vfzox/9aMSaOkjCEkKIUVAUUIl1W+TErOTjAzVjxgw2bNhw3OPuu+8+vv/97/ealPozXiSRSHD11Vdz3XXX8ZnPfGbA8Z4oSVhCCDEKrp3uIWFD1HRwHIeo6ZCwk48P1EiMF3Ech5tuuolp06bx9a9/fcCxDoQkLCGEGAXnlLj5+lk+crwqrXHI8ap8/SzfoKoER2K8yLp163j66ad55ZVXmD17NrNnz+a///u/ez1WxoucABkvInFIHBLHSMUhnS6Gn6ywhBBCjAmSsIQQQowJkrCEEEKMCZKwhBBCjAmSsIQQQowJkrCEEEKMCZKwhBDiFDLc40UAysvLmTlzJrNnz+51VBQMz3gRSVhCCDFK6nabbHg6wt8fC7Ph6Qh1u81BvV7neJEFCxbw0UcfsW3bNh5++GEOHz4MkBovEo/Hez2/c7xIf6xdu5bNmzfz7rvvDirmEyEJSwghRkHdbpMdL8SJtTnoXoi1Oex4IT6opNXXeJELL7wQgLy8PBYuXMiaNWt6Pb9zvIhpDi5xDhdJWEIIMQr2vZVA0UBzJceLaC4FRUs+PlAjNV5EURQWL17MmWeeyRNPPDHgeE/UiA1wFEIIcVSkKbmy6ko1ko8Pp/6MF1myZAlXXHFFn6+xbt06iouLqa2tZdGiRUydOpWLLrpouEJOkRWWEEKMAm+mgt1tMWUnko8P1EiNF+nsm5ifn89VV13FO++8M+CYT4QkLCGEGAXjzzVwLLDiyfEiVtzBsZKPD9RIjBdpb2+ntbU19ecXX3yR008/fcAxnwhJWEIIMQpyK3SmXO7CHVAwI+AOKEy53EVuxcCv1IzEeJHDhw9zwQUXcMYZZzB//nyuuOIKLr/88l6PlfEiJ0DGi0gcEofEMVJxyHiR4ScrLCGEEGOCJCwhhBBjgiQsIYQQY4IkLCGEEGOCJCwhhBBjgiQsIYQQY4IkLCGEOIWMxHiRG2+8kfz8/B43DDc0NLBo0SImT57MokWLaGxs7HFuZWXlgG80loQlhBCjxNzaSvSRSiL37CT6SCXm1tZBvd5IjRdZvnw5L7zwQo/HV65cycKFC9m1axcLFy5k5cqVg/p6upOEJYQQo8Dc2kri19U4zQnwqzjNCRK/rh5U0hqp8SIXXXQR2dnZPR5//vnnueGGGwC44YYbeO655wb4lfROEpYQQowC83/qQVdQ3CqKkvwdXUk+PkAjNV6kL4cPH6aoqAiAoqIiamtrB/Q6fZGEJYQQo8Cpi4OrW2d2l5J8fBj1Z7zIqlWreu3kPtokYQkhxChQcl0Q79bKNe4kHx+gkRov0peCggKqq6sBqK6uJj8//4Rf41gkYQkhxCjQP5EDpoMTs3Gc5O+YTvLxARqJ8SLHsmTJktT1sTVr1nDllVee8GsciyQsIYQYBfrMIMa1RSgZBrTbKBkGxrVF6DODA37NkRgvArBs2TLOPfdcduzYQWlpKatXrwaS18f+9re/MXnyZP72t79xzz339Hp+53mdv373u9/17+uT8SKjQ+KQOCSOUysOGS8y/GSFJYQQYkyQhCWEEGJMkIQlhBBiTJCEJYQQYkyQhCWEEGJMkIQlhBBiTJCEJYQQYkyQhCWEEGJMkIQlhBBiTJCEJYQQYkyQhCWEEGJMkIQlhBBiTJCEJYQQYkyQhCWEEGJMkIQlhBBiTNBH6hNt3ryZJ598Etu2WbhwIUuXLk17/o9//CNvvPEGALZtc/DgQVavXk0gEDjuuUIIIU59I5KwbNtm9erVPPDAA+Tk5HDvvfcyb948SktLU8csWbKEJUuWAPDuu+/yl7/8hUAg0K9zhRBCnPpGZEtw9+7dFBYWUlBQgK7rnHfeeaxfv77P49etW8f5558/oHOFEEKcmkZkhdXQ0EBOTk7q45ycHHbt2tXrsbFYjM2bN3PTTTed8LkvvfQSL730EgArV64kNze3xzG6rvf6+EiTOCQOiUPiECdmRBKW4zg9HlMUpddjN2zYwJQpUwgEAid87mWXXcZll12W+riurq7HMbm5ub0+PtIkDolD4ji14iguLh7haD5+RmRLMCcnh/r6+tTH9fX1ZGVl9XrsunXruOCCCwZ0rhBCiFPXiCSsSZMmUV1dTW1tLaZp8uabbzJv3rwex4XDYbZt25b2XH/PFUIIcWobkS1BTdO48cYb+e53v4tt21xyySWUlZXx4osvArB48WIA3nnnHc444ww8Hs9xzxVCCPHxMmL3Yc2dO5e5c+emPdaZqDotWLCABQsW9OtcIYQQHy/S6UIIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJggCUsIIcSYIAlLCCHEmCAJSwghxJigOI7jjHYQQgghxPF87FZY99xzz2iHAEgc3Ukc6SSOdBKHgI9hwhJCCDE2ScISQggxJnzsEtZll1022iEAEkd3Ekc6iSOdxCFAii6EEEKMER+7FZYQQoixSRKWEEKIMUEf7QCGy+bNm3nyySexbZuFCxeydOnStOcPHTrET3/6U/bu3csXvvAFlixZMipxvPHGGzz//PMAeDwevvSlL1FeXj7icaxfv55nn30WRVHQNI3ly5czderUEY+j0+7du7n//vu58847Oeecc0Y8jg8++IAf/OAH5OfnA3D22Wfz2c9+dsTj6IzlqaeewrIsgsEgDz300IjH8cc//pE33ngDANu2OXjwIKtXryYQCIxoHOFwmJ/85CfU19djWRaf/vSnueSSS4Y0hv7E0dbWxs9+9jMOHz6MYRh8+ctfZty4cUMeh+jGOQVZluXceuutTk1NjZNIJJxvfvObzoEDB9KOaWpqcnbt2uX8+te/dp5//vlRi+PDDz90WltbHcdxnI0bNzr33nvvqMQRiUQc27Ydx3GcyspK5/bbbx+VODqPe/DBB52HH37Yeeutt0Yljvfff9/53ve+N+Sf+0TjaGtrc+644w7nyJEjjuMk/92ORhxdrV+/3nnwwQdHJY7f//73ztNPP+04juM0Nzc7y5cvdxKJxIjH8R//8R/Ob3/7W8dxHOfgwYPOQw89NKQxiN6dkluCu3fvprCwkIKCAnRd57zzzmP9+vVpx2RkZFBRUYGmaaMax5QpU1I/pU6ePJn6+vpRicPj8aAoCgCxWCz155GOA+Cvf/0rZ599NqFQaMhjOJE4hlt/4vj73//O2WefTW5uLpD8dzsacXS1bt06zj///FGJQ1EUotEojuMQjUYJBAKo6tC+jfUnjoMHDzJz5kwASkpKOHLkCE1NTUMah+jplExYDQ0N5OTkpD7OycmhoaHhpI/jlVdeYc6cOaMWxzvvvMMdd9zB9773Pb785S+PShwNDQ288847LF68eMg//4nEAbBz507uuusuHn74YQ4cODAqcVRXV9PW1saDDz7I3XffzWuvvTYqcXSKxWJs3rx5WLZp+xPH5ZdfzqFDh7jlllv4xje+wYoVK4Y8YfUnjvHjx/P2228DyQR35MiRUXmP+bg5JROW00ul/nCsGIYyjvfff5+1a9dy3XXXjVoc8+fP50c/+hF33XUXzz777KjE8dRTT3HdddcN+ZvQicYxYcIEfvrTn7Jq1Souv/xyVq1aNSpxWJbF3r17ueeee7j//vv5/e9/T1VV1YjH0WnDhg1puwIjHcd7773H+PHj+fnPf86qVatYvXo14XB4xONYunQp7e3t3HXXXfz1r39lwoQJw/pvViSdkkUXOTk5aVtr9fX1ZGVlnbRx7Nu3j5///Ofce++9BIPBUYuj0/Tp03n88cdpaWkZ0m25/sTx0Ucf8eMf/xiAlpYWNm3ahKqqzJ8/f0Tj8Pl8qT/PnTuX1atXj8r3Iycnh2AwiMfjwePxMG3aNPbt20dxcfGIxtFp3bp1XHDBBUP2uU80jrVr17J06VIURaGwsJD8/HyqqqqoqKgY0Th8Ph9f+cpXgGSCu/XWW1MFOmL4nJI/EkyaNInq6mpqa2sxTZM333yTefPmnZRx1NXV8cgjj3DrrbcO6ZvQicZRU1OT+slyz549mKY55MmzP3E8/vjjqV/nnHMOX/rSl4Y0WfU3jqamptT3Y/fu3di2PSrfj3nz5vHhhx9iWRaxWIzdu3dTUlIy4nFAskJv27Ztw/Z/qT9x5ObmsnXrViD5d1RVVTXkiaI/cbS3t2OaJgAvv/wy06ZNS/shRwyPU7bTxcaNG1mzZg22bXPJJZfwmc98hhdffBGAxYsX09TUxD333EMkEkFRFDweDz/84Q+H/B/d8eL493//d95+++3URXVN01i5cuWQxtCfOJ577jlef/11NE3D5XLxxS9+cVjK2o8XR1ePP/44Z5555rBcLzleHC+88AIvvvhi6vtx/fXXM2XKlBGPA5Il5WvXrkVVVS699FKuuOKKUYnj1VdfZfPmzdxxxx1D/vn7G0dDQwM//elPaWxsBODKK6/koosuGvE4du7cyb/927+hqiqlpaX8y7/8y7Bsk4p0p2zCEkIIcWo5JbcEhRBCnHokYQkhhBgTJGEJIYQYEyRhCSGEGBMkYQkhhBgTJGEJ0YcnnniC//zP/xztMIQQHaSsXQiS9xi9/PLLfPvb3x7tUIQQfZAVlvhYsCxrtEMQQgySrLDEKeurX/0qixYt4u9//ztVVVVcffXVvPrqqzQ3N5OTk8OyZcuYP38+Bw8e5O6778Y0TVwuF5qm8dRTT/H444+Tk5PDF77wBQBeeuklnn/+edra2pg6dSo333wz2dnZo/xVCvHxISsscUpbt24d99xzD0899RTFxcU89NBDPPXUU3zuc5/jscceo7GxkdLSUm6++WZOO+00nn76aZ566qker/P+++/zm9/8hjvvvJMnnniCvLy8VJNeIcTIkIQlTmmf/OQnyc3NxeVyce6555KdnY2qqpx33nkUFhaye/fufr3OG2+8wSWXXMLEiRMxDINrr72WnTt3UltbO8xfgRCi0yk5XkSITp1NhQFee+01/vznP3PkyBEAotEora2t/XqdxsZGJkyYkPrY4/EQCARoaGiQsRJCjBBJWOJj4ciRI/z85z/nX//1XznttNNQVZW77rqr12F9vcnKyqKuri71cTQapa2tTa5hCTGCZEtQfCzEYjEURUkNYFy7dm3a2PvMzEwaGhpSM466u+CCC1i7di2VlZUkEgl+85vfUFFRIasrIUaQrLDEx0JpaSmf+tSnuP/++1FVlYsuuihtvtXpp5+eKr5QVZXVq1ennT9z5kyuueYaHn30Udra2pgyZcqwzoUSQvQkZe1CCCHGBNkSFEIIMSZIwhJCCDEmSMISQggxJkjCEkIIMSZIwhJCCDEmSMISQggxJkjCEkIIMSZIwhJCCDEm/P/qwrZnFiVgPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    select_size(results_3a_cnn, 'S')\n",
    ")))\n",
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    select_size(results_3a_cnn, 'L')\n",
    ")))\n",
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    results_3a_cnn,\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1c59bbfdb08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_3b(select_size(results_3b_cnn, 'S'))\n",
    "plot_3b(select_size(results_3b_cnn, 'L'))\n",
    "plot_3b(results_3b_cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
