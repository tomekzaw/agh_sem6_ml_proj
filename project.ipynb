{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import backend as K\n",
    "import scikitplot as skplt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layers_1_s = lambda: [\n",
    "    Conv2D(4, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_2_s = lambda: [\n",
    "    Conv2D(4, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_5_s = lambda: [\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(6, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_10_s = lambda: [\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(4, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_1_l = lambda: [\n",
    "    Conv2D(4, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_2_l = lambda: [\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_5_l = lambda: [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_10_l = lambda: [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(12, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns = {\n",
    "    'CNN 1 S': layers_1_s,\n",
    "    'CNN 2 S': layers_2_s,\n",
    "    'CNN 5 S': layers_5_s,\n",
    "    'CNN 10 S': layers_10_s,\n",
    "    'CNN 1 L': layers_1_l,\n",
    "    'CNN 2 L': layers_2_l,\n",
    "    'CNN 5 L': layers_5_l,\n",
    "    'CNN 10 L': layers_10_l,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_org, y_train_org), (X_test_org, y_test_org) = fashion_mnist.load_data()\n",
    "\n",
    "X_train_org = X_train_org.reshape(-1, 28, 28, 1)\n",
    "X_test_org = X_test_org.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_org = X_train_org.astype('float32')\n",
    "X_test_org = X_test_org.astype('float32')\n",
    "X_train_org /= 255\n",
    "X_test_org /= 255\n",
    "\n",
    "X_train_org, y_train_org = resample(X_train_org, y_train_org, random_state=0)\n",
    "X_test_org, y_test_org = resample(X_test_org, y_test_org, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(train_samples, test_samples):\n",
    "    X_train = X_train_org[:train_samples]\n",
    "    y_train = y_train_org[:train_samples]\n",
    "    X_test = X_test_org[:test_samples]\n",
    "    y_test = y_test_org[:test_samples]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_test_samples(total_samples, ratio):\n",
    "    train_samples = int(total_samples * ratio)\n",
    "    test_samples = total_samples - train_samples\n",
    "    return train_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_roc(y_test, y_pred, figsize=(8, 5))\n",
    "    ax.set(xlim=(-0.04, 1.04), ylim=(-0.04, 1.04))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_confusion_matrix(y_test, y_pred.argmax(axis=1), normalize=True, figsize=(7, 7))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_precision_recall(y_test, y_pred, figsize=(8, 6))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "    \n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_m(y_true, y_pred):  \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm(train_samples, test_samples):\n",
    "    X_train, y_train, X_test, y_test = get_train_test_data(train_samples, test_samples)\n",
    "    \n",
    "    X_train = X_train.reshape(-1, 784)\n",
    "    X_test = X_test.reshape(-1, 784)\n",
    "    \n",
    "    svc = SVC(C=5.0, kernel='rbf', probability=True)\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = svc.predict(X_test)\n",
    "    y_pred_proba = svc.predict_proba(X_test)\n",
    "    \n",
    "    accuracy = cross_val_score(svc, X_train, y_train, cv=5).mean()\n",
    "    val_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    roc = plot_roc(y_test, y_pred_proba)\n",
    "    pr = plot_pr(y_test, y_pred_proba)\n",
    "    cm = plot_cm(y_test, y_pred_proba)\n",
    "    \n",
    "    return accuracy, val_accuracy, roc, pr, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn(layers, train_samples, test_samples, epochs):\n",
    "    X_train, y_train, X_test, y_test = get_train_test_data(train_samples, test_samples)    \n",
    "    \n",
    "    clear_session()\n",
    "    np.random.seed(0x859)\n",
    "    tf.random.set_seed(0x859)\n",
    "    \n",
    "    model = Sequential(layers())\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy', f1_m])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=True)\n",
    "    \n",
    "    loss = history.history['loss'][-1]\n",
    "    accuracy = history.history['accuracy'][-1]\n",
    "    f1 = history.history['f1_m'][-1]\n",
    "    \n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    val_f1 = history.history['val_f1_m'][-1]\n",
    "       \n",
    "    y_pred_proba = model.predict(X_test, verbose=False)\n",
    "    \n",
    "    roc = plot_roc(y_test, y_pred_proba)\n",
    "    pr = plot_pr(y_test, y_pred_proba)\n",
    "    cm = plot_cm(y_test, y_pred_proba)\n",
    "    \n",
    "    return loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_size(results_df, size):\n",
    "    return results_df[results_df['model'].str.endswith(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3a(data):\n",
    "    ax = sns.lmplot(x='ratio', y='val_accuracy', hue='model', data=data)\n",
    "    ax.set(xlim=(0.08, 0.92))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3b(data):\n",
    "    ax = sns.lmplot(x='epochs', y='val_accuracy', hue='model', data=data)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>ratio</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>250</td>\n",
       "      <td>9750</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.855179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>500</td>\n",
       "      <td>9500</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.909053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>750</td>\n",
       "      <td>9250</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.919568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1000</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.927222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1250</td>\n",
       "      <td>8750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.920800</td>\n",
       "      <td>0.929143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1500</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.933176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1750</td>\n",
       "      <td>8250</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.937091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2000</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.938250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2250</td>\n",
       "      <td>7750</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>0.943097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2500</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2750</td>\n",
       "      <td>7250</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.941455</td>\n",
       "      <td>0.946207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3000</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.942667</td>\n",
       "      <td>0.947143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3250</td>\n",
       "      <td>6750</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.946769</td>\n",
       "      <td>0.949481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3500</td>\n",
       "      <td>6500</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.949143</td>\n",
       "      <td>0.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3750</td>\n",
       "      <td>6250</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.949600</td>\n",
       "      <td>0.951840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4000</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.952250</td>\n",
       "      <td>0.956833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4250</td>\n",
       "      <td>5750</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.951059</td>\n",
       "      <td>0.955652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4500</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.951556</td>\n",
       "      <td>0.956727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM</td>\n",
       "      <td>4750</td>\n",
       "      <td>5250</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.954316</td>\n",
       "      <td>0.957714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.957200</td>\n",
       "      <td>0.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVM</td>\n",
       "      <td>5250</td>\n",
       "      <td>4750</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.960190</td>\n",
       "      <td>0.961474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVM</td>\n",
       "      <td>5500</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.960182</td>\n",
       "      <td>0.961778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVM</td>\n",
       "      <td>5750</td>\n",
       "      <td>4250</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.962261</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.960250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM</td>\n",
       "      <td>6250</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.963040</td>\n",
       "      <td>0.958667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVM</td>\n",
       "      <td>6500</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.961846</td>\n",
       "      <td>0.963714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVM</td>\n",
       "      <td>6750</td>\n",
       "      <td>3250</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.962370</td>\n",
       "      <td>0.962154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVM</td>\n",
       "      <td>7000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.960571</td>\n",
       "      <td>0.964333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVM</td>\n",
       "      <td>7250</td>\n",
       "      <td>2750</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.961379</td>\n",
       "      <td>0.962182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>7500</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.963467</td>\n",
       "      <td>0.964400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVM</td>\n",
       "      <td>7750</td>\n",
       "      <td>2250</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.963556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.965375</td>\n",
       "      <td>0.964500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8250</td>\n",
       "      <td>1750</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.967394</td>\n",
       "      <td>0.965714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.966706</td>\n",
       "      <td>0.967333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVM</td>\n",
       "      <td>8750</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.968114</td>\n",
       "      <td>0.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>9000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.968222</td>\n",
       "      <td>0.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVM</td>\n",
       "      <td>9250</td>\n",
       "      <td>750</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.968432</td>\n",
       "      <td>0.974667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SVM</td>\n",
       "      <td>9500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.968737</td>\n",
       "      <td>0.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVM</td>\n",
       "      <td>9750</td>\n",
       "      <td>250</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.969026</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  train_samples  test_samples  ratio  accuracy  val_accuracy\n",
       "0    SVM            250          9750  0.025  0.856000      0.855179\n",
       "1    SVM            500          9500  0.050  0.888000      0.909053\n",
       "2    SVM            750          9250  0.075  0.892000      0.919568\n",
       "3    SVM           1000          9000  0.100  0.915000      0.927222\n",
       "4    SVM           1250          8750  0.125  0.920800      0.929143\n",
       "5    SVM           1500          8500  0.150  0.926667      0.933176\n",
       "6    SVM           1750          8250  0.175  0.931429      0.937091\n",
       "7    SVM           2000          8000  0.200  0.936000      0.938250\n",
       "8    SVM           2250          7750  0.225  0.938667      0.943097\n",
       "9    SVM           2500          7500  0.250  0.940800      0.942400\n",
       "10   SVM           2750          7250  0.275  0.941455      0.946207\n",
       "11   SVM           3000          7000  0.300  0.942667      0.947143\n",
       "12   SVM           3250          6750  0.325  0.946769      0.949481\n",
       "13   SVM           3500          6500  0.350  0.949143      0.952000\n",
       "14   SVM           3750          6250  0.375  0.949600      0.951840\n",
       "15   SVM           4000          6000  0.400  0.952250      0.956833\n",
       "16   SVM           4250          5750  0.425  0.951059      0.955652\n",
       "17   SVM           4500          5500  0.450  0.951556      0.956727\n",
       "18   SVM           4750          5250  0.475  0.954316      0.957714\n",
       "19   SVM           5000          5000  0.500  0.957200      0.958000\n",
       "20   SVM           5250          4750  0.525  0.960190      0.961474\n",
       "21   SVM           5500          4500  0.550  0.960182      0.961778\n",
       "22   SVM           5750          4250  0.575  0.962261      0.960000\n",
       "23   SVM           6000          4000  0.600  0.963333      0.960250\n",
       "24   SVM           6250          3750  0.625  0.963040      0.958667\n",
       "25   SVM           6500          3500  0.650  0.961846      0.963714\n",
       "26   SVM           6750          3250  0.675  0.962370      0.962154\n",
       "27   SVM           7000          3000  0.700  0.960571      0.964333\n",
       "28   SVM           7250          2750  0.725  0.961379      0.962182\n",
       "29   SVM           7500          2500  0.750  0.963467      0.964400\n",
       "30   SVM           7750          2250  0.775  0.964516      0.963556\n",
       "31   SVM           8000          2000  0.800  0.965375      0.964500\n",
       "32   SVM           8250          1750  0.825  0.967394      0.965714\n",
       "33   SVM           8500          1500  0.850  0.966706      0.967333\n",
       "34   SVM           8750          1250  0.875  0.968114      0.972000\n",
       "35   SVM           9000          1000  0.900  0.968222      0.976000\n",
       "36   SVM           9250           750  0.925  0.968432      0.974667\n",
       "37   SVM           9500           500  0.950  0.968737      0.978000\n",
       "38   SVM           9750           250  0.975  0.969026      0.980000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_3a_svm():\n",
    "    total_samples = 10000\n",
    "    ratios = np.arange(0.025, 1.0, 0.025)\n",
    "    \n",
    "#     total_samples = 300\n",
    "#     ratios = [0.2, 0.8]\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        train_samples, test_samples = calc_train_test_samples(total_samples, ratio)               \n",
    "        accuracy, val_accuracy, roc, pr, cm = evaluate_svm(train_samples, test_samples)\n",
    "        \n",
    "        yield 'SVM', train_samples, test_samples, ratio, accuracy, val_accuracy        \n",
    "        roc.savefig(f'plots/3a/svm_{ratio}_roc.svg')\n",
    "        pr.savefig(f'plots/3a/svm_{ratio}_pr.svg')\n",
    "        cm.savefig(f'plots/3a/svm_{ratio}_cm.svg')          \n",
    "        plt.close('all')\n",
    "        \n",
    "        \n",
    "# results_3a_svm = pd.DataFrame(gen_3a_svm(), columns=[\n",
    "#     'model', 'train_samples', 'test_samples', 'ratio', 'accuracy', 'val_accuracy'\n",
    "# ])\n",
    "# results_3a_svm.to_csv('results/3a_svm.csv')\n",
    "# results_3a_svm\n",
    "\n",
    "results_3a_svm = pd.read_csv('results/3a_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 3s 6ms/sample - loss: 2.1964 - accuracy: 0.2460 - f1_m: 9.2453 - val_loss: 2.0218 - val_accuracy: 0.4172 - val_f1_m: 8.6711\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.8281 - accuracy: 0.4860 - f1_m: 7.9242 - val_loss: 1.6493 - val_accuracy: 0.5711 - val_f1_m: 7.1644\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.4412 - accuracy: 0.6500 - f1_m: 6.1857 - val_loss: 1.3189 - val_accuracy: 0.6664 - val_f1_m: 5.2533\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.1155 - accuracy: 0.7340 - f1_m: 4.4257 - val_loss: 1.0564 - val_accuracy: 0.7389 - val_f1_m: 4.0718\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.8929 - accuracy: 0.7720 - f1_m: 3.1678 - val_loss: 0.9061 - val_accuracy: 0.7587 - val_f1_m: 3.1577\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7506 - accuracy: 0.7980 - f1_m: 2.6720 - val_loss: 0.7639 - val_accuracy: 0.8040 - val_f1_m: 2.6395\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6346 - accuracy: 0.8360 - f1_m: 2.3185 - val_loss: 0.7005 - val_accuracy: 0.8110 - val_f1_m: 2.3624\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5605 - accuracy: 0.8480 - f1_m: 2.1209 - val_loss: 0.6534 - val_accuracy: 0.8190 - val_f1_m: 2.1974\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4953 - accuracy: 0.8660 - f1_m: 1.9746 - val_loss: 0.6003 - val_accuracy: 0.8340 - val_f1_m: 2.0064\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4482 - accuracy: 0.8760 - f1_m: 1.8056 - val_loss: 0.5870 - val_accuracy: 0.8281 - val_f1_m: 1.8968\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 3ms/sample - loss: 2.2193 - accuracy: 0.2180 - f1_m: 9.7704 - val_loss: 2.0990 - val_accuracy: 0.3500 - val_f1_m: 9.5307\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.9523 - accuracy: 0.4160 - f1_m: 8.6891 - val_loss: 1.7706 - val_accuracy: 0.5071 - val_f1_m: 7.9235\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.5385 - accuracy: 0.5860 - f1_m: 6.6549 - val_loss: 1.3031 - val_accuracy: 0.6713 - val_f1_m: 5.5624\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.0810 - accuracy: 0.6920 - f1_m: 4.2316 - val_loss: 0.9413 - val_accuracy: 0.7481 - val_f1_m: 3.4919\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7882 - accuracy: 0.7540 - f1_m: 2.7160 - val_loss: 0.7262 - val_accuracy: 0.7944 - val_f1_m: 2.4816\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6505 - accuracy: 0.7860 - f1_m: 2.1524 - val_loss: 0.6549 - val_accuracy: 0.8110 - val_f1_m: 2.1526\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5255 - accuracy: 0.8220 - f1_m: 1.9818 - val_loss: 0.5416 - val_accuracy: 0.8480 - val_f1_m: 1.9136\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4736 - accuracy: 0.8360 - f1_m: 1.8035 - val_loss: 0.5397 - val_accuracy: 0.8287 - val_f1_m: 1.8449\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4162 - accuracy: 0.8740 - f1_m: 1.6441 - val_loss: 0.4629 - val_accuracy: 0.8752 - val_f1_m: 1.7101\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3457 - accuracy: 0.9040 - f1_m: 1.5663 - val_loss: 0.4631 - val_accuracy: 0.8573 - val_f1_m: 1.6208\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 3s 5ms/sample - loss: 2.2771 - accuracy: 0.1120 - f1_m: 9.7816 - val_loss: 2.2179 - val_accuracy: 0.1652 - val_f1_m: 9.5427\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 2.0334 - accuracy: 0.3720 - f1_m: 8.8239 - val_loss: 1.7869 - val_accuracy: 0.5307 - val_f1_m: 7.6567\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.3503 - accuracy: 0.5740 - f1_m: 4.6506 - val_loss: 1.0834 - val_accuracy: 0.6454 - val_f1_m: 3.0350\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.9478 - accuracy: 0.6820 - f1_m: 2.5224 - val_loss: 0.8292 - val_accuracy: 0.7456 - val_f1_m: 2.4728\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.6599 - accuracy: 0.8020 - f1_m: 2.0292 - val_loss: 0.7201 - val_accuracy: 0.7706 - val_f1_m: 1.8851\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.6065 - accuracy: 0.8160 - f1_m: 1.7442 - val_loss: 0.6461 - val_accuracy: 0.7958 - val_f1_m: 1.8223\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.4828 - accuracy: 0.8460 - f1_m: 1.6999 - val_loss: 0.5635 - val_accuracy: 0.8175 - val_f1_m: 1.6903\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.4423 - accuracy: 0.8480 - f1_m: 1.5459 - val_loss: 0.6985 - val_accuracy: 0.7848 - val_f1_m: 1.4698\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4099 - accuracy: 0.8520 - f1_m: 1.4812 - val_loss: 0.5969 - val_accuracy: 0.8151 - val_f1_m: 1.5593\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3570 - accuracy: 0.8820 - f1_m: 1.4435 - val_loss: 0.4636 - val_accuracy: 0.8610 - val_f1_m: 1.4625\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 2.2968 - accuracy: 0.1420 - f1_m: 9.9723 - val_loss: 2.2827 - val_accuracy: 0.1204 - val_f1_m: 9.6963\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 2.2083 - accuracy: 0.1860 - f1_m: 9.7727 - val_loss: 2.0161 - val_accuracy: 0.4165 - val_f1_m: 9.0180\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 1.5455 - accuracy: 0.4980 - f1_m: 5.9339 - val_loss: 1.0419 - val_accuracy: 0.6697 - val_f1_m: 2.6292\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.9168 - accuracy: 0.6900 - f1_m: 2.3927 - val_loss: 0.8738 - val_accuracy: 0.7142 - val_f1_m: 2.3026\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.6445 - accuracy: 0.8060 - f1_m: 1.7466 - val_loss: 0.6486 - val_accuracy: 0.7942 - val_f1_m: 1.6194\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.4603 - accuracy: 0.8580 - f1_m: 1.6632 - val_loss: 0.5341 - val_accuracy: 0.8464 - val_f1_m: 1.5383\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.3853 - accuracy: 0.8920 - f1_m: 1.5066 - val_loss: 0.5538 - val_accuracy: 0.8275 - val_f1_m: 1.5851\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.3061 - accuracy: 0.9160 - f1_m: 1.3571 - val_loss: 0.4932 - val_accuracy: 0.8641 - val_f1_m: 1.3281\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.2673 - accuracy: 0.9060 - f1_m: 1.2847 - val_loss: 0.4786 - val_accuracy: 0.8587 - val_f1_m: 1.4133\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.2145 - accuracy: 0.9360 - f1_m: 1.2442 - val_loss: 0.5408 - val_accuracy: 0.8586 - val_f1_m: 1.2999\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 3ms/sample - loss: 1.9811 - accuracy: 0.4160 - f1_m: 8.4310 - val_loss: 1.5430 - val_accuracy: 0.6587 - val_f1_m: 6.7836\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.2279 - accuracy: 0.7500 - f1_m: 5.1944 - val_loss: 0.9844 - val_accuracy: 0.7689 - val_f1_m: 3.7020\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7964 - accuracy: 0.8100 - f1_m: 2.8742 - val_loss: 0.7203 - val_accuracy: 0.8087 - val_f1_m: 2.5405\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5876 - accuracy: 0.8460 - f1_m: 2.2077 - val_loss: 0.5878 - val_accuracy: 0.8379 - val_f1_m: 2.1170\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4545 - accuracy: 0.8740 - f1_m: 1.7616 - val_loss: 0.5437 - val_accuracy: 0.8438 - val_f1_m: 1.8431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3872 - accuracy: 0.8920 - f1_m: 1.6907 - val_loss: 0.4901 - val_accuracy: 0.8636 - val_f1_m: 1.7346\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3304 - accuracy: 0.8980 - f1_m: 1.5686 - val_loss: 0.4536 - val_accuracy: 0.8741 - val_f1_m: 1.6352\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2848 - accuracy: 0.9260 - f1_m: 1.5017 - val_loss: 0.4422 - val_accuracy: 0.8688 - val_f1_m: 1.5868\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2464 - accuracy: 0.9320 - f1_m: 1.4383 - val_loss: 0.4291 - val_accuracy: 0.8762 - val_f1_m: 1.4983\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2106 - accuracy: 0.9580 - f1_m: 1.3784 - val_loss: 0.4344 - val_accuracy: 0.8742 - val_f1_m: 1.4830\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 3ms/sample - loss: 2.1875 - accuracy: 0.3220 - f1_m: 9.4749 - val_loss: 1.9736 - val_accuracy: 0.5026 - val_f1_m: 8.7351\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.5896 - accuracy: 0.5600 - f1_m: 6.5892 - val_loss: 1.2925 - val_accuracy: 0.6109 - val_f1_m: 4.1362\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.9330 - accuracy: 0.6960 - f1_m: 3.0451 - val_loss: 0.7972 - val_accuracy: 0.7354 - val_f1_m: 2.2817\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.6237 - accuracy: 0.7940 - f1_m: 2.0239 - val_loss: 0.6297 - val_accuracy: 0.8214 - val_f1_m: 1.9932\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.4230 - accuracy: 0.8760 - f1_m: 1.6319 - val_loss: 0.5172 - val_accuracy: 0.8496 - val_f1_m: 1.6561\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3469 - accuracy: 0.9020 - f1_m: 1.4831 - val_loss: 0.4843 - val_accuracy: 0.8636 - val_f1_m: 1.5363\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2768 - accuracy: 0.9220 - f1_m: 1.4305 - val_loss: 0.4204 - val_accuracy: 0.8759 - val_f1_m: 1.3993\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2414 - accuracy: 0.9200 - f1_m: 1.3286 - val_loss: 0.3757 - val_accuracy: 0.8953 - val_f1_m: 1.3485\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2066 - accuracy: 0.9340 - f1_m: 1.2487 - val_loss: 0.3611 - val_accuracy: 0.9014 - val_f1_m: 1.3354\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.1390 - accuracy: 0.9680 - f1_m: 1.2125 - val_loss: 0.3657 - val_accuracy: 0.8931 - val_f1_m: 1.2743\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 2.2602 - accuracy: 0.2280 - f1_m: 9.8006 - val_loss: 2.0952 - val_accuracy: 0.4622 - val_f1_m: 9.3698\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 1.5244 - accuracy: 0.5800 - f1_m: 5.8149 - val_loss: 0.9841 - val_accuracy: 0.6680 - val_f1_m: 2.1606\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.7905 - accuracy: 0.7220 - f1_m: 1.9402 - val_loss: 0.6680 - val_accuracy: 0.7946 - val_f1_m: 1.9141\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.5501 - accuracy: 0.8160 - f1_m: 1.7353 - val_loss: 0.5811 - val_accuracy: 0.8288 - val_f1_m: 1.7036\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.3730 - accuracy: 0.8900 - f1_m: 1.4561 - val_loss: 0.4484 - val_accuracy: 0.8694 - val_f1_m: 1.4032\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/sample - loss: 0.2888 - accuracy: 0.8980 - f1_m: 1.3422 - val_loss: 0.4244 - val_accuracy: 0.8775 - val_f1_m: 1.3337\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.2441 - accuracy: 0.9180 - f1_m: 1.3013 - val_loss: 0.4816 - val_accuracy: 0.8657 - val_f1_m: 1.3165\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.2053 - accuracy: 0.9200 - f1_m: 1.2547 - val_loss: 0.3741 - val_accuracy: 0.8924 - val_f1_m: 1.2507\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.1537 - accuracy: 0.9500 - f1_m: 1.1814 - val_loss: 0.3974 - val_accuracy: 0.8902 - val_f1_m: 1.2335\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.1106 - accuracy: 0.9720 - f1_m: 1.1041 - val_loss: 0.4106 - val_accuracy: 0.8961 - val_f1_m: 1.1631\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 2.2805 - accuracy: 0.1100 - f1_m: 9.8646 - val_loss: 2.1631 - val_accuracy: 0.1718 - val_f1_m: 9.1274\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 1.5828 - accuracy: 0.4640 - f1_m: 5.5601 - val_loss: 1.3943 - val_accuracy: 0.6058 - val_f1_m: 2.0101\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.8383 - accuracy: 0.7300 - f1_m: 2.0736 - val_loss: 0.7221 - val_accuracy: 0.7720 - val_f1_m: 1.8627\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.5717 - accuracy: 0.8200 - f1_m: 1.6311 - val_loss: 0.6259 - val_accuracy: 0.8164 - val_f1_m: 1.7094\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.4274 - accuracy: 0.8600 - f1_m: 1.4490 - val_loss: 0.6741 - val_accuracy: 0.8012 - val_f1_m: 1.4977\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.4067 - accuracy: 0.8700 - f1_m: 1.4084 - val_loss: 0.4648 - val_accuracy: 0.8619 - val_f1_m: 1.3907\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.2507 - accuracy: 0.9160 - f1_m: 1.2927 - val_loss: 0.5147 - val_accuracy: 0.8540 - val_f1_m: 1.2981\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.1876 - accuracy: 0.9380 - f1_m: 1.1881 - val_loss: 0.5763 - val_accuracy: 0.8567 - val_f1_m: 1.1960\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.1580 - accuracy: 0.9440 - f1_m: 1.1679 - val_loss: 0.5513 - val_accuracy: 0.8623 - val_f1_m: 1.2536\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 2ms/sample - loss: 0.1181 - accuracy: 0.9600 - f1_m: 1.1259 - val_loss: 0.5066 - val_accuracy: 0.8873 - val_f1_m: 1.1236\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4864 - accuracy: 0.8590 - f1_m: 1.8099 - val_loss: 0.5189 - val_accuracy: 0.8538 - val_f1_m: 1.6915\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 678us/sample - loss: 0.4125 - accuracy: 0.8690 - f1_m: 1.6337 - val_loss: 0.4943 - val_accuracy: 0.8609 - val_f1_m: 1.6048\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 647us/sample - loss: 0.3678 - accuracy: 0.8890 - f1_m: 1.5292 - val_loss: 0.4663 - val_accuracy: 0.8682 - val_f1_m: 1.5254\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 687us/sample - loss: 0.3364 - accuracy: 0.8960 - f1_m: 1.4801 - val_loss: 0.4468 - val_accuracy: 0.8738 - val_f1_m: 1.4722\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 680us/sample - loss: 0.3109 - accuracy: 0.9050 - f1_m: 1.4614 - val_loss: 0.4289 - val_accuracy: 0.8815 - val_f1_m: 1.4318\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 646us/sample - loss: 0.2740 - accuracy: 0.9170 - f1_m: 1.4031 - val_loss: 0.4471 - val_accuracy: 0.8753 - val_f1_m: 1.4039\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 679us/sample - loss: 0.2619 - accuracy: 0.9240 - f1_m: 1.3835 - val_loss: 0.4407 - val_accuracy: 0.8797 - val_f1_m: 1.3582\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 679us/sample - loss: 0.2416 - accuracy: 0.9290 - f1_m: 1.3355 - val_loss: 0.4481 - val_accuracy: 0.8766 - val_f1_m: 1.3508\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 647us/sample - loss: 0.2292 - accuracy: 0.9290 - f1_m: 1.3228 - val_loss: 0.5023 - val_accuracy: 0.8591 - val_f1_m: 1.3509\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 679us/sample - loss: 0.2592 - accuracy: 0.9150 - f1_m: 1.3158 - val_loss: 0.4425 - val_accuracy: 0.8793 - val_f1_m: 1.2942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4073 - accuracy: 0.8660 - f1_m: 1.5968 - val_loss: 0.4347 - val_accuracy: 0.8720 - val_f1_m: 1.5490\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 698us/sample - loss: 0.3361 - accuracy: 0.8910 - f1_m: 1.4725 - val_loss: 0.3962 - val_accuracy: 0.8835 - val_f1_m: 1.4547\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 713us/sample - loss: 0.3005 - accuracy: 0.9150 - f1_m: 1.4050 - val_loss: 0.3625 - val_accuracy: 0.8968 - val_f1_m: 1.3896\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 690us/sample - loss: 0.2690 - accuracy: 0.9210 - f1_m: 1.3416 - val_loss: 0.3685 - val_accuracy: 0.8892 - val_f1_m: 1.3718\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 702us/sample - loss: 0.2504 - accuracy: 0.9320 - f1_m: 1.3327 - val_loss: 0.3569 - val_accuracy: 0.8984 - val_f1_m: 1.3180\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 713us/sample - loss: 0.2244 - accuracy: 0.9290 - f1_m: 1.2867 - val_loss: 0.3866 - val_accuracy: 0.8862 - val_f1_m: 1.3043\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 683us/sample - loss: 0.2084 - accuracy: 0.9310 - f1_m: 1.2613 - val_loss: 0.3431 - val_accuracy: 0.9019 - val_f1_m: 1.2791\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 697us/sample - loss: 0.1911 - accuracy: 0.9480 - f1_m: 1.2427 - val_loss: 0.3291 - val_accuracy: 0.9088 - val_f1_m: 1.2652\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 708us/sample - loss: 0.1896 - accuracy: 0.9410 - f1_m: 1.2279 - val_loss: 0.3465 - val_accuracy: 0.8989 - val_f1_m: 1.2360\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 712us/sample - loss: 0.1768 - accuracy: 0.9450 - f1_m: 1.1956 - val_loss: 0.3261 - val_accuracy: 0.9032 - val_f1_m: 1.2556\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.4594 - accuracy: 0.8530 - f1_m: 1.5117 - val_loss: 0.4455 - val_accuracy: 0.8657 - val_f1_m: 1.4845\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 795us/sample - loss: 0.3368 - accuracy: 0.8990 - f1_m: 1.3629 - val_loss: 0.3692 - val_accuracy: 0.8943 - val_f1_m: 1.3425\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 799us/sample - loss: 0.3212 - accuracy: 0.9050 - f1_m: 1.3086 - val_loss: 0.4043 - val_accuracy: 0.8808 - val_f1_m: 1.3615\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 786us/sample - loss: 0.2929 - accuracy: 0.9070 - f1_m: 1.3066 - val_loss: 0.3414 - val_accuracy: 0.9022 - val_f1_m: 1.3017\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 775us/sample - loss: 0.2382 - accuracy: 0.9320 - f1_m: 1.2537 - val_loss: 0.3320 - val_accuracy: 0.9063 - val_f1_m: 1.2590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 749us/sample - loss: 0.1967 - accuracy: 0.9320 - f1_m: 1.2047 - val_loss: 0.3819 - val_accuracy: 0.8987 - val_f1_m: 1.2585\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.1972 - accuracy: 0.9350 - f1_m: 1.1912 - val_loss: 0.3035 - val_accuracy: 0.9197 - val_f1_m: 1.2047\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 799us/sample - loss: 0.1586 - accuracy: 0.9480 - f1_m: 1.1662 - val_loss: 0.3336 - val_accuracy: 0.9161 - val_f1_m: 1.1820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 777us/sample - loss: 0.1572 - accuracy: 0.9390 - f1_m: 1.1414 - val_loss: 0.3842 - val_accuracy: 0.8882 - val_f1_m: 1.2029\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 803us/sample - loss: 0.1524 - accuracy: 0.9420 - f1_m: 1.1632 - val_loss: 0.3643 - val_accuracy: 0.9065 - val_f1_m: 1.1519\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.4247 - accuracy: 0.8730 - f1_m: 1.4283 - val_loss: 0.4917 - val_accuracy: 0.8474 - val_f1_m: 1.3714\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 874us/sample - loss: 0.2894 - accuracy: 0.9040 - f1_m: 1.2933 - val_loss: 0.4044 - val_accuracy: 0.8828 - val_f1_m: 1.2792\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 954us/sample - loss: 0.2616 - accuracy: 0.9180 - f1_m: 1.2377 - val_loss: 0.3720 - val_accuracy: 0.9003 - val_f1_m: 1.2056\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 909us/sample - loss: 0.2271 - accuracy: 0.9350 - f1_m: 1.1924 - val_loss: 0.4280 - val_accuracy: 0.8777 - val_f1_m: 1.2888\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 918us/sample - loss: 0.1995 - accuracy: 0.9420 - f1_m: 1.1645 - val_loss: 0.3421 - val_accuracy: 0.9042 - val_f1_m: 1.1976\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 912us/sample - loss: 0.1726 - accuracy: 0.9470 - f1_m: 1.1323 - val_loss: 0.4705 - val_accuracy: 0.8673 - val_f1_m: 1.2192\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 903us/sample - loss: 0.1605 - accuracy: 0.9500 - f1_m: 1.1129 - val_loss: 0.3483 - val_accuracy: 0.9075 - val_f1_m: 1.1631\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 919us/sample - loss: 0.1297 - accuracy: 0.9650 - f1_m: 1.1021 - val_loss: 0.3675 - val_accuracy: 0.9038 - val_f1_m: 1.1469\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 916us/sample - loss: 0.1315 - accuracy: 0.9600 - f1_m: 1.1071 - val_loss: 0.3271 - val_accuracy: 0.9073 - val_f1_m: 1.1544\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 936us/sample - loss: 0.1108 - accuracy: 0.9700 - f1_m: 1.0687 - val_loss: 0.3646 - val_accuracy: 0.9104 - val_f1_m: 1.1167\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3418 - accuracy: 0.8820 - f1_m: 1.4530 - val_loss: 0.4802 - val_accuracy: 0.8493 - val_f1_m: 1.4546\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 723us/sample - loss: 0.2834 - accuracy: 0.9050 - f1_m: 1.3655 - val_loss: 0.3891 - val_accuracy: 0.8913 - val_f1_m: 1.3586\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 687us/sample - loss: 0.2446 - accuracy: 0.9290 - f1_m: 1.3151 - val_loss: 0.4124 - val_accuracy: 0.8791 - val_f1_m: 1.3692\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 649us/sample - loss: 0.1995 - accuracy: 0.9420 - f1_m: 1.2955 - val_loss: 0.3714 - val_accuracy: 0.8960 - val_f1_m: 1.2939\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 667us/sample - loss: 0.1708 - accuracy: 0.9530 - f1_m: 1.2351 - val_loss: 0.3769 - val_accuracy: 0.8962 - val_f1_m: 1.2829\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 683us/sample - loss: 0.1448 - accuracy: 0.9620 - f1_m: 1.1987 - val_loss: 0.3857 - val_accuracy: 0.8956 - val_f1_m: 1.2519\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 722us/sample - loss: 0.1329 - accuracy: 0.9660 - f1_m: 1.1934 - val_loss: 0.3968 - val_accuracy: 0.8924 - val_f1_m: 1.2400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 696us/sample - loss: 0.1111 - accuracy: 0.9740 - f1_m: 1.1735 - val_loss: 0.4086 - val_accuracy: 0.8898 - val_f1_m: 1.2335\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 714us/sample - loss: 0.1064 - accuracy: 0.9730 - f1_m: 1.1588 - val_loss: 0.4346 - val_accuracy: 0.8893 - val_f1_m: 1.2246\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 715us/sample - loss: 0.1352 - accuracy: 0.9610 - f1_m: 1.1545 - val_loss: 0.4217 - val_accuracy: 0.8899 - val_f1_m: 1.1676\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2796 - accuracy: 0.9090 - f1_m: 1.3159 - val_loss: 0.3390 - val_accuracy: 0.9036 - val_f1_m: 1.3138\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 767us/sample - loss: 0.1796 - accuracy: 0.9500 - f1_m: 1.2014 - val_loss: 0.2826 - val_accuracy: 0.9220 - val_f1_m: 1.2225\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 742us/sample - loss: 0.1389 - accuracy: 0.9580 - f1_m: 1.1350 - val_loss: 0.2734 - val_accuracy: 0.9245 - val_f1_m: 1.1642\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 732us/sample - loss: 0.1262 - accuracy: 0.9640 - f1_m: 1.1293 - val_loss: 0.3150 - val_accuracy: 0.9114 - val_f1_m: 1.2217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 752us/sample - loss: 0.0969 - accuracy: 0.9700 - f1_m: 1.1057 - val_loss: 0.2532 - val_accuracy: 0.9330 - val_f1_m: 1.1340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 742us/sample - loss: 0.0616 - accuracy: 0.9860 - f1_m: 1.0595 - val_loss: 0.2955 - val_accuracy: 0.9220 - val_f1_m: 1.1179\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 709us/sample - loss: 0.0489 - accuracy: 0.9870 - f1_m: 1.0382 - val_loss: 0.2449 - val_accuracy: 0.9372 - val_f1_m: 1.0843\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 717us/sample - loss: 0.0338 - accuracy: 0.9920 - f1_m: 1.0211 - val_loss: 0.2465 - val_accuracy: 0.9380 - val_f1_m: 1.0724\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 728us/sample - loss: 0.0287 - accuracy: 0.9910 - f1_m: 1.0101 - val_loss: 0.3109 - val_accuracy: 0.9218 - val_f1_m: 1.1142\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 767us/sample - loss: 0.0630 - accuracy: 0.9760 - f1_m: 1.0437 - val_loss: 0.2632 - val_accuracy: 0.9351 - val_f1_m: 1.0825\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.2736 - accuracy: 0.9100 - f1_m: 1.2305 - val_loss: 0.3341 - val_accuracy: 0.9029 - val_f1_m: 1.2474\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 861us/sample - loss: 0.1599 - accuracy: 0.9500 - f1_m: 1.1574 - val_loss: 0.3486 - val_accuracy: 0.9023 - val_f1_m: 1.1658\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.1412 - accuracy: 0.9590 - f1_m: 1.1399 - val_loss: 0.3390 - val_accuracy: 0.9112 - val_f1_m: 1.1611\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 818us/sample - loss: 0.1067 - accuracy: 0.9660 - f1_m: 1.0943 - val_loss: 0.2682 - val_accuracy: 0.9264 - val_f1_m: 1.1066\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 860us/sample - loss: 0.0680 - accuracy: 0.9800 - f1_m: 1.0237 - val_loss: 0.2970 - val_accuracy: 0.9269 - val_f1_m: 1.0888\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 831us/sample - loss: 0.0420 - accuracy: 0.9880 - f1_m: 1.0054 - val_loss: 0.2774 - val_accuracy: 0.9350 - val_f1_m: 1.0506\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 801us/sample - loss: 0.0258 - accuracy: 0.9940 - f1_m: 0.9996 - val_loss: 0.3037 - val_accuracy: 0.9360 - val_f1_m: 1.0348\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 850us/sample - loss: 0.0262 - accuracy: 0.9890 - f1_m: 0.9829 - val_loss: 0.3108 - val_accuracy: 0.9368 - val_f1_m: 1.0392\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 817us/sample - loss: 0.0463 - accuracy: 0.9890 - f1_m: 1.0019 - val_loss: 0.3159 - val_accuracy: 0.9270 - val_f1_m: 1.0753\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 807us/sample - loss: 0.0281 - accuracy: 0.9900 - f1_m: 0.9992 - val_loss: 0.2800 - val_accuracy: 0.9385 - val_f1_m: 1.0392\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.3291 - accuracy: 0.9010 - f1_m: 1.3088 - val_loss: 0.4302 - val_accuracy: 0.8749 - val_f1_m: 1.2313\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 944us/sample - loss: 0.2265 - accuracy: 0.9250 - f1_m: 1.1870 - val_loss: 0.3513 - val_accuracy: 0.8909 - val_f1_m: 1.2784\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 959us/sample - loss: 0.1783 - accuracy: 0.9380 - f1_m: 1.1327 - val_loss: 0.2774 - val_accuracy: 0.9230 - val_f1_m: 1.1456\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 948us/sample - loss: 0.1075 - accuracy: 0.9670 - f1_m: 1.0944 - val_loss: 0.3844 - val_accuracy: 0.8997 - val_f1_m: 1.1355\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.1216 - accuracy: 0.9580 - f1_m: 1.0781 - val_loss: 0.2701 - val_accuracy: 0.9200 - val_f1_m: 1.1704\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 951us/sample - loss: 0.0546 - accuracy: 0.9820 - f1_m: 1.0216 - val_loss: 0.3511 - val_accuracy: 0.9252 - val_f1_m: 1.0454\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 960us/sample - loss: 0.0519 - accuracy: 0.9760 - f1_m: 1.0124 - val_loss: 0.5417 - val_accuracy: 0.8981 - val_f1_m: 1.0589\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 960us/sample - loss: 0.0911 - accuracy: 0.9700 - f1_m: 1.0150 - val_loss: 0.3873 - val_accuracy: 0.9027 - val_f1_m: 1.1167\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 953us/sample - loss: 0.0662 - accuracy: 0.9770 - f1_m: 1.0193 - val_loss: 0.3004 - val_accuracy: 0.9334 - val_f1_m: 1.0766\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 950us/sample - loss: 0.0583 - accuracy: 0.9840 - f1_m: 1.0228 - val_loss: 0.2946 - val_accuracy: 0.9260 - val_f1_m: 1.0638\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 839us/sample - loss: 0.2746 - accuracy: 0.9140 - f1_m: 1.2887 - val_loss: 0.4103 - val_accuracy: 0.8867 - val_f1_m: 1.2869\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 483us/sample - loss: 0.2325 - accuracy: 0.9253 - f1_m: 1.2840 - val_loss: 0.4192 - val_accuracy: 0.8867 - val_f1_m: 1.2670\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 488us/sample - loss: 0.2193 - accuracy: 0.9340 - f1_m: 1.2524 - val_loss: 0.4208 - val_accuracy: 0.8866 - val_f1_m: 1.2607\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 456us/sample - loss: 0.1993 - accuracy: 0.9400 - f1_m: 1.2534 - val_loss: 0.4340 - val_accuracy: 0.8832 - val_f1_m: 1.2723\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 496us/sample - loss: 0.1845 - accuracy: 0.9420 - f1_m: 1.2213 - val_loss: 0.4140 - val_accuracy: 0.8931 - val_f1_m: 1.2330\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 483us/sample - loss: 0.1745 - accuracy: 0.9413 - f1_m: 1.2225 - val_loss: 0.4164 - val_accuracy: 0.8910 - val_f1_m: 1.2177\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 475us/sample - loss: 0.1694 - accuracy: 0.9460 - f1_m: 1.2013 - val_loss: 0.4222 - val_accuracy: 0.8921 - val_f1_m: 1.2225\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 493us/sample - loss: 0.1493 - accuracy: 0.9573 - f1_m: 1.1854 - val_loss: 0.4433 - val_accuracy: 0.8858 - val_f1_m: 1.1997\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 499us/sample - loss: 0.1347 - accuracy: 0.9627 - f1_m: 1.1836 - val_loss: 0.4483 - val_accuracy: 0.8888 - val_f1_m: 1.2132\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 477us/sample - loss: 0.1286 - accuracy: 0.9633 - f1_m: 1.1770 - val_loss: 0.4487 - val_accuracy: 0.8881 - val_f1_m: 1.2027\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 896us/sample - loss: 0.2124 - accuracy: 0.9307 - f1_m: 1.1863 - val_loss: 0.3016 - val_accuracy: 0.9078 - val_f1_m: 1.2113\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 501us/sample - loss: 0.1745 - accuracy: 0.9480 - f1_m: 1.1886 - val_loss: 0.3435 - val_accuracy: 0.9007 - val_f1_m: 1.2134\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 504us/sample - loss: 0.1580 - accuracy: 0.9487 - f1_m: 1.1609 - val_loss: 0.2762 - val_accuracy: 0.9188 - val_f1_m: 1.1891\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 485us/sample - loss: 0.1347 - accuracy: 0.9567 - f1_m: 1.1464 - val_loss: 0.3202 - val_accuracy: 0.9055 - val_f1_m: 1.2009\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 497us/sample - loss: 0.1204 - accuracy: 0.9600 - f1_m: 1.1351 - val_loss: 0.2781 - val_accuracy: 0.9232 - val_f1_m: 1.1613\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 503us/sample - loss: 0.1076 - accuracy: 0.9680 - f1_m: 1.1334 - val_loss: 0.2544 - val_accuracy: 0.9288 - val_f1_m: 1.1526\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 505us/sample - loss: 0.0926 - accuracy: 0.9693 - f1_m: 1.1056 - val_loss: 0.2747 - val_accuracy: 0.9217 - val_f1_m: 1.1351\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 483us/sample - loss: 0.0817 - accuracy: 0.9753 - f1_m: 1.0935 - val_loss: 0.3052 - val_accuracy: 0.9129 - val_f1_m: 1.1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 521us/sample - loss: 0.0730 - accuracy: 0.9767 - f1_m: 1.0833 - val_loss: 0.2695 - val_accuracy: 0.9268 - val_f1_m: 1.1372\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 519us/sample - loss: 0.0618 - accuracy: 0.9827 - f1_m: 1.0678 - val_loss: 0.2737 - val_accuracy: 0.9262 - val_f1_m: 1.1211\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.1839 - accuracy: 0.9427 - f1_m: 1.1560 - val_loss: 0.2850 - val_accuracy: 0.9149 - val_f1_m: 1.1370\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 577us/sample - loss: 0.1461 - accuracy: 0.9553 - f1_m: 1.1375 - val_loss: 0.2820 - val_accuracy: 0.9293 - val_f1_m: 1.1278\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 575us/sample - loss: 0.1061 - accuracy: 0.9673 - f1_m: 1.0986 - val_loss: 0.3047 - val_accuracy: 0.9237 - val_f1_m: 1.0944\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 566us/sample - loss: 0.1115 - accuracy: 0.9607 - f1_m: 1.0892 - val_loss: 0.2791 - val_accuracy: 0.9300 - val_f1_m: 1.0935\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 556us/sample - loss: 0.1008 - accuracy: 0.9567 - f1_m: 1.0821 - val_loss: 0.2876 - val_accuracy: 0.9328 - val_f1_m: 1.0915\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 551us/sample - loss: 0.0952 - accuracy: 0.9660 - f1_m: 1.0635 - val_loss: 0.3241 - val_accuracy: 0.9218 - val_f1_m: 1.0942\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 553us/sample - loss: 0.0627 - accuracy: 0.9793 - f1_m: 1.0353 - val_loss: 0.2755 - val_accuracy: 0.9417 - val_f1_m: 1.0601\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 553us/sample - loss: 0.0592 - accuracy: 0.9767 - f1_m: 1.0215 - val_loss: 0.2928 - val_accuracy: 0.9378 - val_f1_m: 1.0613\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 553us/sample - loss: 0.0332 - accuracy: 0.9853 - f1_m: 1.0090 - val_loss: 0.3503 - val_accuracy: 0.9257 - val_f1_m: 1.0669\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 549us/sample - loss: 0.0356 - accuracy: 0.9893 - f1_m: 1.0088 - val_loss: 0.3715 - val_accuracy: 0.9310 - val_f1_m: 1.0443\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.1875 - accuracy: 0.9473 - f1_m: 1.1432 - val_loss: 0.3260 - val_accuracy: 0.9003 - val_f1_m: 1.1593\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 641us/sample - loss: 0.1437 - accuracy: 0.9593 - f1_m: 1.1051 - val_loss: 0.3132 - val_accuracy: 0.9141 - val_f1_m: 1.1624\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 637us/sample - loss: 0.1215 - accuracy: 0.9620 - f1_m: 1.0763 - val_loss: 0.3282 - val_accuracy: 0.9124 - val_f1_m: 1.1005\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 657us/sample - loss: 0.0841 - accuracy: 0.9727 - f1_m: 1.0505 - val_loss: 0.3306 - val_accuracy: 0.9208 - val_f1_m: 1.0711\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 635us/sample - loss: 0.0897 - accuracy: 0.9760 - f1_m: 1.0385 - val_loss: 0.3234 - val_accuracy: 0.9178 - val_f1_m: 1.1193\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 679us/sample - loss: 0.0683 - accuracy: 0.9780 - f1_m: 1.0301 - val_loss: 0.3361 - val_accuracy: 0.9182 - val_f1_m: 1.0914\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 656us/sample - loss: 0.0591 - accuracy: 0.9780 - f1_m: 1.0337 - val_loss: 0.3856 - val_accuracy: 0.9189 - val_f1_m: 1.0705\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 655us/sample - loss: 0.0573 - accuracy: 0.9807 - f1_m: 1.0260 - val_loss: 0.3874 - val_accuracy: 0.9207 - val_f1_m: 1.0601\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 662us/sample - loss: 0.0378 - accuracy: 0.9873 - f1_m: 1.0020 - val_loss: 0.5231 - val_accuracy: 0.9011 - val_f1_m: 1.0835\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 662us/sample - loss: 0.0611 - accuracy: 0.9793 - f1_m: 1.0173 - val_loss: 0.3876 - val_accuracy: 0.9196 - val_f1_m: 1.0528\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 808us/sample - loss: 0.2168 - accuracy: 0.9387 - f1_m: 1.1631 - val_loss: 0.3643 - val_accuracy: 0.9068 - val_f1_m: 1.1786\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 491us/sample - loss: 0.1562 - accuracy: 0.9540 - f1_m: 1.1479 - val_loss: 0.3860 - val_accuracy: 0.9023 - val_f1_m: 1.1845\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 457us/sample - loss: 0.1236 - accuracy: 0.9667 - f1_m: 1.1347 - val_loss: 0.3996 - val_accuracy: 0.8946 - val_f1_m: 1.1997\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 474us/sample - loss: 0.1086 - accuracy: 0.9707 - f1_m: 1.1311 - val_loss: 0.3762 - val_accuracy: 0.9055 - val_f1_m: 1.1651\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 478us/sample - loss: 0.0933 - accuracy: 0.9673 - f1_m: 1.1037 - val_loss: 0.3967 - val_accuracy: 0.9027 - val_f1_m: 1.1630\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 453us/sample - loss: 0.0710 - accuracy: 0.9813 - f1_m: 1.0915 - val_loss: 0.4048 - val_accuracy: 0.9007 - val_f1_m: 1.1504\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 472us/sample - loss: 0.0653 - accuracy: 0.9807 - f1_m: 1.0701 - val_loss: 0.3995 - val_accuracy: 0.9040 - val_f1_m: 1.1349\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 479us/sample - loss: 0.0495 - accuracy: 0.9873 - f1_m: 1.0621 - val_loss: 0.4034 - val_accuracy: 0.9067 - val_f1_m: 1.1113\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 460us/sample - loss: 0.0388 - accuracy: 0.9953 - f1_m: 1.0541 - val_loss: 0.4227 - val_accuracy: 0.9050 - val_f1_m: 1.1203\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 469us/sample - loss: 0.0350 - accuracy: 0.9940 - f1_m: 1.0242 - val_loss: 0.4226 - val_accuracy: 0.9064 - val_f1_m: 1.1105\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 922us/sample - loss: 0.1166 - accuracy: 0.9667 - f1_m: 1.0556 - val_loss: 0.2098 - val_accuracy: 0.9425 - val_f1_m: 1.0910\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 551us/sample - loss: 0.0446 - accuracy: 0.9907 - f1_m: 1.0277 - val_loss: 0.2006 - val_accuracy: 0.9475 - val_f1_m: 1.0538\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 514us/sample - loss: 0.0254 - accuracy: 0.9953 - f1_m: 0.9949 - val_loss: 0.1985 - val_accuracy: 0.9498 - val_f1_m: 1.0320\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 537us/sample - loss: 0.0260 - accuracy: 0.9927 - f1_m: 0.9973 - val_loss: 0.2430 - val_accuracy: 0.9436 - val_f1_m: 1.0396\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 509us/sample - loss: 0.0211 - accuracy: 0.9933 - f1_m: 0.9881 - val_loss: 0.2074 - val_accuracy: 0.9452 - val_f1_m: 1.0366\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 517us/sample - loss: 0.0117 - accuracy: 0.9987 - f1_m: 0.9706 - val_loss: 0.2208 - val_accuracy: 0.9501 - val_f1_m: 1.0214\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 515us/sample - loss: 0.0074 - accuracy: 0.9980 - f1_m: 0.9610 - val_loss: 0.2060 - val_accuracy: 0.9538 - val_f1_m: 1.0189\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 537us/sample - loss: 0.0027 - accuracy: 1.0000 - f1_m: 0.9518 - val_loss: 0.2097 - val_accuracy: 0.9542 - val_f1_m: 1.0070\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 530us/sample - loss: 0.0016 - accuracy: 1.0000 - f1_m: 0.9510 - val_loss: 0.2198 - val_accuracy: 0.9544 - val_f1_m: 1.0089\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 524us/sample - loss: 0.0013 - accuracy: 1.0000 - f1_m: 0.9506 - val_loss: 0.2269 - val_accuracy: 0.9534 - val_f1_m: 1.0071\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.1173 - accuracy: 0.9673 - f1_m: 1.0439 - val_loss: 0.2465 - val_accuracy: 0.9291 - val_f1_m: 1.0885\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 595us/sample - loss: 0.0514 - accuracy: 0.9807 - f1_m: 1.0277 - val_loss: 0.2148 - val_accuracy: 0.9470 - val_f1_m: 1.0335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 569us/sample - loss: 0.0221 - accuracy: 0.9960 - f1_m: 0.9797 - val_loss: 0.2313 - val_accuracy: 0.9480 - val_f1_m: 1.0300\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 565us/sample - loss: 0.0205 - accuracy: 0.9933 - f1_m: 0.9907 - val_loss: 0.2725 - val_accuracy: 0.9443 - val_f1_m: 1.0133\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 583us/sample - loss: 0.0236 - accuracy: 0.9920 - f1_m: 0.9785 - val_loss: 0.3199 - val_accuracy: 0.9396 - val_f1_m: 1.0226\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 587us/sample - loss: 0.0319 - accuracy: 0.9927 - f1_m: 0.9806 - val_loss: 0.2613 - val_accuracy: 0.9400 - val_f1_m: 1.0339\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 607us/sample - loss: 0.0580 - accuracy: 0.9827 - f1_m: 1.0017 - val_loss: 0.1871 - val_accuracy: 0.9555 - val_f1_m: 1.0267\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 627us/sample - loss: 0.0206 - accuracy: 0.9947 - f1_m: 0.9730 - val_loss: 0.1998 - val_accuracy: 0.9519 - val_f1_m: 1.0147\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 622us/sample - loss: 0.0046 - accuracy: 0.9993 - f1_m: 0.9580 - val_loss: 0.2156 - val_accuracy: 0.9570 - val_f1_m: 1.0051\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 591us/sample - loss: 0.0057 - accuracy: 0.9973 - f1_m: 0.9578 - val_loss: 0.2292 - val_accuracy: 0.9572 - val_f1_m: 1.0004\n",
      "Train on 1500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/sample - loss: 0.1310 - accuracy: 0.9593 - f1_m: 1.0815 - val_loss: 0.2715 - val_accuracy: 0.9255 - val_f1_m: 1.0810\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 711us/sample - loss: 0.0589 - accuracy: 0.9820 - f1_m: 1.0250 - val_loss: 0.3036 - val_accuracy: 0.9312 - val_f1_m: 1.0446\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 720us/sample - loss: 0.0541 - accuracy: 0.9833 - f1_m: 1.0010 - val_loss: 0.2743 - val_accuracy: 0.9318 - val_f1_m: 1.0617\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 723us/sample - loss: 0.0428 - accuracy: 0.9847 - f1_m: 0.9937 - val_loss: 0.3757 - val_accuracy: 0.9245 - val_f1_m: 1.0453\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 685us/sample - loss: 0.0466 - accuracy: 0.9840 - f1_m: 1.0033 - val_loss: 0.3689 - val_accuracy: 0.9301 - val_f1_m: 1.0321\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 708us/sample - loss: 0.0652 - accuracy: 0.9753 - f1_m: 1.0150 - val_loss: 0.2716 - val_accuracy: 0.9374 - val_f1_m: 1.0574\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 695us/sample - loss: 0.0249 - accuracy: 0.9907 - f1_m: 0.9832 - val_loss: 0.4503 - val_accuracy: 0.9175 - val_f1_m: 1.0408\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 721us/sample - loss: 0.0212 - accuracy: 0.9940 - f1_m: 0.9812 - val_loss: 0.3342 - val_accuracy: 0.9476 - val_f1_m: 1.0001\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 709us/sample - loss: 0.0381 - accuracy: 0.9867 - f1_m: 0.9827 - val_loss: 0.4248 - val_accuracy: 0.9176 - val_f1_m: 1.0439\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 716us/sample - loss: 0.0427 - accuracy: 0.9827 - f1_m: 1.0021 - val_loss: 0.3304 - val_accuracy: 0.9368 - val_f1_m: 1.0316\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 799us/sample - loss: 0.2153 - accuracy: 0.9290 - f1_m: 1.1934 - val_loss: 0.4351 - val_accuracy: 0.8910 - val_f1_m: 1.2063\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 378us/sample - loss: 0.1779 - accuracy: 0.9500 - f1_m: 1.1761 - val_loss: 0.4040 - val_accuracy: 0.8979 - val_f1_m: 1.1890\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 380us/sample - loss: 0.1713 - accuracy: 0.9500 - f1_m: 1.1637 - val_loss: 0.4400 - val_accuracy: 0.8891 - val_f1_m: 1.1894\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 376us/sample - loss: 0.1639 - accuracy: 0.9465 - f1_m: 1.1859 - val_loss: 0.4162 - val_accuracy: 0.8944 - val_f1_m: 1.1630\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 368us/sample - loss: 0.1500 - accuracy: 0.9540 - f1_m: 1.1658 - val_loss: 0.4183 - val_accuracy: 0.8960 - val_f1_m: 1.1673\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 382us/sample - loss: 0.1459 - accuracy: 0.9500 - f1_m: 1.1575 - val_loss: 0.4228 - val_accuracy: 0.8946 - val_f1_m: 1.1708\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 391us/sample - loss: 0.1365 - accuracy: 0.9555 - f1_m: 1.1616 - val_loss: 0.4469 - val_accuracy: 0.8913 - val_f1_m: 1.1755\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 384us/sample - loss: 0.1262 - accuracy: 0.9610 - f1_m: 1.1542 - val_loss: 0.4229 - val_accuracy: 0.8960 - val_f1_m: 1.1611\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 375us/sample - loss: 0.1110 - accuracy: 0.9710 - f1_m: 1.1319 - val_loss: 0.4135 - val_accuracy: 0.8964 - val_f1_m: 1.1512\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 376us/sample - loss: 0.1061 - accuracy: 0.9670 - f1_m: 1.1286 - val_loss: 0.4054 - val_accuracy: 0.9001 - val_f1_m: 1.1522\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 708us/sample - loss: 0.1201 - accuracy: 0.9650 - f1_m: 1.0904 - val_loss: 0.2669 - val_accuracy: 0.9276 - val_f1_m: 1.1311\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 404us/sample - loss: 0.0884 - accuracy: 0.9745 - f1_m: 1.0636 - val_loss: 0.2739 - val_accuracy: 0.9239 - val_f1_m: 1.1183\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 398us/sample - loss: 0.0781 - accuracy: 0.9760 - f1_m: 1.0655 - val_loss: 0.2273 - val_accuracy: 0.9377 - val_f1_m: 1.1144\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 394us/sample - loss: 0.0801 - accuracy: 0.9725 - f1_m: 1.0687 - val_loss: 0.2171 - val_accuracy: 0.9389 - val_f1_m: 1.0967\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 397us/sample - loss: 0.0633 - accuracy: 0.9785 - f1_m: 1.0494 - val_loss: 0.2415 - val_accuracy: 0.9364 - val_f1_m: 1.0931\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 400us/sample - loss: 0.0595 - accuracy: 0.9805 - f1_m: 1.0441 - val_loss: 0.2361 - val_accuracy: 0.9382 - val_f1_m: 1.0895\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 395us/sample - loss: 0.0542 - accuracy: 0.9830 - f1_m: 1.0423 - val_loss: 0.2195 - val_accuracy: 0.9413 - val_f1_m: 1.0733\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 383us/sample - loss: 0.0477 - accuracy: 0.9840 - f1_m: 1.0388 - val_loss: 0.2489 - val_accuracy: 0.9317 - val_f1_m: 1.0840\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 393us/sample - loss: 0.0399 - accuracy: 0.9910 - f1_m: 1.0241 - val_loss: 0.2332 - val_accuracy: 0.9397 - val_f1_m: 1.0702\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 395us/sample - loss: 0.0364 - accuracy: 0.9910 - f1_m: 1.0120 - val_loss: 0.2146 - val_accuracy: 0.9446 - val_f1_m: 1.0663\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 840us/sample - loss: 0.1206 - accuracy: 0.9645 - f1_m: 1.0417 - val_loss: 0.2546 - val_accuracy: 0.9417 - val_f1_m: 1.0503\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 438us/sample - loss: 0.0603 - accuracy: 0.9815 - f1_m: 1.0109 - val_loss: 0.2751 - val_accuracy: 0.9338 - val_f1_m: 1.0639\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 436us/sample - loss: 0.0488 - accuracy: 0.9835 - f1_m: 1.0092 - val_loss: 0.2994 - val_accuracy: 0.9338 - val_f1_m: 1.0537\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 437us/sample - loss: 0.0552 - accuracy: 0.9800 - f1_m: 1.0164 - val_loss: 0.2825 - val_accuracy: 0.9372 - val_f1_m: 1.0445\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 465us/sample - loss: 0.0479 - accuracy: 0.9830 - f1_m: 1.0177 - val_loss: 0.3186 - val_accuracy: 0.9322 - val_f1_m: 1.0385\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 446us/sample - loss: 0.0424 - accuracy: 0.9855 - f1_m: 0.9957 - val_loss: 0.2644 - val_accuracy: 0.9397 - val_f1_m: 1.0343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 461us/sample - loss: 0.0367 - accuracy: 0.9860 - f1_m: 0.9953 - val_loss: 0.2499 - val_accuracy: 0.9457 - val_f1_m: 1.0260\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 469us/sample - loss: 0.0153 - accuracy: 0.9955 - f1_m: 0.9821 - val_loss: 0.2861 - val_accuracy: 0.9479 - val_f1_m: 1.0169\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 453us/sample - loss: 0.0079 - accuracy: 0.9985 - f1_m: 0.9605 - val_loss: 0.3094 - val_accuracy: 0.9439 - val_f1_m: 1.0059\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 450us/sample - loss: 0.0373 - accuracy: 0.9875 - f1_m: 0.9861 - val_loss: 0.2914 - val_accuracy: 0.9413 - val_f1_m: 1.0221\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 982us/sample - loss: 0.1530 - accuracy: 0.9575 - f1_m: 1.0675 - val_loss: 0.2420 - val_accuracy: 0.9392 - val_f1_m: 1.0818\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 513us/sample - loss: 0.0985 - accuracy: 0.9760 - f1_m: 1.0294 - val_loss: 0.2505 - val_accuracy: 0.9288 - val_f1_m: 1.1489\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 541us/sample - loss: 0.0747 - accuracy: 0.9785 - f1_m: 1.0516 - val_loss: 0.2599 - val_accuracy: 0.9340 - val_f1_m: 1.0460\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 537us/sample - loss: 0.0631 - accuracy: 0.9805 - f1_m: 1.0227 - val_loss: 0.3166 - val_accuracy: 0.9215 - val_f1_m: 1.0558\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 518us/sample - loss: 0.0884 - accuracy: 0.9700 - f1_m: 1.0436 - val_loss: 0.2545 - val_accuracy: 0.9408 - val_f1_m: 1.0467\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 524us/sample - loss: 0.0506 - accuracy: 0.9815 - f1_m: 1.0143 - val_loss: 0.2598 - val_accuracy: 0.9385 - val_f1_m: 1.0394\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 516us/sample - loss: 0.0303 - accuracy: 0.9900 - f1_m: 0.9851 - val_loss: 0.2680 - val_accuracy: 0.9435 - val_f1_m: 1.0283\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 514us/sample - loss: 0.0558 - accuracy: 0.9800 - f1_m: 1.0078 - val_loss: 0.2916 - val_accuracy: 0.9339 - val_f1_m: 1.0344\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 520us/sample - loss: 0.0429 - accuracy: 0.9830 - f1_m: 1.0011 - val_loss: 0.2991 - val_accuracy: 0.9357 - val_f1_m: 1.0347\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 522us/sample - loss: 0.0237 - accuracy: 0.9925 - f1_m: 0.9695 - val_loss: 0.3656 - val_accuracy: 0.9294 - val_f1_m: 1.0298\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 615us/sample - loss: 0.1634 - accuracy: 0.9510 - f1_m: 1.0655 - val_loss: 0.4073 - val_accuracy: 0.9059 - val_f1_m: 1.1291\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 378us/sample - loss: 0.0976 - accuracy: 0.9780 - f1_m: 1.0587 - val_loss: 0.3803 - val_accuracy: 0.9114 - val_f1_m: 1.1095\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 380us/sample - loss: 0.0798 - accuracy: 0.9750 - f1_m: 1.0496 - val_loss: 0.3846 - val_accuracy: 0.9121 - val_f1_m: 1.0929\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 366us/sample - loss: 0.0744 - accuracy: 0.9785 - f1_m: 1.0650 - val_loss: 0.3983 - val_accuracy: 0.9118 - val_f1_m: 1.0964\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 391us/sample - loss: 0.0559 - accuracy: 0.9860 - f1_m: 1.0514 - val_loss: 0.3918 - val_accuracy: 0.9133 - val_f1_m: 1.0808\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 401us/sample - loss: 0.0493 - accuracy: 0.9840 - f1_m: 1.0393 - val_loss: 0.4154 - val_accuracy: 0.9085 - val_f1_m: 1.0827\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 375us/sample - loss: 0.0559 - accuracy: 0.9820 - f1_m: 1.0403 - val_loss: 0.4235 - val_accuracy: 0.9073 - val_f1_m: 1.0816\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 360us/sample - loss: 0.0481 - accuracy: 0.9845 - f1_m: 1.0318 - val_loss: 0.3971 - val_accuracy: 0.9154 - val_f1_m: 1.0709\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 374us/sample - loss: 0.0242 - accuracy: 0.9970 - f1_m: 1.0054 - val_loss: 0.3926 - val_accuracy: 0.9164 - val_f1_m: 1.0608\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 373us/sample - loss: 0.0206 - accuracy: 0.9965 - f1_m: 0.9933 - val_loss: 0.3915 - val_accuracy: 0.9205 - val_f1_m: 1.0579\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 746us/sample - loss: 0.0907 - accuracy: 0.9740 - f1_m: 1.0106 - val_loss: 0.1739 - val_accuracy: 0.9568 - val_f1_m: 1.0316\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 412us/sample - loss: 0.0347 - accuracy: 0.9890 - f1_m: 0.9887 - val_loss: 0.2007 - val_accuracy: 0.9524 - val_f1_m: 1.0280\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 428us/sample - loss: 0.0205 - accuracy: 0.9955 - f1_m: 0.9782 - val_loss: 0.1790 - val_accuracy: 0.9532 - val_f1_m: 1.0290\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 426us/sample - loss: 0.0113 - accuracy: 0.9990 - f1_m: 0.9711 - val_loss: 0.1673 - val_accuracy: 0.9570 - val_f1_m: 1.0051\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 429us/sample - loss: 0.0079 - accuracy: 0.9995 - f1_m: 0.9633 - val_loss: 0.1811 - val_accuracy: 0.9568 - val_f1_m: 1.0093\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 412us/sample - loss: 0.0140 - accuracy: 0.9960 - f1_m: 0.9706 - val_loss: 0.1730 - val_accuracy: 0.9579 - val_f1_m: 1.0044\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 397us/sample - loss: 0.0149 - accuracy: 0.9940 - f1_m: 0.9699 - val_loss: 0.1909 - val_accuracy: 0.9539 - val_f1_m: 1.0050\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 420us/sample - loss: 0.0044 - accuracy: 1.0000 - f1_m: 0.9576 - val_loss: 0.1730 - val_accuracy: 0.9615 - val_f1_m: 1.0007\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 416us/sample - loss: 0.0014 - accuracy: 1.0000 - f1_m: 0.9486 - val_loss: 0.1754 - val_accuracy: 0.9592 - val_f1_m: 0.9976\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 417us/sample - loss: 6.9526e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1800 - val_accuracy: 0.9593 - val_f1_m: 0.9986\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 865us/sample - loss: 0.0777 - accuracy: 0.9835 - f1_m: 0.9882 - val_loss: 0.1589 - val_accuracy: 0.9606 - val_f1_m: 1.0130\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 488us/sample - loss: 0.0277 - accuracy: 0.9900 - f1_m: 0.9802 - val_loss: 0.1513 - val_accuracy: 0.9595 - val_f1_m: 1.0043\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 464us/sample - loss: 0.0046 - accuracy: 0.9990 - f1_m: 0.9582 - val_loss: 0.1739 - val_accuracy: 0.9586 - val_f1_m: 1.0022\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 479us/sample - loss: 0.0016 - accuracy: 1.0000 - f1_m: 0.9520 - val_loss: 0.1898 - val_accuracy: 0.9621 - val_f1_m: 0.9850\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 465us/sample - loss: 3.3286e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1884 - val_accuracy: 0.9637 - val_f1_m: 0.9822\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 485us/sample - loss: 1.6635e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1926 - val_accuracy: 0.9628 - val_f1_m: 0.9810\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 456us/sample - loss: 1.2269e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1963 - val_accuracy: 0.9630 - val_f1_m: 0.9800\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 455us/sample - loss: 9.5310e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2010 - val_accuracy: 0.9627 - val_f1_m: 0.9781\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 455us/sample - loss: 7.6530e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2040 - val_accuracy: 0.9629 - val_f1_m: 0.9781\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 476us/sample - loss: 6.3702e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2074 - val_accuracy: 0.9629 - val_f1_m: 0.9777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 2s 1ms/sample - loss: 0.1006 - accuracy: 0.9750 - f1_m: 1.0299 - val_loss: 0.2191 - val_accuracy: 0.9412 - val_f1_m: 1.0446\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 606us/sample - loss: 0.0455 - accuracy: 0.9860 - f1_m: 0.9883 - val_loss: 0.2068 - val_accuracy: 0.9412 - val_f1_m: 1.0473\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1s 575us/sample - loss: 0.0184 - accuracy: 0.9940 - f1_m: 0.9745 - val_loss: 0.2833 - val_accuracy: 0.9369 - val_f1_m: 1.0268\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 583us/sample - loss: 0.0268 - accuracy: 0.9920 - f1_m: 0.9725 - val_loss: 0.2955 - val_accuracy: 0.9332 - val_f1_m: 1.0299\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1s 600us/sample - loss: 0.0259 - accuracy: 0.9900 - f1_m: 0.9745 - val_loss: 0.2445 - val_accuracy: 0.9458 - val_f1_m: 1.0182\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 592us/sample - loss: 0.0579 - accuracy: 0.9825 - f1_m: 1.0030 - val_loss: 0.2720 - val_accuracy: 0.9376 - val_f1_m: 1.0567\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 610us/sample - loss: 0.0594 - accuracy: 0.9830 - f1_m: 0.9925 - val_loss: 0.2384 - val_accuracy: 0.9413 - val_f1_m: 1.0291\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 569us/sample - loss: 0.0186 - accuracy: 0.9930 - f1_m: 0.9731 - val_loss: 0.2227 - val_accuracy: 0.9557 - val_f1_m: 1.0021\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 578us/sample - loss: 0.0096 - accuracy: 0.9975 - f1_m: 0.9548 - val_loss: 0.2376 - val_accuracy: 0.9529 - val_f1_m: 1.0087\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 593us/sample - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9534 - val_loss: 0.2579 - val_accuracy: 0.9563 - val_f1_m: 0.9855\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 574us/sample - loss: 0.2056 - accuracy: 0.9488 - f1_m: 1.1260 - val_loss: 0.4168 - val_accuracy: 0.8964 - val_f1_m: 1.1706\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 330us/sample - loss: 0.1792 - accuracy: 0.9492 - f1_m: 1.1547 - val_loss: 0.4153 - val_accuracy: 0.8942 - val_f1_m: 1.1539\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.1747 - accuracy: 0.9492 - f1_m: 1.1474 - val_loss: 0.4223 - val_accuracy: 0.8918 - val_f1_m: 1.1611\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.1516 - accuracy: 0.9524 - f1_m: 1.1357 - val_loss: 0.3944 - val_accuracy: 0.8950 - val_f1_m: 1.1474\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 315us/sample - loss: 0.1527 - accuracy: 0.9540 - f1_m: 1.1391 - val_loss: 0.4075 - val_accuracy: 0.8984 - val_f1_m: 1.1528\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.1420 - accuracy: 0.9556 - f1_m: 1.1283 - val_loss: 0.3987 - val_accuracy: 0.9020 - val_f1_m: 1.1448\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.1317 - accuracy: 0.9652 - f1_m: 1.1170 - val_loss: 0.3873 - val_accuracy: 0.8980 - val_f1_m: 1.1531\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 342us/sample - loss: 0.1168 - accuracy: 0.9656 - f1_m: 1.1263 - val_loss: 0.4030 - val_accuracy: 0.8956 - val_f1_m: 1.1396\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 309us/sample - loss: 0.1132 - accuracy: 0.9648 - f1_m: 1.1189 - val_loss: 0.4248 - val_accuracy: 0.8928 - val_f1_m: 1.1699\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 330us/sample - loss: 0.1087 - accuracy: 0.9676 - f1_m: 1.1176 - val_loss: 0.4350 - val_accuracy: 0.8950 - val_f1_m: 1.1467\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 602us/sample - loss: 0.1087 - accuracy: 0.9708 - f1_m: 1.0225 - val_loss: 0.2283 - val_accuracy: 0.9391 - val_f1_m: 1.0765\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 338us/sample - loss: 0.0761 - accuracy: 0.9788 - f1_m: 1.0460 - val_loss: 0.2441 - val_accuracy: 0.9338 - val_f1_m: 1.0657\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 325us/sample - loss: 0.0745 - accuracy: 0.9812 - f1_m: 1.0355 - val_loss: 0.2196 - val_accuracy: 0.9431 - val_f1_m: 1.0695\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 334us/sample - loss: 0.0692 - accuracy: 0.9812 - f1_m: 1.0327 - val_loss: 0.2431 - val_accuracy: 0.9314 - val_f1_m: 1.0889\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 331us/sample - loss: 0.0570 - accuracy: 0.9856 - f1_m: 1.0294 - val_loss: 0.2084 - val_accuracy: 0.9472 - val_f1_m: 1.0538\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 334us/sample - loss: 0.0455 - accuracy: 0.9868 - f1_m: 1.0242 - val_loss: 0.1963 - val_accuracy: 0.9521 - val_f1_m: 1.0579\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 336us/sample - loss: 0.0402 - accuracy: 0.9896 - f1_m: 1.0053 - val_loss: 0.1892 - val_accuracy: 0.9542 - val_f1_m: 1.0482\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 342us/sample - loss: 0.0383 - accuracy: 0.9900 - f1_m: 1.0122 - val_loss: 0.2496 - val_accuracy: 0.9369 - val_f1_m: 1.0538\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.0351 - accuracy: 0.9908 - f1_m: 1.0116 - val_loss: 0.2097 - val_accuracy: 0.9522 - val_f1_m: 1.0428\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 334us/sample - loss: 0.0239 - accuracy: 0.9956 - f1_m: 0.9994 - val_loss: 0.2143 - val_accuracy: 0.9492 - val_f1_m: 1.0396\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 687us/sample - loss: 0.0869 - accuracy: 0.9764 - f1_m: 1.0045 - val_loss: 0.3383 - val_accuracy: 0.9276 - val_f1_m: 1.0732\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 381us/sample - loss: 0.0644 - accuracy: 0.9800 - f1_m: 1.0097 - val_loss: 0.2384 - val_accuracy: 0.9390 - val_f1_m: 1.0421\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 378us/sample - loss: 0.0439 - accuracy: 0.9860 - f1_m: 1.0069 - val_loss: 0.2827 - val_accuracy: 0.9359 - val_f1_m: 1.0330\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 378us/sample - loss: 0.0410 - accuracy: 0.9852 - f1_m: 0.9980 - val_loss: 0.2507 - val_accuracy: 0.9447 - val_f1_m: 1.0170\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 382us/sample - loss: 0.0327 - accuracy: 0.9904 - f1_m: 0.9881 - val_loss: 0.2470 - val_accuracy: 0.9439 - val_f1_m: 1.0206\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 378us/sample - loss: 0.0273 - accuracy: 0.9920 - f1_m: 0.9860 - val_loss: 0.2197 - val_accuracy: 0.9524 - val_f1_m: 1.0117\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 377us/sample - loss: 0.0148 - accuracy: 0.9940 - f1_m: 0.9731 - val_loss: 0.2373 - val_accuracy: 0.9535 - val_f1_m: 0.9989\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 381us/sample - loss: 0.0262 - accuracy: 0.9916 - f1_m: 0.9690 - val_loss: 0.2723 - val_accuracy: 0.9426 - val_f1_m: 1.0204\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 375us/sample - loss: 0.0359 - accuracy: 0.9876 - f1_m: 0.9791 - val_loss: 0.3584 - val_accuracy: 0.9281 - val_f1_m: 1.0438\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 372us/sample - loss: 0.0253 - accuracy: 0.9916 - f1_m: 0.9806 - val_loss: 0.2496 - val_accuracy: 0.9476 - val_f1_m: 1.0154\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 816us/sample - loss: 0.1068 - accuracy: 0.9744 - f1_m: 1.0219 - val_loss: 0.2156 - val_accuracy: 0.9388 - val_f1_m: 1.0763\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 443us/sample - loss: 0.0663 - accuracy: 0.9816 - f1_m: 1.0125 - val_loss: 0.2302 - val_accuracy: 0.9449 - val_f1_m: 1.0491\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 444us/sample - loss: 0.0667 - accuracy: 0.9808 - f1_m: 1.0187 - val_loss: 0.2161 - val_accuracy: 0.9422 - val_f1_m: 1.0487\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 443us/sample - loss: 0.0441 - accuracy: 0.9852 - f1_m: 0.9970 - val_loss: 0.2613 - val_accuracy: 0.9434 - val_f1_m: 1.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.0384 - accuracy: 0.9900 - f1_m: 0.9854 - val_loss: 0.2719 - val_accuracy: 0.9345 - val_f1_m: 1.0320\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 438us/sample - loss: 0.0913 - accuracy: 0.9724 - f1_m: 1.0424 - val_loss: 0.2316 - val_accuracy: 0.9446 - val_f1_m: 1.0378\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 446us/sample - loss: 0.0280 - accuracy: 0.9920 - f1_m: 0.9842 - val_loss: 0.2427 - val_accuracy: 0.9503 - val_f1_m: 1.0127\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 454us/sample - loss: 0.0240 - accuracy: 0.9928 - f1_m: 0.9786 - val_loss: 0.2882 - val_accuracy: 0.9432 - val_f1_m: 1.0141\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 454us/sample - loss: 0.0098 - accuracy: 0.9968 - f1_m: 0.9660 - val_loss: 0.3137 - val_accuracy: 0.9477 - val_f1_m: 1.0000\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 440us/sample - loss: 0.0122 - accuracy: 0.9972 - f1_m: 0.9620 - val_loss: 0.3523 - val_accuracy: 0.9455 - val_f1_m: 1.0018\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 548us/sample - loss: 0.1459 - accuracy: 0.9636 - f1_m: 1.0252 - val_loss: 0.4210 - val_accuracy: 0.9091 - val_f1_m: 1.1043\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.0863 - accuracy: 0.9784 - f1_m: 1.0370 - val_loss: 0.3828 - val_accuracy: 0.9158 - val_f1_m: 1.0826\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 303us/sample - loss: 0.0790 - accuracy: 0.9760 - f1_m: 1.0423 - val_loss: 0.3825 - val_accuracy: 0.9157 - val_f1_m: 1.0780\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.0538 - accuracy: 0.9860 - f1_m: 1.0269 - val_loss: 0.3821 - val_accuracy: 0.9163 - val_f1_m: 1.0740\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.0534 - accuracy: 0.9820 - f1_m: 1.0255 - val_loss: 0.3810 - val_accuracy: 0.9187 - val_f1_m: 1.0678\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.0454 - accuracy: 0.9880 - f1_m: 1.0075 - val_loss: 0.3915 - val_accuracy: 0.9160 - val_f1_m: 1.0749\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 308us/sample - loss: 0.0347 - accuracy: 0.9928 - f1_m: 1.0091 - val_loss: 0.3667 - val_accuracy: 0.9236 - val_f1_m: 1.0592\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 312us/sample - loss: 0.0272 - accuracy: 0.9952 - f1_m: 0.9962 - val_loss: 0.3950 - val_accuracy: 0.9191 - val_f1_m: 1.0604\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 313us/sample - loss: 0.0206 - accuracy: 0.9968 - f1_m: 0.9852 - val_loss: 0.3978 - val_accuracy: 0.9177 - val_f1_m: 1.0646\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.0191 - accuracy: 0.9968 - f1_m: 0.9911 - val_loss: 0.4009 - val_accuracy: 0.9231 - val_f1_m: 1.0505\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1s 574us/sample - loss: 0.0650 - accuracy: 0.9876 - f1_m: 0.9785 - val_loss: 0.1785 - val_accuracy: 0.9553 - val_f1_m: 1.0292\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 350us/sample - loss: 0.0370 - accuracy: 0.9896 - f1_m: 0.9828 - val_loss: 0.1736 - val_accuracy: 0.9577 - val_f1_m: 1.0209\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 347us/sample - loss: 0.0281 - accuracy: 0.9896 - f1_m: 0.9875 - val_loss: 0.1875 - val_accuracy: 0.9493 - val_f1_m: 1.0202\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 350us/sample - loss: 0.0105 - accuracy: 0.9980 - f1_m: 0.9674 - val_loss: 0.1575 - val_accuracy: 0.9633 - val_f1_m: 1.0012\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 352us/sample - loss: 0.0076 - accuracy: 0.9976 - f1_m: 0.9602 - val_loss: 0.1628 - val_accuracy: 0.9592 - val_f1_m: 1.0089\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 350us/sample - loss: 0.0087 - accuracy: 0.9976 - f1_m: 0.9580 - val_loss: 0.1643 - val_accuracy: 0.9620 - val_f1_m: 1.0070\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 346us/sample - loss: 0.0030 - accuracy: 0.9996 - f1_m: 0.9533 - val_loss: 0.1680 - val_accuracy: 0.9639 - val_f1_m: 0.9965\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 339us/sample - loss: 8.9773e-04 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1585 - val_accuracy: 0.9656 - val_f1_m: 0.9926\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 352us/sample - loss: 6.2585e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1639 - val_accuracy: 0.9670 - val_f1_m: 0.9922\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 350us/sample - loss: 5.0368e-04 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.1692 - val_accuracy: 0.9648 - val_f1_m: 0.9895\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 709us/sample - loss: 0.0840 - accuracy: 0.9820 - f1_m: 0.9758 - val_loss: 0.1394 - val_accuracy: 0.9581 - val_f1_m: 1.0442\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 404us/sample - loss: 0.0259 - accuracy: 0.9928 - f1_m: 0.9731 - val_loss: 0.1550 - val_accuracy: 0.9603 - val_f1_m: 1.0052\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 397us/sample - loss: 0.0230 - accuracy: 0.9912 - f1_m: 0.9718 - val_loss: 0.1736 - val_accuracy: 0.9536 - val_f1_m: 1.0255\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 397us/sample - loss: 0.0091 - accuracy: 0.9972 - f1_m: 0.9617 - val_loss: 0.1613 - val_accuracy: 0.9649 - val_f1_m: 0.9843\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 396us/sample - loss: 0.0043 - accuracy: 0.9988 - f1_m: 0.9549 - val_loss: 0.1799 - val_accuracy: 0.9659 - val_f1_m: 0.9878\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 392us/sample - loss: 0.0080 - accuracy: 0.9972 - f1_m: 0.9552 - val_loss: 0.1629 - val_accuracy: 0.9665 - val_f1_m: 0.9850\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 396us/sample - loss: 0.0159 - accuracy: 0.9944 - f1_m: 0.9599 - val_loss: 0.2014 - val_accuracy: 0.9561 - val_f1_m: 0.9980\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 400us/sample - loss: 0.0294 - accuracy: 0.9908 - f1_m: 0.9751 - val_loss: 0.1741 - val_accuracy: 0.9575 - val_f1_m: 1.0068\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 396us/sample - loss: 0.0082 - accuracy: 0.9976 - f1_m: 0.9597 - val_loss: 0.1636 - val_accuracy: 0.9649 - val_f1_m: 0.9835\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 398us/sample - loss: 0.0140 - accuracy: 0.9932 - f1_m: 0.9613 - val_loss: 0.1864 - val_accuracy: 0.9624 - val_f1_m: 0.9919\n",
      "Train on 2500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 2s 842us/sample - loss: 0.0874 - accuracy: 0.9784 - f1_m: 0.9984 - val_loss: 0.1668 - val_accuracy: 0.9503 - val_f1_m: 1.0631\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 1s 481us/sample - loss: 0.0314 - accuracy: 0.9916 - f1_m: 0.9776 - val_loss: 0.1971 - val_accuracy: 0.9500 - val_f1_m: 1.0354\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 1s 489us/sample - loss: 0.0190 - accuracy: 0.9948 - f1_m: 0.9721 - val_loss: 0.2423 - val_accuracy: 0.9587 - val_f1_m: 0.9986\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 1s 476us/sample - loss: 0.0267 - accuracy: 0.9900 - f1_m: 0.9690 - val_loss: 0.2122 - val_accuracy: 0.9495 - val_f1_m: 1.0217\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 1s 471us/sample - loss: 0.0300 - accuracy: 0.9904 - f1_m: 0.9755 - val_loss: 0.2413 - val_accuracy: 0.9512 - val_f1_m: 1.0050\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 1s 479us/sample - loss: 0.0155 - accuracy: 0.9944 - f1_m: 0.9672 - val_loss: 0.2264 - val_accuracy: 0.9571 - val_f1_m: 1.0042\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 1s 486us/sample - loss: 0.0192 - accuracy: 0.9940 - f1_m: 0.9697 - val_loss: 0.2506 - val_accuracy: 0.9550 - val_f1_m: 0.9939\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 1s 490us/sample - loss: 0.0430 - accuracy: 0.9864 - f1_m: 0.9831 - val_loss: 0.1965 - val_accuracy: 0.9587 - val_f1_m: 1.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 1s 477us/sample - loss: 0.0178 - accuracy: 0.9948 - f1_m: 0.9645 - val_loss: 0.2057 - val_accuracy: 0.9622 - val_f1_m: 0.9908\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 1s 480us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9515 - val_loss: 0.2720 - val_accuracy: 0.9607 - val_f1_m: 0.9771\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 531us/sample - loss: 0.1702 - accuracy: 0.9497 - f1_m: 1.1211 - val_loss: 0.4273 - val_accuracy: 0.8883 - val_f1_m: 1.1479\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 282us/sample - loss: 0.1573 - accuracy: 0.9523 - f1_m: 1.1173 - val_loss: 0.4239 - val_accuracy: 0.8916 - val_f1_m: 1.1460\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 276us/sample - loss: 0.1458 - accuracy: 0.9583 - f1_m: 1.1187 - val_loss: 0.4445 - val_accuracy: 0.8848 - val_f1_m: 1.1832\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 276us/sample - loss: 0.1377 - accuracy: 0.9597 - f1_m: 1.1276 - val_loss: 0.4035 - val_accuracy: 0.8960 - val_f1_m: 1.1340\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 279us/sample - loss: 0.1197 - accuracy: 0.9657 - f1_m: 1.1011 - val_loss: 0.3874 - val_accuracy: 0.9049 - val_f1_m: 1.1318\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 284us/sample - loss: 0.1119 - accuracy: 0.9687 - f1_m: 1.1085 - val_loss: 0.3863 - val_accuracy: 0.9012 - val_f1_m: 1.1374\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.1110 - accuracy: 0.9667 - f1_m: 1.1132 - val_loss: 0.4045 - val_accuracy: 0.8966 - val_f1_m: 1.1446\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 282us/sample - loss: 0.1030 - accuracy: 0.9693 - f1_m: 1.0907 - val_loss: 0.3789 - val_accuracy: 0.9076 - val_f1_m: 1.1268\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.0952 - accuracy: 0.9757 - f1_m: 1.0997 - val_loss: 0.4070 - val_accuracy: 0.8978 - val_f1_m: 1.1263\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 274us/sample - loss: 0.0949 - accuracy: 0.9720 - f1_m: 1.0890 - val_loss: 0.3954 - val_accuracy: 0.9029 - val_f1_m: 1.1188\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 482us/sample - loss: 0.0771 - accuracy: 0.9797 - f1_m: 1.0205 - val_loss: 0.2229 - val_accuracy: 0.9465 - val_f1_m: 1.0525\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 292us/sample - loss: 0.0547 - accuracy: 0.9877 - f1_m: 1.0039 - val_loss: 0.1985 - val_accuracy: 0.9517 - val_f1_m: 1.0400\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 297us/sample - loss: 0.0511 - accuracy: 0.9880 - f1_m: 1.0148 - val_loss: 0.2332 - val_accuracy: 0.9439 - val_f1_m: 1.0605\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 295us/sample - loss: 0.0396 - accuracy: 0.9890 - f1_m: 0.9977 - val_loss: 0.2075 - val_accuracy: 0.9499 - val_f1_m: 1.0478\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 290us/sample - loss: 0.0368 - accuracy: 0.9883 - f1_m: 1.0047 - val_loss: 0.2043 - val_accuracy: 0.9511 - val_f1_m: 1.0401\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 291us/sample - loss: 0.0315 - accuracy: 0.9893 - f1_m: 1.0043 - val_loss: 0.2066 - val_accuracy: 0.9521 - val_f1_m: 1.0453\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 292us/sample - loss: 0.0213 - accuracy: 0.9960 - f1_m: 0.9919 - val_loss: 0.2296 - val_accuracy: 0.9423 - val_f1_m: 1.0398\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 290us/sample - loss: 0.0179 - accuracy: 0.9967 - f1_m: 0.9808 - val_loss: 0.2060 - val_accuracy: 0.9558 - val_f1_m: 1.0218\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.0165 - accuracy: 0.9973 - f1_m: 0.9832 - val_loss: 0.2445 - val_accuracy: 0.9490 - val_f1_m: 1.0248\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 292us/sample - loss: 0.0178 - accuracy: 0.9953 - f1_m: 0.9819 - val_loss: 0.2654 - val_accuracy: 0.9456 - val_f1_m: 1.0344\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 599us/sample - loss: 0.0656 - accuracy: 0.9843 - f1_m: 0.9893 - val_loss: 0.2215 - val_accuracy: 0.9462 - val_f1_m: 1.0239\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 340us/sample - loss: 0.0458 - accuracy: 0.9883 - f1_m: 0.9890 - val_loss: 0.2848 - val_accuracy: 0.9364 - val_f1_m: 1.0271\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 350us/sample - loss: 0.0281 - accuracy: 0.9907 - f1_m: 0.9817 - val_loss: 0.1785 - val_accuracy: 0.9587 - val_f1_m: 1.0115\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 343us/sample - loss: 0.0176 - accuracy: 0.9943 - f1_m: 0.9761 - val_loss: 0.2124 - val_accuracy: 0.9567 - val_f1_m: 1.0049\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 333us/sample - loss: 0.0275 - accuracy: 0.9893 - f1_m: 0.9816 - val_loss: 0.2099 - val_accuracy: 0.9516 - val_f1_m: 1.0025\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 328us/sample - loss: 0.0170 - accuracy: 0.9927 - f1_m: 0.9695 - val_loss: 0.2040 - val_accuracy: 0.9571 - val_f1_m: 0.9991\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 330us/sample - loss: 0.0050 - accuracy: 0.9987 - f1_m: 0.9581 - val_loss: 0.2202 - val_accuracy: 0.9566 - val_f1_m: 0.9918\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 344us/sample - loss: 0.0020 - accuracy: 1.0000 - f1_m: 0.9517 - val_loss: 0.2334 - val_accuracy: 0.9586 - val_f1_m: 0.9870\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 350us/sample - loss: 9.5847e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2334 - val_accuracy: 0.9608 - val_f1_m: 0.9868\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 340us/sample - loss: 4.2762e-04 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.2401 - val_accuracy: 0.9609 - val_f1_m: 0.9840\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 711us/sample - loss: 0.0789 - accuracy: 0.9813 - f1_m: 1.0051 - val_loss: 0.2531 - val_accuracy: 0.9475 - val_f1_m: 1.0201\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 391us/sample - loss: 0.0467 - accuracy: 0.9860 - f1_m: 0.9868 - val_loss: 0.2170 - val_accuracy: 0.9503 - val_f1_m: 1.0317\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 393us/sample - loss: 0.0333 - accuracy: 0.9927 - f1_m: 0.9821 - val_loss: 0.2602 - val_accuracy: 0.9476 - val_f1_m: 1.0223\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 399us/sample - loss: 0.0227 - accuracy: 0.9917 - f1_m: 0.9800 - val_loss: 0.2863 - val_accuracy: 0.9392 - val_f1_m: 1.0302\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 394us/sample - loss: 0.0543 - accuracy: 0.9850 - f1_m: 0.9843 - val_loss: 0.3190 - val_accuracy: 0.9221 - val_f1_m: 1.0557\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 404us/sample - loss: 0.0493 - accuracy: 0.9813 - f1_m: 1.0038 - val_loss: 0.2665 - val_accuracy: 0.9379 - val_f1_m: 1.0279\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 396us/sample - loss: 0.0100 - accuracy: 0.9963 - f1_m: 0.9641 - val_loss: 0.2736 - val_accuracy: 0.9503 - val_f1_m: 0.9958\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 394us/sample - loss: 0.0140 - accuracy: 0.9953 - f1_m: 0.9640 - val_loss: 0.3011 - val_accuracy: 0.9389 - val_f1_m: 1.0091\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 403us/sample - loss: 0.0316 - accuracy: 0.9893 - f1_m: 0.9765 - val_loss: 0.2920 - val_accuracy: 0.9359 - val_f1_m: 1.0395\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 404us/sample - loss: 0.0326 - accuracy: 0.9883 - f1_m: 0.9784 - val_loss: 0.3095 - val_accuracy: 0.9444 - val_f1_m: 0.9996\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 458us/sample - loss: 0.1201 - accuracy: 0.9703 - f1_m: 1.0246 - val_loss: 0.3795 - val_accuracy: 0.9191 - val_f1_m: 1.0637\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.0728 - accuracy: 0.9813 - f1_m: 1.0085 - val_loss: 0.3653 - val_accuracy: 0.9207 - val_f1_m: 1.0669\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.0578 - accuracy: 0.9833 - f1_m: 1.0122 - val_loss: 0.3424 - val_accuracy: 0.9243 - val_f1_m: 1.0618\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 272us/sample - loss: 0.0427 - accuracy: 0.9907 - f1_m: 0.9973 - val_loss: 0.3319 - val_accuracy: 0.9239 - val_f1_m: 1.0576\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 276us/sample - loss: 0.0310 - accuracy: 0.9920 - f1_m: 0.9946 - val_loss: 0.3507 - val_accuracy: 0.9226 - val_f1_m: 1.0616\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 291us/sample - loss: 0.0239 - accuracy: 0.9953 - f1_m: 0.9918 - val_loss: 0.3593 - val_accuracy: 0.9259 - val_f1_m: 1.0474\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 281us/sample - loss: 0.0251 - accuracy: 0.9920 - f1_m: 0.9884 - val_loss: 0.3762 - val_accuracy: 0.9179 - val_f1_m: 1.0545\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 287us/sample - loss: 0.0220 - accuracy: 0.9943 - f1_m: 0.9870 - val_loss: 0.3529 - val_accuracy: 0.9284 - val_f1_m: 1.0415\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 277us/sample - loss: 0.0113 - accuracy: 0.9980 - f1_m: 0.9685 - val_loss: 0.3708 - val_accuracy: 0.9244 - val_f1_m: 1.0437\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 273us/sample - loss: 0.0088 - accuracy: 1.0000 - f1_m: 0.9651 - val_loss: 0.3632 - val_accuracy: 0.9276 - val_f1_m: 1.0320\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 507us/sample - loss: 0.0541 - accuracy: 0.9897 - f1_m: 0.9691 - val_loss: 0.1667 - val_accuracy: 0.9642 - val_f1_m: 0.9974\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 319us/sample - loss: 0.0236 - accuracy: 0.9950 - f1_m: 0.9651 - val_loss: 0.1541 - val_accuracy: 0.9681 - val_f1_m: 1.0052\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 301us/sample - loss: 0.0093 - accuracy: 0.9980 - f1_m: 0.9573 - val_loss: 0.1653 - val_accuracy: 0.9617 - val_f1_m: 0.9988\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 314us/sample - loss: 0.0090 - accuracy: 0.9967 - f1_m: 0.9573 - val_loss: 0.1564 - val_accuracy: 0.9649 - val_f1_m: 0.9945\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 313us/sample - loss: 0.0034 - accuracy: 0.9993 - f1_m: 0.9520 - val_loss: 0.1644 - val_accuracy: 0.9662 - val_f1_m: 0.9926\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 303us/sample - loss: 0.0012 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1584 - val_accuracy: 0.9669 - val_f1_m: 0.9855\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 312us/sample - loss: 6.3936e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1606 - val_accuracy: 0.9668 - val_f1_m: 0.9833\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 313us/sample - loss: 4.4788e-04 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1648 - val_accuracy: 0.9667 - val_f1_m: 0.9818\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 312us/sample - loss: 3.6705e-04 - accuracy: 1.0000 - f1_m: 0.9466 - val_loss: 0.1677 - val_accuracy: 0.9668 - val_f1_m: 0.9817\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 309us/sample - loss: 2.9660e-04 - accuracy: 1.0000 - f1_m: 0.9463 - val_loss: 0.1709 - val_accuracy: 0.9669 - val_f1_m: 0.9822\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 611us/sample - loss: 0.0600 - accuracy: 0.9863 - f1_m: 0.9783 - val_loss: 0.1296 - val_accuracy: 0.9636 - val_f1_m: 1.0068\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 361us/sample - loss: 0.0119 - accuracy: 0.9973 - f1_m: 0.9562 - val_loss: 0.1589 - val_accuracy: 0.9645 - val_f1_m: 1.0001\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 358us/sample - loss: 0.0098 - accuracy: 0.9970 - f1_m: 0.9562 - val_loss: 0.1478 - val_accuracy: 0.9635 - val_f1_m: 0.9956\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 345us/sample - loss: 0.0040 - accuracy: 0.9990 - f1_m: 0.9537 - val_loss: 0.1540 - val_accuracy: 0.9685 - val_f1_m: 0.9837\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 348us/sample - loss: 0.0022 - accuracy: 0.9997 - f1_m: 0.9501 - val_loss: 0.1615 - val_accuracy: 0.9725 - val_f1_m: 0.9779\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 349us/sample - loss: 0.0105 - accuracy: 0.9983 - f1_m: 0.9537 - val_loss: 0.1600 - val_accuracy: 0.9657 - val_f1_m: 0.9886\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 353us/sample - loss: 0.0131 - accuracy: 0.9953 - f1_m: 0.9572 - val_loss: 0.1623 - val_accuracy: 0.9613 - val_f1_m: 1.0004\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 345us/sample - loss: 0.0235 - accuracy: 0.9923 - f1_m: 0.9693 - val_loss: 0.1325 - val_accuracy: 0.9675 - val_f1_m: 0.9932\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 351us/sample - loss: 0.0103 - accuracy: 0.9967 - f1_m: 0.9564 - val_loss: 0.1679 - val_accuracy: 0.9670 - val_f1_m: 0.9910\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 357us/sample - loss: 0.0166 - accuracy: 0.9940 - f1_m: 0.9591 - val_loss: 0.1737 - val_accuracy: 0.9585 - val_f1_m: 1.0075\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2s 751us/sample - loss: 0.0525 - accuracy: 0.9867 - f1_m: 0.9761 - val_loss: 0.1506 - val_accuracy: 0.9604 - val_f1_m: 1.0223\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 1s 436us/sample - loss: 0.0087 - accuracy: 0.9983 - f1_m: 0.9592 - val_loss: 0.1879 - val_accuracy: 0.9627 - val_f1_m: 0.9914\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 1s 445us/sample - loss: 0.0234 - accuracy: 0.9933 - f1_m: 0.9644 - val_loss: 0.1729 - val_accuracy: 0.9609 - val_f1_m: 0.9997\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 1s 435us/sample - loss: 0.0222 - accuracy: 0.9933 - f1_m: 0.9631 - val_loss: 0.2150 - val_accuracy: 0.9566 - val_f1_m: 0.9998\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 438us/sample - loss: 0.0285 - accuracy: 0.9897 - f1_m: 0.9739 - val_loss: 0.2021 - val_accuracy: 0.9592 - val_f1_m: 0.9988\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 1s 430us/sample - loss: 0.0096 - accuracy: 0.9957 - f1_m: 0.9572 - val_loss: 0.2681 - val_accuracy: 0.9548 - val_f1_m: 0.9945\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 444us/sample - loss: 0.0188 - accuracy: 0.9943 - f1_m: 0.9618 - val_loss: 0.2818 - val_accuracy: 0.9418 - val_f1_m: 1.0136\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 1s 433us/sample - loss: 0.0177 - accuracy: 0.9943 - f1_m: 0.9651 - val_loss: 0.2330 - val_accuracy: 0.9624 - val_f1_m: 0.9794\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 422us/sample - loss: 0.0209 - accuracy: 0.9947 - f1_m: 0.9623 - val_loss: 0.2108 - val_accuracy: 0.9504 - val_f1_m: 1.0074\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 1s 427us/sample - loss: 0.0148 - accuracy: 0.9950 - f1_m: 0.9580 - val_loss: 0.2072 - val_accuracy: 0.9619 - val_f1_m: 0.9986\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 407us/sample - loss: 0.1549 - accuracy: 0.9543 - f1_m: 1.1029 - val_loss: 0.3905 - val_accuracy: 0.9013 - val_f1_m: 1.1162\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 254us/sample - loss: 0.1421 - accuracy: 0.9597 - f1_m: 1.1016 - val_loss: 0.3895 - val_accuracy: 0.9011 - val_f1_m: 1.1304\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 260us/sample - loss: 0.1263 - accuracy: 0.9634 - f1_m: 1.0942 - val_loss: 0.3846 - val_accuracy: 0.9011 - val_f1_m: 1.1260\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 267us/sample - loss: 0.1114 - accuracy: 0.9691 - f1_m: 1.0978 - val_loss: 0.3747 - val_accuracy: 0.9054 - val_f1_m: 1.1292\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 244us/sample - loss: 0.1169 - accuracy: 0.9671 - f1_m: 1.1027 - val_loss: 0.3624 - val_accuracy: 0.9072 - val_f1_m: 1.1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 260us/sample - loss: 0.1153 - accuracy: 0.9629 - f1_m: 1.1105 - val_loss: 0.3671 - val_accuracy: 0.9056 - val_f1_m: 1.1219\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 258us/sample - loss: 0.0992 - accuracy: 0.9697 - f1_m: 1.0856 - val_loss: 0.3647 - val_accuracy: 0.9069 - val_f1_m: 1.1211\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 259us/sample - loss: 0.0981 - accuracy: 0.9737 - f1_m: 1.0963 - val_loss: 0.3666 - val_accuracy: 0.9122 - val_f1_m: 1.1108\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 249us/sample - loss: 0.0938 - accuracy: 0.9729 - f1_m: 1.0791 - val_loss: 0.3791 - val_accuracy: 0.9066 - val_f1_m: 1.1139\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 240us/sample - loss: 0.0840 - accuracy: 0.9766 - f1_m: 1.0774 - val_loss: 0.3711 - val_accuracy: 0.9081 - val_f1_m: 1.1086\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 428us/sample - loss: 0.0634 - accuracy: 0.9826 - f1_m: 1.0034 - val_loss: 0.1953 - val_accuracy: 0.9565 - val_f1_m: 1.0157\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 267us/sample - loss: 0.0381 - accuracy: 0.9903 - f1_m: 0.9893 - val_loss: 0.1925 - val_accuracy: 0.9548 - val_f1_m: 1.0287\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 264us/sample - loss: 0.0300 - accuracy: 0.9920 - f1_m: 0.9910 - val_loss: 0.1847 - val_accuracy: 0.9571 - val_f1_m: 1.0247\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 266us/sample - loss: 0.0248 - accuracy: 0.9943 - f1_m: 0.9868 - val_loss: 0.2110 - val_accuracy: 0.9492 - val_f1_m: 1.0403\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 264us/sample - loss: 0.0222 - accuracy: 0.9949 - f1_m: 0.9826 - val_loss: 0.2018 - val_accuracy: 0.9575 - val_f1_m: 1.0309\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 262us/sample - loss: 0.0218 - accuracy: 0.9943 - f1_m: 0.9906 - val_loss: 0.2065 - val_accuracy: 0.9545 - val_f1_m: 1.0192\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 257us/sample - loss: 0.0152 - accuracy: 0.9960 - f1_m: 0.9769 - val_loss: 0.2097 - val_accuracy: 0.9552 - val_f1_m: 1.0184\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 260us/sample - loss: 0.0280 - accuracy: 0.9911 - f1_m: 0.9912 - val_loss: 0.2151 - val_accuracy: 0.9549 - val_f1_m: 1.0186\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 262us/sample - loss: 0.0145 - accuracy: 0.9963 - f1_m: 0.9728 - val_loss: 0.1960 - val_accuracy: 0.9588 - val_f1_m: 1.0138\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 263us/sample - loss: 0.0108 - accuracy: 0.9974 - f1_m: 0.9677 - val_loss: 0.1988 - val_accuracy: 0.9580 - val_f1_m: 1.0056\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 521us/sample - loss: 0.0518 - accuracy: 0.9891 - f1_m: 0.9754 - val_loss: 0.1911 - val_accuracy: 0.9575 - val_f1_m: 1.0089\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 297us/sample - loss: 0.0262 - accuracy: 0.9931 - f1_m: 0.9680 - val_loss: 0.1952 - val_accuracy: 0.9592 - val_f1_m: 1.0051\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 299us/sample - loss: 0.0153 - accuracy: 0.9977 - f1_m: 0.9588 - val_loss: 0.1914 - val_accuracy: 0.9600 - val_f1_m: 0.9979\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 303us/sample - loss: 0.0160 - accuracy: 0.9946 - f1_m: 0.9651 - val_loss: 0.2169 - val_accuracy: 0.9544 - val_f1_m: 1.0035\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 297us/sample - loss: 0.0266 - accuracy: 0.9914 - f1_m: 0.9685 - val_loss: 0.1781 - val_accuracy: 0.9619 - val_f1_m: 1.0059\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 300us/sample - loss: 0.0070 - accuracy: 0.9986 - f1_m: 0.9570 - val_loss: 0.1952 - val_accuracy: 0.9648 - val_f1_m: 0.9929\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 302us/sample - loss: 0.0309 - accuracy: 0.9909 - f1_m: 0.9646 - val_loss: 0.2073 - val_accuracy: 0.9567 - val_f1_m: 1.0122\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 302us/sample - loss: 0.0204 - accuracy: 0.9937 - f1_m: 0.9712 - val_loss: 0.1779 - val_accuracy: 0.9612 - val_f1_m: 0.9999\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 305us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9491 - val_loss: 0.2076 - val_accuracy: 0.9599 - val_f1_m: 0.9943\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 306us/sample - loss: 0.0013 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1945 - val_accuracy: 0.9658 - val_f1_m: 0.9869\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 644us/sample - loss: 0.0653 - accuracy: 0.9809 - f1_m: 0.9942 - val_loss: 0.1961 - val_accuracy: 0.9478 - val_f1_m: 1.0536\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 362us/sample - loss: 0.0351 - accuracy: 0.9903 - f1_m: 0.9831 - val_loss: 0.2110 - val_accuracy: 0.9470 - val_f1_m: 1.0182\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 356us/sample - loss: 0.0370 - accuracy: 0.9906 - f1_m: 0.9765 - val_loss: 0.1836 - val_accuracy: 0.9525 - val_f1_m: 1.0199\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 361us/sample - loss: 0.0129 - accuracy: 0.9974 - f1_m: 0.9636 - val_loss: 0.2480 - val_accuracy: 0.9509 - val_f1_m: 1.0075\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 366us/sample - loss: 0.0266 - accuracy: 0.9900 - f1_m: 0.9763 - val_loss: 0.2513 - val_accuracy: 0.9477 - val_f1_m: 1.0208\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 357us/sample - loss: 0.0533 - accuracy: 0.9806 - f1_m: 0.9938 - val_loss: 0.2162 - val_accuracy: 0.9507 - val_f1_m: 1.0202\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 357us/sample - loss: 0.0097 - accuracy: 0.9977 - f1_m: 0.9632 - val_loss: 0.2507 - val_accuracy: 0.9542 - val_f1_m: 0.9998\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 357us/sample - loss: 0.0032 - accuracy: 0.9991 - f1_m: 0.9533 - val_loss: 0.2657 - val_accuracy: 0.9543 - val_f1_m: 0.9941\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 366us/sample - loss: 0.0316 - accuracy: 0.9903 - f1_m: 0.9771 - val_loss: 0.2623 - val_accuracy: 0.9509 - val_f1_m: 1.0014\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 358us/sample - loss: 0.0377 - accuracy: 0.9877 - f1_m: 0.9769 - val_loss: 0.2222 - val_accuracy: 0.9518 - val_f1_m: 1.0072\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1s 393us/sample - loss: 0.0878 - accuracy: 0.9803 - f1_m: 1.0090 - val_loss: 0.3415 - val_accuracy: 0.9320 - val_f1_m: 1.0375\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 243us/sample - loss: 0.0529 - accuracy: 0.9871 - f1_m: 0.9887 - val_loss: 0.3313 - val_accuracy: 0.9311 - val_f1_m: 1.0496\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 247us/sample - loss: 0.0325 - accuracy: 0.9937 - f1_m: 0.9830 - val_loss: 0.3192 - val_accuracy: 0.9319 - val_f1_m: 1.0427\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 247us/sample - loss: 0.0273 - accuracy: 0.9937 - f1_m: 0.9812 - val_loss: 0.3390 - val_accuracy: 0.9294 - val_f1_m: 1.0544\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 248us/sample - loss: 0.0245 - accuracy: 0.9954 - f1_m: 0.9772 - val_loss: 0.3307 - val_accuracy: 0.9338 - val_f1_m: 1.0347\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 248us/sample - loss: 0.0169 - accuracy: 0.9974 - f1_m: 0.9724 - val_loss: 0.3420 - val_accuracy: 0.9340 - val_f1_m: 1.0394\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 261us/sample - loss: 0.0210 - accuracy: 0.9937 - f1_m: 0.9766 - val_loss: 0.3643 - val_accuracy: 0.9238 - val_f1_m: 1.0460\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 247us/sample - loss: 0.0134 - accuracy: 0.9971 - f1_m: 0.9750 - val_loss: 0.3289 - val_accuracy: 0.9343 - val_f1_m: 1.0205\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 238us/sample - loss: 0.0055 - accuracy: 0.9997 - f1_m: 0.9563 - val_loss: 0.3350 - val_accuracy: 0.9368 - val_f1_m: 1.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 246us/sample - loss: 0.0037 - accuracy: 1.0000 - f1_m: 0.9530 - val_loss: 0.3425 - val_accuracy: 0.9377 - val_f1_m: 1.0167\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 448us/sample - loss: 0.0453 - accuracy: 0.9897 - f1_m: 0.9712 - val_loss: 0.1600 - val_accuracy: 0.9605 - val_f1_m: 1.0071\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 272us/sample - loss: 0.0159 - accuracy: 0.9957 - f1_m: 0.9662 - val_loss: 0.1501 - val_accuracy: 0.9689 - val_f1_m: 0.9928\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 268us/sample - loss: 0.0074 - accuracy: 0.9983 - f1_m: 0.9551 - val_loss: 0.2037 - val_accuracy: 0.9580 - val_f1_m: 1.0047\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 271us/sample - loss: 0.0198 - accuracy: 0.9931 - f1_m: 0.9712 - val_loss: 0.1514 - val_accuracy: 0.9668 - val_f1_m: 0.9924\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 275us/sample - loss: 0.0052 - accuracy: 0.9983 - f1_m: 0.9554 - val_loss: 0.1520 - val_accuracy: 0.9690 - val_f1_m: 0.9840\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 274us/sample - loss: 0.0063 - accuracy: 0.9980 - f1_m: 0.9557 - val_loss: 0.1734 - val_accuracy: 0.9645 - val_f1_m: 0.9903\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 273us/sample - loss: 0.0071 - accuracy: 0.9971 - f1_m: 0.9538 - val_loss: 0.1718 - val_accuracy: 0.9648 - val_f1_m: 0.9930\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 274us/sample - loss: 0.0064 - accuracy: 0.9980 - f1_m: 0.9551 - val_loss: 0.1583 - val_accuracy: 0.9700 - val_f1_m: 0.9806\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 267us/sample - loss: 0.0097 - accuracy: 0.9986 - f1_m: 0.9529 - val_loss: 0.1543 - val_accuracy: 0.9686 - val_f1_m: 0.9840\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 265us/sample - loss: 7.5258e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1446 - val_accuracy: 0.9721 - val_f1_m: 0.9819\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 532us/sample - loss: 0.0452 - accuracy: 0.9880 - f1_m: 0.9663 - val_loss: 0.1091 - val_accuracy: 0.9695 - val_f1_m: 0.9965\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 318us/sample - loss: 0.0092 - accuracy: 0.9966 - f1_m: 0.9542 - val_loss: 0.1150 - val_accuracy: 0.9739 - val_f1_m: 0.9849\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 320us/sample - loss: 0.0020 - accuracy: 0.9991 - f1_m: 0.9495 - val_loss: 0.1071 - val_accuracy: 0.9752 - val_f1_m: 0.9822\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 313us/sample - loss: 4.0332e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1151 - val_accuracy: 0.9758 - val_f1_m: 0.9776\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 313us/sample - loss: 1.0660e-04 - accuracy: 1.0000 - f1_m: 0.9460 - val_loss: 0.1187 - val_accuracy: 0.9773 - val_f1_m: 0.9765\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 315us/sample - loss: 7.0993e-05 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.1218 - val_accuracy: 0.9777 - val_f1_m: 0.9761\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 314us/sample - loss: 5.2666e-05 - accuracy: 1.0000 - f1_m: 0.9463 - val_loss: 0.1244 - val_accuracy: 0.9777 - val_f1_m: 0.9760\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 316us/sample - loss: 4.0351e-05 - accuracy: 1.0000 - f1_m: 0.9460 - val_loss: 0.1268 - val_accuracy: 0.9773 - val_f1_m: 0.9749\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 333us/sample - loss: 3.2331e-05 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.1289 - val_accuracy: 0.9768 - val_f1_m: 0.9747\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 312us/sample - loss: 2.6349e-05 - accuracy: 1.0000 - f1_m: 0.9463 - val_loss: 0.1307 - val_accuracy: 0.9767 - val_f1_m: 0.9747\n",
      "Train on 3500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 2s 648us/sample - loss: 0.0394 - accuracy: 0.9880 - f1_m: 0.9734 - val_loss: 0.1498 - val_accuracy: 0.9665 - val_f1_m: 1.0087\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 1s 385us/sample - loss: 0.0159 - accuracy: 0.9957 - f1_m: 0.9622 - val_loss: 0.1528 - val_accuracy: 0.9635 - val_f1_m: 1.0007\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 1s 389us/sample - loss: 0.0128 - accuracy: 0.9957 - f1_m: 0.9611 - val_loss: 0.2350 - val_accuracy: 0.9623 - val_f1_m: 0.9822\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 1s 388us/sample - loss: 0.0131 - accuracy: 0.9954 - f1_m: 0.9567 - val_loss: 0.2222 - val_accuracy: 0.9526 - val_f1_m: 0.9936\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 1s 376us/sample - loss: 0.0224 - accuracy: 0.9937 - f1_m: 0.9633 - val_loss: 0.1575 - val_accuracy: 0.9652 - val_f1_m: 0.9935\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 1s 389us/sample - loss: 0.0239 - accuracy: 0.9914 - f1_m: 0.9696 - val_loss: 0.2292 - val_accuracy: 0.9523 - val_f1_m: 1.0048\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 1s 386us/sample - loss: 0.0081 - accuracy: 0.9971 - f1_m: 0.9536 - val_loss: 0.1720 - val_accuracy: 0.9640 - val_f1_m: 0.9981\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 1s 379us/sample - loss: 0.0061 - accuracy: 0.9986 - f1_m: 0.9537 - val_loss: 0.2139 - val_accuracy: 0.9627 - val_f1_m: 0.9873\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 1s 389us/sample - loss: 0.0278 - accuracy: 0.9911 - f1_m: 0.9642 - val_loss: 0.1697 - val_accuracy: 0.9653 - val_f1_m: 0.9892\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 1s 386us/sample - loss: 0.0117 - accuracy: 0.9951 - f1_m: 0.9596 - val_loss: 0.1847 - val_accuracy: 0.9624 - val_f1_m: 0.9914\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 344us/sample - loss: 0.1177 - accuracy: 0.9643 - f1_m: 1.0821 - val_loss: 0.3798 - val_accuracy: 0.9121 - val_f1_m: 1.1011\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 212us/sample - loss: 0.1052 - accuracy: 0.9705 - f1_m: 1.0799 - val_loss: 0.3812 - val_accuracy: 0.9098 - val_f1_m: 1.0999\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 218us/sample - loss: 0.0977 - accuracy: 0.9695 - f1_m: 1.0718 - val_loss: 0.3804 - val_accuracy: 0.9132 - val_f1_m: 1.0986\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 224us/sample - loss: 0.0961 - accuracy: 0.9688 - f1_m: 1.0772 - val_loss: 0.3852 - val_accuracy: 0.9119 - val_f1_m: 1.1146\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.0934 - accuracy: 0.9722 - f1_m: 1.0721 - val_loss: 0.3800 - val_accuracy: 0.9120 - val_f1_m: 1.0962\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 221us/sample - loss: 0.0841 - accuracy: 0.9753 - f1_m: 1.0708 - val_loss: 0.3880 - val_accuracy: 0.9131 - val_f1_m: 1.0979\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 217us/sample - loss: 0.0781 - accuracy: 0.9787 - f1_m: 1.0621 - val_loss: 0.3753 - val_accuracy: 0.9091 - val_f1_m: 1.0971\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 218us/sample - loss: 0.0716 - accuracy: 0.9772 - f1_m: 1.0623 - val_loss: 0.3924 - val_accuracy: 0.9153 - val_f1_m: 1.0891\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 217us/sample - loss: 0.0676 - accuracy: 0.9818 - f1_m: 1.0547 - val_loss: 0.3979 - val_accuracy: 0.9036 - val_f1_m: 1.0936\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 211us/sample - loss: 0.0651 - accuracy: 0.9810 - f1_m: 1.0567 - val_loss: 0.4018 - val_accuracy: 0.9071 - val_f1_m: 1.0998\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 374us/sample - loss: 0.0292 - accuracy: 0.9918 - f1_m: 0.9779 - val_loss: 0.2237 - val_accuracy: 0.9546 - val_f1_m: 1.0124\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 234us/sample - loss: 0.0203 - accuracy: 0.9935 - f1_m: 0.9718 - val_loss: 0.2319 - val_accuracy: 0.9525 - val_f1_m: 1.0156\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 225us/sample - loss: 0.0169 - accuracy: 0.9952 - f1_m: 0.9679 - val_loss: 0.1877 - val_accuracy: 0.9626 - val_f1_m: 1.0026\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 229us/sample - loss: 0.0200 - accuracy: 0.9935 - f1_m: 0.9679 - val_loss: 0.2102 - val_accuracy: 0.9584 - val_f1_m: 1.0084\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 233us/sample - loss: 0.0114 - accuracy: 0.9965 - f1_m: 0.9646 - val_loss: 0.2050 - val_accuracy: 0.9582 - val_f1_m: 0.9975\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 238us/sample - loss: 0.0060 - accuracy: 0.9987 - f1_m: 0.9547 - val_loss: 0.1983 - val_accuracy: 0.9603 - val_f1_m: 1.0025\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 237us/sample - loss: 0.0043 - accuracy: 0.9995 - f1_m: 0.9519 - val_loss: 0.2105 - val_accuracy: 0.9604 - val_f1_m: 1.0003\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 233us/sample - loss: 0.0033 - accuracy: 0.9995 - f1_m: 0.9498 - val_loss: 0.1959 - val_accuracy: 0.9634 - val_f1_m: 0.9940\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 248us/sample - loss: 0.0022 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.2033 - val_accuracy: 0.9634 - val_f1_m: 0.9937\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 240us/sample - loss: 0.0014 - accuracy: 1.0000 - f1_m: 0.9444 - val_loss: 0.2012 - val_accuracy: 0.9647 - val_f1_m: 0.9911\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 448us/sample - loss: 0.0372 - accuracy: 0.9898 - f1_m: 0.9662 - val_loss: 0.2131 - val_accuracy: 0.9609 - val_f1_m: 0.9906\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 270us/sample - loss: 0.0158 - accuracy: 0.9962 - f1_m: 0.9568 - val_loss: 0.1766 - val_accuracy: 0.9648 - val_f1_m: 0.9854\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 272us/sample - loss: 0.0184 - accuracy: 0.9940 - f1_m: 0.9546 - val_loss: 0.2138 - val_accuracy: 0.9561 - val_f1_m: 1.0011\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 270us/sample - loss: 0.0140 - accuracy: 0.9955 - f1_m: 0.9634 - val_loss: 0.2012 - val_accuracy: 0.9615 - val_f1_m: 0.9864\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 270us/sample - loss: 0.0075 - accuracy: 0.9967 - f1_m: 0.9502 - val_loss: 0.2129 - val_accuracy: 0.9612 - val_f1_m: 0.9890\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 271us/sample - loss: 0.0097 - accuracy: 0.9965 - f1_m: 0.9564 - val_loss: 0.2265 - val_accuracy: 0.9573 - val_f1_m: 0.9902\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 278us/sample - loss: 0.0068 - accuracy: 0.9987 - f1_m: 0.9496 - val_loss: 0.2082 - val_accuracy: 0.9629 - val_f1_m: 0.9870\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 269us/sample - loss: 9.2374e-04 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.1874 - val_accuracy: 0.9691 - val_f1_m: 0.9786\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 272us/sample - loss: 4.9576e-04 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1938 - val_accuracy: 0.9693 - val_f1_m: 0.9752\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 267us/sample - loss: 1.8198e-04 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1988 - val_accuracy: 0.9687 - val_f1_m: 0.9722\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 541us/sample - loss: 0.0409 - accuracy: 0.9895 - f1_m: 0.9746 - val_loss: 0.2235 - val_accuracy: 0.9559 - val_f1_m: 1.0010\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 322us/sample - loss: 0.0402 - accuracy: 0.9887 - f1_m: 0.9716 - val_loss: 0.1867 - val_accuracy: 0.9550 - val_f1_m: 1.0185\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 333us/sample - loss: 0.0145 - accuracy: 0.9967 - f1_m: 0.9619 - val_loss: 0.2111 - val_accuracy: 0.9555 - val_f1_m: 0.9943\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 328us/sample - loss: 0.0136 - accuracy: 0.9958 - f1_m: 0.9630 - val_loss: 0.2858 - val_accuracy: 0.9474 - val_f1_m: 0.9910\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.0278 - accuracy: 0.9912 - f1_m: 0.9678 - val_loss: 0.2788 - val_accuracy: 0.9504 - val_f1_m: 0.9991\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 331us/sample - loss: 0.0245 - accuracy: 0.9912 - f1_m: 0.9661 - val_loss: 0.3981 - val_accuracy: 0.9341 - val_f1_m: 1.0168\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 324us/sample - loss: 0.0222 - accuracy: 0.9925 - f1_m: 0.9609 - val_loss: 0.2754 - val_accuracy: 0.9379 - val_f1_m: 1.0166\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 322us/sample - loss: 0.0221 - accuracy: 0.9942 - f1_m: 0.9646 - val_loss: 0.2062 - val_accuracy: 0.9573 - val_f1_m: 0.9993\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 326us/sample - loss: 0.0125 - accuracy: 0.9960 - f1_m: 0.9551 - val_loss: 0.2130 - val_accuracy: 0.9535 - val_f1_m: 0.9979\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 324us/sample - loss: 0.0111 - accuracy: 0.9965 - f1_m: 0.9547 - val_loss: 0.2168 - val_accuracy: 0.9571 - val_f1_m: 0.9853\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1s 340us/sample - loss: 0.0480 - accuracy: 0.9880 - f1_m: 0.9844 - val_loss: 0.3715 - val_accuracy: 0.9278 - val_f1_m: 1.0409\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 227us/sample - loss: 0.0240 - accuracy: 0.9942 - f1_m: 0.9698 - val_loss: 0.4064 - val_accuracy: 0.9231 - val_f1_m: 1.0376\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 240us/sample - loss: 0.0237 - accuracy: 0.9908 - f1_m: 0.9784 - val_loss: 0.3672 - val_accuracy: 0.9324 - val_f1_m: 1.0211\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 231us/sample - loss: 0.0098 - accuracy: 0.9985 - f1_m: 0.9599 - val_loss: 0.3513 - val_accuracy: 0.9342 - val_f1_m: 1.0216\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 221us/sample - loss: 0.0156 - accuracy: 0.9958 - f1_m: 0.9674 - val_loss: 0.3742 - val_accuracy: 0.9327 - val_f1_m: 1.0277\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 222us/sample - loss: 0.0183 - accuracy: 0.9952 - f1_m: 0.9647 - val_loss: 0.4443 - val_accuracy: 0.9192 - val_f1_m: 1.0410\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 218us/sample - loss: 0.0194 - accuracy: 0.9950 - f1_m: 0.9709 - val_loss: 0.3935 - val_accuracy: 0.9305 - val_f1_m: 1.0278\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 221us/sample - loss: 0.0046 - accuracy: 0.9998 - f1_m: 0.9545 - val_loss: 0.3454 - val_accuracy: 0.9359 - val_f1_m: 1.0120\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 213us/sample - loss: 0.0023 - accuracy: 1.0000 - f1_m: 0.9465 - val_loss: 0.3533 - val_accuracy: 0.9367 - val_f1_m: 1.0065\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 215us/sample - loss: 0.0016 - accuracy: 1.0000 - f1_m: 0.9444 - val_loss: 0.3543 - val_accuracy: 0.9388 - val_f1_m: 1.0049\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 380us/sample - loss: 0.0164 - accuracy: 0.9962 - f1_m: 0.9570 - val_loss: 0.1924 - val_accuracy: 0.9655 - val_f1_m: 0.9975\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 238us/sample - loss: 0.0106 - accuracy: 0.9967 - f1_m: 0.9557 - val_loss: 0.1670 - val_accuracy: 0.9703 - val_f1_m: 0.9929\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 239us/sample - loss: 0.0170 - accuracy: 0.9937 - f1_m: 0.9610 - val_loss: 0.1537 - val_accuracy: 0.9714 - val_f1_m: 0.9847\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 240us/sample - loss: 0.0023 - accuracy: 0.9992 - f1_m: 0.9468 - val_loss: 0.1526 - val_accuracy: 0.9732 - val_f1_m: 0.9795\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 243us/sample - loss: 4.7286e-04 - accuracy: 1.0000 - f1_m: 0.9439 - val_loss: 0.1496 - val_accuracy: 0.9744 - val_f1_m: 0.9742\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 241us/sample - loss: 1.7033e-04 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1491 - val_accuracy: 0.9746 - val_f1_m: 0.9728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 239us/sample - loss: 1.1596e-04 - accuracy: 1.0000 - f1_m: 0.9430 - val_loss: 0.1503 - val_accuracy: 0.9741 - val_f1_m: 0.9721\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 241us/sample - loss: 9.7287e-05 - accuracy: 1.0000 - f1_m: 0.9432 - val_loss: 0.1520 - val_accuracy: 0.9749 - val_f1_m: 0.9717\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 238us/sample - loss: 8.3627e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1539 - val_accuracy: 0.9748 - val_f1_m: 0.9718\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 233us/sample - loss: 7.1689e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1549 - val_accuracy: 0.9747 - val_f1_m: 0.9717\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 437us/sample - loss: 0.0313 - accuracy: 0.9910 - f1_m: 0.9545 - val_loss: 0.1571 - val_accuracy: 0.9684 - val_f1_m: 0.9817\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 281us/sample - loss: 0.0120 - accuracy: 0.9962 - f1_m: 0.9509 - val_loss: 0.1153 - val_accuracy: 0.9709 - val_f1_m: 0.9873\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 282us/sample - loss: 0.0014 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.1164 - val_accuracy: 0.9734 - val_f1_m: 0.9809\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 281us/sample - loss: 2.3599e-04 - accuracy: 1.0000 - f1_m: 0.9434 - val_loss: 0.1212 - val_accuracy: 0.9762 - val_f1_m: 0.9795\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 283us/sample - loss: 9.2412e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1246 - val_accuracy: 0.9759 - val_f1_m: 0.9769\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 280us/sample - loss: 5.9072e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1275 - val_accuracy: 0.9757 - val_f1_m: 0.9759\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 278us/sample - loss: 4.4008e-05 - accuracy: 1.0000 - f1_m: 0.9430 - val_loss: 0.1299 - val_accuracy: 0.9758 - val_f1_m: 0.9750\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 277us/sample - loss: 3.3915e-05 - accuracy: 1.0000 - f1_m: 0.9432 - val_loss: 0.1322 - val_accuracy: 0.9758 - val_f1_m: 0.9748\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 284us/sample - loss: 2.7230e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1343 - val_accuracy: 0.9755 - val_f1_m: 0.9745\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 279us/sample - loss: 2.2398e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.1364 - val_accuracy: 0.9758 - val_f1_m: 0.9741\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 3s 767us/sample - loss: 0.0253 - accuracy: 0.9923 - f1_m: 0.9580 - val_loss: 0.1974 - val_accuracy: 0.9564 - val_f1_m: 1.0103\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 345us/sample - loss: 0.0079 - accuracy: 0.9970 - f1_m: 0.9541 - val_loss: 0.1632 - val_accuracy: 0.9655 - val_f1_m: 0.9878\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 347us/sample - loss: 0.0067 - accuracy: 0.9973 - f1_m: 0.9487 - val_loss: 0.1868 - val_accuracy: 0.9644 - val_f1_m: 0.9878\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 352us/sample - loss: 0.0262 - accuracy: 0.9900 - f1_m: 0.9628 - val_loss: 0.1469 - val_accuracy: 0.9709 - val_f1_m: 0.9899\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 348us/sample - loss: 0.0131 - accuracy: 0.9958 - f1_m: 0.9529 - val_loss: 0.1496 - val_accuracy: 0.9712 - val_f1_m: 0.9807\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 355us/sample - loss: 0.0020 - accuracy: 0.9995 - f1_m: 0.9459 - val_loss: 0.1913 - val_accuracy: 0.9721 - val_f1_m: 0.9744\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 346us/sample - loss: 2.3614e-04 - accuracy: 1.0000 - f1_m: 0.9435 - val_loss: 0.1963 - val_accuracy: 0.9717 - val_f1_m: 0.9704\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 348us/sample - loss: 2.6983e-05 - accuracy: 1.0000 - f1_m: 0.9432 - val_loss: 0.2005 - val_accuracy: 0.9716 - val_f1_m: 0.9697\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 354us/sample - loss: 1.5709e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.2033 - val_accuracy: 0.9718 - val_f1_m: 0.9685\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 345us/sample - loss: 1.1770e-05 - accuracy: 1.0000 - f1_m: 0.9431 - val_loss: 0.2058 - val_accuracy: 0.9717 - val_f1_m: 0.9682\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 1s 322us/sample - loss: 0.1172 - accuracy: 0.9684 - f1_m: 1.0583 - val_loss: 0.3820 - val_accuracy: 0.9146 - val_f1_m: 1.0870\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 210us/sample - loss: 0.0919 - accuracy: 0.9782 - f1_m: 1.0560 - val_loss: 0.3860 - val_accuracy: 0.9116 - val_f1_m: 1.0885\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 210us/sample - loss: 0.0884 - accuracy: 0.9740 - f1_m: 1.0513 - val_loss: 0.3583 - val_accuracy: 0.9119 - val_f1_m: 1.0963\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 209us/sample - loss: 0.0818 - accuracy: 0.9780 - f1_m: 1.0570 - val_loss: 0.3625 - val_accuracy: 0.9190 - val_f1_m: 1.0754\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 210us/sample - loss: 0.0750 - accuracy: 0.9789 - f1_m: 1.0519 - val_loss: 0.3576 - val_accuracy: 0.9200 - val_f1_m: 1.0778\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 209us/sample - loss: 0.0667 - accuracy: 0.9833 - f1_m: 1.0465 - val_loss: 0.3738 - val_accuracy: 0.9178 - val_f1_m: 1.0813\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 209us/sample - loss: 0.0626 - accuracy: 0.9836 - f1_m: 1.0404 - val_loss: 0.3796 - val_accuracy: 0.9190 - val_f1_m: 1.0671\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 207us/sample - loss: 0.0600 - accuracy: 0.9827 - f1_m: 1.0356 - val_loss: 0.3603 - val_accuracy: 0.9234 - val_f1_m: 1.0720\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 205us/sample - loss: 0.0601 - accuracy: 0.9829 - f1_m: 1.0321 - val_loss: 0.3622 - val_accuracy: 0.9206 - val_f1_m: 1.0732\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 206us/sample - loss: 0.0558 - accuracy: 0.9860 - f1_m: 1.0313 - val_loss: 0.3552 - val_accuracy: 0.9215 - val_f1_m: 1.0761\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 348us/sample - loss: 0.0542 - accuracy: 0.9898 - f1_m: 0.9668 - val_loss: 0.2733 - val_accuracy: 0.9484 - val_f1_m: 1.0138\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 224us/sample - loss: 0.0365 - accuracy: 0.9922 - f1_m: 0.9662 - val_loss: 0.1948 - val_accuracy: 0.9632 - val_f1_m: 0.9995\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 223us/sample - loss: 0.0240 - accuracy: 0.9942 - f1_m: 0.9607 - val_loss: 0.2270 - val_accuracy: 0.9498 - val_f1_m: 1.0132\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 223us/sample - loss: 0.0221 - accuracy: 0.9944 - f1_m: 0.9599 - val_loss: 0.1967 - val_accuracy: 0.9627 - val_f1_m: 0.9974\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 224us/sample - loss: 0.0153 - accuracy: 0.9960 - f1_m: 0.9618 - val_loss: 0.1968 - val_accuracy: 0.9626 - val_f1_m: 0.9966\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 222us/sample - loss: 0.0118 - accuracy: 0.9980 - f1_m: 0.9609 - val_loss: 0.2001 - val_accuracy: 0.9626 - val_f1_m: 0.9960\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 223us/sample - loss: 0.0084 - accuracy: 0.9987 - f1_m: 0.9528 - val_loss: 0.2178 - val_accuracy: 0.9602 - val_f1_m: 0.9945\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 223us/sample - loss: 0.0081 - accuracy: 0.9980 - f1_m: 0.9545 - val_loss: 0.2094 - val_accuracy: 0.9602 - val_f1_m: 0.9934\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 223us/sample - loss: 0.0084 - accuracy: 0.9976 - f1_m: 0.9567 - val_loss: 0.2089 - val_accuracy: 0.9630 - val_f1_m: 0.9899\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 223us/sample - loss: 0.0151 - accuracy: 0.9947 - f1_m: 0.9590 - val_loss: 0.2257 - val_accuracy: 0.9576 - val_f1_m: 0.9957\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 408us/sample - loss: 0.0337 - accuracy: 0.9929 - f1_m: 0.9600 - val_loss: 0.1634 - val_accuracy: 0.9656 - val_f1_m: 0.9951\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 259us/sample - loss: 0.0212 - accuracy: 0.9947 - f1_m: 0.9604 - val_loss: 0.1775 - val_accuracy: 0.9579 - val_f1_m: 1.0003\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 258us/sample - loss: 0.0096 - accuracy: 0.9976 - f1_m: 0.9534 - val_loss: 0.2153 - val_accuracy: 0.9584 - val_f1_m: 0.9993\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 257us/sample - loss: 0.0238 - accuracy: 0.9924 - f1_m: 0.9629 - val_loss: 0.2049 - val_accuracy: 0.9619 - val_f1_m: 0.9976\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 264us/sample - loss: 0.0177 - accuracy: 0.9922 - f1_m: 0.9630 - val_loss: 0.1590 - val_accuracy: 0.9672 - val_f1_m: 0.9917\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 259us/sample - loss: 0.0117 - accuracy: 0.9958 - f1_m: 0.9563 - val_loss: 0.1702 - val_accuracy: 0.9685 - val_f1_m: 0.9846\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 262us/sample - loss: 0.0066 - accuracy: 0.9976 - f1_m: 0.9511 - val_loss: 0.2032 - val_accuracy: 0.9614 - val_f1_m: 0.9844\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 257us/sample - loss: 0.0078 - accuracy: 0.9973 - f1_m: 0.9507 - val_loss: 0.1769 - val_accuracy: 0.9689 - val_f1_m: 0.9816\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 260us/sample - loss: 0.0085 - accuracy: 0.9973 - f1_m: 0.9537 - val_loss: 0.1869 - val_accuracy: 0.9656 - val_f1_m: 0.9846\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 255us/sample - loss: 0.0142 - accuracy: 0.9949 - f1_m: 0.9566 - val_loss: 0.2099 - val_accuracy: 0.9627 - val_f1_m: 0.9833\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 508us/sample - loss: 0.0449 - accuracy: 0.9884 - f1_m: 0.9725 - val_loss: 0.1601 - val_accuracy: 0.9613 - val_f1_m: 1.0080\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 307us/sample - loss: 0.0175 - accuracy: 0.9958 - f1_m: 0.9636 - val_loss: 0.1833 - val_accuracy: 0.9590 - val_f1_m: 1.0090\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 315us/sample - loss: 0.0159 - accuracy: 0.9956 - f1_m: 0.9585 - val_loss: 0.2089 - val_accuracy: 0.9570 - val_f1_m: 0.9975\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 307us/sample - loss: 0.0325 - accuracy: 0.9871 - f1_m: 0.9689 - val_loss: 0.1668 - val_accuracy: 0.9586 - val_f1_m: 1.0150\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 309us/sample - loss: 0.0294 - accuracy: 0.9909 - f1_m: 0.9657 - val_loss: 0.1623 - val_accuracy: 0.9589 - val_f1_m: 1.0096\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 316us/sample - loss: 0.0162 - accuracy: 0.9964 - f1_m: 0.9607 - val_loss: 0.1759 - val_accuracy: 0.9614 - val_f1_m: 0.9887\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 310us/sample - loss: 0.0053 - accuracy: 0.9982 - f1_m: 0.9494 - val_loss: 0.2096 - val_accuracy: 0.9619 - val_f1_m: 0.9841\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 317us/sample - loss: 0.0210 - accuracy: 0.9920 - f1_m: 0.9616 - val_loss: 0.2490 - val_accuracy: 0.9586 - val_f1_m: 0.9901\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 2s 336us/sample - loss: 0.0132 - accuracy: 0.9958 - f1_m: 0.9570 - val_loss: 0.2373 - val_accuracy: 0.9550 - val_f1_m: 0.9924\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 315us/sample - loss: 0.0079 - accuracy: 0.9973 - f1_m: 0.9539 - val_loss: 0.2343 - val_accuracy: 0.9598 - val_f1_m: 0.9844\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 356us/sample - loss: 0.0624 - accuracy: 0.9849 - f1_m: 0.9818 - val_loss: 0.3664 - val_accuracy: 0.9311 - val_f1_m: 1.0286\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 212us/sample - loss: 0.0318 - accuracy: 0.9924 - f1_m: 0.9738 - val_loss: 0.3464 - val_accuracy: 0.9323 - val_f1_m: 1.0223\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 208us/sample - loss: 0.0144 - accuracy: 0.9971 - f1_m: 0.9647 - val_loss: 0.3391 - val_accuracy: 0.9330 - val_f1_m: 1.0399\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 209us/sample - loss: 0.0130 - accuracy: 0.9967 - f1_m: 0.9638 - val_loss: 0.3475 - val_accuracy: 0.9390 - val_f1_m: 1.0209\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 209us/sample - loss: 0.0144 - accuracy: 0.9958 - f1_m: 0.9656 - val_loss: 0.3235 - val_accuracy: 0.9396 - val_f1_m: 1.0125\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 209us/sample - loss: 0.0086 - accuracy: 0.9991 - f1_m: 0.9544 - val_loss: 0.3477 - val_accuracy: 0.9393 - val_f1_m: 1.0145\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 210us/sample - loss: 0.0052 - accuracy: 0.9991 - f1_m: 0.9490 - val_loss: 0.3405 - val_accuracy: 0.9430 - val_f1_m: 1.0073\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 212us/sample - loss: 0.0049 - accuracy: 0.9991 - f1_m: 0.9508 - val_loss: 0.3616 - val_accuracy: 0.9398 - val_f1_m: 1.0160\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 208us/sample - loss: 0.0027 - accuracy: 1.0000 - f1_m: 0.9487 - val_loss: 0.3362 - val_accuracy: 0.9442 - val_f1_m: 1.0063\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 210us/sample - loss: 0.0012 - accuracy: 1.0000 - f1_m: 0.9433 - val_loss: 0.3412 - val_accuracy: 0.9471 - val_f1_m: 1.0060\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 355us/sample - loss: 0.0392 - accuracy: 0.9916 - f1_m: 0.9537 - val_loss: 0.1284 - val_accuracy: 0.9713 - val_f1_m: 0.9911\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 233us/sample - loss: 0.0157 - accuracy: 0.9969 - f1_m: 0.9557 - val_loss: 0.1328 - val_accuracy: 0.9710 - val_f1_m: 0.9897\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 237us/sample - loss: 0.0063 - accuracy: 0.9987 - f1_m: 0.9489 - val_loss: 0.1586 - val_accuracy: 0.9684 - val_f1_m: 0.9920\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 235us/sample - loss: 0.0068 - accuracy: 0.9976 - f1_m: 0.9502 - val_loss: 0.1481 - val_accuracy: 0.9697 - val_f1_m: 0.9806\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 231us/sample - loss: 0.0043 - accuracy: 0.9993 - f1_m: 0.9477 - val_loss: 0.1279 - val_accuracy: 0.9758 - val_f1_m: 0.9833\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 231us/sample - loss: 6.8275e-04 - accuracy: 1.0000 - f1_m: 0.9437 - val_loss: 0.1205 - val_accuracy: 0.9763 - val_f1_m: 0.9734\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 230us/sample - loss: 1.8009e-04 - accuracy: 1.0000 - f1_m: 0.9426 - val_loss: 0.1237 - val_accuracy: 0.9764 - val_f1_m: 0.9718\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 232us/sample - loss: 1.1977e-04 - accuracy: 1.0000 - f1_m: 0.9427 - val_loss: 0.1268 - val_accuracy: 0.9762 - val_f1_m: 0.9708\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 234us/sample - loss: 9.5180e-05 - accuracy: 1.0000 - f1_m: 0.9424 - val_loss: 0.1279 - val_accuracy: 0.9766 - val_f1_m: 0.9716\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 237us/sample - loss: 7.9497e-05 - accuracy: 1.0000 - f1_m: 0.9426 - val_loss: 0.1303 - val_accuracy: 0.9762 - val_f1_m: 0.9711\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 3s 612us/sample - loss: 0.0360 - accuracy: 0.9913 - f1_m: 0.9601 - val_loss: 0.1043 - val_accuracy: 0.9725 - val_f1_m: 0.9929\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 1s 272us/sample - loss: 0.0080 - accuracy: 0.9978 - f1_m: 0.9527 - val_loss: 0.1180 - val_accuracy: 0.9763 - val_f1_m: 0.9758\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 1s 270us/sample - loss: 0.0184 - accuracy: 0.9942 - f1_m: 0.9562 - val_loss: 0.1141 - val_accuracy: 0.9728 - val_f1_m: 0.9912\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 1s 269us/sample - loss: 0.0032 - accuracy: 0.9998 - f1_m: 0.9483 - val_loss: 0.1313 - val_accuracy: 0.9753 - val_f1_m: 0.9773\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 274us/sample - loss: 0.0029 - accuracy: 0.9993 - f1_m: 0.9471 - val_loss: 0.1314 - val_accuracy: 0.9751 - val_f1_m: 0.9739\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 1s 270us/sample - loss: 2.5847e-04 - accuracy: 1.0000 - f1_m: 0.9429 - val_loss: 0.1265 - val_accuracy: 0.9795 - val_f1_m: 0.9702\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 271us/sample - loss: 0.0280 - accuracy: 0.9913 - f1_m: 0.9577 - val_loss: 0.1133 - val_accuracy: 0.9712 - val_f1_m: 0.9888\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 1s 271us/sample - loss: 0.0078 - accuracy: 0.9973 - f1_m: 0.9514 - val_loss: 0.1550 - val_accuracy: 0.9706 - val_f1_m: 0.9883\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 272us/sample - loss: 0.0126 - accuracy: 0.9964 - f1_m: 0.9510 - val_loss: 0.1344 - val_accuracy: 0.9713 - val_f1_m: 0.9901\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 1s 274us/sample - loss: 0.0114 - accuracy: 0.9960 - f1_m: 0.9529 - val_loss: 0.1017 - val_accuracy: 0.9768 - val_f1_m: 0.9769\n",
      "Train on 4500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 2s 530us/sample - loss: 0.0280 - accuracy: 0.9929 - f1_m: 0.9585 - val_loss: 0.1172 - val_accuracy: 0.9711 - val_f1_m: 0.9973\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 2s 344us/sample - loss: 0.0033 - accuracy: 0.9996 - f1_m: 0.9466 - val_loss: 0.1700 - val_accuracy: 0.9720 - val_f1_m: 0.9725\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 1s 331us/sample - loss: 0.0230 - accuracy: 0.9936 - f1_m: 0.9579 - val_loss: 0.1289 - val_accuracy: 0.9673 - val_f1_m: 1.0073\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 2s 341us/sample - loss: 0.0135 - accuracy: 0.9964 - f1_m: 0.9582 - val_loss: 0.1275 - val_accuracy: 0.9711 - val_f1_m: 0.9853\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 1s 331us/sample - loss: 0.0093 - accuracy: 0.9973 - f1_m: 0.9549 - val_loss: 0.2259 - val_accuracy: 0.9563 - val_f1_m: 0.9885\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 2s 340us/sample - loss: 0.0187 - accuracy: 0.9929 - f1_m: 0.9587 - val_loss: 0.2413 - val_accuracy: 0.9653 - val_f1_m: 0.9725\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 1s 331us/sample - loss: 0.0258 - accuracy: 0.9913 - f1_m: 0.9603 - val_loss: 0.1312 - val_accuracy: 0.9701 - val_f1_m: 0.9877\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 2s 340us/sample - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9489 - val_loss: 0.1748 - val_accuracy: 0.9746 - val_f1_m: 0.9702\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 1s 332us/sample - loss: 0.0054 - accuracy: 0.9978 - f1_m: 0.9466 - val_loss: 0.1874 - val_accuracy: 0.9677 - val_f1_m: 0.9759\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 2s 336us/sample - loss: 0.0118 - accuracy: 0.9958 - f1_m: 0.9537 - val_loss: 0.1510 - val_accuracy: 0.9751 - val_f1_m: 0.9794\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 302us/sample - loss: 0.0920 - accuracy: 0.9754 - f1_m: 1.0408 - val_loss: 0.3471 - val_accuracy: 0.9249 - val_f1_m: 1.0853\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 229us/sample - loss: 0.0772 - accuracy: 0.9808 - f1_m: 1.0393 - val_loss: 0.3387 - val_accuracy: 0.9239 - val_f1_m: 1.0744\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 219us/sample - loss: 0.0712 - accuracy: 0.9806 - f1_m: 1.0310 - val_loss: 0.3625 - val_accuracy: 0.9192 - val_f1_m: 1.0690\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 225us/sample - loss: 0.0707 - accuracy: 0.9786 - f1_m: 1.0335 - val_loss: 0.3671 - val_accuracy: 0.9225 - val_f1_m: 1.0714\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 211us/sample - loss: 0.0613 - accuracy: 0.9848 - f1_m: 1.0292 - val_loss: 0.3645 - val_accuracy: 0.9165 - val_f1_m: 1.0653\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 206us/sample - loss: 0.0625 - accuracy: 0.9808 - f1_m: 1.0354 - val_loss: 0.3476 - val_accuracy: 0.9246 - val_f1_m: 1.0714\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 208us/sample - loss: 0.0578 - accuracy: 0.9836 - f1_m: 1.0314 - val_loss: 0.3333 - val_accuracy: 0.9272 - val_f1_m: 1.0630\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 218us/sample - loss: 0.0510 - accuracy: 0.9872 - f1_m: 1.0217 - val_loss: 0.3489 - val_accuracy: 0.9238 - val_f1_m: 1.0665\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 202us/sample - loss: 0.0426 - accuracy: 0.9916 - f1_m: 1.0136 - val_loss: 0.3526 - val_accuracy: 0.9206 - val_f1_m: 1.0709\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 203us/sample - loss: 0.0467 - accuracy: 0.9866 - f1_m: 1.0168 - val_loss: 0.3527 - val_accuracy: 0.9270 - val_f1_m: 1.0631\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 334us/sample - loss: 0.0378 - accuracy: 0.9920 - f1_m: 0.9683 - val_loss: 0.2048 - val_accuracy: 0.9608 - val_f1_m: 0.9980\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 210us/sample - loss: 0.0217 - accuracy: 0.9958 - f1_m: 0.9601 - val_loss: 0.1887 - val_accuracy: 0.9625 - val_f1_m: 0.9941\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.0191 - accuracy: 0.9934 - f1_m: 0.9643 - val_loss: 0.2799 - val_accuracy: 0.9456 - val_f1_m: 1.0053\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 227us/sample - loss: 0.0237 - accuracy: 0.9924 - f1_m: 0.9657 - val_loss: 0.1974 - val_accuracy: 0.9625 - val_f1_m: 0.9958\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 223us/sample - loss: 0.0115 - accuracy: 0.9970 - f1_m: 0.9560 - val_loss: 0.2105 - val_accuracy: 0.9609 - val_f1_m: 0.9959\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 211us/sample - loss: 0.0076 - accuracy: 0.9978 - f1_m: 0.9578 - val_loss: 0.1963 - val_accuracy: 0.9637 - val_f1_m: 0.9912\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 221us/sample - loss: 0.0044 - accuracy: 0.9990 - f1_m: 0.9493 - val_loss: 0.2103 - val_accuracy: 0.9597 - val_f1_m: 0.9933\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 220us/sample - loss: 0.0065 - accuracy: 0.9974 - f1_m: 0.9539 - val_loss: 0.2097 - val_accuracy: 0.9631 - val_f1_m: 0.9900\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 225us/sample - loss: 0.0034 - accuracy: 0.9996 - f1_m: 0.9500 - val_loss: 0.2147 - val_accuracy: 0.9606 - val_f1_m: 0.9934\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 226us/sample - loss: 0.0028 - accuracy: 0.9996 - f1_m: 0.9493 - val_loss: 0.2114 - val_accuracy: 0.9657 - val_f1_m: 0.9840\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 402us/sample - loss: 0.0333 - accuracy: 0.9912 - f1_m: 0.9589 - val_loss: 0.1562 - val_accuracy: 0.9659 - val_f1_m: 0.9844\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 239us/sample - loss: 0.0112 - accuracy: 0.9956 - f1_m: 0.9555 - val_loss: 0.1355 - val_accuracy: 0.9697 - val_f1_m: 0.9875\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 237us/sample - loss: 0.0101 - accuracy: 0.9974 - f1_m: 0.9505 - val_loss: 0.1459 - val_accuracy: 0.9714 - val_f1_m: 0.9795\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 249us/sample - loss: 0.0064 - accuracy: 0.9976 - f1_m: 0.9525 - val_loss: 0.1818 - val_accuracy: 0.9647 - val_f1_m: 0.9854\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 252us/sample - loss: 0.0139 - accuracy: 0.9956 - f1_m: 0.9553 - val_loss: 0.1598 - val_accuracy: 0.9650 - val_f1_m: 0.9874\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 251us/sample - loss: 0.0065 - accuracy: 0.9978 - f1_m: 0.9536 - val_loss: 0.1614 - val_accuracy: 0.9681 - val_f1_m: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 247us/sample - loss: 0.0040 - accuracy: 0.9986 - f1_m: 0.9487 - val_loss: 0.2021 - val_accuracy: 0.9646 - val_f1_m: 0.9798\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 243us/sample - loss: 0.0013 - accuracy: 1.0000 - f1_m: 0.9464 - val_loss: 0.1786 - val_accuracy: 0.9686 - val_f1_m: 0.9744\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 244us/sample - loss: 2.1464e-04 - accuracy: 1.0000 - f1_m: 0.9439 - val_loss: 0.1814 - val_accuracy: 0.9700 - val_f1_m: 0.9735\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 266us/sample - loss: 1.3276e-04 - accuracy: 1.0000 - f1_m: 0.9435 - val_loss: 0.1845 - val_accuracy: 0.9704 - val_f1_m: 0.9723\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 479us/sample - loss: 0.0383 - accuracy: 0.9894 - f1_m: 0.9704 - val_loss: 0.1583 - val_accuracy: 0.9625 - val_f1_m: 1.0012\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 2s 317us/sample - loss: 0.0119 - accuracy: 0.9968 - f1_m: 0.9553 - val_loss: 0.1943 - val_accuracy: 0.9600 - val_f1_m: 1.0020\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 291us/sample - loss: 0.0200 - accuracy: 0.9942 - f1_m: 0.9604 - val_loss: 0.1792 - val_accuracy: 0.9552 - val_f1_m: 1.0029\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 294us/sample - loss: 0.0070 - accuracy: 0.9970 - f1_m: 0.9537 - val_loss: 0.2539 - val_accuracy: 0.9506 - val_f1_m: 0.9885\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0329 - accuracy: 0.9902 - f1_m: 0.9634 - val_loss: 0.1666 - val_accuracy: 0.9594 - val_f1_m: 1.0043\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.0184 - accuracy: 0.9940 - f1_m: 0.9627 - val_loss: 0.1895 - val_accuracy: 0.9601 - val_f1_m: 0.9926\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.0122 - accuracy: 0.9954 - f1_m: 0.9557 - val_loss: 0.2135 - val_accuracy: 0.9654 - val_f1_m: 0.9900\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 293us/sample - loss: 0.0189 - accuracy: 0.9942 - f1_m: 0.9582 - val_loss: 0.1706 - val_accuracy: 0.9657 - val_f1_m: 0.9818\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.0021 - accuracy: 0.9990 - f1_m: 0.9467 - val_loss: 0.2080 - val_accuracy: 0.9666 - val_f1_m: 0.9790\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.0077 - accuracy: 0.9970 - f1_m: 0.9512 - val_loss: 0.2984 - val_accuracy: 0.9528 - val_f1_m: 0.9836\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 1s 293us/sample - loss: 0.0546 - accuracy: 0.9886 - f1_m: 0.9684 - val_loss: 0.3206 - val_accuracy: 0.9404 - val_f1_m: 1.0180\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 197us/sample - loss: 0.0229 - accuracy: 0.9934 - f1_m: 0.9660 - val_loss: 0.3225 - val_accuracy: 0.9444 - val_f1_m: 1.0091\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 197us/sample - loss: 0.0209 - accuracy: 0.9944 - f1_m: 0.9654 - val_loss: 0.3477 - val_accuracy: 0.9348 - val_f1_m: 1.0222\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 194us/sample - loss: 0.0192 - accuracy: 0.9954 - f1_m: 0.9684 - val_loss: 0.3136 - val_accuracy: 0.9436 - val_f1_m: 1.0189\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 197us/sample - loss: 0.0142 - accuracy: 0.9964 - f1_m: 0.9599 - val_loss: 0.3263 - val_accuracy: 0.9436 - val_f1_m: 1.0135\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 190us/sample - loss: 0.0102 - accuracy: 0.9982 - f1_m: 0.9566 - val_loss: 0.3266 - val_accuracy: 0.9424 - val_f1_m: 1.0220\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 193us/sample - loss: 0.0076 - accuracy: 0.9982 - f1_m: 0.9561 - val_loss: 0.3240 - val_accuracy: 0.9460 - val_f1_m: 1.0096\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 189us/sample - loss: 0.0123 - accuracy: 0.9958 - f1_m: 0.9562 - val_loss: 0.3326 - val_accuracy: 0.9443 - val_f1_m: 1.0095\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 197us/sample - loss: 0.0078 - accuracy: 0.9982 - f1_m: 0.9584 - val_loss: 0.3340 - val_accuracy: 0.9449 - val_f1_m: 1.0073\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 197us/sample - loss: 0.0070 - accuracy: 0.9980 - f1_m: 0.9565 - val_loss: 0.3824 - val_accuracy: 0.9383 - val_f1_m: 1.0160\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 329us/sample - loss: 0.0345 - accuracy: 0.9928 - f1_m: 0.9582 - val_loss: 0.1732 - val_accuracy: 0.9682 - val_f1_m: 0.9845\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 217us/sample - loss: 0.0103 - accuracy: 0.9970 - f1_m: 0.9515 - val_loss: 0.1274 - val_accuracy: 0.9748 - val_f1_m: 0.9805\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 1s 219us/sample - loss: 0.0019 - accuracy: 0.9994 - f1_m: 0.9463 - val_loss: 0.1264 - val_accuracy: 0.9758 - val_f1_m: 0.9753\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 233us/sample - loss: 7.1265e-04 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1270 - val_accuracy: 0.9776 - val_f1_m: 0.9742\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 234us/sample - loss: 5.0468e-04 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1289 - val_accuracy: 0.9768 - val_f1_m: 0.9737\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 222us/sample - loss: 1.7392e-04 - accuracy: 1.0000 - f1_m: 0.9434 - val_loss: 0.1296 - val_accuracy: 0.9794 - val_f1_m: 0.9714\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 212us/sample - loss: 1.0272e-04 - accuracy: 1.0000 - f1_m: 0.9434 - val_loss: 0.1307 - val_accuracy: 0.9788 - val_f1_m: 0.9710\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 214us/sample - loss: 8.5183e-05 - accuracy: 1.0000 - f1_m: 0.9436 - val_loss: 0.1319 - val_accuracy: 0.9792 - val_f1_m: 0.9709\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 219us/sample - loss: 6.9731e-05 - accuracy: 1.0000 - f1_m: 0.9439 - val_loss: 0.1330 - val_accuracy: 0.9793 - val_f1_m: 0.9710\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 210us/sample - loss: 5.9730e-05 - accuracy: 1.0000 - f1_m: 0.9435 - val_loss: 0.1339 - val_accuracy: 0.9793 - val_f1_m: 0.9709\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 419us/sample - loss: 0.0205 - accuracy: 0.9942 - f1_m: 0.9531 - val_loss: 0.1118 - val_accuracy: 0.9734 - val_f1_m: 0.9989\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 1s 262us/sample - loss: 0.0057 - accuracy: 0.9988 - f1_m: 0.9490 - val_loss: 0.1027 - val_accuracy: 0.9766 - val_f1_m: 0.9796\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 2s 301us/sample - loss: 0.0033 - accuracy: 0.9990 - f1_m: 0.9488 - val_loss: 0.1705 - val_accuracy: 0.9727 - val_f1_m: 0.9734\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 1s 279us/sample - loss: 0.0144 - accuracy: 0.9950 - f1_m: 0.9545 - val_loss: 0.1411 - val_accuracy: 0.9711 - val_f1_m: 0.9803\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 1s 283us/sample - loss: 0.0086 - accuracy: 0.9976 - f1_m: 0.9528 - val_loss: 0.1749 - val_accuracy: 0.9714 - val_f1_m: 0.9755\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 1s 271us/sample - loss: 0.0138 - accuracy: 0.9956 - f1_m: 0.9514 - val_loss: 0.1173 - val_accuracy: 0.9743 - val_f1_m: 0.9717\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 1s 257us/sample - loss: 0.0034 - accuracy: 0.9990 - f1_m: 0.9470 - val_loss: 0.1352 - val_accuracy: 0.9777 - val_f1_m: 0.9647\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 1s 260us/sample - loss: 7.1925e-04 - accuracy: 0.9996 - f1_m: 0.9445 - val_loss: 0.1549 - val_accuracy: 0.9801 - val_f1_m: 0.9668\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 1s 251us/sample - loss: 0.0236 - accuracy: 0.9920 - f1_m: 0.9582 - val_loss: 0.1068 - val_accuracy: 0.9728 - val_f1_m: 0.9853\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 1s 264us/sample - loss: 0.0014 - accuracy: 0.9998 - f1_m: 0.9460 - val_loss: 0.1112 - val_accuracy: 0.9761 - val_f1_m: 0.9723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 2s 492us/sample - loss: 0.0214 - accuracy: 0.9942 - f1_m: 0.9583 - val_loss: 0.1132 - val_accuracy: 0.9708 - val_f1_m: 0.9929\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 2s 315us/sample - loss: 0.0167 - accuracy: 0.9956 - f1_m: 0.9554 - val_loss: 0.1172 - val_accuracy: 0.9725 - val_f1_m: 0.9857\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 2s 318us/sample - loss: 0.0072 - accuracy: 0.9976 - f1_m: 0.9504 - val_loss: 0.1484 - val_accuracy: 0.9684 - val_f1_m: 0.9800\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 2s 320us/sample - loss: 0.0075 - accuracy: 0.9974 - f1_m: 0.9495 - val_loss: 0.1451 - val_accuracy: 0.9723 - val_f1_m: 0.9772\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 2s 319us/sample - loss: 0.0117 - accuracy: 0.9964 - f1_m: 0.9515 - val_loss: 0.1517 - val_accuracy: 0.9676 - val_f1_m: 1.0003\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 2s 323us/sample - loss: 0.0149 - accuracy: 0.9944 - f1_m: 0.9559 - val_loss: 0.1477 - val_accuracy: 0.9718 - val_f1_m: 0.9808\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 2s 324us/sample - loss: 0.0154 - accuracy: 0.9948 - f1_m: 0.9564 - val_loss: 0.2106 - val_accuracy: 0.9662 - val_f1_m: 0.9797\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 2s 316us/sample - loss: 0.0157 - accuracy: 0.9960 - f1_m: 0.9527 - val_loss: 0.1673 - val_accuracy: 0.9633 - val_f1_m: 0.9987\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 2s 330us/sample - loss: 0.0169 - accuracy: 0.9950 - f1_m: 0.9596 - val_loss: 0.1311 - val_accuracy: 0.9737 - val_f1_m: 0.9820\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 2s 317us/sample - loss: 0.0030 - accuracy: 0.9986 - f1_m: 0.9468 - val_loss: 0.1781 - val_accuracy: 0.9676 - val_f1_m: 0.9735\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 278us/sample - loss: 0.0723 - accuracy: 0.9798 - f1_m: 1.0229 - val_loss: 0.3695 - val_accuracy: 0.9223 - val_f1_m: 1.0648\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 189us/sample - loss: 0.0597 - accuracy: 0.9845 - f1_m: 1.0200 - val_loss: 0.3422 - val_accuracy: 0.9242 - val_f1_m: 1.0633\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 190us/sample - loss: 0.0536 - accuracy: 0.9840 - f1_m: 1.0177 - val_loss: 0.3269 - val_accuracy: 0.9292 - val_f1_m: 1.0538\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 189us/sample - loss: 0.0473 - accuracy: 0.9873 - f1_m: 1.0079 - val_loss: 0.3263 - val_accuracy: 0.9287 - val_f1_m: 1.0540\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 204us/sample - loss: 0.0428 - accuracy: 0.9902 - f1_m: 1.0124 - val_loss: 0.3577 - val_accuracy: 0.9251 - val_f1_m: 1.0546\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 201us/sample - loss: 0.0396 - accuracy: 0.9896 - f1_m: 1.0138 - val_loss: 0.3302 - val_accuracy: 0.9326 - val_f1_m: 1.0525\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 212us/sample - loss: 0.0345 - accuracy: 0.9918 - f1_m: 1.0011 - val_loss: 0.3229 - val_accuracy: 0.9312 - val_f1_m: 1.0498\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 187us/sample - loss: 0.0340 - accuracy: 0.9907 - f1_m: 1.0077 - val_loss: 0.3322 - val_accuracy: 0.9301 - val_f1_m: 1.0534\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 199us/sample - loss: 0.0328 - accuracy: 0.9915 - f1_m: 1.0047 - val_loss: 0.3188 - val_accuracy: 0.9318 - val_f1_m: 1.0468\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 194us/sample - loss: 0.0271 - accuracy: 0.9947 - f1_m: 0.9934 - val_loss: 0.3329 - val_accuracy: 0.9359 - val_f1_m: 1.0416\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 309us/sample - loss: 0.0276 - accuracy: 0.9949 - f1_m: 0.9635 - val_loss: 0.2185 - val_accuracy: 0.9609 - val_f1_m: 0.9907\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 203us/sample - loss: 0.0254 - accuracy: 0.9927 - f1_m: 0.9610 - val_loss: 0.2151 - val_accuracy: 0.9590 - val_f1_m: 0.9968\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 203us/sample - loss: 0.0132 - accuracy: 0.9971 - f1_m: 0.9571 - val_loss: 0.2194 - val_accuracy: 0.9594 - val_f1_m: 0.9916\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 197us/sample - loss: 0.0094 - accuracy: 0.9971 - f1_m: 0.9549 - val_loss: 0.2356 - val_accuracy: 0.9545 - val_f1_m: 0.9963\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 198us/sample - loss: 0.0086 - accuracy: 0.9975 - f1_m: 0.9556 - val_loss: 0.2214 - val_accuracy: 0.9613 - val_f1_m: 0.9858\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 200us/sample - loss: 0.0040 - accuracy: 0.9991 - f1_m: 0.9500 - val_loss: 0.2175 - val_accuracy: 0.9620 - val_f1_m: 0.9876\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 202us/sample - loss: 0.0022 - accuracy: 0.9998 - f1_m: 0.9490 - val_loss: 0.2016 - val_accuracy: 0.9661 - val_f1_m: 0.9850\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 198us/sample - loss: 8.4436e-04 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.2078 - val_accuracy: 0.9661 - val_f1_m: 0.9840\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 198us/sample - loss: 6.2947e-04 - accuracy: 1.0000 - f1_m: 0.9451 - val_loss: 0.2051 - val_accuracy: 0.9670 - val_f1_m: 0.9830\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 197us/sample - loss: 5.1354e-04 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.2062 - val_accuracy: 0.9665 - val_f1_m: 0.9824\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 355us/sample - loss: 0.0274 - accuracy: 0.9940 - f1_m: 0.9581 - val_loss: 0.2333 - val_accuracy: 0.9571 - val_f1_m: 0.9925\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 229us/sample - loss: 0.0137 - accuracy: 0.9958 - f1_m: 0.9549 - val_loss: 0.1543 - val_accuracy: 0.9693 - val_f1_m: 0.9780\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 228us/sample - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9483 - val_loss: 0.1971 - val_accuracy: 0.9655 - val_f1_m: 0.9774\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 234us/sample - loss: 0.0102 - accuracy: 0.9958 - f1_m: 0.9555 - val_loss: 0.1782 - val_accuracy: 0.9662 - val_f1_m: 0.9765\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 229us/sample - loss: 0.0017 - accuracy: 0.9996 - f1_m: 0.9463 - val_loss: 0.1599 - val_accuracy: 0.9715 - val_f1_m: 0.9740\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 235us/sample - loss: 2.3676e-04 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1662 - val_accuracy: 0.9733 - val_f1_m: 0.9688\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 248us/sample - loss: 1.2905e-04 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1683 - val_accuracy: 0.9737 - val_f1_m: 0.9690\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 243us/sample - loss: 8.8961e-05 - accuracy: 1.0000 - f1_m: 0.9444 - val_loss: 0.1727 - val_accuracy: 0.9734 - val_f1_m: 0.9690\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 236us/sample - loss: 6.3948e-05 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1745 - val_accuracy: 0.9735 - val_f1_m: 0.9689\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 253us/sample - loss: 5.1663e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1772 - val_accuracy: 0.9737 - val_f1_m: 0.9684\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 3s 460us/sample - loss: 0.0237 - accuracy: 0.9940 - f1_m: 0.9590 - val_loss: 0.2035 - val_accuracy: 0.9619 - val_f1_m: 0.9881\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 2s 293us/sample - loss: 0.0214 - accuracy: 0.9924 - f1_m: 0.9629 - val_loss: 0.1956 - val_accuracy: 0.9627 - val_f1_m: 0.9822\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 2s 299us/sample - loss: 0.0067 - accuracy: 0.9978 - f1_m: 0.9494 - val_loss: 0.1917 - val_accuracy: 0.9643 - val_f1_m: 0.9851\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 2s 281us/sample - loss: 0.0124 - accuracy: 0.9953 - f1_m: 0.9564 - val_loss: 0.1881 - val_accuracy: 0.9676 - val_f1_m: 0.9797\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 2s 291us/sample - loss: 0.0070 - accuracy: 0.9976 - f1_m: 0.9518 - val_loss: 0.1968 - val_accuracy: 0.9687 - val_f1_m: 0.9704\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 2s 285us/sample - loss: 0.0159 - accuracy: 0.9949 - f1_m: 0.9548 - val_loss: 0.2006 - val_accuracy: 0.9595 - val_f1_m: 0.9832\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 2s 288us/sample - loss: 0.0145 - accuracy: 0.9955 - f1_m: 0.9579 - val_loss: 0.1753 - val_accuracy: 0.9676 - val_f1_m: 0.9805\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 2s 281us/sample - loss: 0.0116 - accuracy: 0.9969 - f1_m: 0.9534 - val_loss: 0.1836 - val_accuracy: 0.9643 - val_f1_m: 0.9888\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 2s 283us/sample - loss: 0.0033 - accuracy: 0.9989 - f1_m: 0.9501 - val_loss: 0.1933 - val_accuracy: 0.9693 - val_f1_m: 0.9716\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 2s 288us/sample - loss: 0.0036 - accuracy: 0.9987 - f1_m: 0.9483 - val_loss: 0.2410 - val_accuracy: 0.9651 - val_f1_m: 0.9718\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 1s 272us/sample - loss: 0.0391 - accuracy: 0.9922 - f1_m: 0.9684 - val_loss: 0.3462 - val_accuracy: 0.9462 - val_f1_m: 1.0069\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 185us/sample - loss: 0.0223 - accuracy: 0.9945 - f1_m: 0.9634 - val_loss: 0.3229 - val_accuracy: 0.9459 - val_f1_m: 0.9995\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 184us/sample - loss: 0.0162 - accuracy: 0.9965 - f1_m: 0.9621 - val_loss: 0.3132 - val_accuracy: 0.9441 - val_f1_m: 1.0072\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 184us/sample - loss: 0.0084 - accuracy: 0.9982 - f1_m: 0.9563 - val_loss: 0.2920 - val_accuracy: 0.9497 - val_f1_m: 1.0092\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 184us/sample - loss: 0.0064 - accuracy: 0.9982 - f1_m: 0.9540 - val_loss: 0.2971 - val_accuracy: 0.9497 - val_f1_m: 1.0062\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 188us/sample - loss: 0.0029 - accuracy: 0.9993 - f1_m: 0.9498 - val_loss: 0.2970 - val_accuracy: 0.9521 - val_f1_m: 0.9945\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 191us/sample - loss: 9.6431e-04 - accuracy: 1.0000 - f1_m: 0.9464 - val_loss: 0.3026 - val_accuracy: 0.9520 - val_f1_m: 0.9935\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 184us/sample - loss: 7.1244e-04 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.3061 - val_accuracy: 0.9536 - val_f1_m: 0.9954\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 187us/sample - loss: 6.4905e-04 - accuracy: 1.0000 - f1_m: 0.9451 - val_loss: 0.3118 - val_accuracy: 0.9534 - val_f1_m: 0.9931\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 194us/sample - loss: 4.7436e-04 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.3138 - val_accuracy: 0.9522 - val_f1_m: 0.9929\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 2s 303us/sample - loss: 0.0255 - accuracy: 0.9951 - f1_m: 0.9549 - val_loss: 0.1430 - val_accuracy: 0.9712 - val_f1_m: 0.9830\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 204us/sample - loss: 0.0076 - accuracy: 0.9982 - f1_m: 0.9502 - val_loss: 0.1234 - val_accuracy: 0.9768 - val_f1_m: 0.9768\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 209us/sample - loss: 6.5022e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1252 - val_accuracy: 0.9770 - val_f1_m: 0.9744\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 211us/sample - loss: 5.2157e-04 - accuracy: 1.0000 - f1_m: 0.9456 - val_loss: 0.1378 - val_accuracy: 0.9755 - val_f1_m: 0.9738\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 210us/sample - loss: 2.2987e-04 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1301 - val_accuracy: 0.9773 - val_f1_m: 0.9716\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 205us/sample - loss: 1.0254e-04 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1314 - val_accuracy: 0.9789 - val_f1_m: 0.9697\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 219us/sample - loss: 7.0323e-05 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1328 - val_accuracy: 0.9781 - val_f1_m: 0.9690\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 207us/sample - loss: 5.5424e-05 - accuracy: 1.0000 - f1_m: 0.9444 - val_loss: 0.1342 - val_accuracy: 0.9794 - val_f1_m: 0.9681\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 204us/sample - loss: 4.5404e-05 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1362 - val_accuracy: 0.9794 - val_f1_m: 0.9681\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 210us/sample - loss: 3.9597e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1370 - val_accuracy: 0.9795 - val_f1_m: 0.9680\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 3s 546us/sample - loss: 0.0150 - accuracy: 0.9962 - f1_m: 0.9502 - val_loss: 0.1670 - val_accuracy: 0.9702 - val_f1_m: 0.9713\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 1s 241us/sample - loss: 0.0059 - accuracy: 0.9985 - f1_m: 0.9483 - val_loss: 0.1510 - val_accuracy: 0.9742 - val_f1_m: 0.9730\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 1s 239us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9466 - val_loss: 0.1853 - val_accuracy: 0.9685 - val_f1_m: 0.9721\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 1s 246us/sample - loss: 0.0039 - accuracy: 0.9984 - f1_m: 0.9465 - val_loss: 0.1444 - val_accuracy: 0.9737 - val_f1_m: 0.9760\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 1s 243us/sample - loss: 0.0038 - accuracy: 0.9991 - f1_m: 0.9484 - val_loss: 0.1561 - val_accuracy: 0.9723 - val_f1_m: 0.9738\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 1s 244us/sample - loss: 0.0060 - accuracy: 0.9982 - f1_m: 0.9496 - val_loss: 0.1537 - val_accuracy: 0.9754 - val_f1_m: 0.9662\n",
      "Epoch 7/10\n",
      "5500/5500 [==============================] - 1s 247us/sample - loss: 0.0053 - accuracy: 0.9985 - f1_m: 0.9498 - val_loss: 0.1653 - val_accuracy: 0.9718 - val_f1_m: 0.9746\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 1s 241us/sample - loss: 0.0151 - accuracy: 0.9960 - f1_m: 0.9534 - val_loss: 0.1426 - val_accuracy: 0.9734 - val_f1_m: 0.9753\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 1s 243us/sample - loss: 0.0044 - accuracy: 0.9987 - f1_m: 0.9481 - val_loss: 0.1199 - val_accuracy: 0.9780 - val_f1_m: 0.9714\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 1s 254us/sample - loss: 1.3814e-04 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1238 - val_accuracy: 0.9793 - val_f1_m: 0.9678\n",
      "Train on 5500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5500/5500 [==============================] - 3s 468us/sample - loss: 0.0189 - accuracy: 0.9960 - f1_m: 0.9524 - val_loss: 0.1165 - val_accuracy: 0.9646 - val_f1_m: 1.0067\n",
      "Epoch 2/10\n",
      "5500/5500 [==============================] - 2s 305us/sample - loss: 0.0045 - accuracy: 0.9989 - f1_m: 0.9513 - val_loss: 0.1182 - val_accuracy: 0.9749 - val_f1_m: 0.9766\n",
      "Epoch 3/10\n",
      "5500/5500 [==============================] - 2s 305us/sample - loss: 5.5527e-04 - accuracy: 0.9998 - f1_m: 0.9455 - val_loss: 0.1317 - val_accuracy: 0.9785 - val_f1_m: 0.9663\n",
      "Epoch 4/10\n",
      "5500/5500 [==============================] - 2s 311us/sample - loss: 3.8165e-05 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1344 - val_accuracy: 0.9782 - val_f1_m: 0.9655\n",
      "Epoch 5/10\n",
      "5500/5500 [==============================] - 2s 316us/sample - loss: 1.2613e-05 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1368 - val_accuracy: 0.9790 - val_f1_m: 0.9653\n",
      "Epoch 6/10\n",
      "5500/5500 [==============================] - 2s 310us/sample - loss: 7.7022e-06 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1390 - val_accuracy: 0.9788 - val_f1_m: 0.9653\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 2s 311us/sample - loss: 5.8023e-06 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1411 - val_accuracy: 0.9787 - val_f1_m: 0.9641\n",
      "Epoch 8/10\n",
      "5500/5500 [==============================] - 2s 308us/sample - loss: 4.5196e-06 - accuracy: 1.0000 - f1_m: 0.9444 - val_loss: 0.1426 - val_accuracy: 0.9788 - val_f1_m: 0.9637\n",
      "Epoch 9/10\n",
      "5500/5500 [==============================] - 2s 306us/sample - loss: 3.5532e-06 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1443 - val_accuracy: 0.9785 - val_f1_m: 0.9633\n",
      "Epoch 10/10\n",
      "5500/5500 [==============================] - 2s 309us/sample - loss: 2.7778e-06 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1454 - val_accuracy: 0.9784 - val_f1_m: 0.9632\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 260us/sample - loss: 0.0525 - accuracy: 0.9865 - f1_m: 1.0106 - val_loss: 0.3483 - val_accuracy: 0.9294 - val_f1_m: 1.0426\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 182us/sample - loss: 0.0473 - accuracy: 0.9880 - f1_m: 1.0049 - val_loss: 0.3685 - val_accuracy: 0.9255 - val_f1_m: 1.0389\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 181us/sample - loss: 0.0362 - accuracy: 0.9912 - f1_m: 0.9964 - val_loss: 0.3442 - val_accuracy: 0.9295 - val_f1_m: 1.0356\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 183us/sample - loss: 0.0320 - accuracy: 0.9928 - f1_m: 0.9941 - val_loss: 0.3358 - val_accuracy: 0.9312 - val_f1_m: 1.0398\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 176us/sample - loss: 0.0285 - accuracy: 0.9932 - f1_m: 0.9893 - val_loss: 0.3107 - val_accuracy: 0.9359 - val_f1_m: 1.0434\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 179us/sample - loss: 0.0251 - accuracy: 0.9942 - f1_m: 0.9938 - val_loss: 0.3325 - val_accuracy: 0.9332 - val_f1_m: 1.0452\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 180us/sample - loss: 0.0224 - accuracy: 0.9955 - f1_m: 0.9856 - val_loss: 0.3412 - val_accuracy: 0.9340 - val_f1_m: 1.0382\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 180us/sample - loss: 0.0221 - accuracy: 0.9955 - f1_m: 0.9876 - val_loss: 0.3382 - val_accuracy: 0.9334 - val_f1_m: 1.0354\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 179us/sample - loss: 0.0235 - accuracy: 0.9947 - f1_m: 0.9898 - val_loss: 0.3416 - val_accuracy: 0.9354 - val_f1_m: 1.0318\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 184us/sample - loss: 0.0149 - accuracy: 0.9977 - f1_m: 0.9761 - val_loss: 0.3468 - val_accuracy: 0.9335 - val_f1_m: 1.0291\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 289us/sample - loss: 0.0273 - accuracy: 0.9952 - f1_m: 0.9577 - val_loss: 0.2132 - val_accuracy: 0.9633 - val_f1_m: 0.9901\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 191us/sample - loss: 0.0204 - accuracy: 0.9940 - f1_m: 0.9640 - val_loss: 0.2157 - val_accuracy: 0.9638 - val_f1_m: 0.9849\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 187us/sample - loss: 0.0122 - accuracy: 0.9963 - f1_m: 0.9576 - val_loss: 0.2026 - val_accuracy: 0.9641 - val_f1_m: 0.9846\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 189us/sample - loss: 0.0084 - accuracy: 0.9973 - f1_m: 0.9542 - val_loss: 0.2023 - val_accuracy: 0.9660 - val_f1_m: 0.9843\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 201us/sample - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9498 - val_loss: 0.2025 - val_accuracy: 0.9672 - val_f1_m: 0.9841\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 201us/sample - loss: 0.0016 - accuracy: 0.9997 - f1_m: 0.9474 - val_loss: 0.2023 - val_accuracy: 0.9666 - val_f1_m: 0.9801\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 198us/sample - loss: 9.2934e-04 - accuracy: 1.0000 - f1_m: 0.9467 - val_loss: 0.2063 - val_accuracy: 0.9649 - val_f1_m: 0.9803\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 189us/sample - loss: 9.0776e-04 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.2088 - val_accuracy: 0.9663 - val_f1_m: 0.9800\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 194us/sample - loss: 5.2576e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.2133 - val_accuracy: 0.9662 - val_f1_m: 0.9768\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 201us/sample - loss: 3.8507e-04 - accuracy: 1.0000 - f1_m: 0.9451 - val_loss: 0.2097 - val_accuracy: 0.9671 - val_f1_m: 0.9801\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 335us/sample - loss: 0.0240 - accuracy: 0.9942 - f1_m: 0.9554 - val_loss: 0.1795 - val_accuracy: 0.9654 - val_f1_m: 0.9790\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 221us/sample - loss: 0.0107 - accuracy: 0.9967 - f1_m: 0.9561 - val_loss: 0.1826 - val_accuracy: 0.9688 - val_f1_m: 0.9774\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 227us/sample - loss: 0.0130 - accuracy: 0.9963 - f1_m: 0.9548 - val_loss: 0.2242 - val_accuracy: 0.9609 - val_f1_m: 0.9823\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 222us/sample - loss: 0.0107 - accuracy: 0.9965 - f1_m: 0.9542 - val_loss: 0.1518 - val_accuracy: 0.9711 - val_f1_m: 0.9805\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 220us/sample - loss: 0.0039 - accuracy: 0.9983 - f1_m: 0.9492 - val_loss: 0.1491 - val_accuracy: 0.9729 - val_f1_m: 0.9781\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 221us/sample - loss: 0.0085 - accuracy: 0.9963 - f1_m: 0.9532 - val_loss: 0.1555 - val_accuracy: 0.9711 - val_f1_m: 0.9777\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 226us/sample - loss: 0.0071 - accuracy: 0.9970 - f1_m: 0.9532 - val_loss: 0.1527 - val_accuracy: 0.9729 - val_f1_m: 0.9751\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 219us/sample - loss: 0.0029 - accuracy: 0.9990 - f1_m: 0.9495 - val_loss: 0.1629 - val_accuracy: 0.9722 - val_f1_m: 0.9746\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 219us/sample - loss: 0.0062 - accuracy: 0.9975 - f1_m: 0.9517 - val_loss: 0.2169 - val_accuracy: 0.9675 - val_f1_m: 0.9769\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 227us/sample - loss: 0.0279 - accuracy: 0.9918 - f1_m: 0.9635 - val_loss: 0.1305 - val_accuracy: 0.9700 - val_f1_m: 0.9801\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 3s 420us/sample - loss: 0.0193 - accuracy: 0.9950 - f1_m: 0.9574 - val_loss: 0.1608 - val_accuracy: 0.9687 - val_f1_m: 0.9821\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 2s 275us/sample - loss: 0.0140 - accuracy: 0.9953 - f1_m: 0.9561 - val_loss: 0.1845 - val_accuracy: 0.9605 - val_f1_m: 0.9916\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 2s 274us/sample - loss: 0.0110 - accuracy: 0.9975 - f1_m: 0.9542 - val_loss: 0.1874 - val_accuracy: 0.9681 - val_f1_m: 0.9778\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 2s 268us/sample - loss: 0.0109 - accuracy: 0.9963 - f1_m: 0.9549 - val_loss: 0.1820 - val_accuracy: 0.9688 - val_f1_m: 0.9759\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 2s 272us/sample - loss: 0.0227 - accuracy: 0.9925 - f1_m: 0.9589 - val_loss: 0.1594 - val_accuracy: 0.9627 - val_f1_m: 0.9966\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 2s 268us/sample - loss: 0.0077 - accuracy: 0.9983 - f1_m: 0.9532 - val_loss: 0.1551 - val_accuracy: 0.9711 - val_f1_m: 0.9754\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 2s 272us/sample - loss: 0.0011 - accuracy: 0.9998 - f1_m: 0.9463 - val_loss: 0.1608 - val_accuracy: 0.9726 - val_f1_m: 0.9690\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 2s 274us/sample - loss: 1.3383e-04 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1685 - val_accuracy: 0.9728 - val_f1_m: 0.9678\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 2s 267us/sample - loss: 6.6534e-05 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1753 - val_accuracy: 0.9727 - val_f1_m: 0.9671\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 2s 273us/sample - loss: 4.6983e-05 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1803 - val_accuracy: 0.9733 - val_f1_m: 0.9664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 261us/sample - loss: 0.0367 - accuracy: 0.9917 - f1_m: 0.9656 - val_loss: 0.3132 - val_accuracy: 0.9483 - val_f1_m: 0.9985\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 174us/sample - loss: 0.0170 - accuracy: 0.9955 - f1_m: 0.9606 - val_loss: 0.3086 - val_accuracy: 0.9452 - val_f1_m: 0.9995\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 174us/sample - loss: 0.0085 - accuracy: 0.9972 - f1_m: 0.9588 - val_loss: 0.3051 - val_accuracy: 0.9490 - val_f1_m: 0.9982\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.0068 - accuracy: 0.9982 - f1_m: 0.9569 - val_loss: 0.2949 - val_accuracy: 0.9507 - val_f1_m: 0.9985\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 176us/sample - loss: 0.0027 - accuracy: 0.9992 - f1_m: 0.9487 - val_loss: 0.3081 - val_accuracy: 0.9519 - val_f1_m: 0.9974\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.0042 - accuracy: 0.9992 - f1_m: 0.9494 - val_loss: 0.3142 - val_accuracy: 0.9498 - val_f1_m: 0.9986\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 176us/sample - loss: 0.0071 - accuracy: 0.9975 - f1_m: 0.9529 - val_loss: 0.3732 - val_accuracy: 0.9397 - val_f1_m: 1.0033\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.0089 - accuracy: 0.9980 - f1_m: 0.9581 - val_loss: 0.3001 - val_accuracy: 0.9516 - val_f1_m: 0.9962\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 177us/sample - loss: 0.0036 - accuracy: 0.9992 - f1_m: 0.9502 - val_loss: 0.3423 - val_accuracy: 0.9491 - val_f1_m: 0.9956\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 175us/sample - loss: 0.0091 - accuracy: 0.9973 - f1_m: 0.9568 - val_loss: 0.3405 - val_accuracy: 0.9478 - val_f1_m: 0.9994\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 287us/sample - loss: 0.0179 - accuracy: 0.9952 - f1_m: 0.9516 - val_loss: 0.1347 - val_accuracy: 0.9752 - val_f1_m: 0.9792\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 196us/sample - loss: 0.0091 - accuracy: 0.9970 - f1_m: 0.9530 - val_loss: 0.1225 - val_accuracy: 0.9738 - val_f1_m: 0.9797\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 195us/sample - loss: 0.0032 - accuracy: 0.9988 - f1_m: 0.9485 - val_loss: 0.1346 - val_accuracy: 0.9753 - val_f1_m: 0.9735\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 197us/sample - loss: 0.0072 - accuracy: 0.9973 - f1_m: 0.9514 - val_loss: 0.1302 - val_accuracy: 0.9746 - val_f1_m: 0.9709\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 198us/sample - loss: 0.0051 - accuracy: 0.9988 - f1_m: 0.9477 - val_loss: 0.1382 - val_accuracy: 0.9747 - val_f1_m: 0.9756\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 198us/sample - loss: 0.0032 - accuracy: 0.9993 - f1_m: 0.9464 - val_loss: 0.1473 - val_accuracy: 0.9735 - val_f1_m: 0.9736\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 197us/sample - loss: 0.0012 - accuracy: 0.9995 - f1_m: 0.9470 - val_loss: 0.1635 - val_accuracy: 0.9733 - val_f1_m: 0.9717\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 194us/sample - loss: 0.0029 - accuracy: 0.9990 - f1_m: 0.9457 - val_loss: 0.1209 - val_accuracy: 0.9756 - val_f1_m: 0.9743\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 195us/sample - loss: 0.0127 - accuracy: 0.9965 - f1_m: 0.9519 - val_loss: 0.1753 - val_accuracy: 0.9676 - val_f1_m: 0.9845\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 201us/sample - loss: 0.0114 - accuracy: 0.9962 - f1_m: 0.9570 - val_loss: 0.1452 - val_accuracy: 0.9724 - val_f1_m: 0.9732\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 2s 349us/sample - loss: 0.0164 - accuracy: 0.9967 - f1_m: 0.9507 - val_loss: 0.1019 - val_accuracy: 0.9755 - val_f1_m: 0.9845\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 1s 227us/sample - loss: 0.0079 - accuracy: 0.9975 - f1_m: 0.9496 - val_loss: 0.1220 - val_accuracy: 0.9728 - val_f1_m: 0.9825\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 1s 230us/sample - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9476 - val_loss: 0.1003 - val_accuracy: 0.9798 - val_f1_m: 0.9708\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 1s 235us/sample - loss: 1.3947e-04 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1019 - val_accuracy: 0.9811 - val_f1_m: 0.9676\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 1s 227us/sample - loss: 3.1812e-05 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1031 - val_accuracy: 0.9812 - val_f1_m: 0.9684\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 1s 233us/sample - loss: 1.8343e-05 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1049 - val_accuracy: 0.9811 - val_f1_m: 0.9682\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 1s 227us/sample - loss: 1.3783e-05 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1066 - val_accuracy: 0.9812 - val_f1_m: 0.9675\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 1s 232us/sample - loss: 1.0694e-05 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1081 - val_accuracy: 0.9815 - val_f1_m: 0.9676\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 1s 234us/sample - loss: 8.5033e-06 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1096 - val_accuracy: 0.9820 - val_f1_m: 0.9674\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 1s 228us/sample - loss: 6.8906e-06 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1110 - val_accuracy: 0.9822 - val_f1_m: 0.9662\n",
      "Train on 6000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 3s 445us/sample - loss: 0.0222 - accuracy: 0.9955 - f1_m: 0.9532 - val_loss: 0.0943 - val_accuracy: 0.9777 - val_f1_m: 0.9771\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 2s 295us/sample - loss: 0.0059 - accuracy: 0.9977 - f1_m: 0.9505 - val_loss: 0.1130 - val_accuracy: 0.9753 - val_f1_m: 0.9769\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 2s 292us/sample - loss: 0.0066 - accuracy: 0.9975 - f1_m: 0.9523 - val_loss: 0.1453 - val_accuracy: 0.9770 - val_f1_m: 0.9696\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 2s 288us/sample - loss: 0.0170 - accuracy: 0.9955 - f1_m: 0.9547 - val_loss: 0.1028 - val_accuracy: 0.9750 - val_f1_m: 0.9800\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 2s 293us/sample - loss: 0.0174 - accuracy: 0.9947 - f1_m: 0.9549 - val_loss: 0.1053 - val_accuracy: 0.9763 - val_f1_m: 0.9778\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 2s 296us/sample - loss: 0.0085 - accuracy: 0.9972 - f1_m: 0.9533 - val_loss: 0.1209 - val_accuracy: 0.9804 - val_f1_m: 0.9667\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 2s 296us/sample - loss: 2.6660e-04 - accuracy: 1.0000 - f1_m: 0.9456 - val_loss: 0.1303 - val_accuracy: 0.9797 - val_f1_m: 0.9653\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 2s 288us/sample - loss: 0.0117 - accuracy: 0.9977 - f1_m: 0.9512 - val_loss: 0.1161 - val_accuracy: 0.9747 - val_f1_m: 0.9811\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 2s 295us/sample - loss: 0.0140 - accuracy: 0.9950 - f1_m: 0.9556 - val_loss: 0.1224 - val_accuracy: 0.9743 - val_f1_m: 0.9811\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 2s 295us/sample - loss: 0.0096 - accuracy: 0.9965 - f1_m: 0.9538 - val_loss: 0.1281 - val_accuracy: 0.9759 - val_f1_m: 0.9731\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 249us/sample - loss: 0.0495 - accuracy: 0.9894 - f1_m: 0.9871 - val_loss: 0.3181 - val_accuracy: 0.9341 - val_f1_m: 1.0383\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.0375 - accuracy: 0.9938 - f1_m: 0.9861 - val_loss: 0.3432 - val_accuracy: 0.9344 - val_f1_m: 1.0347\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.0327 - accuracy: 0.9932 - f1_m: 0.9879 - val_loss: 0.3226 - val_accuracy: 0.9395 - val_f1_m: 1.0254\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.0297 - accuracy: 0.9928 - f1_m: 0.9897 - val_loss: 0.3207 - val_accuracy: 0.9364 - val_f1_m: 1.0318\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 169us/sample - loss: 0.0243 - accuracy: 0.9946 - f1_m: 0.9808 - val_loss: 0.3495 - val_accuracy: 0.9327 - val_f1_m: 1.0353\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 170us/sample - loss: 0.0203 - accuracy: 0.9965 - f1_m: 0.9827 - val_loss: 0.3245 - val_accuracy: 0.9363 - val_f1_m: 1.0328\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 177us/sample - loss: 0.0172 - accuracy: 0.9969 - f1_m: 0.9765 - val_loss: 0.3154 - val_accuracy: 0.9394 - val_f1_m: 1.0238\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 181us/sample - loss: 0.0138 - accuracy: 0.9986 - f1_m: 0.9723 - val_loss: 0.3309 - val_accuracy: 0.9344 - val_f1_m: 1.0242\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 176us/sample - loss: 0.0181 - accuracy: 0.9962 - f1_m: 0.9809 - val_loss: 0.3333 - val_accuracy: 0.9368 - val_f1_m: 1.0327\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 171us/sample - loss: 0.0180 - accuracy: 0.9954 - f1_m: 0.9789 - val_loss: 0.3925 - val_accuracy: 0.9277 - val_f1_m: 1.0375\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 279us/sample - loss: 0.0197 - accuracy: 0.9945 - f1_m: 0.9586 - val_loss: 0.2594 - val_accuracy: 0.9572 - val_f1_m: 0.9914\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 180us/sample - loss: 0.0092 - accuracy: 0.9969 - f1_m: 0.9553 - val_loss: 0.2571 - val_accuracy: 0.9609 - val_f1_m: 0.9889\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 178us/sample - loss: 0.0097 - accuracy: 0.9968 - f1_m: 0.9527 - val_loss: 0.2394 - val_accuracy: 0.9613 - val_f1_m: 0.9857\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 179us/sample - loss: 0.0074 - accuracy: 0.9974 - f1_m: 0.9588 - val_loss: 0.2204 - val_accuracy: 0.9662 - val_f1_m: 0.9837\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 186us/sample - loss: 0.0049 - accuracy: 0.9986 - f1_m: 0.9526 - val_loss: 0.2022 - val_accuracy: 0.9682 - val_f1_m: 0.9805\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 183us/sample - loss: 8.7324e-04 - accuracy: 0.9998 - f1_m: 0.9462 - val_loss: 0.2159 - val_accuracy: 0.9674 - val_f1_m: 0.9781\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 187us/sample - loss: 0.0145 - accuracy: 0.9943 - f1_m: 0.9567 - val_loss: 0.2440 - val_accuracy: 0.9580 - val_f1_m: 0.9821\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 187us/sample - loss: 0.0119 - accuracy: 0.9957 - f1_m: 0.9583 - val_loss: 0.2171 - val_accuracy: 0.9666 - val_f1_m: 0.9771\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 187us/sample - loss: 0.0074 - accuracy: 0.9975 - f1_m: 0.9533 - val_loss: 0.2126 - val_accuracy: 0.9674 - val_f1_m: 0.9761\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 181us/sample - loss: 0.0019 - accuracy: 0.9997 - f1_m: 0.9498 - val_loss: 0.2052 - val_accuracy: 0.9686 - val_f1_m: 0.9761\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 329us/sample - loss: 0.0226 - accuracy: 0.9931 - f1_m: 0.9571 - val_loss: 0.1290 - val_accuracy: 0.9731 - val_f1_m: 0.9769\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 212us/sample - loss: 0.0026 - accuracy: 0.9989 - f1_m: 0.9497 - val_loss: 0.1378 - val_accuracy: 0.9739 - val_f1_m: 0.9705\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 210us/sample - loss: 5.4226e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1458 - val_accuracy: 0.9739 - val_f1_m: 0.9711\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 215us/sample - loss: 1.4017e-04 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1469 - val_accuracy: 0.9756 - val_f1_m: 0.9700\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 212us/sample - loss: 8.1152e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1492 - val_accuracy: 0.9759 - val_f1_m: 0.9701\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 214us/sample - loss: 6.0659e-05 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1527 - val_accuracy: 0.9763 - val_f1_m: 0.9682\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 215us/sample - loss: 4.5410e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1558 - val_accuracy: 0.9756 - val_f1_m: 0.9674\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 210us/sample - loss: 3.5889e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1590 - val_accuracy: 0.9757 - val_f1_m: 0.9673\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 227us/sample - loss: 2.9079e-05 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.1624 - val_accuracy: 0.9754 - val_f1_m: 0.9661\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 218us/sample - loss: 2.3621e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1650 - val_accuracy: 0.9757 - val_f1_m: 0.9662\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 3s 414us/sample - loss: 0.0257 - accuracy: 0.9915 - f1_m: 0.9579 - val_loss: 0.1847 - val_accuracy: 0.9627 - val_f1_m: 0.9906\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 2s 270us/sample - loss: 0.0047 - accuracy: 0.9988 - f1_m: 0.9501 - val_loss: 0.1588 - val_accuracy: 0.9729 - val_f1_m: 0.9705\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 2s 268us/sample - loss: 0.0040 - accuracy: 0.9991 - f1_m: 0.9481 - val_loss: 0.1785 - val_accuracy: 0.9697 - val_f1_m: 0.9757\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 2s 263us/sample - loss: 0.0182 - accuracy: 0.9946 - f1_m: 0.9597 - val_loss: 0.1671 - val_accuracy: 0.9663 - val_f1_m: 0.9831\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 2s 265us/sample - loss: 0.0217 - accuracy: 0.9934 - f1_m: 0.9606 - val_loss: 0.1570 - val_accuracy: 0.9688 - val_f1_m: 0.9814\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 2s 267us/sample - loss: 0.0145 - accuracy: 0.9954 - f1_m: 0.9596 - val_loss: 0.1549 - val_accuracy: 0.9703 - val_f1_m: 0.9782\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 2s 265us/sample - loss: 0.0347 - accuracy: 0.9903 - f1_m: 0.9664 - val_loss: 0.1313 - val_accuracy: 0.9701 - val_f1_m: 0.9864\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 2s 275us/sample - loss: 0.0030 - accuracy: 0.9991 - f1_m: 0.9492 - val_loss: 0.1532 - val_accuracy: 0.9720 - val_f1_m: 0.9754\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 2s 270us/sample - loss: 0.0014 - accuracy: 0.9997 - f1_m: 0.9479 - val_loss: 0.1531 - val_accuracy: 0.9739 - val_f1_m: 0.9706\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 2s 267us/sample - loss: 1.4927e-04 - accuracy: 1.0000 - f1_m: 0.9455 - val_loss: 0.1573 - val_accuracy: 0.9763 - val_f1_m: 0.9690\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 244us/sample - loss: 0.0332 - accuracy: 0.9929 - f1_m: 0.9592 - val_loss: 0.2948 - val_accuracy: 0.9474 - val_f1_m: 1.0017\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 172us/sample - loss: 0.0163 - accuracy: 0.9954 - f1_m: 0.9565 - val_loss: 0.3094 - val_accuracy: 0.9463 - val_f1_m: 1.0002\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 170us/sample - loss: 0.0117 - accuracy: 0.9966 - f1_m: 0.9595 - val_loss: 0.2949 - val_accuracy: 0.9514 - val_f1_m: 0.9948\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.0033 - accuracy: 0.9995 - f1_m: 0.9494 - val_loss: 0.2858 - val_accuracy: 0.9531 - val_f1_m: 0.9927\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 170us/sample - loss: 0.0014 - accuracy: 0.9997 - f1_m: 0.9466 - val_loss: 0.3036 - val_accuracy: 0.9505 - val_f1_m: 0.9968\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 177us/sample - loss: 0.0055 - accuracy: 0.9989 - f1_m: 0.9519 - val_loss: 0.3241 - val_accuracy: 0.9488 - val_f1_m: 1.0022\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 171us/sample - loss: 0.0038 - accuracy: 0.9991 - f1_m: 0.9519 - val_loss: 0.2831 - val_accuracy: 0.9557 - val_f1_m: 0.9933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.0164 - accuracy: 0.9952 - f1_m: 0.9609 - val_loss: 0.3390 - val_accuracy: 0.9416 - val_f1_m: 1.0044\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.0075 - accuracy: 0.9978 - f1_m: 0.9559 - val_loss: 0.3299 - val_accuracy: 0.9476 - val_f1_m: 0.9972\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 168us/sample - loss: 0.0121 - accuracy: 0.9957 - f1_m: 0.9580 - val_loss: 0.3336 - val_accuracy: 0.9516 - val_f1_m: 0.9960\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 275us/sample - loss: 0.0199 - accuracy: 0.9943 - f1_m: 0.9544 - val_loss: 0.1211 - val_accuracy: 0.9737 - val_f1_m: 0.9801\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 188us/sample - loss: 0.0035 - accuracy: 0.9992 - f1_m: 0.9491 - val_loss: 0.1209 - val_accuracy: 0.9764 - val_f1_m: 0.9732\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 197us/sample - loss: 3.4324e-04 - accuracy: 1.0000 - f1_m: 0.9450 - val_loss: 0.1240 - val_accuracy: 0.9776 - val_f1_m: 0.9703\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 194us/sample - loss: 1.9612e-04 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1211 - val_accuracy: 0.9781 - val_f1_m: 0.9700\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 192us/sample - loss: 8.4168e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1238 - val_accuracy: 0.9786 - val_f1_m: 0.9687\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 192us/sample - loss: 6.2681e-05 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1256 - val_accuracy: 0.9788 - val_f1_m: 0.9679\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 194us/sample - loss: 5.0012e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1277 - val_accuracy: 0.9788 - val_f1_m: 0.9670\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 194us/sample - loss: 3.9736e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1291 - val_accuracy: 0.9789 - val_f1_m: 0.9673\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 189us/sample - loss: 3.3108e-05 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.1317 - val_accuracy: 0.9786 - val_f1_m: 0.9672\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 185us/sample - loss: 2.7328e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1329 - val_accuracy: 0.9789 - val_f1_m: 0.9668\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 2s 331us/sample - loss: 0.0156 - accuracy: 0.9963 - f1_m: 0.9509 - val_loss: 0.1109 - val_accuracy: 0.9755 - val_f1_m: 0.9731\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 1s 222us/sample - loss: 7.5155e-04 - accuracy: 0.9998 - f1_m: 0.9461 - val_loss: 0.1153 - val_accuracy: 0.9802 - val_f1_m: 0.9689\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 1s 226us/sample - loss: 7.9488e-05 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1137 - val_accuracy: 0.9814 - val_f1_m: 0.9660\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 1s 224us/sample - loss: 2.5649e-05 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1155 - val_accuracy: 0.9815 - val_f1_m: 0.9658\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 1s 222us/sample - loss: 1.7616e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1170 - val_accuracy: 0.9816 - val_f1_m: 0.9650\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 1s 228us/sample - loss: 1.3006e-05 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1184 - val_accuracy: 0.9817 - val_f1_m: 0.9649\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 1s 224us/sample - loss: 9.9688e-06 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1198 - val_accuracy: 0.9820 - val_f1_m: 0.9644\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 1s 229us/sample - loss: 7.8892e-06 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1211 - val_accuracy: 0.9820 - val_f1_m: 0.9640\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 1s 224us/sample - loss: 6.3616e-06 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.1225 - val_accuracy: 0.9818 - val_f1_m: 0.9637\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 1s 227us/sample - loss: 5.2286e-06 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1238 - val_accuracy: 0.9818 - val_f1_m: 0.9632\n",
      "Train on 6500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 3s 421us/sample - loss: 0.0173 - accuracy: 0.9963 - f1_m: 0.9546 - val_loss: 0.1049 - val_accuracy: 0.9748 - val_f1_m: 0.9787\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 2s 282us/sample - loss: 0.0078 - accuracy: 0.9971 - f1_m: 0.9510 - val_loss: 0.1282 - val_accuracy: 0.9752 - val_f1_m: 0.9729\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 2s 281us/sample - loss: 0.0080 - accuracy: 0.9972 - f1_m: 0.9505 - val_loss: 0.1248 - val_accuracy: 0.9751 - val_f1_m: 0.9747\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 2s 285us/sample - loss: 0.0098 - accuracy: 0.9965 - f1_m: 0.9540 - val_loss: 0.1451 - val_accuracy: 0.9754 - val_f1_m: 0.9659\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 2s 286us/sample - loss: 0.0152 - accuracy: 0.9955 - f1_m: 0.9518 - val_loss: 0.1101 - val_accuracy: 0.9725 - val_f1_m: 0.9855\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 2s 287us/sample - loss: 0.0118 - accuracy: 0.9957 - f1_m: 0.9552 - val_loss: 0.1330 - val_accuracy: 0.9710 - val_f1_m: 0.9861\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 2s 286us/sample - loss: 0.0060 - accuracy: 0.9980 - f1_m: 0.9508 - val_loss: 0.1485 - val_accuracy: 0.9734 - val_f1_m: 0.9752\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 2s 288us/sample - loss: 0.0069 - accuracy: 0.9978 - f1_m: 0.9516 - val_loss: 0.1128 - val_accuracy: 0.9803 - val_f1_m: 0.9698\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 2s 286us/sample - loss: 1.5785e-04 - accuracy: 1.0000 - f1_m: 0.9457 - val_loss: 0.1145 - val_accuracy: 0.9825 - val_f1_m: 0.9639\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 2s 284us/sample - loss: 2.1400e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1167 - val_accuracy: 0.9827 - val_f1_m: 0.9627\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 3s 403us/sample - loss: 0.0386 - accuracy: 0.9906 - f1_m: 0.9820 - val_loss: 0.3196 - val_accuracy: 0.9408 - val_f1_m: 1.0240\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.0266 - accuracy: 0.9941 - f1_m: 0.9728 - val_loss: 0.3210 - val_accuracy: 0.9371 - val_f1_m: 1.0266\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.0233 - accuracy: 0.9934 - f1_m: 0.9804 - val_loss: 0.3196 - val_accuracy: 0.9401 - val_f1_m: 1.0145\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 163us/sample - loss: 0.0214 - accuracy: 0.9940 - f1_m: 0.9788 - val_loss: 0.3281 - val_accuracy: 0.9363 - val_f1_m: 1.0239\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.0134 - accuracy: 0.9976 - f1_m: 0.9721 - val_loss: 0.3286 - val_accuracy: 0.9409 - val_f1_m: 1.0209\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 165us/sample - loss: 0.0120 - accuracy: 0.9977 - f1_m: 0.9686 - val_loss: 0.3229 - val_accuracy: 0.9421 - val_f1_m: 1.0193\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 162us/sample - loss: 0.0098 - accuracy: 0.9983 - f1_m: 0.9670 - val_loss: 0.3197 - val_accuracy: 0.9408 - val_f1_m: 1.0128\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.0081 - accuracy: 0.9990 - f1_m: 0.9613 - val_loss: 0.3129 - val_accuracy: 0.9416 - val_f1_m: 1.0170\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 165us/sample - loss: 0.0093 - accuracy: 0.9984 - f1_m: 0.9657 - val_loss: 0.3225 - val_accuracy: 0.9438 - val_f1_m: 1.0122\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 166us/sample - loss: 0.0121 - accuracy: 0.9980 - f1_m: 0.9668 - val_loss: 0.3289 - val_accuracy: 0.9393 - val_f1_m: 1.0130\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0318 - accuracy: 0.9937 - f1_m: 0.9576 - val_loss: 0.2144 - val_accuracy: 0.9644 - val_f1_m: 0.9871\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 182us/sample - loss: 0.0219 - accuracy: 0.9937 - f1_m: 0.9566 - val_loss: 0.2198 - val_accuracy: 0.9624 - val_f1_m: 0.9849\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 178us/sample - loss: 0.0115 - accuracy: 0.9967 - f1_m: 0.9557 - val_loss: 0.2027 - val_accuracy: 0.9654 - val_f1_m: 0.9840\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 184us/sample - loss: 0.0064 - accuracy: 0.9983 - f1_m: 0.9537 - val_loss: 0.2131 - val_accuracy: 0.9665 - val_f1_m: 0.9821\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 175us/sample - loss: 0.0020 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 0.2024 - val_accuracy: 0.9664 - val_f1_m: 0.9810\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 174us/sample - loss: 0.0037 - accuracy: 0.9984 - f1_m: 0.9490 - val_loss: 0.2057 - val_accuracy: 0.9667 - val_f1_m: 0.9800\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 173us/sample - loss: 0.0014 - accuracy: 1.0000 - f1_m: 0.9484 - val_loss: 0.2081 - val_accuracy: 0.9681 - val_f1_m: 0.9777\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 178us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9482 - val_loss: 0.2121 - val_accuracy: 0.9676 - val_f1_m: 0.9794\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 173us/sample - loss: 0.0144 - accuracy: 0.9946 - f1_m: 0.9551 - val_loss: 0.2752 - val_accuracy: 0.9537 - val_f1_m: 0.9863\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 178us/sample - loss: 0.0217 - accuracy: 0.9937 - f1_m: 0.9642 - val_loss: 0.2131 - val_accuracy: 0.9687 - val_f1_m: 0.9774\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 306us/sample - loss: 0.0184 - accuracy: 0.9960 - f1_m: 0.9512 - val_loss: 0.1461 - val_accuracy: 0.9694 - val_f1_m: 0.9810\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0094 - accuracy: 0.9973 - f1_m: 0.9528 - val_loss: 0.1380 - val_accuracy: 0.9720 - val_f1_m: 0.9815\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0024 - accuracy: 0.9994 - f1_m: 0.9485 - val_loss: 0.1553 - val_accuracy: 0.9724 - val_f1_m: 0.9810\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 221us/sample - loss: 0.0017 - accuracy: 0.9994 - f1_m: 0.9456 - val_loss: 0.1508 - val_accuracy: 0.9723 - val_f1_m: 0.9741\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0125 - accuracy: 0.9961 - f1_m: 0.9518 - val_loss: 0.1981 - val_accuracy: 0.9670 - val_f1_m: 0.9803\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0117 - accuracy: 0.9963 - f1_m: 0.9556 - val_loss: 0.1558 - val_accuracy: 0.9723 - val_f1_m: 0.9714\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 216us/sample - loss: 0.0073 - accuracy: 0.9973 - f1_m: 0.9516 - val_loss: 0.1866 - val_accuracy: 0.9671 - val_f1_m: 0.9792\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 216us/sample - loss: 0.0136 - accuracy: 0.9956 - f1_m: 0.9535 - val_loss: 0.1355 - val_accuracy: 0.9770 - val_f1_m: 0.9699\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0037 - accuracy: 0.9984 - f1_m: 0.9486 - val_loss: 0.1256 - val_accuracy: 0.9757 - val_f1_m: 0.9723\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 214us/sample - loss: 2.6948e-04 - accuracy: 1.0000 - f1_m: 0.9445 - val_loss: 0.1275 - val_accuracy: 0.9764 - val_f1_m: 0.9697\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 3s 388us/sample - loss: 0.0269 - accuracy: 0.9943 - f1_m: 0.9542 - val_loss: 0.1385 - val_accuracy: 0.9730 - val_f1_m: 0.9855\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 262us/sample - loss: 0.0099 - accuracy: 0.9964 - f1_m: 0.9557 - val_loss: 0.1362 - val_accuracy: 0.9734 - val_f1_m: 0.9757\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 273us/sample - loss: 0.0061 - accuracy: 0.9980 - f1_m: 0.9522 - val_loss: 0.1799 - val_accuracy: 0.9673 - val_f1_m: 0.9775\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0298 - accuracy: 0.9901 - f1_m: 0.9639 - val_loss: 0.1362 - val_accuracy: 0.9672 - val_f1_m: 0.9895\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 251us/sample - loss: 0.0096 - accuracy: 0.9967 - f1_m: 0.9552 - val_loss: 0.1567 - val_accuracy: 0.9695 - val_f1_m: 0.9812\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 249us/sample - loss: 0.0134 - accuracy: 0.9969 - f1_m: 0.9568 - val_loss: 0.1576 - val_accuracy: 0.9714 - val_f1_m: 0.9742\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 250us/sample - loss: 0.0050 - accuracy: 0.9983 - f1_m: 0.9488 - val_loss: 0.1816 - val_accuracy: 0.9712 - val_f1_m: 0.9712\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 249us/sample - loss: 0.0228 - accuracy: 0.9930 - f1_m: 0.9572 - val_loss: 0.1373 - val_accuracy: 0.9671 - val_f1_m: 0.9849\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 248us/sample - loss: 0.0045 - accuracy: 0.9981 - f1_m: 0.9500 - val_loss: 0.1855 - val_accuracy: 0.9709 - val_f1_m: 0.9672\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 249us/sample - loss: 0.0130 - accuracy: 0.9967 - f1_m: 0.9536 - val_loss: 0.1426 - val_accuracy: 0.9745 - val_f1_m: 0.9727\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 228us/sample - loss: 0.0368 - accuracy: 0.9930 - f1_m: 0.9602 - val_loss: 0.2852 - val_accuracy: 0.9498 - val_f1_m: 1.0026\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 160us/sample - loss: 0.0136 - accuracy: 0.9959 - f1_m: 0.9561 - val_loss: 0.2747 - val_accuracy: 0.9497 - val_f1_m: 1.0047\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 159us/sample - loss: 0.0040 - accuracy: 0.9991 - f1_m: 0.9529 - val_loss: 0.2679 - val_accuracy: 0.9546 - val_f1_m: 0.9950\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 158us/sample - loss: 0.0017 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.2658 - val_accuracy: 0.9543 - val_f1_m: 0.9901\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 157us/sample - loss: 9.0788e-04 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.2779 - val_accuracy: 0.9546 - val_f1_m: 0.9899\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 8.8977e-04 - accuracy: 0.9999 - f1_m: 0.9449 - val_loss: 0.2740 - val_accuracy: 0.9541 - val_f1_m: 0.9905\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 4.0912e-04 - accuracy: 1.0000 - f1_m: 0.9444 - val_loss: 0.2718 - val_accuracy: 0.9555 - val_f1_m: 0.9895\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 3.1469e-04 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.2744 - val_accuracy: 0.9578 - val_f1_m: 0.9867\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 2.7538e-04 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.2769 - val_accuracy: 0.9567 - val_f1_m: 0.9870\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 2.4083e-04 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.2815 - val_accuracy: 0.9575 - val_f1_m: 0.9867\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 252us/sample - loss: 0.0175 - accuracy: 0.9957 - f1_m: 0.9516 - val_loss: 0.1458 - val_accuracy: 0.9717 - val_f1_m: 0.9786\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 179us/sample - loss: 0.0040 - accuracy: 0.9990 - f1_m: 0.9490 - val_loss: 0.1315 - val_accuracy: 0.9766 - val_f1_m: 0.9710\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 178us/sample - loss: 8.8029e-04 - accuracy: 0.9999 - f1_m: 0.9461 - val_loss: 0.1443 - val_accuracy: 0.9758 - val_f1_m: 0.9654\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 180us/sample - loss: 4.0211e-04 - accuracy: 0.9999 - f1_m: 0.9448 - val_loss: 0.1293 - val_accuracy: 0.9777 - val_f1_m: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 180us/sample - loss: 7.3050e-05 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1259 - val_accuracy: 0.9778 - val_f1_m: 0.9651\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 179us/sample - loss: 4.9024e-05 - accuracy: 1.0000 - f1_m: 0.9441 - val_loss: 0.1260 - val_accuracy: 0.9783 - val_f1_m: 0.9650\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 180us/sample - loss: 3.7801e-05 - accuracy: 1.0000 - f1_m: 0.9443 - val_loss: 0.1277 - val_accuracy: 0.9784 - val_f1_m: 0.9647\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 181us/sample - loss: 3.1084e-05 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1287 - val_accuracy: 0.9782 - val_f1_m: 0.9643\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 181us/sample - loss: 2.5831e-05 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1295 - val_accuracy: 0.9783 - val_f1_m: 0.9642\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 177us/sample - loss: 2.2099e-05 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1308 - val_accuracy: 0.9786 - val_f1_m: 0.9642\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 2s 303us/sample - loss: 0.0140 - accuracy: 0.9976 - f1_m: 0.9490 - val_loss: 0.1561 - val_accuracy: 0.9743 - val_f1_m: 0.9747\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0065 - accuracy: 0.9973 - f1_m: 0.9497 - val_loss: 0.1254 - val_accuracy: 0.9783 - val_f1_m: 0.9683\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0024 - accuracy: 0.9991 - f1_m: 0.9472 - val_loss: 0.1438 - val_accuracy: 0.9791 - val_f1_m: 0.9668\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0030 - accuracy: 0.9996 - f1_m: 0.9459 - val_loss: 0.1400 - val_accuracy: 0.9786 - val_f1_m: 0.9683\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0118 - accuracy: 0.9957 - f1_m: 0.9517 - val_loss: 0.1250 - val_accuracy: 0.9779 - val_f1_m: 0.9799\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0085 - accuracy: 0.9974 - f1_m: 0.9493 - val_loss: 0.1175 - val_accuracy: 0.9774 - val_f1_m: 0.9771\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0043 - accuracy: 0.9984 - f1_m: 0.9493 - val_loss: 0.1114 - val_accuracy: 0.9787 - val_f1_m: 0.9684\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0011 - accuracy: 0.9994 - f1_m: 0.9462 - val_loss: 0.1168 - val_accuracy: 0.9813 - val_f1_m: 0.9660\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 1s 214us/sample - loss: 3.9164e-04 - accuracy: 0.9999 - f1_m: 0.9451 - val_loss: 0.1247 - val_accuracy: 0.9827 - val_f1_m: 0.9653\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 3.6636e-05 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1262 - val_accuracy: 0.9827 - val_f1_m: 0.9659\n",
      "Train on 7000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 3s 387us/sample - loss: 0.0216 - accuracy: 0.9957 - f1_m: 0.9506 - val_loss: 0.0938 - val_accuracy: 0.9778 - val_f1_m: 0.9805\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 2s 266us/sample - loss: 0.0033 - accuracy: 0.9993 - f1_m: 0.9478 - val_loss: 0.1247 - val_accuracy: 0.9783 - val_f1_m: 0.9700\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 2s 265us/sample - loss: 2.9729e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1080 - val_accuracy: 0.9838 - val_f1_m: 0.9643\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 2s 267us/sample - loss: 1.7294e-05 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1107 - val_accuracy: 0.9836 - val_f1_m: 0.9641\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 2s 266us/sample - loss: 1.0475e-05 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1126 - val_accuracy: 0.9837 - val_f1_m: 0.9633\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 2s 287us/sample - loss: 7.3707e-06 - accuracy: 1.0000 - f1_m: 0.9441 - val_loss: 0.1144 - val_accuracy: 0.9839 - val_f1_m: 0.9633\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 2s 270us/sample - loss: 5.5137e-06 - accuracy: 1.0000 - f1_m: 0.9443 - val_loss: 0.1160 - val_accuracy: 0.9845 - val_f1_m: 0.9631\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 2s 268us/sample - loss: 4.2712e-06 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1176 - val_accuracy: 0.9846 - val_f1_m: 0.9627\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 2s 267us/sample - loss: 3.3997e-06 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1191 - val_accuracy: 0.9846 - val_f1_m: 0.9617\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 2s 267us/sample - loss: 2.7496e-06 - accuracy: 1.0000 - f1_m: 0.9442 - val_loss: 0.1205 - val_accuracy: 0.9847 - val_f1_m: 0.9611\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 218us/sample - loss: 0.0346 - accuracy: 0.9925 - f1_m: 0.9728 - val_loss: 0.3322 - val_accuracy: 0.9397 - val_f1_m: 1.0156\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 153us/sample - loss: 0.0259 - accuracy: 0.9937 - f1_m: 0.9694 - val_loss: 0.3159 - val_accuracy: 0.9428 - val_f1_m: 1.0168\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0193 - accuracy: 0.9957 - f1_m: 0.9693 - val_loss: 0.3133 - val_accuracy: 0.9430 - val_f1_m: 1.0141\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 152us/sample - loss: 0.0141 - accuracy: 0.9971 - f1_m: 0.9667 - val_loss: 0.3173 - val_accuracy: 0.9427 - val_f1_m: 1.0135\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0150 - accuracy: 0.9961 - f1_m: 0.9684 - val_loss: 0.3227 - val_accuracy: 0.9439 - val_f1_m: 1.0129\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 152us/sample - loss: 0.0092 - accuracy: 0.9987 - f1_m: 0.9618 - val_loss: 0.3507 - val_accuracy: 0.9383 - val_f1_m: 1.0154\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0072 - accuracy: 0.9989 - f1_m: 0.9576 - val_loss: 0.3273 - val_accuracy: 0.9442 - val_f1_m: 1.0061\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0058 - accuracy: 0.9995 - f1_m: 0.9558 - val_loss: 0.3175 - val_accuracy: 0.9441 - val_f1_m: 1.0119\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0061 - accuracy: 0.9991 - f1_m: 0.9562 - val_loss: 0.3447 - val_accuracy: 0.9434 - val_f1_m: 1.0044\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0065 - accuracy: 0.9987 - f1_m: 0.9571 - val_loss: 0.3449 - val_accuracy: 0.9421 - val_f1_m: 1.0121\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 235us/sample - loss: 0.0206 - accuracy: 0.9948 - f1_m: 0.9590 - val_loss: 0.2077 - val_accuracy: 0.9658 - val_f1_m: 0.9808\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 162us/sample - loss: 0.0111 - accuracy: 0.9961 - f1_m: 0.9545 - val_loss: 0.2157 - val_accuracy: 0.9657 - val_f1_m: 0.9824\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 161us/sample - loss: 0.0110 - accuracy: 0.9964 - f1_m: 0.9551 - val_loss: 0.2068 - val_accuracy: 0.9658 - val_f1_m: 0.9784\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 164us/sample - loss: 0.0054 - accuracy: 0.9985 - f1_m: 0.9519 - val_loss: 0.2066 - val_accuracy: 0.9676 - val_f1_m: 0.9799\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 0.0041 - accuracy: 0.9988 - f1_m: 0.9500 - val_loss: 0.1966 - val_accuracy: 0.9680 - val_f1_m: 0.9781\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 167us/sample - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9486 - val_loss: 0.1888 - val_accuracy: 0.9690 - val_f1_m: 0.9796\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 8.3244e-04 - accuracy: 0.9997 - f1_m: 0.9459 - val_loss: 0.2038 - val_accuracy: 0.9663 - val_f1_m: 0.9768\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 5.5120e-04 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.2036 - val_accuracy: 0.9697 - val_f1_m: 0.9754\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 3.0979e-04 - accuracy: 1.0000 - f1_m: 0.9448 - val_loss: 0.1932 - val_accuracy: 0.9717 - val_f1_m: 0.9753\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 165us/sample - loss: 1.9237e-04 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1973 - val_accuracy: 0.9702 - val_f1_m: 0.9741\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 281us/sample - loss: 0.0213 - accuracy: 0.9953 - f1_m: 0.9536 - val_loss: 0.1092 - val_accuracy: 0.9747 - val_f1_m: 0.9827\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 194us/sample - loss: 0.0107 - accuracy: 0.9977 - f1_m: 0.9515 - val_loss: 0.1285 - val_accuracy: 0.9731 - val_f1_m: 0.9782\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 193us/sample - loss: 0.0082 - accuracy: 0.9971 - f1_m: 0.9517 - val_loss: 0.1399 - val_accuracy: 0.9740 - val_f1_m: 0.9735\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 193us/sample - loss: 0.0085 - accuracy: 0.9972 - f1_m: 0.9497 - val_loss: 0.1260 - val_accuracy: 0.9759 - val_f1_m: 0.9751\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 193us/sample - loss: 0.0037 - accuracy: 0.9988 - f1_m: 0.9475 - val_loss: 0.1127 - val_accuracy: 0.9749 - val_f1_m: 0.9771\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 193us/sample - loss: 0.0020 - accuracy: 0.9997 - f1_m: 0.9471 - val_loss: 0.1075 - val_accuracy: 0.9778 - val_f1_m: 0.9686\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 194us/sample - loss: 9.2643e-04 - accuracy: 0.9997 - f1_m: 0.9455 - val_loss: 0.1208 - val_accuracy: 0.9775 - val_f1_m: 0.9684\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 193us/sample - loss: 1.5915e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1277 - val_accuracy: 0.9769 - val_f1_m: 0.9708\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 194us/sample - loss: 5.7312e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1294 - val_accuracy: 0.9775 - val_f1_m: 0.9690\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 194us/sample - loss: 4.0673e-05 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1314 - val_accuracy: 0.9775 - val_f1_m: 0.9681\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 3s 366us/sample - loss: 0.0222 - accuracy: 0.9949 - f1_m: 0.9557 - val_loss: 0.1502 - val_accuracy: 0.9651 - val_f1_m: 0.9862\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 2s 242us/sample - loss: 0.0080 - accuracy: 0.9983 - f1_m: 0.9515 - val_loss: 0.1352 - val_accuracy: 0.9689 - val_f1_m: 0.9928\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 2s 243us/sample - loss: 0.0074 - accuracy: 0.9972 - f1_m: 0.9516 - val_loss: 0.1612 - val_accuracy: 0.9701 - val_f1_m: 0.9745\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 2s 243us/sample - loss: 0.0103 - accuracy: 0.9964 - f1_m: 0.9552 - val_loss: 0.1713 - val_accuracy: 0.9722 - val_f1_m: 0.9725\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 2s 242us/sample - loss: 0.0167 - accuracy: 0.9948 - f1_m: 0.9545 - val_loss: 0.1380 - val_accuracy: 0.9689 - val_f1_m: 0.9812\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 2s 242us/sample - loss: 0.0098 - accuracy: 0.9964 - f1_m: 0.9549 - val_loss: 0.1508 - val_accuracy: 0.9711 - val_f1_m: 0.9798\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 2s 241us/sample - loss: 0.0144 - accuracy: 0.9956 - f1_m: 0.9554 - val_loss: 0.1829 - val_accuracy: 0.9684 - val_f1_m: 0.9814\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 2s 241us/sample - loss: 0.0044 - accuracy: 0.9988 - f1_m: 0.9491 - val_loss: 0.1926 - val_accuracy: 0.9714 - val_f1_m: 0.9697\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 2s 241us/sample - loss: 0.0018 - accuracy: 0.9996 - f1_m: 0.9474 - val_loss: 0.1751 - val_accuracy: 0.9763 - val_f1_m: 0.9644\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 2s 243us/sample - loss: 0.0066 - accuracy: 0.9983 - f1_m: 0.9493 - val_loss: 0.1666 - val_accuracy: 0.9729 - val_f1_m: 0.9752\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 215us/sample - loss: 0.0321 - accuracy: 0.9937 - f1_m: 0.9588 - val_loss: 0.2976 - val_accuracy: 0.9483 - val_f1_m: 0.9927\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 153us/sample - loss: 0.0117 - accuracy: 0.9977 - f1_m: 0.9525 - val_loss: 0.2870 - val_accuracy: 0.9514 - val_f1_m: 1.0022\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 152us/sample - loss: 0.0101 - accuracy: 0.9968 - f1_m: 0.9537 - val_loss: 0.2793 - val_accuracy: 0.9538 - val_f1_m: 0.9917\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0048 - accuracy: 0.9987 - f1_m: 0.9501 - val_loss: 0.2712 - val_accuracy: 0.9559 - val_f1_m: 0.9946\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0017 - accuracy: 0.9997 - f1_m: 0.9474 - val_loss: 0.2629 - val_accuracy: 0.9566 - val_f1_m: 0.9867\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0015 - accuracy: 0.9999 - f1_m: 0.9458 - val_loss: 0.2610 - val_accuracy: 0.9572 - val_f1_m: 0.9861\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 6.3120e-04 - accuracy: 0.9999 - f1_m: 0.9452 - val_loss: 0.2694 - val_accuracy: 0.9578 - val_f1_m: 0.9845\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0012 - accuracy: 0.9999 - f1_m: 0.9463 - val_loss: 0.2733 - val_accuracy: 0.9572 - val_f1_m: 0.9875\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 152us/sample - loss: 9.2731e-04 - accuracy: 0.9999 - f1_m: 0.9453 - val_loss: 0.2824 - val_accuracy: 0.9578 - val_f1_m: 0.9844\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 151us/sample - loss: 0.0081 - accuracy: 0.9985 - f1_m: 0.9504 - val_loss: 0.4733 - val_accuracy: 0.9276 - val_f1_m: 1.0032\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 244us/sample - loss: 0.0172 - accuracy: 0.9967 - f1_m: 0.9522 - val_loss: 0.1423 - val_accuracy: 0.9729 - val_f1_m: 0.9774\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 174us/sample - loss: 0.0076 - accuracy: 0.9981 - f1_m: 0.9489 - val_loss: 0.1362 - val_accuracy: 0.9735 - val_f1_m: 0.9757\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 174us/sample - loss: 0.0068 - accuracy: 0.9984 - f1_m: 0.9485 - val_loss: 0.1360 - val_accuracy: 0.9733 - val_f1_m: 0.9801\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 172us/sample - loss: 0.0042 - accuracy: 0.9989 - f1_m: 0.9478 - val_loss: 0.1039 - val_accuracy: 0.9808 - val_f1_m: 0.9765\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 173us/sample - loss: 6.7678e-04 - accuracy: 0.9999 - f1_m: 0.9461 - val_loss: 0.1193 - val_accuracy: 0.9781 - val_f1_m: 0.9699\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 173us/sample - loss: 3.8409e-04 - accuracy: 1.0000 - f1_m: 0.9455 - val_loss: 0.1212 - val_accuracy: 0.9784 - val_f1_m: 0.9698\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 170us/sample - loss: 7.1160e-05 - accuracy: 1.0000 - f1_m: 0.9451 - val_loss: 0.1165 - val_accuracy: 0.9793 - val_f1_m: 0.9683\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 173us/sample - loss: 3.3926e-05 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1168 - val_accuracy: 0.9798 - val_f1_m: 0.9680\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 172us/sample - loss: 2.7176e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1173 - val_accuracy: 0.9800 - val_f1_m: 0.9670\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 171us/sample - loss: 2.2693e-05 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1184 - val_accuracy: 0.9799 - val_f1_m: 0.9669\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 2s 291us/sample - loss: 0.0152 - accuracy: 0.9968 - f1_m: 0.9501 - val_loss: 0.1007 - val_accuracy: 0.9803 - val_f1_m: 0.9728\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 2s 205us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9473 - val_loss: 0.1101 - val_accuracy: 0.9808 - val_f1_m: 0.9714\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 2s 207us/sample - loss: 0.0029 - accuracy: 0.9997 - f1_m: 0.9451 - val_loss: 0.1061 - val_accuracy: 0.9812 - val_f1_m: 0.9698\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 2s 206us/sample - loss: 0.0020 - accuracy: 0.9995 - f1_m: 0.9465 - val_loss: 0.1220 - val_accuracy: 0.9819 - val_f1_m: 0.9674\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 2s 205us/sample - loss: 9.1649e-05 - accuracy: 1.0000 - f1_m: 0.9450 - val_loss: 0.1249 - val_accuracy: 0.9820 - val_f1_m: 0.9640\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 2s 205us/sample - loss: 2.2793e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1275 - val_accuracy: 0.9817 - val_f1_m: 0.9637\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 2s 208us/sample - loss: 1.1319e-05 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1292 - val_accuracy: 0.9819 - val_f1_m: 0.9634\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 2s 206us/sample - loss: 8.4054e-06 - accuracy: 1.0000 - f1_m: 0.9449 - val_loss: 0.1310 - val_accuracy: 0.9824 - val_f1_m: 0.9621\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 2s 206us/sample - loss: 6.4953e-06 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1327 - val_accuracy: 0.9824 - val_f1_m: 0.9619\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 2s 207us/sample - loss: 5.1535e-06 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1343 - val_accuracy: 0.9825 - val_f1_m: 0.9619\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 3s 374us/sample - loss: 0.0146 - accuracy: 0.9969 - f1_m: 0.9524 - val_loss: 0.1022 - val_accuracy: 0.9803 - val_f1_m: 0.9694\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 2s 265us/sample - loss: 0.0051 - accuracy: 0.9988 - f1_m: 0.9484 - val_loss: 0.1218 - val_accuracy: 0.9763 - val_f1_m: 0.9737\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 2s 282us/sample - loss: 0.0149 - accuracy: 0.9951 - f1_m: 0.9546 - val_loss: 0.1086 - val_accuracy: 0.9797 - val_f1_m: 0.9714\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 2s 277us/sample - loss: 0.0144 - accuracy: 0.9957 - f1_m: 0.9529 - val_loss: 0.1519 - val_accuracy: 0.9707 - val_f1_m: 0.9855\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 2s 278us/sample - loss: 0.0082 - accuracy: 0.9975 - f1_m: 0.9521 - val_loss: 0.1190 - val_accuracy: 0.9766 - val_f1_m: 0.9703\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 2s 268us/sample - loss: 0.0046 - accuracy: 0.9983 - f1_m: 0.9489 - val_loss: 0.1168 - val_accuracy: 0.9811 - val_f1_m: 0.9642\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 2s 268us/sample - loss: 4.0038e-04 - accuracy: 0.9997 - f1_m: 0.9456 - val_loss: 0.1152 - val_accuracy: 0.9827 - val_f1_m: 0.9627\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 2s 271us/sample - loss: 3.9780e-05 - accuracy: 1.0000 - f1_m: 0.9450 - val_loss: 0.1167 - val_accuracy: 0.9830 - val_f1_m: 0.9609\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 2s 266us/sample - loss: 1.2364e-05 - accuracy: 1.0000 - f1_m: 0.9446 - val_loss: 0.1188 - val_accuracy: 0.9834 - val_f1_m: 0.9604\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 2s 265us/sample - loss: 8.9626e-06 - accuracy: 1.0000 - f1_m: 0.9447 - val_loss: 0.1205 - val_accuracy: 0.9836 - val_f1_m: 0.9604\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 203us/sample - loss: 0.0274 - accuracy: 0.9937 - f1_m: 0.9699 - val_loss: 0.3195 - val_accuracy: 0.9453 - val_f1_m: 1.0056\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.0166 - accuracy: 0.9956 - f1_m: 0.9666 - val_loss: 0.3234 - val_accuracy: 0.9450 - val_f1_m: 1.0074\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 142us/sample - loss: 0.0102 - accuracy: 0.9974 - f1_m: 0.9630 - val_loss: 0.3306 - val_accuracy: 0.9435 - val_f1_m: 1.0113\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 142us/sample - loss: 0.0096 - accuracy: 0.9981 - f1_m: 0.9612 - val_loss: 0.3207 - val_accuracy: 0.9456 - val_f1_m: 1.0059\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 142us/sample - loss: 0.0059 - accuracy: 0.9991 - f1_m: 0.9580 - val_loss: 0.3249 - val_accuracy: 0.9473 - val_f1_m: 1.0046\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 147us/sample - loss: 0.0053 - accuracy: 0.9990 - f1_m: 0.9565 - val_loss: 0.3219 - val_accuracy: 0.9429 - val_f1_m: 1.0018\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0041 - accuracy: 0.9995 - f1_m: 0.9535 - val_loss: 0.3387 - val_accuracy: 0.9428 - val_f1_m: 1.0006\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 144us/sample - loss: 0.0100 - accuracy: 0.9970 - f1_m: 0.9592 - val_loss: 0.3479 - val_accuracy: 0.9423 - val_f1_m: 1.0067\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0114 - accuracy: 0.9969 - f1_m: 0.9637 - val_loss: 0.3287 - val_accuracy: 0.9478 - val_f1_m: 1.0031\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 143us/sample - loss: 0.0048 - accuracy: 0.9996 - f1_m: 0.9547 - val_loss: 0.3339 - val_accuracy: 0.9458 - val_f1_m: 1.0032\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 222us/sample - loss: 0.0156 - accuracy: 0.9955 - f1_m: 0.9559 - val_loss: 0.2024 - val_accuracy: 0.9693 - val_f1_m: 0.9736\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 153us/sample - loss: 0.0082 - accuracy: 0.9981 - f1_m: 0.9526 - val_loss: 0.2081 - val_accuracy: 0.9688 - val_f1_m: 0.9771\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 154us/sample - loss: 0.0061 - accuracy: 0.9983 - f1_m: 0.9506 - val_loss: 0.2266 - val_accuracy: 0.9658 - val_f1_m: 0.9821\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 158us/sample - loss: 0.0043 - accuracy: 0.9987 - f1_m: 0.9525 - val_loss: 0.2024 - val_accuracy: 0.9714 - val_f1_m: 0.9723\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 155us/sample - loss: 8.8996e-04 - accuracy: 0.9999 - f1_m: 0.9472 - val_loss: 0.1981 - val_accuracy: 0.9716 - val_f1_m: 0.9729\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 153us/sample - loss: 4.1334e-04 - accuracy: 1.0000 - f1_m: 0.9457 - val_loss: 0.2002 - val_accuracy: 0.9717 - val_f1_m: 0.9731\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 153us/sample - loss: 2.3869e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.2037 - val_accuracy: 0.9711 - val_f1_m: 0.9729\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 158us/sample - loss: 1.8355e-04 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.2045 - val_accuracy: 0.9711 - val_f1_m: 0.9712\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 154us/sample - loss: 1.5821e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.2043 - val_accuracy: 0.9709 - val_f1_m: 0.9715\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 155us/sample - loss: 1.3045e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.2054 - val_accuracy: 0.9710 - val_f1_m: 0.9718\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 272us/sample - loss: 0.0175 - accuracy: 0.9969 - f1_m: 0.9503 - val_loss: 0.1400 - val_accuracy: 0.9729 - val_f1_m: 0.9734\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 195us/sample - loss: 0.0057 - accuracy: 0.9987 - f1_m: 0.9498 - val_loss: 0.1101 - val_accuracy: 0.9782 - val_f1_m: 0.9731\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 193us/sample - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9486 - val_loss: 0.1178 - val_accuracy: 0.9781 - val_f1_m: 0.9704\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 197us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9478 - val_loss: 0.1544 - val_accuracy: 0.9733 - val_f1_m: 0.9735\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 195us/sample - loss: 0.0208 - accuracy: 0.9935 - f1_m: 0.9581 - val_loss: 0.1010 - val_accuracy: 0.9776 - val_f1_m: 0.9824\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 184us/sample - loss: 0.0037 - accuracy: 0.9992 - f1_m: 0.9509 - val_loss: 0.1330 - val_accuracy: 0.9741 - val_f1_m: 0.9742\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 189us/sample - loss: 4.8508e-04 - accuracy: 1.0000 - f1_m: 0.9465 - val_loss: 0.1267 - val_accuracy: 0.9783 - val_f1_m: 0.9724\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 191us/sample - loss: 1.1001e-04 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.1302 - val_accuracy: 0.9787 - val_f1_m: 0.9703\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 194us/sample - loss: 7.1818e-05 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.1333 - val_accuracy: 0.9786 - val_f1_m: 0.9704\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2s 191us/sample - loss: 5.3658e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1363 - val_accuracy: 0.9783 - val_f1_m: 0.9694\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 3s 352us/sample - loss: 0.0167 - accuracy: 0.9960 - f1_m: 0.9550 - val_loss: 0.1545 - val_accuracy: 0.9729 - val_f1_m: 0.9736\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 234us/sample - loss: 0.0147 - accuracy: 0.9959 - f1_m: 0.9544 - val_loss: 0.1900 - val_accuracy: 0.9656 - val_f1_m: 0.9808\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 0.0111 - accuracy: 0.9966 - f1_m: 0.9550 - val_loss: 0.1697 - val_accuracy: 0.9693 - val_f1_m: 0.9764\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 236us/sample - loss: 0.0158 - accuracy: 0.9956 - f1_m: 0.9581 - val_loss: 0.1591 - val_accuracy: 0.9710 - val_f1_m: 0.9773\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 241us/sample - loss: 0.0143 - accuracy: 0.9945 - f1_m: 0.9578 - val_loss: 0.1270 - val_accuracy: 0.9755 - val_f1_m: 0.9797\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 238us/sample - loss: 0.0087 - accuracy: 0.9974 - f1_m: 0.9521 - val_loss: 0.1466 - val_accuracy: 0.9747 - val_f1_m: 0.9684\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 230us/sample - loss: 0.0032 - accuracy: 0.9987 - f1_m: 0.9483 - val_loss: 0.1977 - val_accuracy: 0.9695 - val_f1_m: 0.9684\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0126 - accuracy: 0.9955 - f1_m: 0.9557 - val_loss: 0.1445 - val_accuracy: 0.9735 - val_f1_m: 0.9753\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.0024 - accuracy: 0.9994 - f1_m: 0.9495 - val_loss: 0.1614 - val_accuracy: 0.9746 - val_f1_m: 0.9679\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2s 239us/sample - loss: 0.0022 - accuracy: 0.9991 - f1_m: 0.9482 - val_loss: 0.1548 - val_accuracy: 0.9764 - val_f1_m: 0.9673\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 206us/sample - loss: 0.0212 - accuracy: 0.9950 - f1_m: 0.9554 - val_loss: 0.2948 - val_accuracy: 0.9512 - val_f1_m: 0.9834\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 0.0106 - accuracy: 0.9970 - f1_m: 0.9548 - val_loss: 0.2857 - val_accuracy: 0.9533 - val_f1_m: 0.9882\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 145us/sample - loss: 0.0032 - accuracy: 0.9990 - f1_m: 0.9505 - val_loss: 0.2783 - val_accuracy: 0.9539 - val_f1_m: 0.9880\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.0013 - accuracy: 1.0000 - f1_m: 0.9484 - val_loss: 0.2604 - val_accuracy: 0.9578 - val_f1_m: 0.9835\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 154us/sample - loss: 3.5166e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.2582 - val_accuracy: 0.9584 - val_f1_m: 0.9835\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 155us/sample - loss: 2.4460e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.2623 - val_accuracy: 0.9598 - val_f1_m: 0.9825\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 154us/sample - loss: 2.0108e-04 - accuracy: 1.0000 - f1_m: 0.9451 - val_loss: 0.2650 - val_accuracy: 0.9601 - val_f1_m: 0.9824\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 145us/sample - loss: 1.7355e-04 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.2675 - val_accuracy: 0.9601 - val_f1_m: 0.9806\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 167us/sample - loss: 1.5600e-04 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.2713 - val_accuracy: 0.9589 - val_f1_m: 0.9808\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 146us/sample - loss: 1.3477e-04 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.2736 - val_accuracy: 0.9600 - val_f1_m: 0.9799\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 229us/sample - loss: 0.0164 - accuracy: 0.9973 - f1_m: 0.9523 - val_loss: 0.1422 - val_accuracy: 0.9777 - val_f1_m: 0.9689\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s 169us/sample - loss: 0.0039 - accuracy: 0.9990 - f1_m: 0.9494 - val_loss: 0.1170 - val_accuracy: 0.9786 - val_f1_m: 0.9656\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s 164us/sample - loss: 2.9764e-04 - accuracy: 0.9999 - f1_m: 0.9455 - val_loss: 0.1229 - val_accuracy: 0.9796 - val_f1_m: 0.9649\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s 168us/sample - loss: 1.1038e-04 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.1216 - val_accuracy: 0.9799 - val_f1_m: 0.9654\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1s 161us/sample - loss: 4.4918e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1222 - val_accuracy: 0.9799 - val_f1_m: 0.9643\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s 162us/sample - loss: 3.1991e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1240 - val_accuracy: 0.9799 - val_f1_m: 0.9640\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s 166us/sample - loss: 2.5530e-05 - accuracy: 1.0000 - f1_m: 0.9451 - val_loss: 0.1256 - val_accuracy: 0.9794 - val_f1_m: 0.9634\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s 165us/sample - loss: 2.0905e-05 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.1272 - val_accuracy: 0.9794 - val_f1_m: 0.9638\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1s 159us/sample - loss: 1.7428e-05 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.1285 - val_accuracy: 0.9795 - val_f1_m: 0.9638\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s 160us/sample - loss: 1.4706e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1300 - val_accuracy: 0.9794 - val_f1_m: 0.9626\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 4s 467us/sample - loss: 0.0190 - accuracy: 0.9962 - f1_m: 0.9508 - val_loss: 0.1440 - val_accuracy: 0.9746 - val_f1_m: 0.9794\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 197us/sample - loss: 0.0053 - accuracy: 0.9984 - f1_m: 0.9509 - val_loss: 0.1179 - val_accuracy: 0.9805 - val_f1_m: 0.9688\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 200us/sample - loss: 4.4558e-04 - accuracy: 0.9999 - f1_m: 0.9458 - val_loss: 0.1141 - val_accuracy: 0.9815 - val_f1_m: 0.9670\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 198us/sample - loss: 3.3988e-05 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.1171 - val_accuracy: 0.9817 - val_f1_m: 0.9661\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 201us/sample - loss: 2.1880e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1197 - val_accuracy: 0.9817 - val_f1_m: 0.9649\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 194us/sample - loss: 1.5546e-05 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1222 - val_accuracy: 0.9819 - val_f1_m: 0.9646\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 2s 204us/sample - loss: 1.1682e-05 - accuracy: 1.0000 - f1_m: 0.9451 - val_loss: 0.1242 - val_accuracy: 0.9819 - val_f1_m: 0.9643\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 199us/sample - loss: 9.0368e-06 - accuracy: 1.0000 - f1_m: 0.9454 - val_loss: 0.1264 - val_accuracy: 0.9819 - val_f1_m: 0.9634\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 200us/sample - loss: 7.1761e-06 - accuracy: 1.0000 - f1_m: 0.9452 - val_loss: 0.1283 - val_accuracy: 0.9819 - val_f1_m: 0.9636\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2s 201us/sample - loss: 5.7994e-06 - accuracy: 1.0000 - f1_m: 0.9453 - val_loss: 0.1300 - val_accuracy: 0.9819 - val_f1_m: 0.9621\n",
      "Train on 8000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 3s 374us/sample - loss: 0.0168 - accuracy: 0.9967 - f1_m: 0.9523 - val_loss: 0.1415 - val_accuracy: 0.9761 - val_f1_m: 0.9682\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.0095 - accuracy: 0.9974 - f1_m: 0.9503 - val_loss: 0.1028 - val_accuracy: 0.9807 - val_f1_m: 0.9687\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.0062 - accuracy: 0.9979 - f1_m: 0.9501 - val_loss: 0.1398 - val_accuracy: 0.9782 - val_f1_m: 0.9673\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.0065 - accuracy: 0.9986 - f1_m: 0.9493 - val_loss: 0.1300 - val_accuracy: 0.9770 - val_f1_m: 0.9737\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s 253us/sample - loss: 0.0090 - accuracy: 0.9970 - f1_m: 0.9518 - val_loss: 0.1173 - val_accuracy: 0.9790 - val_f1_m: 0.9672\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 0.0151 - accuracy: 0.9956 - f1_m: 0.9526 - val_loss: 0.1271 - val_accuracy: 0.9758 - val_f1_m: 0.9743\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 0.0071 - accuracy: 0.9984 - f1_m: 0.9504 - val_loss: 0.1323 - val_accuracy: 0.9765 - val_f1_m: 0.9751\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.0100 - accuracy: 0.9975 - f1_m: 0.9513 - val_loss: 0.1074 - val_accuracy: 0.9793 - val_f1_m: 0.9794\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s 262us/sample - loss: 0.0023 - accuracy: 0.9992 - f1_m: 0.9478 - val_loss: 0.0983 - val_accuracy: 0.9821 - val_f1_m: 0.9675\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2s 253us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9470 - val_loss: 0.1111 - val_accuracy: 0.9830 - val_f1_m: 0.9674\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 207us/sample - loss: 0.0360 - accuracy: 0.9948 - f1_m: 0.9642 - val_loss: 0.3395 - val_accuracy: 0.9447 - val_f1_m: 1.0049\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 150us/sample - loss: 0.0274 - accuracy: 0.9952 - f1_m: 0.9648 - val_loss: 0.3247 - val_accuracy: 0.9441 - val_f1_m: 1.0145\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0226 - accuracy: 0.9942 - f1_m: 0.9685 - val_loss: 0.3002 - val_accuracy: 0.9491 - val_f1_m: 1.0028\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 147us/sample - loss: 0.0139 - accuracy: 0.9974 - f1_m: 0.9617 - val_loss: 0.2987 - val_accuracy: 0.9478 - val_f1_m: 1.0015\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0094 - accuracy: 0.9987 - f1_m: 0.9581 - val_loss: 0.3003 - val_accuracy: 0.9485 - val_f1_m: 1.0033\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 149us/sample - loss: 0.0060 - accuracy: 0.9994 - f1_m: 0.9551 - val_loss: 0.2926 - val_accuracy: 0.9520 - val_f1_m: 1.0045\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0048 - accuracy: 0.9994 - f1_m: 0.9542 - val_loss: 0.3026 - val_accuracy: 0.9469 - val_f1_m: 1.0012\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 147us/sample - loss: 0.0066 - accuracy: 0.9987 - f1_m: 0.9583 - val_loss: 0.3130 - val_accuracy: 0.9476 - val_f1_m: 1.0035\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 147us/sample - loss: 0.0137 - accuracy: 0.9958 - f1_m: 0.9606 - val_loss: 0.3409 - val_accuracy: 0.9485 - val_f1_m: 1.0081\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 151us/sample - loss: 0.0051 - accuracy: 0.9994 - f1_m: 0.9587 - val_loss: 0.3053 - val_accuracy: 0.9485 - val_f1_m: 1.0029\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 224us/sample - loss: 0.0213 - accuracy: 0.9954 - f1_m: 0.9545 - val_loss: 0.2082 - val_accuracy: 0.9677 - val_f1_m: 0.9770\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 157us/sample - loss: 0.0103 - accuracy: 0.9971 - f1_m: 0.9524 - val_loss: 0.2139 - val_accuracy: 0.9687 - val_f1_m: 0.9754\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 158us/sample - loss: 0.0063 - accuracy: 0.9980 - f1_m: 0.9535 - val_loss: 0.2151 - val_accuracy: 0.9689 - val_f1_m: 0.9737\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 160us/sample - loss: 0.0045 - accuracy: 0.9985 - f1_m: 0.9529 - val_loss: 0.1921 - val_accuracy: 0.9700 - val_f1_m: 0.9736\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 158us/sample - loss: 0.0137 - accuracy: 0.9953 - f1_m: 0.9599 - val_loss: 0.2163 - val_accuracy: 0.9685 - val_f1_m: 0.9762\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 157us/sample - loss: 0.0068 - accuracy: 0.9975 - f1_m: 0.9527 - val_loss: 0.2206 - val_accuracy: 0.9643 - val_f1_m: 0.9770\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 162us/sample - loss: 0.0019 - accuracy: 0.9996 - f1_m: 0.9508 - val_loss: 0.1815 - val_accuracy: 0.9712 - val_f1_m: 0.9721\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 158us/sample - loss: 6.8271e-04 - accuracy: 0.9998 - f1_m: 0.9473 - val_loss: 0.1873 - val_accuracy: 0.9718 - val_f1_m: 0.9727\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 158us/sample - loss: 2.4335e-04 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1858 - val_accuracy: 0.9721 - val_f1_m: 0.9723\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 161us/sample - loss: 1.6050e-04 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1851 - val_accuracy: 0.9727 - val_f1_m: 0.9707\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 267us/sample - loss: 0.0109 - accuracy: 0.9968 - f1_m: 0.9512 - val_loss: 0.1401 - val_accuracy: 0.9734 - val_f1_m: 0.9751\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 190us/sample - loss: 0.0091 - accuracy: 0.9974 - f1_m: 0.9529 - val_loss: 0.1524 - val_accuracy: 0.9713 - val_f1_m: 0.9778\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 185us/sample - loss: 0.0034 - accuracy: 0.9985 - f1_m: 0.9499 - val_loss: 0.1096 - val_accuracy: 0.9790 - val_f1_m: 0.9699\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 190us/sample - loss: 0.0069 - accuracy: 0.9976 - f1_m: 0.9519 - val_loss: 0.1582 - val_accuracy: 0.9711 - val_f1_m: 0.9775\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 188us/sample - loss: 0.0153 - accuracy: 0.9948 - f1_m: 0.9564 - val_loss: 0.0976 - val_accuracy: 0.9787 - val_f1_m: 0.9786\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 189us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_m: 0.9493 - val_loss: 0.1080 - val_accuracy: 0.9804 - val_f1_m: 0.9757\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 191us/sample - loss: 4.8155e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1086 - val_accuracy: 0.9793 - val_f1_m: 0.9703\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 186us/sample - loss: 1.0994e-04 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1090 - val_accuracy: 0.9804 - val_f1_m: 0.9678\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 190us/sample - loss: 6.7283e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1110 - val_accuracy: 0.9803 - val_f1_m: 0.9682\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 188us/sample - loss: 5.1190e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1132 - val_accuracy: 0.9805 - val_f1_m: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 3s 337us/sample - loss: 0.0149 - accuracy: 0.9964 - f1_m: 0.9548 - val_loss: 0.1786 - val_accuracy: 0.9685 - val_f1_m: 0.9732\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 235us/sample - loss: 0.0137 - accuracy: 0.9955 - f1_m: 0.9553 - val_loss: 0.2025 - val_accuracy: 0.9655 - val_f1_m: 0.9839\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 235us/sample - loss: 0.0111 - accuracy: 0.9973 - f1_m: 0.9536 - val_loss: 0.1830 - val_accuracy: 0.9720 - val_f1_m: 0.9677\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 234us/sample - loss: 0.0071 - accuracy: 0.9980 - f1_m: 0.9516 - val_loss: 0.1577 - val_accuracy: 0.9758 - val_f1_m: 0.9671\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 236us/sample - loss: 0.0098 - accuracy: 0.9978 - f1_m: 0.9508 - val_loss: 0.1460 - val_accuracy: 0.9707 - val_f1_m: 0.9769\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 236us/sample - loss: 0.0226 - accuracy: 0.9928 - f1_m: 0.9617 - val_loss: 0.1264 - val_accuracy: 0.9746 - val_f1_m: 0.9759\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 235us/sample - loss: 0.0014 - accuracy: 0.9998 - f1_m: 0.9495 - val_loss: 0.1608 - val_accuracy: 0.9755 - val_f1_m: 0.9714\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 255us/sample - loss: 0.0014 - accuracy: 0.9998 - f1_m: 0.9478 - val_loss: 0.1484 - val_accuracy: 0.9764 - val_f1_m: 0.9697\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 245us/sample - loss: 3.4471e-04 - accuracy: 0.9999 - f1_m: 0.9467 - val_loss: 0.1625 - val_accuracy: 0.9770 - val_f1_m: 0.9662\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 244us/sample - loss: 5.0117e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1669 - val_accuracy: 0.9769 - val_f1_m: 0.9634\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 210us/sample - loss: 0.0218 - accuracy: 0.9962 - f1_m: 0.9561 - val_loss: 0.2646 - val_accuracy: 0.9563 - val_f1_m: 0.9908\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 155us/sample - loss: 0.0135 - accuracy: 0.9971 - f1_m: 0.9545 - val_loss: 0.2543 - val_accuracy: 0.9549 - val_f1_m: 0.9917\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 154us/sample - loss: 0.0053 - accuracy: 0.9989 - f1_m: 0.9505 - val_loss: 0.2461 - val_accuracy: 0.9588 - val_f1_m: 0.9912\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 154us/sample - loss: 0.0027 - accuracy: 0.9996 - f1_m: 0.9489 - val_loss: 0.2466 - val_accuracy: 0.9597 - val_f1_m: 0.9846\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 148us/sample - loss: 0.0032 - accuracy: 0.9992 - f1_m: 0.9485 - val_loss: 0.2728 - val_accuracy: 0.9568 - val_f1_m: 0.9866\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0053 - accuracy: 0.9985 - f1_m: 0.9522 - val_loss: 0.2499 - val_accuracy: 0.9599 - val_f1_m: 0.9871\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 154us/sample - loss: 0.0134 - accuracy: 0.9956 - f1_m: 0.9563 - val_loss: 0.2781 - val_accuracy: 0.9537 - val_f1_m: 0.9872\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0042 - accuracy: 0.9986 - f1_m: 0.9531 - val_loss: 0.2448 - val_accuracy: 0.9577 - val_f1_m: 0.9880\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 146us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9474 - val_loss: 0.2466 - val_accuracy: 0.9593 - val_f1_m: 0.9846\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 148us/sample - loss: 2.6792e-04 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.2426 - val_accuracy: 0.9602 - val_f1_m: 0.9841\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 238us/sample - loss: 0.0140 - accuracy: 0.9966 - f1_m: 0.9514 - val_loss: 0.1358 - val_accuracy: 0.9764 - val_f1_m: 0.9739\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 1s 171us/sample - loss: 0.0084 - accuracy: 0.9976 - f1_m: 0.9516 - val_loss: 0.1249 - val_accuracy: 0.9735 - val_f1_m: 0.9831\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 1s 164us/sample - loss: 0.0038 - accuracy: 0.9987 - f1_m: 0.9495 - val_loss: 0.1086 - val_accuracy: 0.9795 - val_f1_m: 0.9694\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 1s 170us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9503 - val_loss: 0.1251 - val_accuracy: 0.9770 - val_f1_m: 0.9664\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 1s 166us/sample - loss: 9.2427e-04 - accuracy: 0.9996 - f1_m: 0.9471 - val_loss: 0.1133 - val_accuracy: 0.9805 - val_f1_m: 0.9639\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 1s 172us/sample - loss: 9.6359e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1136 - val_accuracy: 0.9810 - val_f1_m: 0.9638\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 1s 166us/sample - loss: 4.4301e-05 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.1137 - val_accuracy: 0.9809 - val_f1_m: 0.9626\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 1s 163us/sample - loss: 3.3430e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1146 - val_accuracy: 0.9808 - val_f1_m: 0.9629\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 1s 172us/sample - loss: 2.7450e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1158 - val_accuracy: 0.9807 - val_f1_m: 0.9625\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 1s 164us/sample - loss: 2.2697e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1171 - val_accuracy: 0.9810 - val_f1_m: 0.9627\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 2s 293us/sample - loss: 0.0106 - accuracy: 0.9969 - f1_m: 0.9501 - val_loss: 0.1469 - val_accuracy: 0.9757 - val_f1_m: 0.9673\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 208us/sample - loss: 0.0042 - accuracy: 0.9988 - f1_m: 0.9499 - val_loss: 0.1153 - val_accuracy: 0.9802 - val_f1_m: 0.9674\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 206us/sample - loss: 1.8574e-04 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1172 - val_accuracy: 0.9824 - val_f1_m: 0.9629\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 203us/sample - loss: 2.5223e-05 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1197 - val_accuracy: 0.9824 - val_f1_m: 0.9621\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 204us/sample - loss: 1.3247e-05 - accuracy: 1.0000 - f1_m: 0.9460 - val_loss: 0.1217 - val_accuracy: 0.9827 - val_f1_m: 0.9627\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 206us/sample - loss: 9.7464e-06 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.1234 - val_accuracy: 0.9824 - val_f1_m: 0.9630\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 200us/sample - loss: 7.4799e-06 - accuracy: 1.0000 - f1_m: 0.9461 - val_loss: 0.1254 - val_accuracy: 0.9823 - val_f1_m: 0.9628\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 204us/sample - loss: 5.8749e-06 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1271 - val_accuracy: 0.9823 - val_f1_m: 0.9622\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 209us/sample - loss: 4.7166e-06 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1289 - val_accuracy: 0.9823 - val_f1_m: 0.9618\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 202us/sample - loss: 3.8213e-06 - accuracy: 1.0000 - f1_m: 0.9462 - val_loss: 0.1306 - val_accuracy: 0.9823 - val_f1_m: 0.9615\n",
      "Train on 8500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 3s 359us/sample - loss: 0.0135 - accuracy: 0.9961 - f1_m: 0.9527 - val_loss: 0.1236 - val_accuracy: 0.9791 - val_f1_m: 0.9698\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 2s 256us/sample - loss: 0.0096 - accuracy: 0.9974 - f1_m: 0.9502 - val_loss: 0.1176 - val_accuracy: 0.9761 - val_f1_m: 0.9771\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 2s 263us/sample - loss: 0.0069 - accuracy: 0.9979 - f1_m: 0.9511 - val_loss: 0.1424 - val_accuracy: 0.9770 - val_f1_m: 0.9694\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 2s 252us/sample - loss: 0.0090 - accuracy: 0.9975 - f1_m: 0.9519 - val_loss: 0.1324 - val_accuracy: 0.9784 - val_f1_m: 0.9662\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 2s 258us/sample - loss: 0.0104 - accuracy: 0.9968 - f1_m: 0.9535 - val_loss: 0.1267 - val_accuracy: 0.9765 - val_f1_m: 0.9697\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 2s 255us/sample - loss: 0.0056 - accuracy: 0.9985 - f1_m: 0.9494 - val_loss: 0.0985 - val_accuracy: 0.9825 - val_f1_m: 0.9661\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 2s 251us/sample - loss: 0.0050 - accuracy: 0.9979 - f1_m: 0.9516 - val_loss: 0.1175 - val_accuracy: 0.9782 - val_f1_m: 0.9689\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 2s 259us/sample - loss: 0.0129 - accuracy: 0.9969 - f1_m: 0.9533 - val_loss: 0.1413 - val_accuracy: 0.9745 - val_f1_m: 0.9727\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 2s 259us/sample - loss: 0.0040 - accuracy: 0.9985 - f1_m: 0.9508 - val_loss: 0.1146 - val_accuracy: 0.9810 - val_f1_m: 0.9667\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 2s 258us/sample - loss: 9.3329e-04 - accuracy: 0.9996 - f1_m: 0.9468 - val_loss: 0.1329 - val_accuracy: 0.9792 - val_f1_m: 0.9664\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 195us/sample - loss: 0.0226 - accuracy: 0.9940 - f1_m: 0.9663 - val_loss: 0.3166 - val_accuracy: 0.9501 - val_f1_m: 1.0030\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 145us/sample - loss: 0.0153 - accuracy: 0.9963 - f1_m: 0.9644 - val_loss: 0.2982 - val_accuracy: 0.9539 - val_f1_m: 0.9976\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 148us/sample - loss: 0.0068 - accuracy: 0.9982 - f1_m: 0.9597 - val_loss: 0.3202 - val_accuracy: 0.9498 - val_f1_m: 0.9937\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 149us/sample - loss: 0.0050 - accuracy: 0.9992 - f1_m: 0.9570 - val_loss: 0.3234 - val_accuracy: 0.9486 - val_f1_m: 0.9955\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 146us/sample - loss: 0.0074 - accuracy: 0.9979 - f1_m: 0.9609 - val_loss: 0.3159 - val_accuracy: 0.9528 - val_f1_m: 0.9943\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 141us/sample - loss: 0.0047 - accuracy: 0.9991 - f1_m: 0.9562 - val_loss: 0.3142 - val_accuracy: 0.9506 - val_f1_m: 0.9926\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 143us/sample - loss: 0.0036 - accuracy: 0.9996 - f1_m: 0.9552 - val_loss: 0.2986 - val_accuracy: 0.9545 - val_f1_m: 0.9897\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0025 - accuracy: 0.9999 - f1_m: 0.9527 - val_loss: 0.3070 - val_accuracy: 0.9517 - val_f1_m: 0.9942\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 143us/sample - loss: 0.0020 - accuracy: 0.9999 - f1_m: 0.9508 - val_loss: 0.3152 - val_accuracy: 0.9530 - val_f1_m: 0.9900\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 144us/sample - loss: 0.0071 - accuracy: 0.9982 - f1_m: 0.9564 - val_loss: 0.3674 - val_accuracy: 0.9458 - val_f1_m: 0.9992\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 215us/sample - loss: 0.0138 - accuracy: 0.9972 - f1_m: 0.9545 - val_loss: 0.2197 - val_accuracy: 0.9646 - val_f1_m: 0.9797\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 161us/sample - loss: 0.0120 - accuracy: 0.9961 - f1_m: 0.9558 - val_loss: 0.2216 - val_accuracy: 0.9662 - val_f1_m: 0.9738\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 152us/sample - loss: 0.0045 - accuracy: 0.9992 - f1_m: 0.9533 - val_loss: 0.1833 - val_accuracy: 0.9709 - val_f1_m: 0.9759\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 152us/sample - loss: 0.0048 - accuracy: 0.9981 - f1_m: 0.9534 - val_loss: 0.2072 - val_accuracy: 0.9668 - val_f1_m: 0.9736\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 155us/sample - loss: 0.0114 - accuracy: 0.9964 - f1_m: 0.9578 - val_loss: 0.2059 - val_accuracy: 0.9672 - val_f1_m: 0.9706\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0103 - accuracy: 0.9961 - f1_m: 0.9562 - val_loss: 0.1922 - val_accuracy: 0.9697 - val_f1_m: 0.9722\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 151us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9507 - val_loss: 0.1967 - val_accuracy: 0.9688 - val_f1_m: 0.9735\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 155us/sample - loss: 6.1717e-04 - accuracy: 0.9999 - f1_m: 0.9482 - val_loss: 0.1871 - val_accuracy: 0.9713 - val_f1_m: 0.9707\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 153us/sample - loss: 1.7630e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1850 - val_accuracy: 0.9716 - val_f1_m: 0.9689\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 158us/sample - loss: 1.4016e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1863 - val_accuracy: 0.9721 - val_f1_m: 0.9699\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 4s 441us/sample - loss: 0.0107 - accuracy: 0.9969 - f1_m: 0.9539 - val_loss: 0.1258 - val_accuracy: 0.9758 - val_f1_m: 0.9709\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 187us/sample - loss: 0.0016 - accuracy: 0.9997 - f1_m: 0.9505 - val_loss: 0.1113 - val_accuracy: 0.9794 - val_f1_m: 0.9675\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 190us/sample - loss: 0.0168 - accuracy: 0.9952 - f1_m: 0.9565 - val_loss: 0.1313 - val_accuracy: 0.9737 - val_f1_m: 0.9751\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 191us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9521 - val_loss: 0.1183 - val_accuracy: 0.9790 - val_f1_m: 0.9671\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 197us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9497 - val_loss: 0.1239 - val_accuracy: 0.9802 - val_f1_m: 0.9635\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 189us/sample - loss: 5.0008e-04 - accuracy: 0.9999 - f1_m: 0.9484 - val_loss: 0.1454 - val_accuracy: 0.9780 - val_f1_m: 0.9640\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 196us/sample - loss: 0.0177 - accuracy: 0.9943 - f1_m: 0.9540 - val_loss: 0.1554 - val_accuracy: 0.9701 - val_f1_m: 0.9859\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 188us/sample - loss: 0.0166 - accuracy: 0.9950 - f1_m: 0.9577 - val_loss: 0.1035 - val_accuracy: 0.9808 - val_f1_m: 0.9705\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 185us/sample - loss: 8.1555e-04 - accuracy: 1.0000 - f1_m: 0.9497 - val_loss: 0.1098 - val_accuracy: 0.9810 - val_f1_m: 0.9666\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 198us/sample - loss: 1.8088e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1121 - val_accuracy: 0.9815 - val_f1_m: 0.9645\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 340us/sample - loss: 0.0190 - accuracy: 0.9953 - f1_m: 0.9544 - val_loss: 0.1435 - val_accuracy: 0.9727 - val_f1_m: 0.9765\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 237us/sample - loss: 0.0076 - accuracy: 0.9978 - f1_m: 0.9531 - val_loss: 0.1539 - val_accuracy: 0.9753 - val_f1_m: 0.9700\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 240us/sample - loss: 0.0042 - accuracy: 0.9982 - f1_m: 0.9512 - val_loss: 0.1676 - val_accuracy: 0.9738 - val_f1_m: 0.9698\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 235us/sample - loss: 0.0145 - accuracy: 0.9959 - f1_m: 0.9553 - val_loss: 0.1698 - val_accuracy: 0.9728 - val_f1_m: 0.9703\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 239us/sample - loss: 0.0103 - accuracy: 0.9969 - f1_m: 0.9545 - val_loss: 0.1381 - val_accuracy: 0.9775 - val_f1_m: 0.9704\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 236us/sample - loss: 0.0012 - accuracy: 0.9994 - f1_m: 0.9500 - val_loss: 0.1479 - val_accuracy: 0.9798 - val_f1_m: 0.9642\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 241us/sample - loss: 1.5996e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1544 - val_accuracy: 0.9793 - val_f1_m: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 238us/sample - loss: 3.8607e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1592 - val_accuracy: 0.9798 - val_f1_m: 0.9627\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 246us/sample - loss: 2.3559e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1615 - val_accuracy: 0.9795 - val_f1_m: 0.9629\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 245us/sample - loss: 1.7508e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1639 - val_accuracy: 0.9795 - val_f1_m: 0.9625\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 202us/sample - loss: 0.0192 - accuracy: 0.9950 - f1_m: 0.9584 - val_loss: 0.2365 - val_accuracy: 0.9586 - val_f1_m: 0.9889\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 144us/sample - loss: 0.0061 - accuracy: 0.9983 - f1_m: 0.9539 - val_loss: 0.2683 - val_accuracy: 0.9575 - val_f1_m: 0.9845\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 140us/sample - loss: 0.0017 - accuracy: 0.9998 - f1_m: 0.9507 - val_loss: 0.2374 - val_accuracy: 0.9634 - val_f1_m: 0.9821\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 140us/sample - loss: 5.0775e-04 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.2344 - val_accuracy: 0.9631 - val_f1_m: 0.9818\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 140us/sample - loss: 3.0473e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2349 - val_accuracy: 0.9637 - val_f1_m: 0.9782\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 140us/sample - loss: 1.8043e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2383 - val_accuracy: 0.9639 - val_f1_m: 0.9792\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 139us/sample - loss: 1.5033e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2400 - val_accuracy: 0.9641 - val_f1_m: 0.9767\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 140us/sample - loss: 1.2775e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2426 - val_accuracy: 0.9641 - val_f1_m: 0.9764\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 140us/sample - loss: 1.0816e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2449 - val_accuracy: 0.9641 - val_f1_m: 0.9778\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 140us/sample - loss: 9.5245e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2459 - val_accuracy: 0.9642 - val_f1_m: 0.9763\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s 225us/sample - loss: 0.0109 - accuracy: 0.9966 - f1_m: 0.9524 - val_loss: 0.1273 - val_accuracy: 0.9736 - val_f1_m: 0.9710\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 172us/sample - loss: 0.0022 - accuracy: 0.9991 - f1_m: 0.9511 - val_loss: 0.1245 - val_accuracy: 0.9780 - val_f1_m: 0.9662\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 165us/sample - loss: 0.0011 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.1143 - val_accuracy: 0.9784 - val_f1_m: 0.9642\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 166us/sample - loss: 1.2413e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1170 - val_accuracy: 0.9789 - val_f1_m: 0.9635\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 163us/sample - loss: 2.6529e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1175 - val_accuracy: 0.9791 - val_f1_m: 0.9629\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 160us/sample - loss: 2.0515e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1182 - val_accuracy: 0.9792 - val_f1_m: 0.9636\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 165us/sample - loss: 1.7089e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1190 - val_accuracy: 0.9792 - val_f1_m: 0.9639\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 164us/sample - loss: 1.4636e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1196 - val_accuracy: 0.9792 - val_f1_m: 0.9638\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 166us/sample - loss: 1.2579e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1202 - val_accuracy: 0.9792 - val_f1_m: 0.9633\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 161us/sample - loss: 1.0880e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1211 - val_accuracy: 0.9794 - val_f1_m: 0.9631\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 280us/sample - loss: 0.0060 - accuracy: 0.9990 - f1_m: 0.9492 - val_loss: 0.1362 - val_accuracy: 0.9811 - val_f1_m: 0.9617\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 206us/sample - loss: 0.0135 - accuracy: 0.9963 - f1_m: 0.9530 - val_loss: 0.0853 - val_accuracy: 0.9819 - val_f1_m: 0.9701\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 202us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9491 - val_loss: 0.1058 - val_accuracy: 0.9829 - val_f1_m: 0.9684\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 203us/sample - loss: 8.6794e-04 - accuracy: 0.9996 - f1_m: 0.9491 - val_loss: 0.0839 - val_accuracy: 0.9856 - val_f1_m: 0.9636\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 197us/sample - loss: 8.6236e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.0884 - val_accuracy: 0.9851 - val_f1_m: 0.9619\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 200us/sample - loss: 1.9644e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.0901 - val_accuracy: 0.9858 - val_f1_m: 0.9612\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 203us/sample - loss: 8.9414e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.0916 - val_accuracy: 0.9860 - val_f1_m: 0.9606\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 203us/sample - loss: 6.5431e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.0930 - val_accuracy: 0.9855 - val_f1_m: 0.9602\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 199us/sample - loss: 5.2264e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.0943 - val_accuracy: 0.9855 - val_f1_m: 0.9599\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 205us/sample - loss: 4.2363e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.0955 - val_accuracy: 0.9856 - val_f1_m: 0.9599\n",
      "Train on 9000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 354us/sample - loss: 0.0118 - accuracy: 0.9973 - f1_m: 0.9519 - val_loss: 0.1366 - val_accuracy: 0.9793 - val_f1_m: 0.9664\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 258us/sample - loss: 0.0078 - accuracy: 0.9979 - f1_m: 0.9520 - val_loss: 0.1152 - val_accuracy: 0.9767 - val_f1_m: 0.9751\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 258us/sample - loss: 0.0044 - accuracy: 0.9983 - f1_m: 0.9520 - val_loss: 0.1201 - val_accuracy: 0.9811 - val_f1_m: 0.9608\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 254us/sample - loss: 0.0084 - accuracy: 0.9978 - f1_m: 0.9521 - val_loss: 0.1319 - val_accuracy: 0.9784 - val_f1_m: 0.9678\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 248us/sample - loss: 0.0041 - accuracy: 0.9989 - f1_m: 0.9502 - val_loss: 0.1572 - val_accuracy: 0.9772 - val_f1_m: 0.9658\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 247us/sample - loss: 0.0202 - accuracy: 0.9938 - f1_m: 0.9607 - val_loss: 0.1173 - val_accuracy: 0.9768 - val_f1_m: 0.9749\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 249us/sample - loss: 0.0058 - accuracy: 0.9980 - f1_m: 0.9517 - val_loss: 0.1185 - val_accuracy: 0.9788 - val_f1_m: 0.9675\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 251us/sample - loss: 0.0017 - accuracy: 0.9994 - f1_m: 0.9495 - val_loss: 0.1308 - val_accuracy: 0.9817 - val_f1_m: 0.9634\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 251us/sample - loss: 0.0030 - accuracy: 0.9991 - f1_m: 0.9498 - val_loss: 0.1817 - val_accuracy: 0.9735 - val_f1_m: 0.9719\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 250us/sample - loss: 0.0161 - accuracy: 0.9954 - f1_m: 0.9541 - val_loss: 0.1192 - val_accuracy: 0.9733 - val_f1_m: 0.9817\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 204us/sample - loss: 0.0266 - accuracy: 0.9942 - f1_m: 0.9624 - val_loss: 0.3187 - val_accuracy: 0.9523 - val_f1_m: 0.9898\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 159us/sample - loss: 0.0166 - accuracy: 0.9961 - f1_m: 0.9604 - val_loss: 0.3201 - val_accuracy: 0.9513 - val_f1_m: 0.9956\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 140us/sample - loss: 0.0098 - accuracy: 0.9975 - f1_m: 0.9583 - val_loss: 0.3145 - val_accuracy: 0.9523 - val_f1_m: 0.9904\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 0.0071 - accuracy: 0.9985 - f1_m: 0.9587 - val_loss: 0.2916 - val_accuracy: 0.9566 - val_f1_m: 0.9925\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 141us/sample - loss: 0.0046 - accuracy: 0.9993 - f1_m: 0.9558 - val_loss: 0.3016 - val_accuracy: 0.9552 - val_f1_m: 0.9896\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 0.0024 - accuracy: 0.9999 - f1_m: 0.9511 - val_loss: 0.3050 - val_accuracy: 0.9546 - val_f1_m: 0.9911\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 0.0086 - accuracy: 0.9979 - f1_m: 0.9573 - val_loss: 0.3229 - val_accuracy: 0.9517 - val_f1_m: 0.9972\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 142us/sample - loss: 0.0089 - accuracy: 0.9974 - f1_m: 0.9600 - val_loss: 0.3276 - val_accuracy: 0.9546 - val_f1_m: 0.9873\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 137us/sample - loss: 0.0123 - accuracy: 0.9961 - f1_m: 0.9641 - val_loss: 0.3319 - val_accuracy: 0.9523 - val_f1_m: 0.9922\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 0.0053 - accuracy: 0.9985 - f1_m: 0.9574 - val_loss: 0.3197 - val_accuracy: 0.9548 - val_f1_m: 0.9882\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 210us/sample - loss: 0.0173 - accuracy: 0.9952 - f1_m: 0.9545 - val_loss: 0.1940 - val_accuracy: 0.9677 - val_f1_m: 0.9750\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 157us/sample - loss: 0.0072 - accuracy: 0.9982 - f1_m: 0.9526 - val_loss: 0.1854 - val_accuracy: 0.9724 - val_f1_m: 0.9697\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 149us/sample - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9531 - val_loss: 0.1874 - val_accuracy: 0.9730 - val_f1_m: 0.9707\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 152us/sample - loss: 0.0010 - accuracy: 0.9999 - f1_m: 0.9499 - val_loss: 0.1797 - val_accuracy: 0.9731 - val_f1_m: 0.9685\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 150us/sample - loss: 2.2683e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1788 - val_accuracy: 0.9740 - val_f1_m: 0.9698\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 151us/sample - loss: 1.3492e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1791 - val_accuracy: 0.9738 - val_f1_m: 0.9685\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 150us/sample - loss: 1.0344e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1814 - val_accuracy: 0.9741 - val_f1_m: 0.9680\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 150us/sample - loss: 9.1542e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1830 - val_accuracy: 0.9742 - val_f1_m: 0.9684\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 153us/sample - loss: 8.0400e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1850 - val_accuracy: 0.9748 - val_f1_m: 0.9681\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 151us/sample - loss: 7.0852e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1876 - val_accuracy: 0.9738 - val_f1_m: 0.9669\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 256us/sample - loss: 0.0116 - accuracy: 0.9976 - f1_m: 0.9525 - val_loss: 0.1222 - val_accuracy: 0.9771 - val_f1_m: 0.9677\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 181us/sample - loss: 0.0038 - accuracy: 0.9983 - f1_m: 0.9523 - val_loss: 0.1412 - val_accuracy: 0.9780 - val_f1_m: 0.9698\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 179us/sample - loss: 0.0037 - accuracy: 0.9988 - f1_m: 0.9508 - val_loss: 0.1500 - val_accuracy: 0.9766 - val_f1_m: 0.9660\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 182us/sample - loss: 0.0117 - accuracy: 0.9964 - f1_m: 0.9543 - val_loss: 0.1094 - val_accuracy: 0.9772 - val_f1_m: 0.9688\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 183us/sample - loss: 0.0066 - accuracy: 0.9977 - f1_m: 0.9533 - val_loss: 0.1123 - val_accuracy: 0.9808 - val_f1_m: 0.9650\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 180us/sample - loss: 4.2419e-04 - accuracy: 1.0000 - f1_m: 0.9484 - val_loss: 0.1112 - val_accuracy: 0.9823 - val_f1_m: 0.9651\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 184us/sample - loss: 9.3413e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1141 - val_accuracy: 0.9823 - val_f1_m: 0.9651\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 183us/sample - loss: 4.6145e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1169 - val_accuracy: 0.9817 - val_f1_m: 0.9647\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 183us/sample - loss: 3.2969e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1192 - val_accuracy: 0.9820 - val_f1_m: 0.9638\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 200us/sample - loss: 2.5757e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1213 - val_accuracy: 0.9825 - val_f1_m: 0.9636\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 3s 320us/sample - loss: 0.0170 - accuracy: 0.9959 - f1_m: 0.9575 - val_loss: 0.1260 - val_accuracy: 0.9739 - val_f1_m: 0.9765\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0132 - accuracy: 0.9962 - f1_m: 0.9549 - val_loss: 0.1496 - val_accuracy: 0.9744 - val_f1_m: 0.9748\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 228us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9532 - val_loss: 0.1563 - val_accuracy: 0.9749 - val_f1_m: 0.9738\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0142 - accuracy: 0.9956 - f1_m: 0.9571 - val_loss: 0.1466 - val_accuracy: 0.9725 - val_f1_m: 0.9806\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0131 - accuracy: 0.9958 - f1_m: 0.9572 - val_loss: 0.1336 - val_accuracy: 0.9717 - val_f1_m: 0.9779\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 225us/sample - loss: 0.0073 - accuracy: 0.9975 - f1_m: 0.9548 - val_loss: 0.1456 - val_accuracy: 0.9752 - val_f1_m: 0.9670\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 229us/sample - loss: 0.0035 - accuracy: 0.9983 - f1_m: 0.9514 - val_loss: 0.1624 - val_accuracy: 0.9739 - val_f1_m: 0.9710\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0140 - accuracy: 0.9953 - f1_m: 0.9572 - val_loss: 0.1309 - val_accuracy: 0.9734 - val_f1_m: 0.9762\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 226us/sample - loss: 0.0121 - accuracy: 0.9961 - f1_m: 0.9542 - val_loss: 0.1480 - val_accuracy: 0.9735 - val_f1_m: 0.9745\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 225us/sample - loss: 0.0135 - accuracy: 0.9956 - f1_m: 0.9567 - val_loss: 0.1482 - val_accuracy: 0.9747 - val_f1_m: 0.9733\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 192us/sample - loss: 0.0182 - accuracy: 0.9969 - f1_m: 0.9544 - val_loss: 0.3129 - val_accuracy: 0.9428 - val_f1_m: 1.0031\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 0.0074 - accuracy: 0.9987 - f1_m: 0.9537 - val_loss: 0.2241 - val_accuracy: 0.9624 - val_f1_m: 0.9807\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 142us/sample - loss: 0.0022 - accuracy: 0.9993 - f1_m: 0.9505 - val_loss: 0.2229 - val_accuracy: 0.9621 - val_f1_m: 0.9850\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 7.4874e-04 - accuracy: 1.0000 - f1_m: 0.9491 - val_loss: 0.2316 - val_accuracy: 0.9624 - val_f1_m: 0.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 6.2070e-04 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.2287 - val_accuracy: 0.9642 - val_f1_m: 0.9794\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 1s 141us/sample - loss: 1.4934e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2303 - val_accuracy: 0.9642 - val_f1_m: 0.9774\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 1s 137us/sample - loss: 1.1711e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2350 - val_accuracy: 0.9643 - val_f1_m: 0.9773\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 1s 138us/sample - loss: 9.4805e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2362 - val_accuracy: 0.9639 - val_f1_m: 0.9774\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 1s 142us/sample - loss: 8.0260e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2395 - val_accuracy: 0.9646 - val_f1_m: 0.9767\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 1s 139us/sample - loss: 7.0448e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2405 - val_accuracy: 0.9648 - val_f1_m: 0.9757\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 2s 214us/sample - loss: 0.0147 - accuracy: 0.9972 - f1_m: 0.9527 - val_loss: 0.1060 - val_accuracy: 0.9791 - val_f1_m: 0.9680\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 160us/sample - loss: 0.0028 - accuracy: 0.9986 - f1_m: 0.9521 - val_loss: 0.1190 - val_accuracy: 0.9790 - val_f1_m: 0.9684\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 1s 157us/sample - loss: 0.0027 - accuracy: 0.9993 - f1_m: 0.9513 - val_loss: 0.1095 - val_accuracy: 0.9792 - val_f1_m: 0.9657\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 159us/sample - loss: 3.2096e-04 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1005 - val_accuracy: 0.9814 - val_f1_m: 0.9623\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 159us/sample - loss: 6.0186e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1000 - val_accuracy: 0.9818 - val_f1_m: 0.9607\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 168us/sample - loss: 2.9402e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1024 - val_accuracy: 0.9819 - val_f1_m: 0.9604\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 174us/sample - loss: 1.8274e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1040 - val_accuracy: 0.9820 - val_f1_m: 0.9605\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 166us/sample - loss: 1.5073e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1051 - val_accuracy: 0.9819 - val_f1_m: 0.9608\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 159us/sample - loss: 1.2635e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1063 - val_accuracy: 0.9818 - val_f1_m: 0.9605\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 161us/sample - loss: 1.0692e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1074 - val_accuracy: 0.9818 - val_f1_m: 0.9596\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 3s 275us/sample - loss: 0.0111 - accuracy: 0.9975 - f1_m: 0.9514 - val_loss: 0.0784 - val_accuracy: 0.9822 - val_f1_m: 0.9697\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 191us/sample - loss: 0.0038 - accuracy: 0.9987 - f1_m: 0.9507 - val_loss: 0.1304 - val_accuracy: 0.9770 - val_f1_m: 0.9633\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 195us/sample - loss: 0.0049 - accuracy: 0.9982 - f1_m: 0.9519 - val_loss: 0.1245 - val_accuracy: 0.9800 - val_f1_m: 0.9627\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 199us/sample - loss: 0.0046 - accuracy: 0.9988 - f1_m: 0.9501 - val_loss: 0.0955 - val_accuracy: 0.9832 - val_f1_m: 0.9602\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 202us/sample - loss: 0.0027 - accuracy: 0.9993 - f1_m: 0.9495 - val_loss: 0.1021 - val_accuracy: 0.9830 - val_f1_m: 0.9616\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 191us/sample - loss: 3.1743e-04 - accuracy: 0.9999 - f1_m: 0.9482 - val_loss: 0.1033 - val_accuracy: 0.9838 - val_f1_m: 0.9608\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 200us/sample - loss: 1.8163e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1058 - val_accuracy: 0.9840 - val_f1_m: 0.9604\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 195us/sample - loss: 7.3335e-06 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1064 - val_accuracy: 0.9839 - val_f1_m: 0.9602\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 197us/sample - loss: 5.4365e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1073 - val_accuracy: 0.9841 - val_f1_m: 0.9586\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 197us/sample - loss: 4.2819e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1082 - val_accuracy: 0.9841 - val_f1_m: 0.9584\n",
      "Train on 9500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 3s 345us/sample - loss: 0.0153 - accuracy: 0.9956 - f1_m: 0.9559 - val_loss: 0.1130 - val_accuracy: 0.9771 - val_f1_m: 0.9694\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 2s 252us/sample - loss: 0.0078 - accuracy: 0.9976 - f1_m: 0.9527 - val_loss: 0.0961 - val_accuracy: 0.9824 - val_f1_m: 0.9647\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 2s 260us/sample - loss: 0.0086 - accuracy: 0.9975 - f1_m: 0.9516 - val_loss: 0.1219 - val_accuracy: 0.9771 - val_f1_m: 0.9735\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 2s 249us/sample - loss: 0.0101 - accuracy: 0.9965 - f1_m: 0.9540 - val_loss: 0.1130 - val_accuracy: 0.9811 - val_f1_m: 0.9666\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 2s 250us/sample - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9495 - val_loss: 0.1460 - val_accuracy: 0.9810 - val_f1_m: 0.9614\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 2s 243us/sample - loss: 4.5715e-04 - accuracy: 0.9999 - f1_m: 0.9484 - val_loss: 0.1490 - val_accuracy: 0.9816 - val_f1_m: 0.9573\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 2s 242us/sample - loss: 0.0195 - accuracy: 0.9947 - f1_m: 0.9540 - val_loss: 0.0944 - val_accuracy: 0.9794 - val_f1_m: 0.9767\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 2s 251us/sample - loss: 0.0107 - accuracy: 0.9964 - f1_m: 0.9545 - val_loss: 0.1021 - val_accuracy: 0.9802 - val_f1_m: 0.9682\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 2s 246us/sample - loss: 0.0021 - accuracy: 0.9993 - f1_m: 0.9494 - val_loss: 0.1075 - val_accuracy: 0.9836 - val_f1_m: 0.9618\n",
      "Epoch 10/10\n",
      "9500/9500 [==============================] - 2s 244us/sample - loss: 0.0049 - accuracy: 0.9984 - f1_m: 0.9503 - val_loss: 0.1343 - val_accuracy: 0.9787 - val_f1_m: 0.9635\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 198us/sample - loss: 0.0183 - accuracy: 0.9963 - f1_m: 0.9590 - val_loss: 0.2984 - val_accuracy: 0.9555 - val_f1_m: 0.9888\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 136us/sample - loss: 0.0097 - accuracy: 0.9982 - f1_m: 0.9583 - val_loss: 0.3084 - val_accuracy: 0.9545 - val_f1_m: 0.9870\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 148us/sample - loss: 0.0118 - accuracy: 0.9964 - f1_m: 0.9597 - val_loss: 0.3280 - val_accuracy: 0.9493 - val_f1_m: 0.9930\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 135us/sample - loss: 0.0056 - accuracy: 0.9991 - f1_m: 0.9557 - val_loss: 0.3008 - val_accuracy: 0.9545 - val_f1_m: 0.9900\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 140us/sample - loss: 0.0062 - accuracy: 0.9984 - f1_m: 0.9546 - val_loss: 0.3153 - val_accuracy: 0.9528 - val_f1_m: 0.9917\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 141us/sample - loss: 0.0031 - accuracy: 0.9996 - f1_m: 0.9548 - val_loss: 0.2987 - val_accuracy: 0.9551 - val_f1_m: 0.9876\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 144us/sample - loss: 0.0017 - accuracy: 1.0000 - f1_m: 0.9506 - val_loss: 0.3017 - val_accuracy: 0.9557 - val_f1_m: 0.9893\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 0.0080 - accuracy: 0.9978 - f1_m: 0.9566 - val_loss: 0.3156 - val_accuracy: 0.9551 - val_f1_m: 0.9861\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 148us/sample - loss: 0.0079 - accuracy: 0.9974 - f1_m: 0.9579 - val_loss: 0.3254 - val_accuracy: 0.9505 - val_f1_m: 0.9912\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 137us/sample - loss: 0.0060 - accuracy: 0.9985 - f1_m: 0.9572 - val_loss: 0.3152 - val_accuracy: 0.9557 - val_f1_m: 0.9867\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.0124 - accuracy: 0.9976 - f1_m: 0.9540 - val_loss: 0.2112 - val_accuracy: 0.9695 - val_f1_m: 0.9750\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 149us/sample - loss: 0.0080 - accuracy: 0.9985 - f1_m: 0.9519 - val_loss: 0.2307 - val_accuracy: 0.9648 - val_f1_m: 0.9742\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 147us/sample - loss: 0.0099 - accuracy: 0.9966 - f1_m: 0.9559 - val_loss: 0.2021 - val_accuracy: 0.9688 - val_f1_m: 0.9739\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 147us/sample - loss: 5.8611e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1812 - val_accuracy: 0.9744 - val_f1_m: 0.9698\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 151us/sample - loss: 2.4212e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1836 - val_accuracy: 0.9762 - val_f1_m: 0.9690\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 151us/sample - loss: 1.6843e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1828 - val_accuracy: 0.9744 - val_f1_m: 0.9681\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 149us/sample - loss: 1.2811e-04 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1837 - val_accuracy: 0.9741 - val_f1_m: 0.9681\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 148us/sample - loss: 1.0450e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1853 - val_accuracy: 0.9747 - val_f1_m: 0.9683\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 148us/sample - loss: 8.9696e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1868 - val_accuracy: 0.9746 - val_f1_m: 0.9678\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 147us/sample - loss: 7.9230e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1886 - val_accuracy: 0.9743 - val_f1_m: 0.9678\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 247us/sample - loss: 0.0078 - accuracy: 0.9980 - f1_m: 0.9506 - val_loss: 0.1303 - val_accuracy: 0.9786 - val_f1_m: 0.9657\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 181us/sample - loss: 0.0112 - accuracy: 0.9974 - f1_m: 0.9523 - val_loss: 0.1546 - val_accuracy: 0.9796 - val_f1_m: 0.9674\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 179us/sample - loss: 0.0052 - accuracy: 0.9982 - f1_m: 0.9512 - val_loss: 0.1285 - val_accuracy: 0.9807 - val_f1_m: 0.9636\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 175us/sample - loss: 0.0031 - accuracy: 0.9989 - f1_m: 0.9492 - val_loss: 0.1394 - val_accuracy: 0.9775 - val_f1_m: 0.9679\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 181us/sample - loss: 0.0047 - accuracy: 0.9981 - f1_m: 0.9526 - val_loss: 0.1544 - val_accuracy: 0.9764 - val_f1_m: 0.9662\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 181us/sample - loss: 7.7435e-04 - accuracy: 1.0000 - f1_m: 0.9490 - val_loss: 0.1326 - val_accuracy: 0.9835 - val_f1_m: 0.9636\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 178us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_m: 0.9487 - val_loss: 0.1793 - val_accuracy: 0.9794 - val_f1_m: 0.9598\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 178us/sample - loss: 0.0141 - accuracy: 0.9953 - f1_m: 0.9550 - val_loss: 0.1366 - val_accuracy: 0.9740 - val_f1_m: 0.9742\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 177us/sample - loss: 0.0051 - accuracy: 0.9981 - f1_m: 0.9517 - val_loss: 0.1334 - val_accuracy: 0.9747 - val_f1_m: 0.9686\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 180us/sample - loss: 0.0023 - accuracy: 0.9992 - f1_m: 0.9497 - val_loss: 0.1192 - val_accuracy: 0.9794 - val_f1_m: 0.9650\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 3s 313us/sample - loss: 0.0159 - accuracy: 0.9963 - f1_m: 0.9570 - val_loss: 0.1099 - val_accuracy: 0.9785 - val_f1_m: 0.9749\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.0055 - accuracy: 0.9982 - f1_m: 0.9520 - val_loss: 0.1703 - val_accuracy: 0.9706 - val_f1_m: 0.9723\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 223us/sample - loss: 0.0188 - accuracy: 0.9940 - f1_m: 0.9598 - val_loss: 0.1294 - val_accuracy: 0.9738 - val_f1_m: 0.9757\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 222us/sample - loss: 0.0057 - accuracy: 0.9985 - f1_m: 0.9503 - val_loss: 0.1679 - val_accuracy: 0.9730 - val_f1_m: 0.9749\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 224us/sample - loss: 0.0070 - accuracy: 0.9983 - f1_m: 0.9529 - val_loss: 0.1533 - val_accuracy: 0.9747 - val_f1_m: 0.9675\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.0082 - accuracy: 0.9974 - f1_m: 0.9514 - val_loss: 0.1941 - val_accuracy: 0.9692 - val_f1_m: 0.9747\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0090 - accuracy: 0.9966 - f1_m: 0.9558 - val_loss: 0.1705 - val_accuracy: 0.9756 - val_f1_m: 0.9649\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 233us/sample - loss: 0.0105 - accuracy: 0.9966 - f1_m: 0.9551 - val_loss: 0.1490 - val_accuracy: 0.9732 - val_f1_m: 0.9734\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 231us/sample - loss: 0.0023 - accuracy: 0.9993 - f1_m: 0.9500 - val_loss: 0.1432 - val_accuracy: 0.9777 - val_f1_m: 0.9625\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 224us/sample - loss: 6.7957e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1471 - val_accuracy: 0.9791 - val_f1_m: 0.9616\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 189us/sample - loss: 0.0174 - accuracy: 0.9962 - f1_m: 0.9546 - val_loss: 0.2374 - val_accuracy: 0.9616 - val_f1_m: 0.9865\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 136us/sample - loss: 0.0071 - accuracy: 0.9987 - f1_m: 0.9497 - val_loss: 0.2543 - val_accuracy: 0.9595 - val_f1_m: 0.9888\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 139us/sample - loss: 0.0029 - accuracy: 0.9991 - f1_m: 0.9508 - val_loss: 0.2668 - val_accuracy: 0.9600 - val_f1_m: 0.9792\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 140us/sample - loss: 0.0060 - accuracy: 0.9980 - f1_m: 0.9517 - val_loss: 0.3000 - val_accuracy: 0.9535 - val_f1_m: 0.9885\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 143us/sample - loss: 0.0063 - accuracy: 0.9982 - f1_m: 0.9542 - val_loss: 0.2308 - val_accuracy: 0.9627 - val_f1_m: 0.9802\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 137us/sample - loss: 5.0070e-04 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.2266 - val_accuracy: 0.9652 - val_f1_m: 0.9792\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 139us/sample - loss: 1.7457e-04 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.2259 - val_accuracy: 0.9658 - val_f1_m: 0.9777\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 1.2236e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2269 - val_accuracy: 0.9665 - val_f1_m: 0.9770\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 141us/sample - loss: 1.0345e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2288 - val_accuracy: 0.9666 - val_f1_m: 0.9759\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 143us/sample - loss: 8.5651e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.2312 - val_accuracy: 0.9663 - val_f1_m: 0.9754\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 214us/sample - loss: 0.0089 - accuracy: 0.9977 - f1_m: 0.9510 - val_loss: 0.1496 - val_accuracy: 0.9745 - val_f1_m: 0.9665\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 153us/sample - loss: 0.0066 - accuracy: 0.9988 - f1_m: 0.9506 - val_loss: 0.1950 - val_accuracy: 0.9723 - val_f1_m: 0.9748\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 162us/sample - loss: 0.0063 - accuracy: 0.9980 - f1_m: 0.9519 - val_loss: 0.1231 - val_accuracy: 0.9792 - val_f1_m: 0.9670\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 156us/sample - loss: 0.0027 - accuracy: 0.9994 - f1_m: 0.9489 - val_loss: 0.1197 - val_accuracy: 0.9803 - val_f1_m: 0.9640\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 156us/sample - loss: 3.2542e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1092 - val_accuracy: 0.9829 - val_f1_m: 0.9645\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 156us/sample - loss: 1.1707e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1065 - val_accuracy: 0.9826 - val_f1_m: 0.9631\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 153us/sample - loss: 3.1362e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1080 - val_accuracy: 0.9835 - val_f1_m: 0.9629\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 160us/sample - loss: 2.1311e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1088 - val_accuracy: 0.9840 - val_f1_m: 0.9627\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 157us/sample - loss: 1.6889e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1095 - val_accuracy: 0.9837 - val_f1_m: 0.9621\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 160us/sample - loss: 1.3698e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1109 - val_accuracy: 0.9836 - val_f1_m: 0.9617\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 3s 258us/sample - loss: 0.0104 - accuracy: 0.9984 - f1_m: 0.9489 - val_loss: 0.1090 - val_accuracy: 0.9811 - val_f1_m: 0.9648\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 193us/sample - loss: 0.0052 - accuracy: 0.9986 - f1_m: 0.9501 - val_loss: 0.0735 - val_accuracy: 0.9852 - val_f1_m: 0.9674\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 192us/sample - loss: 0.0057 - accuracy: 0.9982 - f1_m: 0.9500 - val_loss: 0.1047 - val_accuracy: 0.9790 - val_f1_m: 0.9741\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 189us/sample - loss: 0.0092 - accuracy: 0.9967 - f1_m: 0.9530 - val_loss: 0.1056 - val_accuracy: 0.9790 - val_f1_m: 0.9654\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 187us/sample - loss: 0.0016 - accuracy: 0.9992 - f1_m: 0.9489 - val_loss: 0.1283 - val_accuracy: 0.9806 - val_f1_m: 0.9641\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 187us/sample - loss: 0.0035 - accuracy: 0.9986 - f1_m: 0.9503 - val_loss: 0.1114 - val_accuracy: 0.9787 - val_f1_m: 0.9687\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 190us/sample - loss: 0.0051 - accuracy: 0.9984 - f1_m: 0.9514 - val_loss: 0.1511 - val_accuracy: 0.9770 - val_f1_m: 0.9690\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 192us/sample - loss: 0.0090 - accuracy: 0.9971 - f1_m: 0.9534 - val_loss: 0.1083 - val_accuracy: 0.9821 - val_f1_m: 0.9662\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 192us/sample - loss: 8.7458e-04 - accuracy: 0.9997 - f1_m: 0.9482 - val_loss: 0.1149 - val_accuracy: 0.9831 - val_f1_m: 0.9599\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 197us/sample - loss: 3.1855e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1203 - val_accuracy: 0.9830 - val_f1_m: 0.9587\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 3s 347us/sample - loss: 0.0116 - accuracy: 0.9973 - f1_m: 0.9509 - val_loss: 0.1234 - val_accuracy: 0.9816 - val_f1_m: 0.9665\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 246us/sample - loss: 0.0065 - accuracy: 0.9980 - f1_m: 0.9516 - val_loss: 0.1177 - val_accuracy: 0.9794 - val_f1_m: 0.9643\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 248us/sample - loss: 0.0080 - accuracy: 0.9977 - f1_m: 0.9502 - val_loss: 0.1636 - val_accuracy: 0.9787 - val_f1_m: 0.9606\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.0153 - accuracy: 0.9960 - f1_m: 0.9520 - val_loss: 0.1073 - val_accuracy: 0.9831 - val_f1_m: 0.9663\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.0057 - accuracy: 0.9977 - f1_m: 0.9510 - val_loss: 0.1198 - val_accuracy: 0.9800 - val_f1_m: 0.9666\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.0028 - accuracy: 0.9993 - f1_m: 0.9497 - val_loss: 0.1540 - val_accuracy: 0.9801 - val_f1_m: 0.9654\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 247us/sample - loss: 7.4095e-04 - accuracy: 0.9998 - f1_m: 0.9484 - val_loss: 0.1277 - val_accuracy: 0.9816 - val_f1_m: 0.9610\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 247us/sample - loss: 0.0031 - accuracy: 0.9993 - f1_m: 0.9491 - val_loss: 0.1148 - val_accuracy: 0.9807 - val_f1_m: 0.9680\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 238us/sample - loss: 0.0180 - accuracy: 0.9953 - f1_m: 0.9557 - val_loss: 0.1300 - val_accuracy: 0.9785 - val_f1_m: 0.9661\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 245us/sample - loss: 0.0065 - accuracy: 0.9982 - f1_m: 0.9505 - val_loss: 0.1474 - val_accuracy: 0.9775 - val_f1_m: 0.9669\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 187us/sample - loss: 0.0158 - accuracy: 0.9967 - f1_m: 0.9592 - val_loss: 0.3270 - val_accuracy: 0.9538 - val_f1_m: 0.9920\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 1s 134us/sample - loss: 0.0091 - accuracy: 0.9980 - f1_m: 0.9575 - val_loss: 0.2998 - val_accuracy: 0.9577 - val_f1_m: 0.9866\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 1s 129us/sample - loss: 0.0059 - accuracy: 0.9987 - f1_m: 0.9558 - val_loss: 0.2962 - val_accuracy: 0.9586 - val_f1_m: 0.9857\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 1s 134us/sample - loss: 0.0047 - accuracy: 0.9992 - f1_m: 0.9551 - val_loss: 0.3100 - val_accuracy: 0.9563 - val_f1_m: 0.9860\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 1s 131us/sample - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9527 - val_loss: 0.3116 - val_accuracy: 0.9571 - val_f1_m: 0.9854\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 1s 135us/sample - loss: 0.0025 - accuracy: 0.9996 - f1_m: 0.9523 - val_loss: 0.3055 - val_accuracy: 0.9567 - val_f1_m: 0.9849\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 1s 135us/sample - loss: 9.6862e-04 - accuracy: 0.9999 - f1_m: 0.9490 - val_loss: 0.3047 - val_accuracy: 0.9586 - val_f1_m: 0.9827\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 1s 129us/sample - loss: 5.9454e-04 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.3072 - val_accuracy: 0.9582 - val_f1_m: 0.9829\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 1s 129us/sample - loss: 4.9976e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.3096 - val_accuracy: 0.9571 - val_f1_m: 0.9802\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 1s 133us/sample - loss: 4.3580e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.3115 - val_accuracy: 0.9573 - val_f1_m: 0.9793\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 199us/sample - loss: 0.0096 - accuracy: 0.9973 - f1_m: 0.9522 - val_loss: 0.2403 - val_accuracy: 0.9661 - val_f1_m: 0.9698\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 1s 142us/sample - loss: 0.0126 - accuracy: 0.9957 - f1_m: 0.9541 - val_loss: 0.1944 - val_accuracy: 0.9740 - val_f1_m: 0.9677\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 143us/sample - loss: 0.0020 - accuracy: 0.9993 - f1_m: 0.9499 - val_loss: 0.2058 - val_accuracy: 0.9728 - val_f1_m: 0.9705\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 1s 141us/sample - loss: 0.0086 - accuracy: 0.9974 - f1_m: 0.9518 - val_loss: 0.1920 - val_accuracy: 0.9711 - val_f1_m: 0.9686\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 148us/sample - loss: 0.0033 - accuracy: 0.9987 - f1_m: 0.9513 - val_loss: 0.1911 - val_accuracy: 0.9715 - val_f1_m: 0.9667\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 150us/sample - loss: 3.1378e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1794 - val_accuracy: 0.9736 - val_f1_m: 0.9687\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 1s 142us/sample - loss: 1.9667e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1807 - val_accuracy: 0.9742 - val_f1_m: 0.9669\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 1s 140us/sample - loss: 8.9309e-05 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1786 - val_accuracy: 0.9746 - val_f1_m: 0.9684\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 146us/sample - loss: 7.3519e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1799 - val_accuracy: 0.9746 - val_f1_m: 0.9676\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 147us/sample - loss: 6.3448e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1800 - val_accuracy: 0.9743 - val_f1_m: 0.9673\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 237us/sample - loss: 0.0078 - accuracy: 0.9979 - f1_m: 0.9502 - val_loss: 0.1471 - val_accuracy: 0.9757 - val_f1_m: 0.9727\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 177us/sample - loss: 0.0025 - accuracy: 0.9990 - f1_m: 0.9500 - val_loss: 0.1286 - val_accuracy: 0.9813 - val_f1_m: 0.9633\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 176us/sample - loss: 2.8371e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1228 - val_accuracy: 0.9812 - val_f1_m: 0.9614\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 176us/sample - loss: 0.0167 - accuracy: 0.9948 - f1_m: 0.9564 - val_loss: 0.1298 - val_accuracy: 0.9756 - val_f1_m: 0.9770\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 174us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9518 - val_loss: 0.1433 - val_accuracy: 0.9778 - val_f1_m: 0.9641\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 180us/sample - loss: 0.0027 - accuracy: 0.9988 - f1_m: 0.9507 - val_loss: 0.1359 - val_accuracy: 0.9817 - val_f1_m: 0.9614\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 181us/sample - loss: 8.3846e-04 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.1247 - val_accuracy: 0.9796 - val_f1_m: 0.9628\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 186us/sample - loss: 1.1241e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1246 - val_accuracy: 0.9817 - val_f1_m: 0.9615\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 176us/sample - loss: 2.3703e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1258 - val_accuracy: 0.9813 - val_f1_m: 0.9616\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 184us/sample - loss: 1.6494e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1271 - val_accuracy: 0.9818 - val_f1_m: 0.9613\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 3s 314us/sample - loss: 0.0079 - accuracy: 0.9973 - f1_m: 0.9527 - val_loss: 0.1999 - val_accuracy: 0.9741 - val_f1_m: 0.9648\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 219us/sample - loss: 0.0097 - accuracy: 0.9967 - f1_m: 0.9540 - val_loss: 0.1970 - val_accuracy: 0.9688 - val_f1_m: 0.9746\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 225us/sample - loss: 0.0108 - accuracy: 0.9966 - f1_m: 0.9527 - val_loss: 0.1499 - val_accuracy: 0.9767 - val_f1_m: 0.9670\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 230us/sample - loss: 0.0068 - accuracy: 0.9979 - f1_m: 0.9521 - val_loss: 0.1668 - val_accuracy: 0.9749 - val_f1_m: 0.9676\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 224us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9498 - val_loss: 0.1536 - val_accuracy: 0.9777 - val_f1_m: 0.9668\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 223us/sample - loss: 0.0109 - accuracy: 0.9970 - f1_m: 0.9532 - val_loss: 0.1499 - val_accuracy: 0.9739 - val_f1_m: 0.9730\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 217us/sample - loss: 0.0037 - accuracy: 0.9989 - f1_m: 0.9512 - val_loss: 0.1586 - val_accuracy: 0.9742 - val_f1_m: 0.9690\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 220us/sample - loss: 0.0115 - accuracy: 0.9972 - f1_m: 0.9534 - val_loss: 0.1292 - val_accuracy: 0.9776 - val_f1_m: 0.9687\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 218us/sample - loss: 0.0148 - accuracy: 0.9957 - f1_m: 0.9555 - val_loss: 0.1403 - val_accuracy: 0.9733 - val_f1_m: 0.9719\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 217us/sample - loss: 0.0049 - accuracy: 0.9983 - f1_m: 0.9513 - val_loss: 0.1298 - val_accuracy: 0.9783 - val_f1_m: 0.9659\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 179us/sample - loss: 0.0147 - accuracy: 0.9961 - f1_m: 0.9552 - val_loss: 0.2372 - val_accuracy: 0.9629 - val_f1_m: 0.9840\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 1s 133us/sample - loss: 0.0062 - accuracy: 0.9981 - f1_m: 0.9525 - val_loss: 0.2346 - val_accuracy: 0.9644 - val_f1_m: 0.9788\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 1s 131us/sample - loss: 0.0029 - accuracy: 0.9992 - f1_m: 0.9513 - val_loss: 0.2343 - val_accuracy: 0.9647 - val_f1_m: 0.9763\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 1s 128us/sample - loss: 5.0981e-04 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.2252 - val_accuracy: 0.9652 - val_f1_m: 0.9720\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 1s 132us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9485 - val_loss: 0.2350 - val_accuracy: 0.9637 - val_f1_m: 0.9733\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 1s 128us/sample - loss: 0.0060 - accuracy: 0.9982 - f1_m: 0.9541 - val_loss: 0.2670 - val_accuracy: 0.9620 - val_f1_m: 0.9757\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 1s 129us/sample - loss: 0.0017 - accuracy: 0.9996 - f1_m: 0.9499 - val_loss: 0.2630 - val_accuracy: 0.9631 - val_f1_m: 0.9769\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 1s 132us/sample - loss: 6.6281e-04 - accuracy: 0.9999 - f1_m: 0.9476 - val_loss: 0.2444 - val_accuracy: 0.9644 - val_f1_m: 0.9725\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 1s 129us/sample - loss: 1.3417e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2399 - val_accuracy: 0.9669 - val_f1_m: 0.9725\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 1s 135us/sample - loss: 7.7965e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2412 - val_accuracy: 0.9669 - val_f1_m: 0.9734\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 2s 201us/sample - loss: 0.0081 - accuracy: 0.9972 - f1_m: 0.9529 - val_loss: 0.1423 - val_accuracy: 0.9756 - val_f1_m: 0.9647\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 148us/sample - loss: 0.0053 - accuracy: 0.9980 - f1_m: 0.9507 - val_loss: 0.1321 - val_accuracy: 0.9786 - val_f1_m: 0.9648\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 151us/sample - loss: 6.2767e-04 - accuracy: 0.9999 - f1_m: 0.9487 - val_loss: 0.1123 - val_accuracy: 0.9818 - val_f1_m: 0.9635\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 145us/sample - loss: 4.8846e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1114 - val_accuracy: 0.9821 - val_f1_m: 0.9624\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 149us/sample - loss: 2.6600e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1115 - val_accuracy: 0.9820 - val_f1_m: 0.9623\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 147us/sample - loss: 1.9766e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1120 - val_accuracy: 0.9820 - val_f1_m: 0.9618\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 2s 149us/sample - loss: 1.5766e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1124 - val_accuracy: 0.9819 - val_f1_m: 0.9616\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 150us/sample - loss: 1.2881e-05 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1130 - val_accuracy: 0.9822 - val_f1_m: 0.9614\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 145us/sample - loss: 1.0582e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1136 - val_accuracy: 0.9828 - val_f1_m: 0.9614\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 147us/sample - loss: 8.7935e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1142 - val_accuracy: 0.9827 - val_f1_m: 0.9613\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 3s 242us/sample - loss: 0.0080 - accuracy: 0.9978 - f1_m: 0.9500 - val_loss: 0.1163 - val_accuracy: 0.9797 - val_f1_m: 0.9674\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 182us/sample - loss: 0.0062 - accuracy: 0.9983 - f1_m: 0.9511 - val_loss: 0.1153 - val_accuracy: 0.9818 - val_f1_m: 0.9644\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 188us/sample - loss: 3.4431e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1179 - val_accuracy: 0.9834 - val_f1_m: 0.9603\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 2s 183us/sample - loss: 1.7041e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1197 - val_accuracy: 0.9833 - val_f1_m: 0.9603\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 180us/sample - loss: 7.6691e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1206 - val_accuracy: 0.9834 - val_f1_m: 0.9599\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 180us/sample - loss: 5.5732e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1216 - val_accuracy: 0.9834 - val_f1_m: 0.9589\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 181us/sample - loss: 4.2930e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1224 - val_accuracy: 0.9834 - val_f1_m: 0.9579\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 180us/sample - loss: 3.3972e-06 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1236 - val_accuracy: 0.9838 - val_f1_m: 0.9583\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 2s 180us/sample - loss: 2.7193e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1246 - val_accuracy: 0.9838 - val_f1_m: 0.9579\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 183us/sample - loss: 2.2115e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1257 - val_accuracy: 0.9838 - val_f1_m: 0.9577\n",
      "Train on 10500 samples, validate on 9500 samples\n",
      "Epoch 1/10\n",
      "10500/10500 [==============================] - 3s 325us/sample - loss: 0.0102 - accuracy: 0.9973 - f1_m: 0.9519 - val_loss: 0.0919 - val_accuracy: 0.9824 - val_f1_m: 0.9691\n",
      "Epoch 2/10\n",
      "10500/10500 [==============================] - 2s 237us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9528 - val_loss: 0.1926 - val_accuracy: 0.9738 - val_f1_m: 0.9669\n",
      "Epoch 3/10\n",
      "10500/10500 [==============================] - 2s 238us/sample - loss: 0.0097 - accuracy: 0.9975 - f1_m: 0.9519 - val_loss: 0.1166 - val_accuracy: 0.9838 - val_f1_m: 0.9623\n",
      "Epoch 4/10\n",
      "10500/10500 [==============================] - 3s 242us/sample - loss: 0.0099 - accuracy: 0.9978 - f1_m: 0.9507 - val_loss: 0.1405 - val_accuracy: 0.9738 - val_f1_m: 0.9802\n",
      "Epoch 5/10\n",
      "10500/10500 [==============================] - 2s 233us/sample - loss: 0.0050 - accuracy: 0.9983 - f1_m: 0.9514 - val_loss: 0.1552 - val_accuracy: 0.9808 - val_f1_m: 0.9633\n",
      "Epoch 6/10\n",
      "10500/10500 [==============================] - 2s 234us/sample - loss: 0.0168 - accuracy: 0.9953 - f1_m: 0.9556 - val_loss: 0.1107 - val_accuracy: 0.9821 - val_f1_m: 0.9694\n",
      "Epoch 7/10\n",
      "10500/10500 [==============================] - 2s 237us/sample - loss: 0.0046 - accuracy: 0.9985 - f1_m: 0.9509 - val_loss: 0.1056 - val_accuracy: 0.9818 - val_f1_m: 0.9640\n",
      "Epoch 8/10\n",
      "10500/10500 [==============================] - 2s 233us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9486 - val_loss: 0.1322 - val_accuracy: 0.9820 - val_f1_m: 0.9615\n",
      "Epoch 9/10\n",
      "10500/10500 [==============================] - 3s 239us/sample - loss: 1.3877e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1379 - val_accuracy: 0.9824 - val_f1_m: 0.9602\n",
      "Epoch 10/10\n",
      "10500/10500 [==============================] - 2s 234us/sample - loss: 1.3172e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1401 - val_accuracy: 0.9828 - val_f1_m: 0.9600\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 175us/sample - loss: 0.0213 - accuracy: 0.9962 - f1_m: 0.9578 - val_loss: 0.3274 - val_accuracy: 0.9546 - val_f1_m: 0.9828\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 1s 127us/sample - loss: 0.0118 - accuracy: 0.9976 - f1_m: 0.9570 - val_loss: 0.3083 - val_accuracy: 0.9551 - val_f1_m: 0.9827\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 1s 129us/sample - loss: 0.0095 - accuracy: 0.9981 - f1_m: 0.9549 - val_loss: 0.3025 - val_accuracy: 0.9543 - val_f1_m: 0.9834\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 1s 128us/sample - loss: 0.0063 - accuracy: 0.9980 - f1_m: 0.9550 - val_loss: 0.3006 - val_accuracy: 0.9558 - val_f1_m: 0.9845\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 1s 125us/sample - loss: 0.0027 - accuracy: 0.9995 - f1_m: 0.9526 - val_loss: 0.2991 - val_accuracy: 0.9578 - val_f1_m: 0.9784\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 1s 130us/sample - loss: 0.0013 - accuracy: 0.9999 - f1_m: 0.9499 - val_loss: 0.3116 - val_accuracy: 0.9566 - val_f1_m: 0.9805\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 1s 131us/sample - loss: 0.0012 - accuracy: 0.9999 - f1_m: 0.9489 - val_loss: 0.3047 - val_accuracy: 0.9581 - val_f1_m: 0.9810\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 1s 136us/sample - loss: 6.0532e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.3074 - val_accuracy: 0.9576 - val_f1_m: 0.9791\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 1s 127us/sample - loss: 5.5662e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.3116 - val_accuracy: 0.9569 - val_f1_m: 0.9798\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 1s 131us/sample - loss: 5.1769e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.3098 - val_accuracy: 0.9584 - val_f1_m: 0.9791\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 191us/sample - loss: 0.0137 - accuracy: 0.9968 - f1_m: 0.9540 - val_loss: 0.2168 - val_accuracy: 0.9721 - val_f1_m: 0.9645\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 138us/sample - loss: 0.0052 - accuracy: 0.9986 - f1_m: 0.9509 - val_loss: 0.1894 - val_accuracy: 0.9724 - val_f1_m: 0.9659\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 144us/sample - loss: 0.0094 - accuracy: 0.9970 - f1_m: 0.9539 - val_loss: 0.2173 - val_accuracy: 0.9693 - val_f1_m: 0.9698\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 142us/sample - loss: 0.0050 - accuracy: 0.9985 - f1_m: 0.9521 - val_loss: 0.1876 - val_accuracy: 0.9734 - val_f1_m: 0.9670\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 141us/sample - loss: 0.0034 - accuracy: 0.9987 - f1_m: 0.9506 - val_loss: 0.1984 - val_accuracy: 0.9721 - val_f1_m: 0.9674\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 1s 136us/sample - loss: 0.0068 - accuracy: 0.9977 - f1_m: 0.9532 - val_loss: 0.1926 - val_accuracy: 0.9736 - val_f1_m: 0.9690\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 139us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9484 - val_loss: 0.1890 - val_accuracy: 0.9748 - val_f1_m: 0.9649\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 141us/sample - loss: 1.4765e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1874 - val_accuracy: 0.9749 - val_f1_m: 0.9642\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 147us/sample - loss: 8.4323e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1878 - val_accuracy: 0.9753 - val_f1_m: 0.9638\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 145us/sample - loss: 6.8057e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1880 - val_accuracy: 0.9753 - val_f1_m: 0.9630\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 3s 235us/sample - loss: 0.0135 - accuracy: 0.9976 - f1_m: 0.9497 - val_loss: 0.1277 - val_accuracy: 0.9800 - val_f1_m: 0.9650\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 167us/sample - loss: 0.0033 - accuracy: 0.9992 - f1_m: 0.9509 - val_loss: 0.1647 - val_accuracy: 0.9758 - val_f1_m: 0.9657\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 167us/sample - loss: 0.0028 - accuracy: 0.9989 - f1_m: 0.9493 - val_loss: 0.1281 - val_accuracy: 0.9800 - val_f1_m: 0.9658\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 168us/sample - loss: 6.2784e-04 - accuracy: 0.9997 - f1_m: 0.9480 - val_loss: 0.1245 - val_accuracy: 0.9807 - val_f1_m: 0.9604\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 171us/sample - loss: 8.0003e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1284 - val_accuracy: 0.9824 - val_f1_m: 0.9589\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 166us/sample - loss: 2.2740e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1296 - val_accuracy: 0.9822 - val_f1_m: 0.9586\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 173us/sample - loss: 1.6689e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1312 - val_accuracy: 0.9823 - val_f1_m: 0.9583\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 168us/sample - loss: 1.2965e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1328 - val_accuracy: 0.9824 - val_f1_m: 0.9577\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 167us/sample - loss: 1.0395e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1348 - val_accuracy: 0.9822 - val_f1_m: 0.9577\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 168us/sample - loss: 8.4213e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1366 - val_accuracy: 0.9822 - val_f1_m: 0.9579\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 3s 296us/sample - loss: 0.0164 - accuracy: 0.9963 - f1_m: 0.9546 - val_loss: 0.1190 - val_accuracy: 0.9780 - val_f1_m: 0.9728\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 215us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9502 - val_loss: 0.1454 - val_accuracy: 0.9727 - val_f1_m: 0.9696\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 209us/sample - loss: 0.0118 - accuracy: 0.9956 - f1_m: 0.9552 - val_loss: 0.1317 - val_accuracy: 0.9774 - val_f1_m: 0.9648\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 217us/sample - loss: 0.0078 - accuracy: 0.9973 - f1_m: 0.9520 - val_loss: 0.1891 - val_accuracy: 0.9699 - val_f1_m: 0.9696\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 222us/sample - loss: 0.0096 - accuracy: 0.9969 - f1_m: 0.9556 - val_loss: 0.1888 - val_accuracy: 0.9723 - val_f1_m: 0.9688\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 212us/sample - loss: 0.0140 - accuracy: 0.9956 - f1_m: 0.9541 - val_loss: 0.1831 - val_accuracy: 0.9739 - val_f1_m: 0.9674\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 216us/sample - loss: 0.0094 - accuracy: 0.9967 - f1_m: 0.9532 - val_loss: 0.1408 - val_accuracy: 0.9733 - val_f1_m: 0.9717\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 220us/sample - loss: 0.0029 - accuracy: 0.9988 - f1_m: 0.9502 - val_loss: 0.1462 - val_accuracy: 0.9771 - val_f1_m: 0.9643\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 220us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9481 - val_loss: 0.1421 - val_accuracy: 0.9767 - val_f1_m: 0.9644\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 226us/sample - loss: 5.0469e-04 - accuracy: 0.9999 - f1_m: 0.9484 - val_loss: 0.1425 - val_accuracy: 0.9769 - val_f1_m: 0.9617\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 178us/sample - loss: 0.0175 - accuracy: 0.9973 - f1_m: 0.9534 - val_loss: 0.2431 - val_accuracy: 0.9630 - val_f1_m: 0.9835\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 1s 125us/sample - loss: 0.0053 - accuracy: 0.9980 - f1_m: 0.9517 - val_loss: 0.2786 - val_accuracy: 0.9579 - val_f1_m: 0.9821\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 0.0062 - accuracy: 0.9976 - f1_m: 0.9532 - val_loss: 0.2569 - val_accuracy: 0.9636 - val_f1_m: 0.9804\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 1s 130us/sample - loss: 0.0032 - accuracy: 0.9991 - f1_m: 0.9520 - val_loss: 0.2410 - val_accuracy: 0.9629 - val_f1_m: 0.9773\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 1s 132us/sample - loss: 0.0024 - accuracy: 0.9995 - f1_m: 0.9487 - val_loss: 0.2208 - val_accuracy: 0.9679 - val_f1_m: 0.9770\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 1s 126us/sample - loss: 2.5903e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2141 - val_accuracy: 0.9670 - val_f1_m: 0.9760\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 1s 128us/sample - loss: 8.9531e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2168 - val_accuracy: 0.9668 - val_f1_m: 0.9761\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 7.4167e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2173 - val_accuracy: 0.9672 - val_f1_m: 0.9766\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 1s 130us/sample - loss: 6.3525e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2191 - val_accuracy: 0.9670 - val_f1_m: 0.9774\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 1s 135us/sample - loss: 5.5710e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2202 - val_accuracy: 0.9668 - val_f1_m: 0.9757\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 2s 202us/sample - loss: 0.0119 - accuracy: 0.9975 - f1_m: 0.9509 - val_loss: 0.1575 - val_accuracy: 0.9740 - val_f1_m: 0.9675\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 150us/sample - loss: 0.0053 - accuracy: 0.9977 - f1_m: 0.9518 - val_loss: 0.1269 - val_accuracy: 0.9819 - val_f1_m: 0.9621\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 142us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9488 - val_loss: 0.1093 - val_accuracy: 0.9821 - val_f1_m: 0.9616\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 149us/sample - loss: 7.2423e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1124 - val_accuracy: 0.9831 - val_f1_m: 0.9610\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 145us/sample - loss: 2.8605e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1137 - val_accuracy: 0.9832 - val_f1_m: 0.9604\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 147us/sample - loss: 2.0938e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1151 - val_accuracy: 0.9831 - val_f1_m: 0.9606\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 145us/sample - loss: 1.6190e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1162 - val_accuracy: 0.9831 - val_f1_m: 0.9595\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 144us/sample - loss: 1.2972e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1173 - val_accuracy: 0.9831 - val_f1_m: 0.9592\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 149us/sample - loss: 1.0507e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1184 - val_accuracy: 0.9832 - val_f1_m: 0.9591\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 146us/sample - loss: 8.6060e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1196 - val_accuracy: 0.9832 - val_f1_m: 0.9589\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 3s 244us/sample - loss: 0.0114 - accuracy: 0.9979 - f1_m: 0.9503 - val_loss: 0.1339 - val_accuracy: 0.9789 - val_f1_m: 0.9637\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 2s 176us/sample - loss: 0.0030 - accuracy: 0.9990 - f1_m: 0.9492 - val_loss: 0.1543 - val_accuracy: 0.9807 - val_f1_m: 0.9618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 2s 179us/sample - loss: 0.0042 - accuracy: 0.9986 - f1_m: 0.9491 - val_loss: 0.1118 - val_accuracy: 0.9816 - val_f1_m: 0.9625\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 2s 177us/sample - loss: 0.0033 - accuracy: 0.9994 - f1_m: 0.9486 - val_loss: 0.1156 - val_accuracy: 0.9783 - val_f1_m: 0.9627\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 2s 176us/sample - loss: 2.8573e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1105 - val_accuracy: 0.9857 - val_f1_m: 0.9617\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 176us/sample - loss: 1.7526e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1112 - val_accuracy: 0.9860 - val_f1_m: 0.9602\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 174us/sample - loss: 9.3733e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1120 - val_accuracy: 0.9863 - val_f1_m: 0.9602\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 175us/sample - loss: 6.7964e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1130 - val_accuracy: 0.9863 - val_f1_m: 0.9597\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 175us/sample - loss: 5.1558e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1139 - val_accuracy: 0.9866 - val_f1_m: 0.9593\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 180us/sample - loss: 4.0347e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1149 - val_accuracy: 0.9867 - val_f1_m: 0.9584\n",
      "Train on 11000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 3s 310us/sample - loss: 0.0127 - accuracy: 0.9976 - f1_m: 0.9498 - val_loss: 0.1470 - val_accuracy: 0.9827 - val_f1_m: 0.9629\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 3s 227us/sample - loss: 0.0050 - accuracy: 0.9986 - f1_m: 0.9497 - val_loss: 0.1722 - val_accuracy: 0.9789 - val_f1_m: 0.9601\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 3s 231us/sample - loss: 0.0024 - accuracy: 0.9994 - f1_m: 0.9493 - val_loss: 0.1870 - val_accuracy: 0.9824 - val_f1_m: 0.9554\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 3s 230us/sample - loss: 0.0162 - accuracy: 0.9950 - f1_m: 0.9536 - val_loss: 0.1390 - val_accuracy: 0.9804 - val_f1_m: 0.9595\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 3s 231us/sample - loss: 0.0078 - accuracy: 0.9976 - f1_m: 0.9512 - val_loss: 0.1215 - val_accuracy: 0.9799 - val_f1_m: 0.9618\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 2s 226us/sample - loss: 0.0044 - accuracy: 0.9988 - f1_m: 0.9505 - val_loss: 0.1502 - val_accuracy: 0.9733 - val_f1_m: 0.9697\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 2s 225us/sample - loss: 0.0058 - accuracy: 0.9980 - f1_m: 0.9510 - val_loss: 0.1318 - val_accuracy: 0.9826 - val_f1_m: 0.9608\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 2s 226us/sample - loss: 1.5878e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1344 - val_accuracy: 0.9826 - val_f1_m: 0.9581\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 2s 224us/sample - loss: 1.2331e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1360 - val_accuracy: 0.9828 - val_f1_m: 0.9576\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 2s 227us/sample - loss: 8.1117e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1373 - val_accuracy: 0.9829 - val_f1_m: 0.9571\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 166us/sample - loss: 0.0369 - accuracy: 0.9953 - f1_m: 0.9577 - val_loss: 0.3282 - val_accuracy: 0.9525 - val_f1_m: 0.9897\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 1s 121us/sample - loss: 0.0274 - accuracy: 0.9957 - f1_m: 0.9591 - val_loss: 0.3254 - val_accuracy: 0.9559 - val_f1_m: 0.9840\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 1s 122us/sample - loss: 0.0200 - accuracy: 0.9970 - f1_m: 0.9564 - val_loss: 0.2930 - val_accuracy: 0.9560 - val_f1_m: 0.9789\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 1s 120us/sample - loss: 0.0148 - accuracy: 0.9980 - f1_m: 0.9544 - val_loss: 0.2993 - val_accuracy: 0.9547 - val_f1_m: 0.9870\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 1s 122us/sample - loss: 0.0194 - accuracy: 0.9958 - f1_m: 0.9625 - val_loss: 0.3137 - val_accuracy: 0.9538 - val_f1_m: 0.9882\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 1s 122us/sample - loss: 0.0109 - accuracy: 0.9977 - f1_m: 0.9562 - val_loss: 0.2994 - val_accuracy: 0.9558 - val_f1_m: 0.9854\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 1s 120us/sample - loss: 0.0075 - accuracy: 0.9984 - f1_m: 0.9543 - val_loss: 0.2986 - val_accuracy: 0.9542 - val_f1_m: 0.9837\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 1s 125us/sample - loss: 0.0051 - accuracy: 0.9992 - f1_m: 0.9552 - val_loss: 0.3048 - val_accuracy: 0.9553 - val_f1_m: 0.9844\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 1s 121us/sample - loss: 0.0026 - accuracy: 0.9997 - f1_m: 0.9526 - val_loss: 0.2993 - val_accuracy: 0.9562 - val_f1_m: 0.9822\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 1s 120us/sample - loss: 0.0014 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 0.3105 - val_accuracy: 0.9549 - val_f1_m: 0.9848\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 183us/sample - loss: 0.0227 - accuracy: 0.9974 - f1_m: 0.9521 - val_loss: 0.2384 - val_accuracy: 0.9638 - val_f1_m: 0.9841\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 132us/sample - loss: 0.0173 - accuracy: 0.9969 - f1_m: 0.9535 - val_loss: 0.1691 - val_accuracy: 0.9728 - val_f1_m: 0.9726\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 134us/sample - loss: 0.0076 - accuracy: 0.9983 - f1_m: 0.9533 - val_loss: 0.1612 - val_accuracy: 0.9741 - val_f1_m: 0.9724\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 131us/sample - loss: 0.0049 - accuracy: 0.9987 - f1_m: 0.9512 - val_loss: 0.2042 - val_accuracy: 0.9701 - val_f1_m: 0.9717\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 139us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9521 - val_loss: 0.1787 - val_accuracy: 0.9721 - val_f1_m: 0.9707\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 135us/sample - loss: 0.0122 - accuracy: 0.9959 - f1_m: 0.9553 - val_loss: 0.1739 - val_accuracy: 0.9745 - val_f1_m: 0.9640\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 143us/sample - loss: 0.0034 - accuracy: 0.9990 - f1_m: 0.9512 - val_loss: 0.1848 - val_accuracy: 0.9739 - val_f1_m: 0.9699\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 136us/sample - loss: 0.0068 - accuracy: 0.9977 - f1_m: 0.9532 - val_loss: 0.1918 - val_accuracy: 0.9719 - val_f1_m: 0.9707\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 138us/sample - loss: 0.0027 - accuracy: 0.9992 - f1_m: 0.9503 - val_loss: 0.1842 - val_accuracy: 0.9729 - val_f1_m: 0.9696\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 136us/sample - loss: 0.0029 - accuracy: 0.9992 - f1_m: 0.9503 - val_loss: 0.1969 - val_accuracy: 0.9700 - val_f1_m: 0.9689\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 3s 223us/sample - loss: 0.0188 - accuracy: 0.9963 - f1_m: 0.9518 - val_loss: 0.1276 - val_accuracy: 0.9749 - val_f1_m: 0.9706\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 161us/sample - loss: 0.0049 - accuracy: 0.9990 - f1_m: 0.9503 - val_loss: 0.1146 - val_accuracy: 0.9809 - val_f1_m: 0.9681\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 163us/sample - loss: 0.0020 - accuracy: 0.9996 - f1_m: 0.9498 - val_loss: 0.1294 - val_accuracy: 0.9801 - val_f1_m: 0.9628\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 163us/sample - loss: 0.0033 - accuracy: 0.9992 - f1_m: 0.9489 - val_loss: 0.1239 - val_accuracy: 0.9813 - val_f1_m: 0.9656\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 162us/sample - loss: 4.8002e-04 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.1445 - val_accuracy: 0.9791 - val_f1_m: 0.9636\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 169us/sample - loss: 0.0117 - accuracy: 0.9962 - f1_m: 0.9529 - val_loss: 0.1346 - val_accuracy: 0.9748 - val_f1_m: 0.9760\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 164us/sample - loss: 0.0082 - accuracy: 0.9975 - f1_m: 0.9526 - val_loss: 0.1324 - val_accuracy: 0.9775 - val_f1_m: 0.9657\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 166us/sample - loss: 0.0025 - accuracy: 0.9991 - f1_m: 0.9499 - val_loss: 0.1963 - val_accuracy: 0.9747 - val_f1_m: 0.9674\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 160us/sample - loss: 0.0112 - accuracy: 0.9962 - f1_m: 0.9542 - val_loss: 0.1379 - val_accuracy: 0.9774 - val_f1_m: 0.9694\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 165us/sample - loss: 0.0068 - accuracy: 0.9973 - f1_m: 0.9527 - val_loss: 0.1468 - val_accuracy: 0.9778 - val_f1_m: 0.9684\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 3s 285us/sample - loss: 0.0169 - accuracy: 0.9970 - f1_m: 0.9534 - val_loss: 0.1215 - val_accuracy: 0.9784 - val_f1_m: 0.9661\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 205us/sample - loss: 0.0111 - accuracy: 0.9971 - f1_m: 0.9544 - val_loss: 0.1200 - val_accuracy: 0.9787 - val_f1_m: 0.9674\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 202us/sample - loss: 0.0049 - accuracy: 0.9988 - f1_m: 0.9511 - val_loss: 0.1206 - val_accuracy: 0.9794 - val_f1_m: 0.9691\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 212us/sample - loss: 0.0093 - accuracy: 0.9977 - f1_m: 0.9529 - val_loss: 0.0974 - val_accuracy: 0.9789 - val_f1_m: 0.9712\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 217us/sample - loss: 0.0057 - accuracy: 0.9983 - f1_m: 0.9526 - val_loss: 0.1511 - val_accuracy: 0.9785 - val_f1_m: 0.9719\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 213us/sample - loss: 0.0182 - accuracy: 0.9943 - f1_m: 0.9590 - val_loss: 0.1498 - val_accuracy: 0.9738 - val_f1_m: 0.9712\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 212us/sample - loss: 0.0053 - accuracy: 0.9982 - f1_m: 0.9519 - val_loss: 0.1496 - val_accuracy: 0.9776 - val_f1_m: 0.9645\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 206us/sample - loss: 0.0107 - accuracy: 0.9971 - f1_m: 0.9524 - val_loss: 0.1732 - val_accuracy: 0.9732 - val_f1_m: 0.9680\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 204us/sample - loss: 0.0068 - accuracy: 0.9977 - f1_m: 0.9519 - val_loss: 0.1143 - val_accuracy: 0.9788 - val_f1_m: 0.9745\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 202us/sample - loss: 0.0084 - accuracy: 0.9975 - f1_m: 0.9517 - val_loss: 0.1574 - val_accuracy: 0.9767 - val_f1_m: 0.9664\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 164us/sample - loss: 0.0244 - accuracy: 0.9972 - f1_m: 0.9541 - val_loss: 0.2257 - val_accuracy: 0.9631 - val_f1_m: 0.9812\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 1s 127us/sample - loss: 0.0106 - accuracy: 0.9983 - f1_m: 0.9515 - val_loss: 0.2129 - val_accuracy: 0.9620 - val_f1_m: 0.9812\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 1s 129us/sample - loss: 0.0051 - accuracy: 0.9991 - f1_m: 0.9522 - val_loss: 0.2126 - val_accuracy: 0.9614 - val_f1_m: 0.9826\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 1s 119us/sample - loss: 0.0018 - accuracy: 0.9998 - f1_m: 0.9484 - val_loss: 0.2129 - val_accuracy: 0.9626 - val_f1_m: 0.9809\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 1s 124us/sample - loss: 6.1530e-04 - accuracy: 0.9998 - f1_m: 0.9478 - val_loss: 0.2171 - val_accuracy: 0.9647 - val_f1_m: 0.9809\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 1s 125us/sample - loss: 3.5034e-04 - accuracy: 0.9999 - f1_m: 0.9474 - val_loss: 0.2064 - val_accuracy: 0.9654 - val_f1_m: 0.9795\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 1s 121us/sample - loss: 1.0650e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2070 - val_accuracy: 0.9655 - val_f1_m: 0.9784\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 1s 120us/sample - loss: 7.8871e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2094 - val_accuracy: 0.9653 - val_f1_m: 0.9788\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 1s 120us/sample - loss: 6.5964e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2118 - val_accuracy: 0.9653 - val_f1_m: 0.9779\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 1s 124us/sample - loss: 5.6524e-05 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.2137 - val_accuracy: 0.9653 - val_f1_m: 0.9776\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 2s 189us/sample - loss: 0.0154 - accuracy: 0.9978 - f1_m: 0.9512 - val_loss: 0.1129 - val_accuracy: 0.9775 - val_f1_m: 0.9657\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 140us/sample - loss: 0.0047 - accuracy: 0.9992 - f1_m: 0.9504 - val_loss: 0.1004 - val_accuracy: 0.9798 - val_f1_m: 0.9646\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 137us/sample - loss: 0.0016 - accuracy: 0.9996 - f1_m: 0.9491 - val_loss: 0.1133 - val_accuracy: 0.9782 - val_f1_m: 0.9669\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 140us/sample - loss: 0.0069 - accuracy: 0.9975 - f1_m: 0.9520 - val_loss: 0.1457 - val_accuracy: 0.9769 - val_f1_m: 0.9682\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 137us/sample - loss: 0.0047 - accuracy: 0.9988 - f1_m: 0.9510 - val_loss: 0.0923 - val_accuracy: 0.9820 - val_f1_m: 0.9621\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 142us/sample - loss: 3.9956e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1035 - val_accuracy: 0.9815 - val_f1_m: 0.9639\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 141us/sample - loss: 1.2835e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.0985 - val_accuracy: 0.9841 - val_f1_m: 0.9632\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 136us/sample - loss: 3.9576e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.0995 - val_accuracy: 0.9841 - val_f1_m: 0.9622\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 2s 145us/sample - loss: 2.7159e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1004 - val_accuracy: 0.9844 - val_f1_m: 0.9614\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 137us/sample - loss: 2.1629e-05 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.1015 - val_accuracy: 0.9841 - val_f1_m: 0.9608\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 5s 412us/sample - loss: 0.0095 - accuracy: 0.9984 - f1_m: 0.9491 - val_loss: 0.0825 - val_accuracy: 0.9813 - val_f1_m: 0.9709\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 2s 173us/sample - loss: 0.0049 - accuracy: 0.9983 - f1_m: 0.9505 - val_loss: 0.1212 - val_accuracy: 0.9807 - val_f1_m: 0.9629\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 2s 172us/sample - loss: 0.0075 - accuracy: 0.9973 - f1_m: 0.9521 - val_loss: 0.1101 - val_accuracy: 0.9824 - val_f1_m: 0.9647\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 2s 173us/sample - loss: 0.0035 - accuracy: 0.9986 - f1_m: 0.9499 - val_loss: 0.1107 - val_accuracy: 0.9801 - val_f1_m: 0.9627\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 2s 172us/sample - loss: 0.0049 - accuracy: 0.9990 - f1_m: 0.9500 - val_loss: 0.1107 - val_accuracy: 0.9834 - val_f1_m: 0.9621\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 2s 172us/sample - loss: 2.8116e-04 - accuracy: 0.9998 - f1_m: 0.9474 - val_loss: 0.1076 - val_accuracy: 0.9853 - val_f1_m: 0.9613\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 2s 173us/sample - loss: 0.0030 - accuracy: 0.9994 - f1_m: 0.9487 - val_loss: 0.1388 - val_accuracy: 0.9733 - val_f1_m: 0.9744\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 2s 173us/sample - loss: 0.0122 - accuracy: 0.9966 - f1_m: 0.9537 - val_loss: 0.1004 - val_accuracy: 0.9829 - val_f1_m: 0.9680\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500/11500 [==============================] - 2s 173us/sample - loss: 8.2320e-04 - accuracy: 0.9998 - f1_m: 0.9491 - val_loss: 0.1163 - val_accuracy: 0.9844 - val_f1_m: 0.9598\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 2s 172us/sample - loss: 9.9695e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1111 - val_accuracy: 0.9842 - val_f1_m: 0.9606\n",
      "Train on 11500 samples, validate on 8500 samples\n",
      "Epoch 1/10\n",
      "11500/11500 [==============================] - 3s 298us/sample - loss: 0.0140 - accuracy: 0.9979 - f1_m: 0.9509 - val_loss: 0.1144 - val_accuracy: 0.9815 - val_f1_m: 0.9666\n",
      "Epoch 2/10\n",
      "11500/11500 [==============================] - 3s 221us/sample - loss: 0.0066 - accuracy: 0.9976 - f1_m: 0.9523 - val_loss: 0.2283 - val_accuracy: 0.9708 - val_f1_m: 0.9676\n",
      "Epoch 3/10\n",
      "11500/11500 [==============================] - 3s 221us/sample - loss: 0.0156 - accuracy: 0.9954 - f1_m: 0.9536 - val_loss: 0.1385 - val_accuracy: 0.9782 - val_f1_m: 0.9608\n",
      "Epoch 4/10\n",
      "11500/11500 [==============================] - 3s 220us/sample - loss: 0.0028 - accuracy: 0.9990 - f1_m: 0.9496 - val_loss: 0.1418 - val_accuracy: 0.9824 - val_f1_m: 0.9582\n",
      "Epoch 5/10\n",
      "11500/11500 [==============================] - 3s 222us/sample - loss: 0.0051 - accuracy: 0.9990 - f1_m: 0.9500 - val_loss: 0.1584 - val_accuracy: 0.9749 - val_f1_m: 0.9720\n",
      "Epoch 6/10\n",
      "11500/11500 [==============================] - 3s 218us/sample - loss: 0.0096 - accuracy: 0.9973 - f1_m: 0.9521 - val_loss: 0.1428 - val_accuracy: 0.9787 - val_f1_m: 0.9688\n",
      "Epoch 7/10\n",
      "11500/11500 [==============================] - 3s 220us/sample - loss: 0.0038 - accuracy: 0.9990 - f1_m: 0.9500 - val_loss: 0.1201 - val_accuracy: 0.9799 - val_f1_m: 0.9617\n",
      "Epoch 8/10\n",
      "11500/11500 [==============================] - 3s 221us/sample - loss: 5.6322e-04 - accuracy: 0.9999 - f1_m: 0.9480 - val_loss: 0.1388 - val_accuracy: 0.9827 - val_f1_m: 0.9580\n",
      "Epoch 9/10\n",
      "11500/11500 [==============================] - 3s 221us/sample - loss: 4.7489e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1309 - val_accuracy: 0.9853 - val_f1_m: 0.9596\n",
      "Epoch 10/10\n",
      "11500/11500 [==============================] - 3s 218us/sample - loss: 3.8587e-06 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.1315 - val_accuracy: 0.9854 - val_f1_m: 0.9591\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 146us/sample - loss: 0.0213 - accuracy: 0.9967 - f1_m: 0.9596 - val_loss: 0.3013 - val_accuracy: 0.9545 - val_f1_m: 0.9848\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 104us/sample - loss: 0.0119 - accuracy: 0.9975 - f1_m: 0.9578 - val_loss: 0.2878 - val_accuracy: 0.9559 - val_f1_m: 0.9860\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1s 104us/sample - loss: 0.0115 - accuracy: 0.9974 - f1_m: 0.9564 - val_loss: 0.2929 - val_accuracy: 0.9551 - val_f1_m: 0.9849\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 103us/sample - loss: 0.0096 - accuracy: 0.9974 - f1_m: 0.9581 - val_loss: 0.2869 - val_accuracy: 0.9584 - val_f1_m: 0.9872\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 0.0079 - accuracy: 0.9973 - f1_m: 0.9570 - val_loss: 0.2930 - val_accuracy: 0.9560 - val_f1_m: 0.9908\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1s 103us/sample - loss: 0.0082 - accuracy: 0.9973 - f1_m: 0.9597 - val_loss: 0.3095 - val_accuracy: 0.9563 - val_f1_m: 0.9842\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 105us/sample - loss: 0.0058 - accuracy: 0.9983 - f1_m: 0.9562 - val_loss: 0.2961 - val_accuracy: 0.9554 - val_f1_m: 0.9895\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 103us/sample - loss: 0.0040 - accuracy: 0.9986 - f1_m: 0.9533 - val_loss: 0.2937 - val_accuracy: 0.9559 - val_f1_m: 0.9869\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 103us/sample - loss: 0.0025 - accuracy: 0.9993 - f1_m: 0.9526 - val_loss: 0.3262 - val_accuracy: 0.9496 - val_f1_m: 0.9894\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 0.0034 - accuracy: 0.9991 - f1_m: 0.9534 - val_loss: 0.3022 - val_accuracy: 0.9563 - val_f1_m: 0.9834\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 159us/sample - loss: 0.0124 - accuracy: 0.9975 - f1_m: 0.9530 - val_loss: 0.1866 - val_accuracy: 0.9716 - val_f1_m: 0.9700\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 118us/sample - loss: 0.0088 - accuracy: 0.9978 - f1_m: 0.9527 - val_loss: 0.1710 - val_accuracy: 0.9756 - val_f1_m: 0.9654\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1s 113us/sample - loss: 0.0071 - accuracy: 0.9979 - f1_m: 0.9515 - val_loss: 0.2127 - val_accuracy: 0.9709 - val_f1_m: 0.9705\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 112us/sample - loss: 0.0102 - accuracy: 0.9968 - f1_m: 0.9538 - val_loss: 0.2094 - val_accuracy: 0.9681 - val_f1_m: 0.9722\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 116us/sample - loss: 0.0042 - accuracy: 0.9981 - f1_m: 0.9525 - val_loss: 0.1854 - val_accuracy: 0.9729 - val_f1_m: 0.9665\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1s 118us/sample - loss: 6.0720e-04 - accuracy: 0.9999 - f1_m: 0.9485 - val_loss: 0.1738 - val_accuracy: 0.9740 - val_f1_m: 0.9673\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 119us/sample - loss: 2.4494e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1755 - val_accuracy: 0.9739 - val_f1_m: 0.9686\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 114us/sample - loss: 1.8722e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1731 - val_accuracy: 0.9746 - val_f1_m: 0.9659\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 115us/sample - loss: 1.1572e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1733 - val_accuracy: 0.9745 - val_f1_m: 0.9656\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1s 115us/sample - loss: 9.4449e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1738 - val_accuracy: 0.9753 - val_f1_m: 0.9669\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 205us/sample - loss: 0.0101 - accuracy: 0.9978 - f1_m: 0.9519 - val_loss: 0.1340 - val_accuracy: 0.9780 - val_f1_m: 0.9643\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 2s 142us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9504 - val_loss: 0.1339 - val_accuracy: 0.9780 - val_f1_m: 0.9633\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 141us/sample - loss: 0.0053 - accuracy: 0.9984 - f1_m: 0.9510 - val_loss: 0.1386 - val_accuracy: 0.9756 - val_f1_m: 0.9730\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 140us/sample - loss: 0.0058 - accuracy: 0.9979 - f1_m: 0.9523 - val_loss: 0.1321 - val_accuracy: 0.9786 - val_f1_m: 0.9661\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 2s 142us/sample - loss: 3.0856e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1436 - val_accuracy: 0.9794 - val_f1_m: 0.9624\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 142us/sample - loss: 1.1156e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1421 - val_accuracy: 0.9799 - val_f1_m: 0.9622\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 2s 140us/sample - loss: 3.1568e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1421 - val_accuracy: 0.9809 - val_f1_m: 0.9627\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 142us/sample - loss: 1.9671e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1429 - val_accuracy: 0.9810 - val_f1_m: 0.9619\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 2s 142us/sample - loss: 1.5044e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1441 - val_accuracy: 0.9814 - val_f1_m: 0.9615\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 140us/sample - loss: 1.1927e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1453 - val_accuracy: 0.9811 - val_f1_m: 0.9612\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 3s 259us/sample - loss: 0.0179 - accuracy: 0.9957 - f1_m: 0.9551 - val_loss: 0.1067 - val_accuracy: 0.9745 - val_f1_m: 0.9769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 2s 186us/sample - loss: 0.0073 - accuracy: 0.9979 - f1_m: 0.9534 - val_loss: 0.1130 - val_accuracy: 0.9784 - val_f1_m: 0.9695\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 181us/sample - loss: 0.0054 - accuracy: 0.9989 - f1_m: 0.9510 - val_loss: 0.1287 - val_accuracy: 0.9799 - val_f1_m: 0.9646\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 181us/sample - loss: 3.5014e-04 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.1392 - val_accuracy: 0.9810 - val_f1_m: 0.9586\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 2s 183us/sample - loss: 4.5327e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1451 - val_accuracy: 0.9810 - val_f1_m: 0.9577\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 184us/sample - loss: 1.5209e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1494 - val_accuracy: 0.9809 - val_f1_m: 0.9576\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 2s 184us/sample - loss: 1.0347e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1524 - val_accuracy: 0.9805 - val_f1_m: 0.9572\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 182us/sample - loss: 7.6234e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1555 - val_accuracy: 0.9805 - val_f1_m: 0.9567\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 2s 182us/sample - loss: 5.7253e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1582 - val_accuracy: 0.9805 - val_f1_m: 0.9567\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 183us/sample - loss: 4.3591e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1609 - val_accuracy: 0.9805 - val_f1_m: 0.9564\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 146us/sample - loss: 0.0195 - accuracy: 0.9969 - f1_m: 0.9538 - val_loss: 0.2308 - val_accuracy: 0.9609 - val_f1_m: 0.9817\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 103us/sample - loss: 0.0109 - accuracy: 0.9973 - f1_m: 0.9538 - val_loss: 0.2473 - val_accuracy: 0.9574 - val_f1_m: 0.9827\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1s 105us/sample - loss: 0.0054 - accuracy: 0.9988 - f1_m: 0.9515 - val_loss: 0.2124 - val_accuracy: 0.9628 - val_f1_m: 0.9764\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 104us/sample - loss: 0.0012 - accuracy: 0.9999 - f1_m: 0.9488 - val_loss: 0.2121 - val_accuracy: 0.9638 - val_f1_m: 0.9792\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 0.0017 - accuracy: 0.9994 - f1_m: 0.9494 - val_loss: 0.2492 - val_accuracy: 0.9579 - val_f1_m: 0.9781\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 0.0097 - accuracy: 0.9967 - f1_m: 0.9552 - val_loss: 0.2165 - val_accuracy: 0.9625 - val_f1_m: 0.9851\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 103us/sample - loss: 0.0031 - accuracy: 0.9993 - f1_m: 0.9507 - val_loss: 0.2186 - val_accuracy: 0.9635 - val_f1_m: 0.9829\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 104us/sample - loss: 5.8183e-04 - accuracy: 1.0000 - f1_m: 0.9484 - val_loss: 0.2303 - val_accuracy: 0.9628 - val_f1_m: 0.9778\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 103us/sample - loss: 2.0755e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2081 - val_accuracy: 0.9663 - val_f1_m: 0.9767\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1s 102us/sample - loss: 8.0351e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2084 - val_accuracy: 0.9657 - val_f1_m: 0.9767\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 161us/sample - loss: 0.0116 - accuracy: 0.9972 - f1_m: 0.9517 - val_loss: 0.1045 - val_accuracy: 0.9791 - val_f1_m: 0.9691\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1s 120us/sample - loss: 0.0034 - accuracy: 0.9988 - f1_m: 0.9506 - val_loss: 0.1015 - val_accuracy: 0.9818 - val_f1_m: 0.9641\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1s 119us/sample - loss: 1.3525e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.0991 - val_accuracy: 0.9825 - val_f1_m: 0.9626\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1s 116us/sample - loss: 4.4805e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.0995 - val_accuracy: 0.9826 - val_f1_m: 0.9622\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1s 122us/sample - loss: 3.0535e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1003 - val_accuracy: 0.9827 - val_f1_m: 0.9617\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1s 117us/sample - loss: 2.2699e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1012 - val_accuracy: 0.9827 - val_f1_m: 0.9620\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1s 120us/sample - loss: 1.7170e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1022 - val_accuracy: 0.9827 - val_f1_m: 0.9619\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1s 116us/sample - loss: 1.3459e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1034 - val_accuracy: 0.9826 - val_f1_m: 0.9620\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1s 118us/sample - loss: 1.0688e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1043 - val_accuracy: 0.9824 - val_f1_m: 0.9615\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 126us/sample - loss: 8.5528e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1054 - val_accuracy: 0.9826 - val_f1_m: 0.9614\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 2s 203us/sample - loss: 0.0101 - accuracy: 0.9984 - f1_m: 0.9502 - val_loss: 0.0774 - val_accuracy: 0.9800 - val_f1_m: 0.9734\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 2s 153us/sample - loss: 0.0021 - accuracy: 0.9991 - f1_m: 0.9496 - val_loss: 0.0901 - val_accuracy: 0.9816 - val_f1_m: 0.9644\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 163us/sample - loss: 1.1896e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.0952 - val_accuracy: 0.9834 - val_f1_m: 0.9646\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 148us/sample - loss: 1.3620e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.0981 - val_accuracy: 0.9829 - val_f1_m: 0.9643\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 2s 154us/sample - loss: 7.5156e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1004 - val_accuracy: 0.9830 - val_f1_m: 0.9645\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 156us/sample - loss: 4.9813e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1036 - val_accuracy: 0.9839 - val_f1_m: 0.9629\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 2s 156us/sample - loss: 3.4134e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1074 - val_accuracy: 0.9837 - val_f1_m: 0.9614\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 146us/sample - loss: 2.1999e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1136 - val_accuracy: 0.9829 - val_f1_m: 0.9605\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 2s 155us/sample - loss: 1.3518e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1227 - val_accuracy: 0.9833 - val_f1_m: 0.9595\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 153us/sample - loss: 8.1416e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1315 - val_accuracy: 0.9831 - val_f1_m: 0.9586\n",
      "Train on 12000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 3s 281us/sample - loss: 0.0159 - accuracy: 0.9970 - f1_m: 0.9509 - val_loss: 0.1234 - val_accuracy: 0.9796 - val_f1_m: 0.9674\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 3s 211us/sample - loss: 0.0081 - accuracy: 0.9980 - f1_m: 0.9512 - val_loss: 0.1076 - val_accuracy: 0.9847 - val_f1_m: 0.9605\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 2s 204us/sample - loss: 2.5433e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1219 - val_accuracy: 0.9843 - val_f1_m: 0.9612\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 2s 201us/sample - loss: 8.7658e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1232 - val_accuracy: 0.9844 - val_f1_m: 0.9608\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 3s 224us/sample - loss: 2.1826e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1262 - val_accuracy: 0.9854 - val_f1_m: 0.9608\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 2s 200us/sample - loss: 7.3936e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1271 - val_accuracy: 0.9856 - val_f1_m: 0.9602\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 3s 233us/sample - loss: 4.8041e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1280 - val_accuracy: 0.9856 - val_f1_m: 0.9598\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 2s 200us/sample - loss: 3.5615e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1289 - val_accuracy: 0.9858 - val_f1_m: 0.9596\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 3s 209us/sample - loss: 2.7151e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1299 - val_accuracy: 0.9858 - val_f1_m: 0.9593\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 2s 201us/sample - loss: 2.1142e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1309 - val_accuracy: 0.9858 - val_f1_m: 0.9584\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 3s 201us/sample - loss: 0.0189 - accuracy: 0.9960 - f1_m: 0.9581 - val_loss: 0.2899 - val_accuracy: 0.9539 - val_f1_m: 0.9886\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 125us/sample - loss: 0.0098 - accuracy: 0.9974 - f1_m: 0.9561 - val_loss: 0.2784 - val_accuracy: 0.9555 - val_f1_m: 0.9866\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 1s 110us/sample - loss: 0.0046 - accuracy: 0.9993 - f1_m: 0.9528 - val_loss: 0.2793 - val_accuracy: 0.9583 - val_f1_m: 0.9832\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 124us/sample - loss: 0.0048 - accuracy: 0.9991 - f1_m: 0.9544 - val_loss: 0.3009 - val_accuracy: 0.9540 - val_f1_m: 0.9838\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 128us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9559 - val_loss: 0.3244 - val_accuracy: 0.9515 - val_f1_m: 0.9906\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 130us/sample - loss: 0.0071 - accuracy: 0.9977 - f1_m: 0.9576 - val_loss: 0.2791 - val_accuracy: 0.9599 - val_f1_m: 0.9797\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 127us/sample - loss: 0.0019 - accuracy: 0.9997 - f1_m: 0.9508 - val_loss: 0.3034 - val_accuracy: 0.9533 - val_f1_m: 0.9886\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 136us/sample - loss: 0.0029 - accuracy: 0.9993 - f1_m: 0.9525 - val_loss: 0.3085 - val_accuracy: 0.9545 - val_f1_m: 0.9857\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 1s 117us/sample - loss: 0.0045 - accuracy: 0.9989 - f1_m: 0.9554 - val_loss: 0.2989 - val_accuracy: 0.9561 - val_f1_m: 0.9842\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 1s 110us/sample - loss: 0.0022 - accuracy: 0.9997 - f1_m: 0.9518 - val_loss: 0.2896 - val_accuracy: 0.9579 - val_f1_m: 0.9841\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 179us/sample - loss: 0.0142 - accuracy: 0.9970 - f1_m: 0.9538 - val_loss: 0.1940 - val_accuracy: 0.9717 - val_f1_m: 0.9682\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 135us/sample - loss: 0.0071 - accuracy: 0.9985 - f1_m: 0.9516 - val_loss: 0.1769 - val_accuracy: 0.9729 - val_f1_m: 0.9694\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 123us/sample - loss: 0.0074 - accuracy: 0.9977 - f1_m: 0.9531 - val_loss: 0.2123 - val_accuracy: 0.9701 - val_f1_m: 0.9709\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 124us/sample - loss: 0.0059 - accuracy: 0.9981 - f1_m: 0.9528 - val_loss: 0.2178 - val_accuracy: 0.9684 - val_f1_m: 0.9711\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 121us/sample - loss: 0.0040 - accuracy: 0.9988 - f1_m: 0.9518 - val_loss: 0.1868 - val_accuracy: 0.9729 - val_f1_m: 0.9683\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 124us/sample - loss: 8.4876e-04 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.1765 - val_accuracy: 0.9739 - val_f1_m: 0.9704\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 121us/sample - loss: 2.8648e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1789 - val_accuracy: 0.9739 - val_f1_m: 0.9689\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 129us/sample - loss: 1.1262e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1809 - val_accuracy: 0.9741 - val_f1_m: 0.9679\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 128us/sample - loss: 8.9344e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1815 - val_accuracy: 0.9740 - val_f1_m: 0.9683\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 126us/sample - loss: 7.5451e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1819 - val_accuracy: 0.9739 - val_f1_m: 0.9681\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 3s 206us/sample - loss: 0.0135 - accuracy: 0.9976 - f1_m: 0.9503 - val_loss: 0.1143 - val_accuracy: 0.9797 - val_f1_m: 0.9638\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 151us/sample - loss: 0.0018 - accuracy: 0.9997 - f1_m: 0.9497 - val_loss: 0.1234 - val_accuracy: 0.9813 - val_f1_m: 0.9640\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 149us/sample - loss: 0.0015 - accuracy: 0.9992 - f1_m: 0.9498 - val_loss: 0.1361 - val_accuracy: 0.9791 - val_f1_m: 0.9626\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 149us/sample - loss: 0.0119 - accuracy: 0.9962 - f1_m: 0.9549 - val_loss: 0.1268 - val_accuracy: 0.9800 - val_f1_m: 0.9649\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 151us/sample - loss: 0.0035 - accuracy: 0.9988 - f1_m: 0.9506 - val_loss: 0.1620 - val_accuracy: 0.9795 - val_f1_m: 0.9621\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 150us/sample - loss: 6.7051e-04 - accuracy: 0.9999 - f1_m: 0.9490 - val_loss: 0.1606 - val_accuracy: 0.9820 - val_f1_m: 0.9617\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 150us/sample - loss: 0.0117 - accuracy: 0.9971 - f1_m: 0.9516 - val_loss: 0.1224 - val_accuracy: 0.9756 - val_f1_m: 0.9702\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 152us/sample - loss: 0.0014 - accuracy: 0.9995 - f1_m: 0.9493 - val_loss: 0.1269 - val_accuracy: 0.9821 - val_f1_m: 0.9614\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 153us/sample - loss: 0.0034 - accuracy: 0.9987 - f1_m: 0.9511 - val_loss: 0.1317 - val_accuracy: 0.9816 - val_f1_m: 0.9612\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 152us/sample - loss: 0.0119 - accuracy: 0.9965 - f1_m: 0.9526 - val_loss: 0.1533 - val_accuracy: 0.9764 - val_f1_m: 0.9651\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 3s 267us/sample - loss: 0.0102 - accuracy: 0.9976 - f1_m: 0.9505 - val_loss: 0.1533 - val_accuracy: 0.9777 - val_f1_m: 0.9644\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 195us/sample - loss: 0.0123 - accuracy: 0.9962 - f1_m: 0.9531 - val_loss: 0.1284 - val_accuracy: 0.9760 - val_f1_m: 0.9683\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 3s 204us/sample - loss: 0.0088 - accuracy: 0.9976 - f1_m: 0.9530 - val_loss: 0.1305 - val_accuracy: 0.9788 - val_f1_m: 0.9640\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 3s 207us/sample - loss: 0.0058 - accuracy: 0.9981 - f1_m: 0.9530 - val_loss: 0.1300 - val_accuracy: 0.9773 - val_f1_m: 0.9656\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 193us/sample - loss: 0.0068 - accuracy: 0.9981 - f1_m: 0.9520 - val_loss: 0.1356 - val_accuracy: 0.9785 - val_f1_m: 0.9650\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 188us/sample - loss: 0.0020 - accuracy: 0.9994 - f1_m: 0.9494 - val_loss: 0.1646 - val_accuracy: 0.9784 - val_f1_m: 0.9624\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 2s 186us/sample - loss: 9.2801e-04 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.1727 - val_accuracy: 0.9747 - val_f1_m: 0.9700\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 186us/sample - loss: 0.0206 - accuracy: 0.9941 - f1_m: 0.9565 - val_loss: 0.1335 - val_accuracy: 0.9752 - val_f1_m: 0.9720\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 186us/sample - loss: 0.0047 - accuracy: 0.9984 - f1_m: 0.9523 - val_loss: 0.1610 - val_accuracy: 0.9768 - val_f1_m: 0.9695\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 186us/sample - loss: 0.0091 - accuracy: 0.9973 - f1_m: 0.9524 - val_loss: 0.1447 - val_accuracy: 0.9765 - val_f1_m: 0.9681\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 148us/sample - loss: 0.0098 - accuracy: 0.9982 - f1_m: 0.9524 - val_loss: 0.2492 - val_accuracy: 0.9611 - val_f1_m: 0.9798\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 1s 110us/sample - loss: 0.0039 - accuracy: 0.9986 - f1_m: 0.9534 - val_loss: 0.2370 - val_accuracy: 0.9636 - val_f1_m: 0.9744\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 1s 108us/sample - loss: 7.5583e-04 - accuracy: 0.9998 - f1_m: 0.9489 - val_loss: 0.2201 - val_accuracy: 0.9648 - val_f1_m: 0.9750\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 1s 108us/sample - loss: 1.4944e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2239 - val_accuracy: 0.9663 - val_f1_m: 0.9768\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 1s 108us/sample - loss: 8.7561e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2190 - val_accuracy: 0.9656 - val_f1_m: 0.9748\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 1s 108us/sample - loss: 5.6069e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2200 - val_accuracy: 0.9663 - val_f1_m: 0.9750\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 130us/sample - loss: 4.6349e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2224 - val_accuracy: 0.9664 - val_f1_m: 0.9743\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 1s 112us/sample - loss: 3.9234e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2234 - val_accuracy: 0.9669 - val_f1_m: 0.9754\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 1s 114us/sample - loss: 3.3746e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2254 - val_accuracy: 0.9664 - val_f1_m: 0.9750\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 1s 112us/sample - loss: 2.8712e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2262 - val_accuracy: 0.9665 - val_f1_m: 0.9749\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2s 175us/sample - loss: 0.0116 - accuracy: 0.9981 - f1_m: 0.9508 - val_loss: 0.0907 - val_accuracy: 0.9809 - val_f1_m: 0.9732\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 126us/sample - loss: 0.0024 - accuracy: 0.9994 - f1_m: 0.9497 - val_loss: 0.0902 - val_accuracy: 0.9821 - val_f1_m: 0.9683\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 127us/sample - loss: 0.0010 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.0909 - val_accuracy: 0.9824 - val_f1_m: 0.9639\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 126us/sample - loss: 6.6151e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.0927 - val_accuracy: 0.9825 - val_f1_m: 0.9629\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 126us/sample - loss: 2.5924e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.0937 - val_accuracy: 0.9829 - val_f1_m: 0.9629\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 127us/sample - loss: 1.8910e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.0950 - val_accuracy: 0.9828 - val_f1_m: 0.9623\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 127us/sample - loss: 1.4450e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.0963 - val_accuracy: 0.9828 - val_f1_m: 0.9632\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 127us/sample - loss: 1.1420e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.0977 - val_accuracy: 0.9827 - val_f1_m: 0.9629\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 128us/sample - loss: 9.1872e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.0990 - val_accuracy: 0.9828 - val_f1_m: 0.9632\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 125us/sample - loss: 7.3039e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1004 - val_accuracy: 0.9827 - val_f1_m: 0.9620\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 3s 207us/sample - loss: 0.0104 - accuracy: 0.9978 - f1_m: 0.9505 - val_loss: 0.0890 - val_accuracy: 0.9825 - val_f1_m: 0.9658\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2s 154us/sample - loss: 0.0042 - accuracy: 0.9986 - f1_m: 0.9502 - val_loss: 0.1028 - val_accuracy: 0.9843 - val_f1_m: 0.9647\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2s 156us/sample - loss: 0.0026 - accuracy: 0.9991 - f1_m: 0.9498 - val_loss: 0.1147 - val_accuracy: 0.9840 - val_f1_m: 0.9606\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 2s 155us/sample - loss: 1.5152e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1218 - val_accuracy: 0.9839 - val_f1_m: 0.9608\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 2s 155us/sample - loss: 0.0010 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.1324 - val_accuracy: 0.9823 - val_f1_m: 0.9594\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 2s 154us/sample - loss: 0.0057 - accuracy: 0.9984 - f1_m: 0.9511 - val_loss: 0.1521 - val_accuracy: 0.9736 - val_f1_m: 0.9666\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 2s 155us/sample - loss: 0.0086 - accuracy: 0.9981 - f1_m: 0.9515 - val_loss: 0.1292 - val_accuracy: 0.9759 - val_f1_m: 0.9715\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 2s 155us/sample - loss: 0.0063 - accuracy: 0.9982 - f1_m: 0.9508 - val_loss: 0.1011 - val_accuracy: 0.9823 - val_f1_m: 0.9661\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 2s 154us/sample - loss: 5.2018e-04 - accuracy: 0.9998 - f1_m: 0.9485 - val_loss: 0.1107 - val_accuracy: 0.9828 - val_f1_m: 0.9617\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 2s 155us/sample - loss: 5.2785e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1085 - val_accuracy: 0.9833 - val_f1_m: 0.9601\n",
      "Train on 12500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 6s 449us/sample - loss: 0.0190 - accuracy: 0.9963 - f1_m: 0.9516 - val_loss: 0.1242 - val_accuracy: 0.9779 - val_f1_m: 0.9688\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 3s 202us/sample - loss: 0.0045 - accuracy: 0.9986 - f1_m: 0.9502 - val_loss: 0.1305 - val_accuracy: 0.9827 - val_f1_m: 0.9591\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 3s 203us/sample - loss: 0.0048 - accuracy: 0.9984 - f1_m: 0.9505 - val_loss: 0.1143 - val_accuracy: 0.9832 - val_f1_m: 0.9603\n",
      "Epoch 4/10\n",
      "12500/12500 [==============================] - 3s 204us/sample - loss: 0.0093 - accuracy: 0.9976 - f1_m: 0.9510 - val_loss: 0.1200 - val_accuracy: 0.9820 - val_f1_m: 0.9625\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 3s 203us/sample - loss: 0.0098 - accuracy: 0.9974 - f1_m: 0.9519 - val_loss: 0.1133 - val_accuracy: 0.9812 - val_f1_m: 0.9683\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 3s 205us/sample - loss: 0.0074 - accuracy: 0.9979 - f1_m: 0.9514 - val_loss: 0.1272 - val_accuracy: 0.9819 - val_f1_m: 0.9652\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 3s 203us/sample - loss: 0.0055 - accuracy: 0.9987 - f1_m: 0.9502 - val_loss: 0.1095 - val_accuracy: 0.9837 - val_f1_m: 0.9610\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 3s 202us/sample - loss: 0.0076 - accuracy: 0.9982 - f1_m: 0.9503 - val_loss: 0.1105 - val_accuracy: 0.9833 - val_f1_m: 0.9657\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 3s 204us/sample - loss: 0.0056 - accuracy: 0.9988 - f1_m: 0.9502 - val_loss: 0.1204 - val_accuracy: 0.9837 - val_f1_m: 0.9611\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 3s 202us/sample - loss: 3.5292e-04 - accuracy: 0.9999 - f1_m: 0.9484 - val_loss: 0.1213 - val_accuracy: 0.9841 - val_f1_m: 0.9579\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 145us/sample - loss: 0.0120 - accuracy: 0.9972 - f1_m: 0.9551 - val_loss: 0.2811 - val_accuracy: 0.9571 - val_f1_m: 0.9851\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 0.0054 - accuracy: 0.9981 - f1_m: 0.9550 - val_loss: 0.2953 - val_accuracy: 0.9540 - val_f1_m: 0.9841\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9535 - val_loss: 0.2809 - val_accuracy: 0.9563 - val_f1_m: 0.9840\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 9.2637e-04 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.2902 - val_accuracy: 0.9559 - val_f1_m: 0.9864\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 5.2264e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2838 - val_accuracy: 0.9571 - val_f1_m: 0.9814\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 3.7967e-04 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.2831 - val_accuracy: 0.9571 - val_f1_m: 0.9813\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 3.4288e-04 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.2835 - val_accuracy: 0.9571 - val_f1_m: 0.9809\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 2.9939e-04 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.2886 - val_accuracy: 0.9581 - val_f1_m: 0.9767\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 2.7016e-04 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.2869 - val_accuracy: 0.9583 - val_f1_m: 0.9796\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 2.4439e-04 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.2930 - val_accuracy: 0.9573 - val_f1_m: 0.9796\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 157us/sample - loss: 0.0125 - accuracy: 0.9968 - f1_m: 0.9523 - val_loss: 0.2049 - val_accuracy: 0.9721 - val_f1_m: 0.9678\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 117us/sample - loss: 0.0039 - accuracy: 0.9988 - f1_m: 0.9503 - val_loss: 0.2046 - val_accuracy: 0.9717 - val_f1_m: 0.9660\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 117us/sample - loss: 0.0050 - accuracy: 0.9982 - f1_m: 0.9508 - val_loss: 0.2036 - val_accuracy: 0.9710 - val_f1_m: 0.9728\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 0.0027 - accuracy: 0.9991 - f1_m: 0.9503 - val_loss: 0.1829 - val_accuracy: 0.9729 - val_f1_m: 0.9673\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 2.3808e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1815 - val_accuracy: 0.9743 - val_f1_m: 0.9660\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 117us/sample - loss: 1.1076e-04 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1818 - val_accuracy: 0.9746 - val_f1_m: 0.9663\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 7.9087e-05 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.1830 - val_accuracy: 0.9749 - val_f1_m: 0.9667\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 6.7723e-05 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1842 - val_accuracy: 0.9736 - val_f1_m: 0.9664\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 117us/sample - loss: 5.8868e-05 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1847 - val_accuracy: 0.9756 - val_f1_m: 0.9663\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 118us/sample - loss: 5.0021e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1878 - val_accuracy: 0.9731 - val_f1_m: 0.9670\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 3s 193us/sample - loss: 0.0044 - accuracy: 0.9986 - f1_m: 0.9503 - val_loss: 0.1608 - val_accuracy: 0.9746 - val_f1_m: 0.9688\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 0.0066 - accuracy: 0.9977 - f1_m: 0.9515 - val_loss: 0.1241 - val_accuracy: 0.9790 - val_f1_m: 0.9658\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 0.0033 - accuracy: 0.9990 - f1_m: 0.9496 - val_loss: 0.1157 - val_accuracy: 0.9816 - val_f1_m: 0.9656\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 0.0011 - accuracy: 0.9995 - f1_m: 0.9483 - val_loss: 0.1266 - val_accuracy: 0.9803 - val_f1_m: 0.9611\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 0.0089 - accuracy: 0.9983 - f1_m: 0.9499 - val_loss: 0.1548 - val_accuracy: 0.9739 - val_f1_m: 0.9696\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 142us/sample - loss: 0.0048 - accuracy: 0.9985 - f1_m: 0.9503 - val_loss: 0.2154 - val_accuracy: 0.9711 - val_f1_m: 0.9699\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 142us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9486 - val_loss: 0.1228 - val_accuracy: 0.9824 - val_f1_m: 0.9639\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 9.1254e-05 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1284 - val_accuracy: 0.9836 - val_f1_m: 0.9608\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 3.7662e-05 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1310 - val_accuracy: 0.9834 - val_f1_m: 0.9590\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 143us/sample - loss: 1.4866e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1319 - val_accuracy: 0.9837 - val_f1_m: 0.9578\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 3s 251us/sample - loss: 0.0111 - accuracy: 0.9972 - f1_m: 0.9527 - val_loss: 0.1443 - val_accuracy: 0.9779 - val_f1_m: 0.9660\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 185us/sample - loss: 0.0107 - accuracy: 0.9968 - f1_m: 0.9526 - val_loss: 0.1218 - val_accuracy: 0.9799 - val_f1_m: 0.9723\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 185us/sample - loss: 0.0052 - accuracy: 0.9983 - f1_m: 0.9510 - val_loss: 0.1781 - val_accuracy: 0.9733 - val_f1_m: 0.9662\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 184us/sample - loss: 0.0064 - accuracy: 0.9975 - f1_m: 0.9520 - val_loss: 0.1772 - val_accuracy: 0.9771 - val_f1_m: 0.9611\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 184us/sample - loss: 0.0070 - accuracy: 0.9982 - f1_m: 0.9519 - val_loss: 0.1312 - val_accuracy: 0.9806 - val_f1_m: 0.9672\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 184us/sample - loss: 0.0031 - accuracy: 0.9991 - f1_m: 0.9487 - val_loss: 0.1827 - val_accuracy: 0.9740 - val_f1_m: 0.9663\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 184us/sample - loss: 0.0174 - accuracy: 0.9952 - f1_m: 0.9554 - val_loss: 0.1402 - val_accuracy: 0.9736 - val_f1_m: 0.9742\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 184us/sample - loss: 0.0112 - accuracy: 0.9967 - f1_m: 0.9530 - val_loss: 0.1353 - val_accuracy: 0.9796 - val_f1_m: 0.9672\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 184us/sample - loss: 0.0095 - accuracy: 0.9967 - f1_m: 0.9522 - val_loss: 0.1126 - val_accuracy: 0.9796 - val_f1_m: 0.9641\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 182us/sample - loss: 0.0018 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.1662 - val_accuracy: 0.9753 - val_f1_m: 0.9635\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 145us/sample - loss: 0.0087 - accuracy: 0.9987 - f1_m: 0.9499 - val_loss: 0.2275 - val_accuracy: 0.9654 - val_f1_m: 0.9751\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 0.0038 - accuracy: 0.9992 - f1_m: 0.9499 - val_loss: 0.2262 - val_accuracy: 0.9661 - val_f1_m: 0.9809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 4.5686e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2344 - val_accuracy: 0.9633 - val_f1_m: 0.9737\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 0.0021 - accuracy: 0.9990 - f1_m: 0.9498 - val_loss: 0.2925 - val_accuracy: 0.9591 - val_f1_m: 0.9770\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 0.0099 - accuracy: 0.9963 - f1_m: 0.9545 - val_loss: 0.2341 - val_accuracy: 0.9640 - val_f1_m: 0.9787\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 0.0032 - accuracy: 0.9987 - f1_m: 0.9502 - val_loss: 0.2339 - val_accuracy: 0.9671 - val_f1_m: 0.9755\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 1s 106us/sample - loss: 9.2048e-04 - accuracy: 0.9998 - f1_m: 0.9477 - val_loss: 0.2142 - val_accuracy: 0.9681 - val_f1_m: 0.9758\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 9.1703e-05 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.2104 - val_accuracy: 0.9686 - val_f1_m: 0.9735\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 5.2721e-05 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.2117 - val_accuracy: 0.9680 - val_f1_m: 0.9728\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 1s 105us/sample - loss: 4.3277e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.2122 - val_accuracy: 0.9679 - val_f1_m: 0.9726\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 2s 169us/sample - loss: 0.0065 - accuracy: 0.9982 - f1_m: 0.9502 - val_loss: 0.1185 - val_accuracy: 0.9779 - val_f1_m: 0.9638\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 121us/sample - loss: 0.0047 - accuracy: 0.9986 - f1_m: 0.9506 - val_loss: 0.1148 - val_accuracy: 0.9807 - val_f1_m: 0.9647\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 123us/sample - loss: 0.0010 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 0.1095 - val_accuracy: 0.9811 - val_f1_m: 0.9635\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 123us/sample - loss: 0.0021 - accuracy: 0.9993 - f1_m: 0.9486 - val_loss: 0.1189 - val_accuracy: 0.9807 - val_f1_m: 0.9645\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 123us/sample - loss: 6.4478e-04 - accuracy: 0.9998 - f1_m: 0.9475 - val_loss: 0.1672 - val_accuracy: 0.9756 - val_f1_m: 0.9635\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 123us/sample - loss: 0.0034 - accuracy: 0.9992 - f1_m: 0.9490 - val_loss: 0.1128 - val_accuracy: 0.9803 - val_f1_m: 0.9646\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 123us/sample - loss: 0.0096 - accuracy: 0.9971 - f1_m: 0.9514 - val_loss: 0.1053 - val_accuracy: 0.9789 - val_f1_m: 0.9630\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 123us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9485 - val_loss: 0.1031 - val_accuracy: 0.9817 - val_f1_m: 0.9635\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 123us/sample - loss: 1.1701e-04 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.1050 - val_accuracy: 0.9820 - val_f1_m: 0.9615\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 124us/sample - loss: 2.5549e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1045 - val_accuracy: 0.9823 - val_f1_m: 0.9612\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 3s 201us/sample - loss: 0.0037 - accuracy: 0.9985 - f1_m: 0.9486 - val_loss: 0.1305 - val_accuracy: 0.9814 - val_f1_m: 0.9598\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 2s 151us/sample - loss: 0.0044 - accuracy: 0.9985 - f1_m: 0.9493 - val_loss: 0.1033 - val_accuracy: 0.9817 - val_f1_m: 0.9627\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 2s 151us/sample - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9489 - val_loss: 0.1209 - val_accuracy: 0.9821 - val_f1_m: 0.9619\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 2s 151us/sample - loss: 0.0045 - accuracy: 0.9987 - f1_m: 0.9495 - val_loss: 0.0973 - val_accuracy: 0.9836 - val_f1_m: 0.9639\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 2s 152us/sample - loss: 2.2017e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1035 - val_accuracy: 0.9836 - val_f1_m: 0.9618\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 2s 152us/sample - loss: 3.6669e-05 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1044 - val_accuracy: 0.9833 - val_f1_m: 0.9616\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 2s 150us/sample - loss: 9.2114e-06 - accuracy: 1.0000 - f1_m: 0.9469 - val_loss: 0.1057 - val_accuracy: 0.9844 - val_f1_m: 0.9611\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 2s 152us/sample - loss: 6.6549e-06 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1069 - val_accuracy: 0.9847 - val_f1_m: 0.9606\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 2s 151us/sample - loss: 5.0307e-06 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1082 - val_accuracy: 0.9850 - val_f1_m: 0.9606\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 2s 151us/sample - loss: 3.8599e-06 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1095 - val_accuracy: 0.9851 - val_f1_m: 0.9602\n",
      "Train on 13000 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "13000/13000 [==============================] - 3s 262us/sample - loss: 0.0084 - accuracy: 0.9978 - f1_m: 0.9497 - val_loss: 0.1340 - val_accuracy: 0.9803 - val_f1_m: 0.9615\n",
      "Epoch 2/10\n",
      "13000/13000 [==============================] - 3s 196us/sample - loss: 0.0047 - accuracy: 0.9984 - f1_m: 0.9499 - val_loss: 0.1271 - val_accuracy: 0.9859 - val_f1_m: 0.9611\n",
      "Epoch 3/10\n",
      "13000/13000 [==============================] - 3s 196us/sample - loss: 0.0042 - accuracy: 0.9985 - f1_m: 0.9498 - val_loss: 0.2069 - val_accuracy: 0.9799 - val_f1_m: 0.9600\n",
      "Epoch 4/10\n",
      "13000/13000 [==============================] - 3s 196us/sample - loss: 0.0203 - accuracy: 0.9958 - f1_m: 0.9529 - val_loss: 0.1033 - val_accuracy: 0.9803 - val_f1_m: 0.9766\n",
      "Epoch 5/10\n",
      "13000/13000 [==============================] - 3s 195us/sample - loss: 0.0038 - accuracy: 0.9991 - f1_m: 0.9496 - val_loss: 0.1229 - val_accuracy: 0.9821 - val_f1_m: 0.9615\n",
      "Epoch 6/10\n",
      "13000/13000 [==============================] - 3s 196us/sample - loss: 3.5346e-04 - accuracy: 0.9998 - f1_m: 0.9476 - val_loss: 0.1079 - val_accuracy: 0.9843 - val_f1_m: 0.9621\n",
      "Epoch 7/10\n",
      "13000/13000 [==============================] - 3s 196us/sample - loss: 8.0125e-05 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1113 - val_accuracy: 0.9841 - val_f1_m: 0.9600\n",
      "Epoch 8/10\n",
      "13000/13000 [==============================] - 3s 196us/sample - loss: 1.4194e-05 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1131 - val_accuracy: 0.9840 - val_f1_m: 0.9594\n",
      "Epoch 9/10\n",
      "13000/13000 [==============================] - 3s 195us/sample - loss: 9.6202e-06 - accuracy: 1.0000 - f1_m: 0.9468 - val_loss: 0.1147 - val_accuracy: 0.9840 - val_f1_m: 0.9588\n",
      "Epoch 10/10\n",
      "13000/13000 [==============================] - 3s 196us/sample - loss: 7.1179e-06 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1165 - val_accuracy: 0.9840 - val_f1_m: 0.9584\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 139us/sample - loss: 0.0133 - accuracy: 0.9979 - f1_m: 0.9538 - val_loss: 0.2934 - val_accuracy: 0.9558 - val_f1_m: 0.9823\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 1s 104us/sample - loss: 0.0091 - accuracy: 0.9979 - f1_m: 0.9540 - val_loss: 0.2933 - val_accuracy: 0.9554 - val_f1_m: 0.9816\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 1s 102us/sample - loss: 0.0047 - accuracy: 0.9990 - f1_m: 0.9518 - val_loss: 0.3108 - val_accuracy: 0.9546 - val_f1_m: 0.9801\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 0.0036 - accuracy: 0.9991 - f1_m: 0.9515 - val_loss: 0.2974 - val_accuracy: 0.9569 - val_f1_m: 0.9768\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 0.0026 - accuracy: 0.9995 - f1_m: 0.9501 - val_loss: 0.2930 - val_accuracy: 0.9589 - val_f1_m: 0.9812\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500/13500 [==============================] - 1s 103us/sample - loss: 6.7588e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2933 - val_accuracy: 0.9585 - val_f1_m: 0.9784\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 1s 102us/sample - loss: 4.1647e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2936 - val_accuracy: 0.9574 - val_f1_m: 0.9777\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 1s 102us/sample - loss: 3.9743e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2961 - val_accuracy: 0.9577 - val_f1_m: 0.9759\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 1s 101us/sample - loss: 2.6089e-04 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.3001 - val_accuracy: 0.9572 - val_f1_m: 0.9755\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 1s 102us/sample - loss: 2.3005e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2963 - val_accuracy: 0.9572 - val_f1_m: 0.9752\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 153us/sample - loss: 0.0108 - accuracy: 0.9977 - f1_m: 0.9509 - val_loss: 0.1932 - val_accuracy: 0.9725 - val_f1_m: 0.9664\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 114us/sample - loss: 0.0061 - accuracy: 0.9990 - f1_m: 0.9506 - val_loss: 0.1818 - val_accuracy: 0.9732 - val_f1_m: 0.9648\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 113us/sample - loss: 0.0053 - accuracy: 0.9986 - f1_m: 0.9513 - val_loss: 0.1883 - val_accuracy: 0.9737 - val_f1_m: 0.9647\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 113us/sample - loss: 0.0040 - accuracy: 0.9988 - f1_m: 0.9507 - val_loss: 0.1708 - val_accuracy: 0.9738 - val_f1_m: 0.9649\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 111us/sample - loss: 0.0030 - accuracy: 0.9994 - f1_m: 0.9489 - val_loss: 0.1813 - val_accuracy: 0.9728 - val_f1_m: 0.9655\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 112us/sample - loss: 0.0032 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1893 - val_accuracy: 0.9714 - val_f1_m: 0.9692\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 112us/sample - loss: 0.0101 - accuracy: 0.9969 - f1_m: 0.9544 - val_loss: 0.2088 - val_accuracy: 0.9715 - val_f1_m: 0.9711\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 114us/sample - loss: 0.0055 - accuracy: 0.9984 - f1_m: 0.9511 - val_loss: 0.2113 - val_accuracy: 0.9708 - val_f1_m: 0.9720\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 1s 111us/sample - loss: 0.0030 - accuracy: 0.9989 - f1_m: 0.9506 - val_loss: 0.1895 - val_accuracy: 0.9726 - val_f1_m: 0.9745\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 112us/sample - loss: 5.7194e-04 - accuracy: 1.0000 - f1_m: 0.9490 - val_loss: 0.1779 - val_accuracy: 0.9746 - val_f1_m: 0.9689\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 3s 186us/sample - loss: 0.0080 - accuracy: 0.9985 - f1_m: 0.9498 - val_loss: 0.1162 - val_accuracy: 0.9812 - val_f1_m: 0.9645\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 0.0021 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.1121 - val_accuracy: 0.9846 - val_f1_m: 0.9625\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 7.7631e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1179 - val_accuracy: 0.9848 - val_f1_m: 0.9616\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 147us/sample - loss: 2.9428e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1169 - val_accuracy: 0.9849 - val_f1_m: 0.9619\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 142us/sample - loss: 1.2676e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1191 - val_accuracy: 0.9849 - val_f1_m: 0.9612\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 9.2129e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1205 - val_accuracy: 0.9846 - val_f1_m: 0.9603\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 7.1392e-06 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1222 - val_accuracy: 0.9843 - val_f1_m: 0.9601\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 141us/sample - loss: 5.5126e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1237 - val_accuracy: 0.9846 - val_f1_m: 0.9596\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 140us/sample - loss: 4.3736e-06 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1256 - val_accuracy: 0.9846 - val_f1_m: 0.9598\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 139us/sample - loss: 3.4572e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1274 - val_accuracy: 0.9846 - val_f1_m: 0.9591\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 3s 241us/sample - loss: 0.0093 - accuracy: 0.9973 - f1_m: 0.9525 - val_loss: 0.1352 - val_accuracy: 0.9772 - val_f1_m: 0.9731\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 179us/sample - loss: 0.0137 - accuracy: 0.9964 - f1_m: 0.9543 - val_loss: 0.1380 - val_accuracy: 0.9780 - val_f1_m: 0.9672\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 184us/sample - loss: 0.0089 - accuracy: 0.9982 - f1_m: 0.9507 - val_loss: 0.1561 - val_accuracy: 0.9757 - val_f1_m: 0.9667\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 182us/sample - loss: 0.0097 - accuracy: 0.9964 - f1_m: 0.9521 - val_loss: 0.1353 - val_accuracy: 0.9809 - val_f1_m: 0.9665\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 184us/sample - loss: 0.0020 - accuracy: 0.9993 - f1_m: 0.9494 - val_loss: 0.1275 - val_accuracy: 0.9811 - val_f1_m: 0.9627\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 3s 190us/sample - loss: 0.0049 - accuracy: 0.9984 - f1_m: 0.9500 - val_loss: 0.1434 - val_accuracy: 0.9772 - val_f1_m: 0.9659\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 181us/sample - loss: 0.0109 - accuracy: 0.9959 - f1_m: 0.9539 - val_loss: 0.1527 - val_accuracy: 0.9755 - val_f1_m: 0.9664\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 181us/sample - loss: 0.0077 - accuracy: 0.9975 - f1_m: 0.9524 - val_loss: 0.1403 - val_accuracy: 0.9806 - val_f1_m: 0.9630\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 185us/sample - loss: 0.0054 - accuracy: 0.9981 - f1_m: 0.9504 - val_loss: 0.1406 - val_accuracy: 0.9812 - val_f1_m: 0.9628\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 181us/sample - loss: 0.0077 - accuracy: 0.9975 - f1_m: 0.9525 - val_loss: 0.1313 - val_accuracy: 0.9791 - val_f1_m: 0.9645\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 141us/sample - loss: 0.0107 - accuracy: 0.9979 - f1_m: 0.9512 - val_loss: 0.2553 - val_accuracy: 0.9572 - val_f1_m: 0.9846\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 0.0049 - accuracy: 0.9984 - f1_m: 0.9503 - val_loss: 0.2094 - val_accuracy: 0.9677 - val_f1_m: 0.9759\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 0.0020 - accuracy: 0.9996 - f1_m: 0.9482 - val_loss: 0.2368 - val_accuracy: 0.9623 - val_f1_m: 0.9836\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 1s 104us/sample - loss: 8.8069e-04 - accuracy: 0.9997 - f1_m: 0.9486 - val_loss: 0.2032 - val_accuracy: 0.9694 - val_f1_m: 0.9760\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 1s 104us/sample - loss: 8.5396e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2019 - val_accuracy: 0.9677 - val_f1_m: 0.9739\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 5.0343e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2025 - val_accuracy: 0.9685 - val_f1_m: 0.9759\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 4.1146e-05 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.2045 - val_accuracy: 0.9680 - val_f1_m: 0.9746\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 1s 104us/sample - loss: 3.3393e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2058 - val_accuracy: 0.9682 - val_f1_m: 0.9740\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 2.8574e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.2080 - val_accuracy: 0.9678 - val_f1_m: 0.9738\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 1s 103us/sample - loss: 2.4524e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2092 - val_accuracy: 0.9678 - val_f1_m: 0.9726\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 2s 161us/sample - loss: 0.0049 - accuracy: 0.9989 - f1_m: 0.9495 - val_loss: 0.1379 - val_accuracy: 0.9789 - val_f1_m: 0.9615\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 120us/sample - loss: 0.0048 - accuracy: 0.9988 - f1_m: 0.9495 - val_loss: 0.1148 - val_accuracy: 0.9811 - val_f1_m: 0.9660\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 120us/sample - loss: 5.1293e-04 - accuracy: 0.9998 - f1_m: 0.9482 - val_loss: 0.1121 - val_accuracy: 0.9828 - val_f1_m: 0.9602\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 122us/sample - loss: 2.7084e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1115 - val_accuracy: 0.9828 - val_f1_m: 0.9611\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 121us/sample - loss: 1.6112e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1117 - val_accuracy: 0.9826 - val_f1_m: 0.9608\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 122us/sample - loss: 1.1714e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1123 - val_accuracy: 0.9826 - val_f1_m: 0.9595\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 121us/sample - loss: 8.8848e-06 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1129 - val_accuracy: 0.9829 - val_f1_m: 0.9598\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 120us/sample - loss: 6.9349e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1139 - val_accuracy: 0.9831 - val_f1_m: 0.9600\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 121us/sample - loss: 5.4440e-06 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1145 - val_accuracy: 0.9829 - val_f1_m: 0.9603\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 122us/sample - loss: 4.3726e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1155 - val_accuracy: 0.9829 - val_f1_m: 0.9597\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 3s 195us/sample - loss: 0.0062 - accuracy: 0.9984 - f1_m: 0.9493 - val_loss: 0.1551 - val_accuracy: 0.9812 - val_f1_m: 0.9605\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 2s 147us/sample - loss: 0.0046 - accuracy: 0.9988 - f1_m: 0.9492 - val_loss: 0.1487 - val_accuracy: 0.9786 - val_f1_m: 0.9665\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 2s 145us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9490 - val_loss: 0.1366 - val_accuracy: 0.9838 - val_f1_m: 0.9631\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 2s 149us/sample - loss: 0.0035 - accuracy: 0.9991 - f1_m: 0.9489 - val_loss: 0.1374 - val_accuracy: 0.9820 - val_f1_m: 0.9615\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 2s 147us/sample - loss: 0.0019 - accuracy: 0.9993 - f1_m: 0.9480 - val_loss: 0.1106 - val_accuracy: 0.9858 - val_f1_m: 0.9636\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 2s 147us/sample - loss: 4.1577e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1158 - val_accuracy: 0.9849 - val_f1_m: 0.9625\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 2s 147us/sample - loss: 9.1075e-06 - accuracy: 1.0000 - f1_m: 0.9470 - val_loss: 0.1157 - val_accuracy: 0.9862 - val_f1_m: 0.9619\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 2s 148us/sample - loss: 5.4317e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1166 - val_accuracy: 0.9862 - val_f1_m: 0.9619\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 2s 147us/sample - loss: 4.0183e-06 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1176 - val_accuracy: 0.9862 - val_f1_m: 0.9614\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 2s 147us/sample - loss: 3.0949e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1186 - val_accuracy: 0.9860 - val_f1_m: 0.9619\n",
      "Train on 13500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 3s 259us/sample - loss: 0.0106 - accuracy: 0.9979 - f1_m: 0.9493 - val_loss: 0.1334 - val_accuracy: 0.9791 - val_f1_m: 0.9672\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 3s 193us/sample - loss: 0.0036 - accuracy: 0.9987 - f1_m: 0.9501 - val_loss: 0.1318 - val_accuracy: 0.9837 - val_f1_m: 0.9579\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 3s 194us/sample - loss: 0.0031 - accuracy: 0.9990 - f1_m: 0.9490 - val_loss: 0.2299 - val_accuracy: 0.9800 - val_f1_m: 0.9592\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 3s 194us/sample - loss: 0.0236 - accuracy: 0.9943 - f1_m: 0.9527 - val_loss: 0.1268 - val_accuracy: 0.9840 - val_f1_m: 0.9646\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 3s 194us/sample - loss: 0.0059 - accuracy: 0.9983 - f1_m: 0.9512 - val_loss: 0.1344 - val_accuracy: 0.9846 - val_f1_m: 0.9616\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 3s 194us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9478 - val_loss: 0.1362 - val_accuracy: 0.9845 - val_f1_m: 0.9582\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 3s 194us/sample - loss: 0.0077 - accuracy: 0.9984 - f1_m: 0.9494 - val_loss: 0.1813 - val_accuracy: 0.9774 - val_f1_m: 0.9605\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 3s 194us/sample - loss: 0.0105 - accuracy: 0.9968 - f1_m: 0.9506 - val_loss: 0.1621 - val_accuracy: 0.9797 - val_f1_m: 0.9607\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 3s 193us/sample - loss: 0.0075 - accuracy: 0.9978 - f1_m: 0.9507 - val_loss: 0.1653 - val_accuracy: 0.9835 - val_f1_m: 0.9598\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 3s 195us/sample - loss: 0.0030 - accuracy: 0.9993 - f1_m: 0.9486 - val_loss: 0.1446 - val_accuracy: 0.9828 - val_f1_m: 0.9595\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 135us/sample - loss: 0.0122 - accuracy: 0.9974 - f1_m: 0.9537 - val_loss: 0.2863 - val_accuracy: 0.9578 - val_f1_m: 0.9779\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 1s 100us/sample - loss: 0.0074 - accuracy: 0.9983 - f1_m: 0.9541 - val_loss: 0.3052 - val_accuracy: 0.9572 - val_f1_m: 0.9798\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 1s 99us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9516 - val_loss: 0.3100 - val_accuracy: 0.9582 - val_f1_m: 0.9834\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 1s 100us/sample - loss: 0.0054 - accuracy: 0.9984 - f1_m: 0.9555 - val_loss: 0.3085 - val_accuracy: 0.9568 - val_f1_m: 0.9830\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 1s 99us/sample - loss: 0.0030 - accuracy: 0.9991 - f1_m: 0.9516 - val_loss: 0.3078 - val_accuracy: 0.9562 - val_f1_m: 0.9809\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 1s 101us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9515 - val_loss: 0.2918 - val_accuracy: 0.9567 - val_f1_m: 0.9745\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 1s 99us/sample - loss: 6.7342e-04 - accuracy: 0.9999 - f1_m: 0.9485 - val_loss: 0.3050 - val_accuracy: 0.9558 - val_f1_m: 0.9737\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 1s 101us/sample - loss: 3.8503e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2891 - val_accuracy: 0.9580 - val_f1_m: 0.9765\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 1s 100us/sample - loss: 2.6025e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2886 - val_accuracy: 0.9588 - val_f1_m: 0.9757\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 1s 99us/sample - loss: 2.2702e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2911 - val_accuracy: 0.9588 - val_f1_m: 0.9750\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 149us/sample - loss: 0.0096 - accuracy: 0.9978 - f1_m: 0.9516 - val_loss: 0.1842 - val_accuracy: 0.9738 - val_f1_m: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 111us/sample - loss: 0.0046 - accuracy: 0.9986 - f1_m: 0.9509 - val_loss: 0.1774 - val_accuracy: 0.9752 - val_f1_m: 0.9689\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 112us/sample - loss: 0.0050 - accuracy: 0.9983 - f1_m: 0.9512 - val_loss: 0.1813 - val_accuracy: 0.9760 - val_f1_m: 0.9664\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 110us/sample - loss: 0.0043 - accuracy: 0.9986 - f1_m: 0.9516 - val_loss: 0.1635 - val_accuracy: 0.9755 - val_f1_m: 0.9664\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 110us/sample - loss: 0.0040 - accuracy: 0.9984 - f1_m: 0.9512 - val_loss: 0.1964 - val_accuracy: 0.9732 - val_f1_m: 0.9692\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 109us/sample - loss: 0.0040 - accuracy: 0.9984 - f1_m: 0.9527 - val_loss: 0.2146 - val_accuracy: 0.9733 - val_f1_m: 0.9692\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 109us/sample - loss: 0.0022 - accuracy: 0.9992 - f1_m: 0.9496 - val_loss: 0.2149 - val_accuracy: 0.9697 - val_f1_m: 0.9732\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 109us/sample - loss: 0.0077 - accuracy: 0.9978 - f1_m: 0.9523 - val_loss: 0.1635 - val_accuracy: 0.9752 - val_f1_m: 0.9653\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 109us/sample - loss: 5.2349e-04 - accuracy: 0.9999 - f1_m: 0.9482 - val_loss: 0.1697 - val_accuracy: 0.9780 - val_f1_m: 0.9643\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 108us/sample - loss: 1.3165e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1696 - val_accuracy: 0.9760 - val_f1_m: 0.9662\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 5s 360us/sample - loss: 0.0091 - accuracy: 0.9984 - f1_m: 0.9493 - val_loss: 0.1489 - val_accuracy: 0.9777 - val_f1_m: 0.9651\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 0.0034 - accuracy: 0.9991 - f1_m: 0.9499 - val_loss: 0.0993 - val_accuracy: 0.9858 - val_f1_m: 0.9603\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 136us/sample - loss: 0.0022 - accuracy: 0.9994 - f1_m: 0.9479 - val_loss: 0.1677 - val_accuracy: 0.9783 - val_f1_m: 0.9660\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 138us/sample - loss: 0.0111 - accuracy: 0.9968 - f1_m: 0.9520 - val_loss: 0.1669 - val_accuracy: 0.9782 - val_f1_m: 0.9610\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 138us/sample - loss: 0.0030 - accuracy: 0.9989 - f1_m: 0.9494 - val_loss: 0.1405 - val_accuracy: 0.9805 - val_f1_m: 0.9606\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 2.8238e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1605 - val_accuracy: 0.9782 - val_f1_m: 0.9635\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 3.9188e-04 - accuracy: 0.9999 - f1_m: 0.9481 - val_loss: 0.1428 - val_accuracy: 0.9820 - val_f1_m: 0.9595\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 5.0193e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1336 - val_accuracy: 0.9843 - val_f1_m: 0.9605\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 8.7342e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1350 - val_accuracy: 0.9838 - val_f1_m: 0.9605\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 138us/sample - loss: 6.8185e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1362 - val_accuracy: 0.9838 - val_f1_m: 0.9600\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 3s 239us/sample - loss: 0.0113 - accuracy: 0.9969 - f1_m: 0.9527 - val_loss: 0.1074 - val_accuracy: 0.9815 - val_f1_m: 0.9695\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 179us/sample - loss: 0.0042 - accuracy: 0.9986 - f1_m: 0.9510 - val_loss: 0.1284 - val_accuracy: 0.9795 - val_f1_m: 0.9638\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 177us/sample - loss: 0.0135 - accuracy: 0.9957 - f1_m: 0.9530 - val_loss: 0.1645 - val_accuracy: 0.9760 - val_f1_m: 0.9669\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 175us/sample - loss: 0.0059 - accuracy: 0.9978 - f1_m: 0.9519 - val_loss: 0.1280 - val_accuracy: 0.9800 - val_f1_m: 0.9624\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 176us/sample - loss: 0.0010 - accuracy: 0.9997 - f1_m: 0.9486 - val_loss: 0.1672 - val_accuracy: 0.9818 - val_f1_m: 0.9602\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 177us/sample - loss: 0.0124 - accuracy: 0.9968 - f1_m: 0.9534 - val_loss: 0.1308 - val_accuracy: 0.9792 - val_f1_m: 0.9669\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 176us/sample - loss: 0.0052 - accuracy: 0.9981 - f1_m: 0.9521 - val_loss: 0.1519 - val_accuracy: 0.9795 - val_f1_m: 0.9661\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 177us/sample - loss: 0.0036 - accuracy: 0.9987 - f1_m: 0.9505 - val_loss: 0.1554 - val_accuracy: 0.9805 - val_f1_m: 0.9616\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 177us/sample - loss: 0.0087 - accuracy: 0.9969 - f1_m: 0.9518 - val_loss: 0.1688 - val_accuracy: 0.9805 - val_f1_m: 0.9620\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 177us/sample - loss: 0.0111 - accuracy: 0.9966 - f1_m: 0.9538 - val_loss: 0.1536 - val_accuracy: 0.9783 - val_f1_m: 0.9673\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 137us/sample - loss: 0.0109 - accuracy: 0.9977 - f1_m: 0.9512 - val_loss: 0.2274 - val_accuracy: 0.9648 - val_f1_m: 0.9737\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 1s 101us/sample - loss: 0.0030 - accuracy: 0.9994 - f1_m: 0.9497 - val_loss: 0.2260 - val_accuracy: 0.9642 - val_f1_m: 0.9748\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 1s 101us/sample - loss: 0.0056 - accuracy: 0.9985 - f1_m: 0.9504 - val_loss: 0.2392 - val_accuracy: 0.9643 - val_f1_m: 0.9724\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 1s 100us/sample - loss: 0.0029 - accuracy: 0.9992 - f1_m: 0.9494 - val_loss: 0.2182 - val_accuracy: 0.9667 - val_f1_m: 0.9740\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 1s 101us/sample - loss: 0.0024 - accuracy: 0.9991 - f1_m: 0.9492 - val_loss: 0.2126 - val_accuracy: 0.9675 - val_f1_m: 0.9761\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 1s 100us/sample - loss: 3.4585e-04 - accuracy: 0.9999 - f1_m: 0.9476 - val_loss: 0.2152 - val_accuracy: 0.9657 - val_f1_m: 0.9705\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 1s 100us/sample - loss: 4.6494e-04 - accuracy: 0.9999 - f1_m: 0.9475 - val_loss: 0.2166 - val_accuracy: 0.9658 - val_f1_m: 0.9709\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 1s 101us/sample - loss: 2.5059e-04 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 0.2184 - val_accuracy: 0.9662 - val_f1_m: 0.9703\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 1s 100us/sample - loss: 5.6576e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2148 - val_accuracy: 0.9668 - val_f1_m: 0.9704\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 1s 101us/sample - loss: 2.9961e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2140 - val_accuracy: 0.9663 - val_f1_m: 0.9706\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 2s 157us/sample - loss: 0.0075 - accuracy: 0.9987 - f1_m: 0.9493 - val_loss: 0.1342 - val_accuracy: 0.9817 - val_f1_m: 0.9623\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 116us/sample - loss: 1.5668e-04 - accuracy: 0.9999 - f1_m: 0.9475 - val_loss: 0.1207 - val_accuracy: 0.9827 - val_f1_m: 0.9594\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 116us/sample - loss: 1.1617e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1257 - val_accuracy: 0.9817 - val_f1_m: 0.9614\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 118us/sample - loss: 1.7926e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1309 - val_accuracy: 0.9818 - val_f1_m: 0.9595\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 117us/sample - loss: 9.4744e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1249 - val_accuracy: 0.9822 - val_f1_m: 0.9603\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 119us/sample - loss: 4.4856e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1242 - val_accuracy: 0.9815 - val_f1_m: 0.9604\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 118us/sample - loss: 3.4667e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1240 - val_accuracy: 0.9815 - val_f1_m: 0.9596\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 118us/sample - loss: 2.8255e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1242 - val_accuracy: 0.9813 - val_f1_m: 0.9597\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 117us/sample - loss: 2.3410e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1246 - val_accuracy: 0.9810 - val_f1_m: 0.9595\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 117us/sample - loss: 1.9464e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1254 - val_accuracy: 0.9810 - val_f1_m: 0.9590\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 3s 194us/sample - loss: 0.0080 - accuracy: 0.9988 - f1_m: 0.9494 - val_loss: 0.1040 - val_accuracy: 0.9848 - val_f1_m: 0.9706\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 2s 146us/sample - loss: 0.0041 - accuracy: 0.9989 - f1_m: 0.9489 - val_loss: 0.1301 - val_accuracy: 0.9843 - val_f1_m: 0.9596\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 2s 144us/sample - loss: 0.0022 - accuracy: 0.9994 - f1_m: 0.9485 - val_loss: 0.1089 - val_accuracy: 0.9842 - val_f1_m: 0.9618\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 2s 145us/sample - loss: 3.6406e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1339 - val_accuracy: 0.9843 - val_f1_m: 0.9592\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 2s 144us/sample - loss: 4.1592e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1421 - val_accuracy: 0.9845 - val_f1_m: 0.9606\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 2s 144us/sample - loss: 3.8957e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1422 - val_accuracy: 0.9838 - val_f1_m: 0.9591\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 2s 144us/sample - loss: 4.6815e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1424 - val_accuracy: 0.9843 - val_f1_m: 0.9601\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 2s 145us/sample - loss: 2.1259e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1425 - val_accuracy: 0.9845 - val_f1_m: 0.9598\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 2s 144us/sample - loss: 1.5904e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1427 - val_accuracy: 0.9848 - val_f1_m: 0.9587\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 2s 146us/sample - loss: 1.2123e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1432 - val_accuracy: 0.9848 - val_f1_m: 0.9584\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 4s 254us/sample - loss: 0.0135 - accuracy: 0.9971 - f1_m: 0.9510 - val_loss: 0.1287 - val_accuracy: 0.9820 - val_f1_m: 0.9604\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 3s 190us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_m: 0.9501 - val_loss: 0.1121 - val_accuracy: 0.9873 - val_f1_m: 0.9584\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 3s 192us/sample - loss: 0.0084 - accuracy: 0.9976 - f1_m: 0.9516 - val_loss: 0.1739 - val_accuracy: 0.9752 - val_f1_m: 0.9645\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 3s 193us/sample - loss: 0.0123 - accuracy: 0.9970 - f1_m: 0.9531 - val_loss: 0.2008 - val_accuracy: 0.9803 - val_f1_m: 0.9597\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 3s 191us/sample - loss: 0.0110 - accuracy: 0.9970 - f1_m: 0.9503 - val_loss: 0.0983 - val_accuracy: 0.9838 - val_f1_m: 0.9650\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 3s 191us/sample - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9492 - val_loss: 0.0992 - val_accuracy: 0.9865 - val_f1_m: 0.9610\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 3s 193us/sample - loss: 0.0056 - accuracy: 0.9983 - f1_m: 0.9500 - val_loss: 0.0933 - val_accuracy: 0.9863 - val_f1_m: 0.9630\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 3s 192us/sample - loss: 0.0074 - accuracy: 0.9981 - f1_m: 0.9501 - val_loss: 0.1185 - val_accuracy: 0.9823 - val_f1_m: 0.9590\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 3s 192us/sample - loss: 0.0097 - accuracy: 0.9975 - f1_m: 0.9506 - val_loss: 0.1079 - val_accuracy: 0.9825 - val_f1_m: 0.9610\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 3s 191us/sample - loss: 0.0027 - accuracy: 0.9991 - f1_m: 0.9489 - val_loss: 0.1562 - val_accuracy: 0.9822 - val_f1_m: 0.9591\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 133us/sample - loss: 0.0195 - accuracy: 0.9961 - f1_m: 0.9553 - val_loss: 0.2957 - val_accuracy: 0.9558 - val_f1_m: 0.9807\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 1s 98us/sample - loss: 0.0102 - accuracy: 0.9981 - f1_m: 0.9538 - val_loss: 0.2852 - val_accuracy: 0.9595 - val_f1_m: 0.9819\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 1s 96us/sample - loss: 0.0074 - accuracy: 0.9983 - f1_m: 0.9539 - val_loss: 0.2931 - val_accuracy: 0.9580 - val_f1_m: 0.9794\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 1s 98us/sample - loss: 0.0061 - accuracy: 0.9984 - f1_m: 0.9534 - val_loss: 0.3232 - val_accuracy: 0.9553 - val_f1_m: 0.9836\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 0.0043 - accuracy: 0.9990 - f1_m: 0.9534 - val_loss: 0.2916 - val_accuracy: 0.9587 - val_f1_m: 0.9766\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 1s 98us/sample - loss: 7.4972e-04 - accuracy: 1.0000 - f1_m: 0.9487 - val_loss: 0.2894 - val_accuracy: 0.9580 - val_f1_m: 0.9789\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 4.6153e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2854 - val_accuracy: 0.9596 - val_f1_m: 0.9768\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 1s 98us/sample - loss: 3.5326e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2906 - val_accuracy: 0.9591 - val_f1_m: 0.9757\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 3.0098e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2916 - val_accuracy: 0.9578 - val_f1_m: 0.9765\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 2.6333e-04 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2930 - val_accuracy: 0.9591 - val_f1_m: 0.9727\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 147us/sample - loss: 0.0162 - accuracy: 0.9965 - f1_m: 0.9525 - val_loss: 0.2156 - val_accuracy: 0.9709 - val_f1_m: 0.9710\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 110us/sample - loss: 0.0062 - accuracy: 0.9987 - f1_m: 0.9507 - val_loss: 0.1755 - val_accuracy: 0.9764 - val_f1_m: 0.9671\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 108us/sample - loss: 0.0079 - accuracy: 0.9974 - f1_m: 0.9514 - val_loss: 0.1847 - val_accuracy: 0.9749 - val_f1_m: 0.9738\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 0.0038 - accuracy: 0.9988 - f1_m: 0.9510 - val_loss: 0.1738 - val_accuracy: 0.9756 - val_f1_m: 0.9690\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 0.0019 - accuracy: 0.9996 - f1_m: 0.9500 - val_loss: 0.1693 - val_accuracy: 0.9784 - val_f1_m: 0.9652\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 108us/sample - loss: 5.3267e-04 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.1768 - val_accuracy: 0.9762 - val_f1_m: 0.9658\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 107us/sample - loss: 1.1755e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1759 - val_accuracy: 0.9780 - val_f1_m: 0.9645\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14500/14500 [==============================] - 2s 108us/sample - loss: 6.6715e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1768 - val_accuracy: 0.9780 - val_f1_m: 0.9644\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 5.5135e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1790 - val_accuracy: 0.9775 - val_f1_m: 0.9650\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 109us/sample - loss: 4.6694e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1798 - val_accuracy: 0.9778 - val_f1_m: 0.9644\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 3s 179us/sample - loss: 0.0082 - accuracy: 0.9983 - f1_m: 0.9503 - val_loss: 0.1635 - val_accuracy: 0.9813 - val_f1_m: 0.9638\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0041 - accuracy: 0.9988 - f1_m: 0.9499 - val_loss: 0.2024 - val_accuracy: 0.9800 - val_f1_m: 0.9615\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0050 - accuracy: 0.9983 - f1_m: 0.9509 - val_loss: 0.1525 - val_accuracy: 0.9815 - val_f1_m: 0.9620\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0030 - accuracy: 0.9991 - f1_m: 0.9486 - val_loss: 0.1529 - val_accuracy: 0.9809 - val_f1_m: 0.9629\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0070 - accuracy: 0.9980 - f1_m: 0.9512 - val_loss: 0.1704 - val_accuracy: 0.9805 - val_f1_m: 0.9656\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 0.0034 - accuracy: 0.9990 - f1_m: 0.9504 - val_loss: 0.1432 - val_accuracy: 0.9824 - val_f1_m: 0.9605\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 136us/sample - loss: 1.1311e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1404 - val_accuracy: 0.9825 - val_f1_m: 0.9628\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 131us/sample - loss: 3.0112e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1415 - val_accuracy: 0.9833 - val_f1_m: 0.9627\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 134us/sample - loss: 2.1328e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1427 - val_accuracy: 0.9835 - val_f1_m: 0.9616\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 132us/sample - loss: 1.5553e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1446 - val_accuracy: 0.9835 - val_f1_m: 0.9615\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 3s 232us/sample - loss: 0.0154 - accuracy: 0.9963 - f1_m: 0.9529 - val_loss: 0.1574 - val_accuracy: 0.9780 - val_f1_m: 0.9681\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 3s 173us/sample - loss: 0.0069 - accuracy: 0.9977 - f1_m: 0.9516 - val_loss: 0.1541 - val_accuracy: 0.9800 - val_f1_m: 0.9640\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 172us/sample - loss: 0.0104 - accuracy: 0.9972 - f1_m: 0.9518 - val_loss: 0.1270 - val_accuracy: 0.9769 - val_f1_m: 0.9659\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 3s 173us/sample - loss: 0.0017 - accuracy: 0.9997 - f1_m: 0.9492 - val_loss: 0.1418 - val_accuracy: 0.9782 - val_f1_m: 0.9624\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 172us/sample - loss: 2.0794e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1467 - val_accuracy: 0.9780 - val_f1_m: 0.9626\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 172us/sample - loss: 7.6618e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1544 - val_accuracy: 0.9798 - val_f1_m: 0.9606\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 3s 173us/sample - loss: 1.1045e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1556 - val_accuracy: 0.9795 - val_f1_m: 0.9611\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 171us/sample - loss: 5.9286e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1576 - val_accuracy: 0.9798 - val_f1_m: 0.9611\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 171us/sample - loss: 4.5198e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1599 - val_accuracy: 0.9796 - val_f1_m: 0.9614\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 172us/sample - loss: 3.5305e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1622 - val_accuracy: 0.9796 - val_f1_m: 0.9613\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 131us/sample - loss: 0.0130 - accuracy: 0.9974 - f1_m: 0.9516 - val_loss: 0.2538 - val_accuracy: 0.9629 - val_f1_m: 0.9754\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 0.0021 - accuracy: 0.9994 - f1_m: 0.9494 - val_loss: 0.2252 - val_accuracy: 0.9676 - val_f1_m: 0.9751\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 1s 96us/sample - loss: 0.0012 - accuracy: 0.9997 - f1_m: 0.9492 - val_loss: 0.2395 - val_accuracy: 0.9638 - val_f1_m: 0.9776\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 1s 98us/sample - loss: 1.4065e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2191 - val_accuracy: 0.9678 - val_f1_m: 0.9776\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 1s 96us/sample - loss: 4.8558e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.2228 - val_accuracy: 0.9673 - val_f1_m: 0.9770\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 3.5119e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2238 - val_accuracy: 0.9675 - val_f1_m: 0.9753\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 1s 96us/sample - loss: 2.8786e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2250 - val_accuracy: 0.9676 - val_f1_m: 0.9758\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 2.4105e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2278 - val_accuracy: 0.9676 - val_f1_m: 0.9752\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 1s 97us/sample - loss: 2.0622e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2288 - val_accuracy: 0.9682 - val_f1_m: 0.9746\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 1s 98us/sample - loss: 1.7633e-05 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.2320 - val_accuracy: 0.9678 - val_f1_m: 0.9753\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 2s 151us/sample - loss: 0.0113 - accuracy: 0.9978 - f1_m: 0.9501 - val_loss: 0.1460 - val_accuracy: 0.9784 - val_f1_m: 0.9673\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 114us/sample - loss: 0.0010 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 0.1220 - val_accuracy: 0.9829 - val_f1_m: 0.9598\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 115us/sample - loss: 2.2907e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1168 - val_accuracy: 0.9829 - val_f1_m: 0.9600\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 114us/sample - loss: 2.1790e-05 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1164 - val_accuracy: 0.9833 - val_f1_m: 0.9586\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 115us/sample - loss: 8.1401e-06 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1164 - val_accuracy: 0.9833 - val_f1_m: 0.9588\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 114us/sample - loss: 6.4401e-06 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1166 - val_accuracy: 0.9836 - val_f1_m: 0.9588\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 115us/sample - loss: 5.2154e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1170 - val_accuracy: 0.9838 - val_f1_m: 0.9588\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 114us/sample - loss: 4.2784e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1175 - val_accuracy: 0.9838 - val_f1_m: 0.9579\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 116us/sample - loss: 3.5448e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1182 - val_accuracy: 0.9838 - val_f1_m: 0.9579\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 115us/sample - loss: 2.9314e-06 - accuracy: 1.0000 - f1_m: 0.9472 - val_loss: 0.1189 - val_accuracy: 0.9838 - val_f1_m: 0.9575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 3s 185us/sample - loss: 0.0085 - accuracy: 0.9986 - f1_m: 0.9502 - val_loss: 0.0831 - val_accuracy: 0.9856 - val_f1_m: 0.9662\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 2s 140us/sample - loss: 0.0041 - accuracy: 0.9988 - f1_m: 0.9500 - val_loss: 0.1186 - val_accuracy: 0.9835 - val_f1_m: 0.9643\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 2s 139us/sample - loss: 0.0041 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1587 - val_accuracy: 0.9807 - val_f1_m: 0.9616\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 2s 141us/sample - loss: 0.0031 - accuracy: 0.9992 - f1_m: 0.9483 - val_loss: 0.1200 - val_accuracy: 0.9807 - val_f1_m: 0.9655\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 2s 140us/sample - loss: 0.0034 - accuracy: 0.9990 - f1_m: 0.9496 - val_loss: 0.1041 - val_accuracy: 0.9829 - val_f1_m: 0.9605\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 2s 140us/sample - loss: 0.0062 - accuracy: 0.9981 - f1_m: 0.9499 - val_loss: 0.1411 - val_accuracy: 0.9791 - val_f1_m: 0.9671\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 2s 140us/sample - loss: 0.0052 - accuracy: 0.9986 - f1_m: 0.9501 - val_loss: 0.1086 - val_accuracy: 0.9842 - val_f1_m: 0.9615\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 2s 140us/sample - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9486 - val_loss: 0.1199 - val_accuracy: 0.9831 - val_f1_m: 0.9630\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 2s 140us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9483 - val_loss: 0.1019 - val_accuracy: 0.9853 - val_f1_m: 0.9612\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 2s 142us/sample - loss: 4.4986e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1057 - val_accuracy: 0.9869 - val_f1_m: 0.9588\n",
      "Train on 14500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "14500/14500 [==============================] - 4s 247us/sample - loss: 0.0115 - accuracy: 0.9972 - f1_m: 0.9503 - val_loss: 0.1403 - val_accuracy: 0.9822 - val_f1_m: 0.9640\n",
      "Epoch 2/10\n",
      "14500/14500 [==============================] - 3s 187us/sample - loss: 0.0036 - accuracy: 0.9988 - f1_m: 0.9499 - val_loss: 0.1703 - val_accuracy: 0.9785 - val_f1_m: 0.9611\n",
      "Epoch 3/10\n",
      "14500/14500 [==============================] - 3s 185us/sample - loss: 0.0090 - accuracy: 0.9977 - f1_m: 0.9510 - val_loss: 0.1135 - val_accuracy: 0.9838 - val_f1_m: 0.9651\n",
      "Epoch 4/10\n",
      "14500/14500 [==============================] - 3s 187us/sample - loss: 0.0108 - accuracy: 0.9971 - f1_m: 0.9510 - val_loss: 0.1420 - val_accuracy: 0.9849 - val_f1_m: 0.9585\n",
      "Epoch 5/10\n",
      "14500/14500 [==============================] - 3s 186us/sample - loss: 0.0069 - accuracy: 0.9981 - f1_m: 0.9494 - val_loss: 0.1071 - val_accuracy: 0.9853 - val_f1_m: 0.9644\n",
      "Epoch 6/10\n",
      "14500/14500 [==============================] - 3s 186us/sample - loss: 0.0023 - accuracy: 0.9991 - f1_m: 0.9491 - val_loss: 0.1224 - val_accuracy: 0.9860 - val_f1_m: 0.9621\n",
      "Epoch 7/10\n",
      "14500/14500 [==============================] - 3s 186us/sample - loss: 0.0016 - accuracy: 0.9993 - f1_m: 0.9491 - val_loss: 0.1291 - val_accuracy: 0.9862 - val_f1_m: 0.9567\n",
      "Epoch 8/10\n",
      "14500/14500 [==============================] - 3s 186us/sample - loss: 0.0091 - accuracy: 0.9980 - f1_m: 0.9500 - val_loss: 0.1185 - val_accuracy: 0.9782 - val_f1_m: 0.9753\n",
      "Epoch 9/10\n",
      "14500/14500 [==============================] - 3s 186us/sample - loss: 0.0150 - accuracy: 0.9959 - f1_m: 0.9549 - val_loss: 0.0652 - val_accuracy: 0.9865 - val_f1_m: 0.9691\n",
      "Epoch 10/10\n",
      "14500/14500 [==============================] - 3s 186us/sample - loss: 0.0022 - accuracy: 0.9992 - f1_m: 0.9486 - val_loss: 0.0813 - val_accuracy: 0.9864 - val_f1_m: 0.9639\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 127us/sample - loss: 0.0100 - accuracy: 0.9978 - f1_m: 0.9548 - val_loss: 0.3370 - val_accuracy: 0.9522 - val_f1_m: 0.9801\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.0059 - accuracy: 0.9988 - f1_m: 0.9531 - val_loss: 0.2828 - val_accuracy: 0.9586 - val_f1_m: 0.9746\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 0.0047 - accuracy: 0.9987 - f1_m: 0.9522 - val_loss: 0.2868 - val_accuracy: 0.9594 - val_f1_m: 0.9775\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.0020 - accuracy: 0.9997 - f1_m: 0.9498 - val_loss: 0.2951 - val_accuracy: 0.9570 - val_f1_m: 0.9735\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 1s 94us/sample - loss: 0.0032 - accuracy: 0.9993 - f1_m: 0.9513 - val_loss: 0.3008 - val_accuracy: 0.9596 - val_f1_m: 0.9772\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.0050 - accuracy: 0.9982 - f1_m: 0.9546 - val_loss: 0.3245 - val_accuracy: 0.9534 - val_f1_m: 0.9840\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 1s 94us/sample - loss: 0.0019 - accuracy: 0.9996 - f1_m: 0.9504 - val_loss: 0.3038 - val_accuracy: 0.9566 - val_f1_m: 0.9779\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.0058 - accuracy: 0.9979 - f1_m: 0.9538 - val_loss: 0.3114 - val_accuracy: 0.9554 - val_f1_m: 0.9802\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.0060 - accuracy: 0.9978 - f1_m: 0.9546 - val_loss: 0.3082 - val_accuracy: 0.9566 - val_f1_m: 0.9814\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.0050 - accuracy: 0.9989 - f1_m: 0.9533 - val_loss: 0.3176 - val_accuracy: 0.9562 - val_f1_m: 0.9796\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 141us/sample - loss: 0.0074 - accuracy: 0.9984 - f1_m: 0.9508 - val_loss: 0.1983 - val_accuracy: 0.9724 - val_f1_m: 0.9696\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 0.0073 - accuracy: 0.9979 - f1_m: 0.9526 - val_loss: 0.1808 - val_accuracy: 0.9766 - val_f1_m: 0.9678\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 0.0043 - accuracy: 0.9985 - f1_m: 0.9514 - val_loss: 0.1886 - val_accuracy: 0.9730 - val_f1_m: 0.9661\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 103us/sample - loss: 0.0053 - accuracy: 0.9981 - f1_m: 0.9512 - val_loss: 0.1840 - val_accuracy: 0.9746 - val_f1_m: 0.9718\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 0.0022 - accuracy: 0.9993 - f1_m: 0.9494 - val_loss: 0.1921 - val_accuracy: 0.9760 - val_f1_m: 0.9652\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 7.6970e-04 - accuracy: 0.9999 - f1_m: 0.9481 - val_loss: 0.1774 - val_accuracy: 0.9772 - val_f1_m: 0.9652\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 8.2481e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1786 - val_accuracy: 0.9772 - val_f1_m: 0.9639\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 103us/sample - loss: 5.5780e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1812 - val_accuracy: 0.9782 - val_f1_m: 0.9645\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 4.5453e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1818 - val_accuracy: 0.9782 - val_f1_m: 0.9635\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 104us/sample - loss: 3.7141e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1825 - val_accuracy: 0.9786 - val_f1_m: 0.9643\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 3s 176us/sample - loss: 0.0055 - accuracy: 0.9989 - f1_m: 0.9502 - val_loss: 0.1790 - val_accuracy: 0.9812 - val_f1_m: 0.9579\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0055 - accuracy: 0.9983 - f1_m: 0.9509 - val_loss: 0.1746 - val_accuracy: 0.9808 - val_f1_m: 0.9618\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0062 - accuracy: 0.9982 - f1_m: 0.9504 - val_loss: 0.1496 - val_accuracy: 0.9802 - val_f1_m: 0.9627\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0014 - accuracy: 0.9994 - f1_m: 0.9487 - val_loss: 0.1514 - val_accuracy: 0.9818 - val_f1_m: 0.9614\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0016 - accuracy: 0.9993 - f1_m: 0.9491 - val_loss: 0.1737 - val_accuracy: 0.9800 - val_f1_m: 0.9624\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0029 - accuracy: 0.9987 - f1_m: 0.9499 - val_loss: 0.1432 - val_accuracy: 0.9770 - val_f1_m: 0.9659\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0048 - accuracy: 0.9985 - f1_m: 0.9506 - val_loss: 0.2109 - val_accuracy: 0.9776 - val_f1_m: 0.9623\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0037 - accuracy: 0.9987 - f1_m: 0.9504 - val_loss: 0.1506 - val_accuracy: 0.9824 - val_f1_m: 0.9645\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 130us/sample - loss: 0.0068 - accuracy: 0.9977 - f1_m: 0.9502 - val_loss: 0.1616 - val_accuracy: 0.9798 - val_f1_m: 0.9649\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 131us/sample - loss: 0.0061 - accuracy: 0.9982 - f1_m: 0.9502 - val_loss: 0.1385 - val_accuracy: 0.9826 - val_f1_m: 0.9604\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 3s 226us/sample - loss: 0.0099 - accuracy: 0.9980 - f1_m: 0.9510 - val_loss: 0.1315 - val_accuracy: 0.9786 - val_f1_m: 0.9674\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 3s 171us/sample - loss: 0.0072 - accuracy: 0.9977 - f1_m: 0.9513 - val_loss: 0.1438 - val_accuracy: 0.9794 - val_f1_m: 0.9642\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9507 - val_loss: 0.1542 - val_accuracy: 0.9772 - val_f1_m: 0.9668\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 3s 169us/sample - loss: 0.0105 - accuracy: 0.9963 - f1_m: 0.9548 - val_loss: 0.1866 - val_accuracy: 0.9750 - val_f1_m: 0.9634\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0081 - accuracy: 0.9981 - f1_m: 0.9502 - val_loss: 0.1511 - val_accuracy: 0.9800 - val_f1_m: 0.9653\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0156 - accuracy: 0.9955 - f1_m: 0.9542 - val_loss: 0.1458 - val_accuracy: 0.9724 - val_f1_m: 0.9736\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0161 - accuracy: 0.9960 - f1_m: 0.9529 - val_loss: 0.1345 - val_accuracy: 0.9800 - val_f1_m: 0.9671\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0041 - accuracy: 0.9985 - f1_m: 0.9509 - val_loss: 0.1372 - val_accuracy: 0.9816 - val_f1_m: 0.9641\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0046 - accuracy: 0.9986 - f1_m: 0.9500 - val_loss: 0.1412 - val_accuracy: 0.9796 - val_f1_m: 0.9665\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 3s 169us/sample - loss: 8.2551e-04 - accuracy: 0.9997 - f1_m: 0.9486 - val_loss: 0.1419 - val_accuracy: 0.9802 - val_f1_m: 0.9634\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 129us/sample - loss: 0.0067 - accuracy: 0.9989 - f1_m: 0.9504 - val_loss: 0.2645 - val_accuracy: 0.9636 - val_f1_m: 0.9779\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 0.0043 - accuracy: 0.9989 - f1_m: 0.9512 - val_loss: 0.2513 - val_accuracy: 0.9650 - val_f1_m: 0.9697\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 1s 94us/sample - loss: 0.0034 - accuracy: 0.9993 - f1_m: 0.9496 - val_loss: 0.2129 - val_accuracy: 0.9676 - val_f1_m: 0.9726\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.0015 - accuracy: 0.9997 - f1_m: 0.9486 - val_loss: 0.2201 - val_accuracy: 0.9678 - val_f1_m: 0.9732\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 1s 94us/sample - loss: 1.0969e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2179 - val_accuracy: 0.9676 - val_f1_m: 0.9724\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 4.0699e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2183 - val_accuracy: 0.9676 - val_f1_m: 0.9719\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 1s 93us/sample - loss: 3.1885e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2185 - val_accuracy: 0.9686 - val_f1_m: 0.9715\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 2.5885e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2202 - val_accuracy: 0.9682 - val_f1_m: 0.9724\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 1s 94us/sample - loss: 2.1533e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2214 - val_accuracy: 0.9686 - val_f1_m: 0.9709\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 1.7940e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2220 - val_accuracy: 0.9696 - val_f1_m: 0.9715\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 148us/sample - loss: 0.0051 - accuracy: 0.9989 - f1_m: 0.9495 - val_loss: 0.1470 - val_accuracy: 0.9800 - val_f1_m: 0.9643\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 111us/sample - loss: 0.0030 - accuracy: 0.9991 - f1_m: 0.9494 - val_loss: 0.1236 - val_accuracy: 0.9818 - val_f1_m: 0.9629\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.0073 - accuracy: 0.9984 - f1_m: 0.9503 - val_loss: 0.1400 - val_accuracy: 0.9804 - val_f1_m: 0.9659\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 111us/sample - loss: 4.0762e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1161 - val_accuracy: 0.9838 - val_f1_m: 0.9617\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 112us/sample - loss: 1.4485e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1083 - val_accuracy: 0.9854 - val_f1_m: 0.9616\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 112us/sample - loss: 6.1946e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1134 - val_accuracy: 0.9850 - val_f1_m: 0.9594\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 112us/sample - loss: 7.6639e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1133 - val_accuracy: 0.9850 - val_f1_m: 0.9592\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 111us/sample - loss: 5.8243e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1136 - val_accuracy: 0.9846 - val_f1_m: 0.9594\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 112us/sample - loss: 4.6759e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1141 - val_accuracy: 0.9848 - val_f1_m: 0.9585\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 113us/sample - loss: 3.8130e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1147 - val_accuracy: 0.9848 - val_f1_m: 0.9576\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 5s 359us/sample - loss: 0.0048 - accuracy: 0.9989 - f1_m: 0.9489 - val_loss: 0.1804 - val_accuracy: 0.9824 - val_f1_m: 0.9580\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 139us/sample - loss: 0.0022 - accuracy: 0.9993 - f1_m: 0.9485 - val_loss: 0.1406 - val_accuracy: 0.9872 - val_f1_m: 0.9585\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 139us/sample - loss: 0.0076 - accuracy: 0.9984 - f1_m: 0.9501 - val_loss: 0.1444 - val_accuracy: 0.9814 - val_f1_m: 0.9671\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0027 - accuracy: 0.9990 - f1_m: 0.9494 - val_loss: 0.1506 - val_accuracy: 0.9810 - val_f1_m: 0.9629\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 139us/sample - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9487 - val_loss: 0.1813 - val_accuracy: 0.9788 - val_f1_m: 0.9609\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9489 - val_loss: 0.1263 - val_accuracy: 0.9812 - val_f1_m: 0.9646\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 139us/sample - loss: 0.0025 - accuracy: 0.9993 - f1_m: 0.9485 - val_loss: 0.1414 - val_accuracy: 0.9834 - val_f1_m: 0.9618\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0023 - accuracy: 0.9995 - f1_m: 0.9489 - val_loss: 0.1736 - val_accuracy: 0.9822 - val_f1_m: 0.9594\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0120 - accuracy: 0.9972 - f1_m: 0.9503 - val_loss: 0.1197 - val_accuracy: 0.9810 - val_f1_m: 0.9650\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 138us/sample - loss: 0.0026 - accuracy: 0.9991 - f1_m: 0.9487 - val_loss: 0.1285 - val_accuracy: 0.9856 - val_f1_m: 0.9599\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 4s 243us/sample - loss: 0.0071 - accuracy: 0.9989 - f1_m: 0.9499 - val_loss: 0.1253 - val_accuracy: 0.9842 - val_f1_m: 0.9606\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 3s 183us/sample - loss: 0.0127 - accuracy: 0.9968 - f1_m: 0.9516 - val_loss: 0.1025 - val_accuracy: 0.9856 - val_f1_m: 0.9637\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 3s 184us/sample - loss: 0.0061 - accuracy: 0.9981 - f1_m: 0.9501 - val_loss: 0.0942 - val_accuracy: 0.9858 - val_f1_m: 0.9614\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 3s 184us/sample - loss: 0.0049 - accuracy: 0.9985 - f1_m: 0.9497 - val_loss: 0.1369 - val_accuracy: 0.9806 - val_f1_m: 0.9667\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 3s 183us/sample - loss: 0.0110 - accuracy: 0.9975 - f1_m: 0.9509 - val_loss: 0.1396 - val_accuracy: 0.9852 - val_f1_m: 0.9607\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 3s 184us/sample - loss: 0.0052 - accuracy: 0.9985 - f1_m: 0.9500 - val_loss: 0.1141 - val_accuracy: 0.9878 - val_f1_m: 0.9591\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 3s 182us/sample - loss: 0.0036 - accuracy: 0.9990 - f1_m: 0.9495 - val_loss: 0.2770 - val_accuracy: 0.9730 - val_f1_m: 0.9660\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 3s 184us/sample - loss: 0.0202 - accuracy: 0.9959 - f1_m: 0.9529 - val_loss: 0.1425 - val_accuracy: 0.9828 - val_f1_m: 0.9628\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 3s 184us/sample - loss: 0.0041 - accuracy: 0.9989 - f1_m: 0.9496 - val_loss: 0.1148 - val_accuracy: 0.9872 - val_f1_m: 0.9602\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 3s 183us/sample - loss: 2.6176e-04 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 0.0997 - val_accuracy: 0.9874 - val_f1_m: 0.9621\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 126us/sample - loss: 0.0152 - accuracy: 0.9968 - f1_m: 0.9556 - val_loss: 0.2829 - val_accuracy: 0.9576 - val_f1_m: 0.9788\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0076 - accuracy: 0.9984 - f1_m: 0.9522 - val_loss: 0.2933 - val_accuracy: 0.9578 - val_f1_m: 0.9746\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0041 - accuracy: 0.9993 - f1_m: 0.9512 - val_loss: 0.2751 - val_accuracy: 0.9587 - val_f1_m: 0.9780\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0040 - accuracy: 0.9993 - f1_m: 0.9513 - val_loss: 0.2771 - val_accuracy: 0.9598 - val_f1_m: 0.9766\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0096 - accuracy: 0.9969 - f1_m: 0.9556 - val_loss: 0.2728 - val_accuracy: 0.9600 - val_f1_m: 0.9783\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 1s 94us/sample - loss: 0.0035 - accuracy: 0.9990 - f1_m: 0.9519 - val_loss: 0.2562 - val_accuracy: 0.9627 - val_f1_m: 0.9768\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0014 - accuracy: 0.9998 - f1_m: 0.9492 - val_loss: 0.2637 - val_accuracy: 0.9627 - val_f1_m: 0.9736\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0076 - accuracy: 0.9973 - f1_m: 0.9544 - val_loss: 0.3010 - val_accuracy: 0.9598 - val_f1_m: 0.9838\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 98us/sample - loss: 0.0062 - accuracy: 0.9983 - f1_m: 0.9546 - val_loss: 0.3481 - val_accuracy: 0.9513 - val_f1_m: 0.9806\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0044 - accuracy: 0.9988 - f1_m: 0.9528 - val_loss: 0.2785 - val_accuracy: 0.9611 - val_f1_m: 0.9751\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 138us/sample - loss: 0.0105 - accuracy: 0.9983 - f1_m: 0.9512 - val_loss: 0.1871 - val_accuracy: 0.9764 - val_f1_m: 0.9634\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 103us/sample - loss: 0.0035 - accuracy: 0.9997 - f1_m: 0.9488 - val_loss: 0.1967 - val_accuracy: 0.9758 - val_f1_m: 0.9623\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 102us/sample - loss: 0.0045 - accuracy: 0.9990 - f1_m: 0.9496 - val_loss: 0.2284 - val_accuracy: 0.9724 - val_f1_m: 0.9625\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 103us/sample - loss: 0.0080 - accuracy: 0.9979 - f1_m: 0.9517 - val_loss: 0.2435 - val_accuracy: 0.9711 - val_f1_m: 0.9700\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 102us/sample - loss: 0.0066 - accuracy: 0.9979 - f1_m: 0.9527 - val_loss: 0.1938 - val_accuracy: 0.9769 - val_f1_m: 0.9626\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 0.0023 - accuracy: 0.9992 - f1_m: 0.9500 - val_loss: 0.1756 - val_accuracy: 0.9773 - val_f1_m: 0.9645\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 103us/sample - loss: 8.0511e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1885 - val_accuracy: 0.9769 - val_f1_m: 0.9662\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 104us/sample - loss: 1.3066e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.1898 - val_accuracy: 0.9769 - val_f1_m: 0.9649\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 103us/sample - loss: 5.5456e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1902 - val_accuracy: 0.9771 - val_f1_m: 0.9652\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 103us/sample - loss: 4.0815e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1907 - val_accuracy: 0.9758 - val_f1_m: 0.9635\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 3s 172us/sample - loss: 0.0085 - accuracy: 0.9977 - f1_m: 0.9507 - val_loss: 0.1585 - val_accuracy: 0.9809 - val_f1_m: 0.9597\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 128us/sample - loss: 0.0043 - accuracy: 0.9988 - f1_m: 0.9495 - val_loss: 0.1806 - val_accuracy: 0.9773 - val_f1_m: 0.9609\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 126us/sample - loss: 0.0059 - accuracy: 0.9983 - f1_m: 0.9495 - val_loss: 0.1565 - val_accuracy: 0.9800 - val_f1_m: 0.9574\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0056 - accuracy: 0.9980 - f1_m: 0.9500 - val_loss: 0.1463 - val_accuracy: 0.9811 - val_f1_m: 0.9601\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0032 - accuracy: 0.9989 - f1_m: 0.9494 - val_loss: 0.1383 - val_accuracy: 0.9829 - val_f1_m: 0.9604\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0047 - accuracy: 0.9987 - f1_m: 0.9494 - val_loss: 0.1407 - val_accuracy: 0.9800 - val_f1_m: 0.9607\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 128us/sample - loss: 0.0030 - accuracy: 0.9988 - f1_m: 0.9501 - val_loss: 0.1792 - val_accuracy: 0.9818 - val_f1_m: 0.9586\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 128us/sample - loss: 8.4170e-04 - accuracy: 0.9997 - f1_m: 0.9485 - val_loss: 0.2010 - val_accuracy: 0.9822 - val_f1_m: 0.9569\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 127us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9484 - val_loss: 0.1881 - val_accuracy: 0.9767 - val_f1_m: 0.9652\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 128us/sample - loss: 0.0107 - accuracy: 0.9971 - f1_m: 0.9521 - val_loss: 0.1428 - val_accuracy: 0.9829 - val_f1_m: 0.9606\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 3s 222us/sample - loss: 0.0147 - accuracy: 0.9966 - f1_m: 0.9532 - val_loss: 0.1238 - val_accuracy: 0.9767 - val_f1_m: 0.9675\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 3s 165us/sample - loss: 0.0071 - accuracy: 0.9979 - f1_m: 0.9510 - val_loss: 0.1620 - val_accuracy: 0.9789 - val_f1_m: 0.9622\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 3s 167us/sample - loss: 0.0105 - accuracy: 0.9970 - f1_m: 0.9518 - val_loss: 0.1426 - val_accuracy: 0.9809 - val_f1_m: 0.9629\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 3s 166us/sample - loss: 0.0062 - accuracy: 0.9981 - f1_m: 0.9505 - val_loss: 0.1539 - val_accuracy: 0.9789 - val_f1_m: 0.9649\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 3s 166us/sample - loss: 0.0029 - accuracy: 0.9991 - f1_m: 0.9489 - val_loss: 0.2072 - val_accuracy: 0.9804 - val_f1_m: 0.9567\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 3s 167us/sample - loss: 0.0108 - accuracy: 0.9972 - f1_m: 0.9523 - val_loss: 0.1465 - val_accuracy: 0.9807 - val_f1_m: 0.9631\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 3s 166us/sample - loss: 0.0086 - accuracy: 0.9975 - f1_m: 0.9517 - val_loss: 0.1647 - val_accuracy: 0.9776 - val_f1_m: 0.9643\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 3s 166us/sample - loss: 0.0090 - accuracy: 0.9970 - f1_m: 0.9520 - val_loss: 0.1648 - val_accuracy: 0.9778 - val_f1_m: 0.9591\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 3s 168us/sample - loss: 0.0109 - accuracy: 0.9974 - f1_m: 0.9523 - val_loss: 0.1177 - val_accuracy: 0.9796 - val_f1_m: 0.9642\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 3s 166us/sample - loss: 0.0032 - accuracy: 0.9989 - f1_m: 0.9502 - val_loss: 0.1301 - val_accuracy: 0.9784 - val_f1_m: 0.9624\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 124us/sample - loss: 0.0084 - accuracy: 0.9981 - f1_m: 0.9509 - val_loss: 0.2209 - val_accuracy: 0.9671 - val_f1_m: 0.9699\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9500 - val_loss: 0.2387 - val_accuracy: 0.9653 - val_f1_m: 0.9706\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 1s 92us/sample - loss: 0.0028 - accuracy: 0.9991 - f1_m: 0.9498 - val_loss: 0.2291 - val_accuracy: 0.9671 - val_f1_m: 0.9685\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 1s 92us/sample - loss: 0.0016 - accuracy: 0.9998 - f1_m: 0.9481 - val_loss: 0.2461 - val_accuracy: 0.9642 - val_f1_m: 0.9663\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 1s 93us/sample - loss: 0.0014 - accuracy: 0.9995 - f1_m: 0.9482 - val_loss: 0.2481 - val_accuracy: 0.9671 - val_f1_m: 0.9646\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 1s 92us/sample - loss: 0.0033 - accuracy: 0.9990 - f1_m: 0.9502 - val_loss: 0.2499 - val_accuracy: 0.9656 - val_f1_m: 0.9718\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 1s 92us/sample - loss: 1.6356e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2319 - val_accuracy: 0.9676 - val_f1_m: 0.9672\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 1s 91us/sample - loss: 4.8515e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2390 - val_accuracy: 0.9673 - val_f1_m: 0.9649\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 1s 92us/sample - loss: 2.9402e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2376 - val_accuracy: 0.9669 - val_f1_m: 0.9648\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 1s 91us/sample - loss: 2.2425e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2391 - val_accuracy: 0.9678 - val_f1_m: 0.9648\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 2s 143us/sample - loss: 0.0075 - accuracy: 0.9988 - f1_m: 0.9489 - val_loss: 0.1125 - val_accuracy: 0.9838 - val_f1_m: 0.9578\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 108us/sample - loss: 0.0031 - accuracy: 0.9991 - f1_m: 0.9490 - val_loss: 0.1127 - val_accuracy: 0.9844 - val_f1_m: 0.9569\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 108us/sample - loss: 0.0024 - accuracy: 0.9994 - f1_m: 0.9488 - val_loss: 0.1375 - val_accuracy: 0.9813 - val_f1_m: 0.9578\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 108us/sample - loss: 0.0017 - accuracy: 0.9997 - f1_m: 0.9481 - val_loss: 0.1147 - val_accuracy: 0.9827 - val_f1_m: 0.9623\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 107us/sample - loss: 0.0015 - accuracy: 0.9997 - f1_m: 0.9479 - val_loss: 0.1157 - val_accuracy: 0.9842 - val_f1_m: 0.9587\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 109us/sample - loss: 3.1996e-04 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 0.1198 - val_accuracy: 0.9833 - val_f1_m: 0.9588\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 109us/sample - loss: 5.1390e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1205 - val_accuracy: 0.9844 - val_f1_m: 0.9572\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 107us/sample - loss: 1.2862e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1169 - val_accuracy: 0.9840 - val_f1_m: 0.9578\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 109us/sample - loss: 5.1126e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1172 - val_accuracy: 0.9842 - val_f1_m: 0.9572\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 109us/sample - loss: 3.9305e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1176 - val_accuracy: 0.9844 - val_f1_m: 0.9571\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 3s 179us/sample - loss: 0.0118 - accuracy: 0.9983 - f1_m: 0.9488 - val_loss: 0.1226 - val_accuracy: 0.9833 - val_f1_m: 0.9603\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 2s 135us/sample - loss: 0.0017 - accuracy: 0.9997 - f1_m: 0.9483 - val_loss: 0.1069 - val_accuracy: 0.9851 - val_f1_m: 0.9604\n",
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 2s 136us/sample - loss: 7.8003e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1193 - val_accuracy: 0.9844 - val_f1_m: 0.9585\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 2s 136us/sample - loss: 1.1835e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1227 - val_accuracy: 0.9849 - val_f1_m: 0.9596\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 2s 136us/sample - loss: 4.0785e-06 - accuracy: 1.0000 - f1_m: 0.9471 - val_loss: 0.1236 - val_accuracy: 0.9849 - val_f1_m: 0.9590\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 2s 136us/sample - loss: 2.8271e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1247 - val_accuracy: 0.9849 - val_f1_m: 0.9588\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 2s 135us/sample - loss: 2.0652e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1256 - val_accuracy: 0.9849 - val_f1_m: 0.9588\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 2s 135us/sample - loss: 1.5563e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1267 - val_accuracy: 0.9849 - val_f1_m: 0.9588\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 2s 135us/sample - loss: 1.1827e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1279 - val_accuracy: 0.9849 - val_f1_m: 0.9588\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 2s 135us/sample - loss: 9.0940e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1289 - val_accuracy: 0.9847 - val_f1_m: 0.9583\n",
      "Train on 15500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "15500/15500 [==============================] - 4s 236us/sample - loss: 0.0118 - accuracy: 0.9979 - f1_m: 0.9494 - val_loss: 0.1696 - val_accuracy: 0.9842 - val_f1_m: 0.9590\n",
      "Epoch 2/10\n",
      "15500/15500 [==============================] - 3s 180us/sample - loss: 0.0060 - accuracy: 0.9983 - f1_m: 0.9492 - val_loss: 0.1747 - val_accuracy: 0.9791 - val_f1_m: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "15500/15500 [==============================] - 3s 179us/sample - loss: 0.0080 - accuracy: 0.9979 - f1_m: 0.9509 - val_loss: 0.1873 - val_accuracy: 0.9813 - val_f1_m: 0.9557\n",
      "Epoch 4/10\n",
      "15500/15500 [==============================] - 3s 179us/sample - loss: 0.0114 - accuracy: 0.9975 - f1_m: 0.9504 - val_loss: 0.1113 - val_accuracy: 0.9836 - val_f1_m: 0.9623\n",
      "Epoch 5/10\n",
      "15500/15500 [==============================] - 3s 179us/sample - loss: 0.0076 - accuracy: 0.9977 - f1_m: 0.9500 - val_loss: 0.1258 - val_accuracy: 0.9813 - val_f1_m: 0.9661\n",
      "Epoch 6/10\n",
      "15500/15500 [==============================] - 3s 179us/sample - loss: 0.0093 - accuracy: 0.9975 - f1_m: 0.9507 - val_loss: 0.1391 - val_accuracy: 0.9831 - val_f1_m: 0.9586\n",
      "Epoch 7/10\n",
      "15500/15500 [==============================] - 3s 179us/sample - loss: 0.0072 - accuracy: 0.9981 - f1_m: 0.9499 - val_loss: 0.1504 - val_accuracy: 0.9824 - val_f1_m: 0.9589\n",
      "Epoch 8/10\n",
      "15500/15500 [==============================] - 3s 180us/sample - loss: 0.0041 - accuracy: 0.9985 - f1_m: 0.9497 - val_loss: 0.1563 - val_accuracy: 0.9816 - val_f1_m: 0.9578\n",
      "Epoch 9/10\n",
      "15500/15500 [==============================] - 3s 180us/sample - loss: 0.0057 - accuracy: 0.9986 - f1_m: 0.9498 - val_loss: 0.1308 - val_accuracy: 0.9851 - val_f1_m: 0.9607\n",
      "Epoch 10/10\n",
      "15500/15500 [==============================] - 3s 181us/sample - loss: 0.0054 - accuracy: 0.9988 - f1_m: 0.9494 - val_loss: 0.1432 - val_accuracy: 0.9849 - val_f1_m: 0.9556\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 111us/sample - loss: 0.0115 - accuracy: 0.9976 - f1_m: 0.9539 - val_loss: 0.2947 - val_accuracy: 0.9613 - val_f1_m: 0.9788\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 0.0052 - accuracy: 0.9986 - f1_m: 0.9523 - val_loss: 0.2851 - val_accuracy: 0.9605 - val_f1_m: 0.9785\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 0.0058 - accuracy: 0.9979 - f1_m: 0.9537 - val_loss: 0.3084 - val_accuracy: 0.9600 - val_f1_m: 0.9783\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 0.0042 - accuracy: 0.9987 - f1_m: 0.9520 - val_loss: 0.3306 - val_accuracy: 0.9557 - val_f1_m: 0.9757\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 82us/sample - loss: 0.0022 - accuracy: 0.9994 - f1_m: 0.9514 - val_loss: 0.3235 - val_accuracy: 0.9575 - val_f1_m: 0.9809\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 8.3288e-04 - accuracy: 0.9999 - f1_m: 0.9496 - val_loss: 0.3020 - val_accuracy: 0.9590 - val_f1_m: 0.9794\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 82us/sample - loss: 3.4356e-04 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.3041 - val_accuracy: 0.9567 - val_f1_m: 0.9783\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 80us/sample - loss: 2.2593e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.3018 - val_accuracy: 0.9582 - val_f1_m: 0.9795\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 1.8957e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.3065 - val_accuracy: 0.9582 - val_f1_m: 0.9801\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 1.7281e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.3076 - val_accuracy: 0.9578 - val_f1_m: 0.9797\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 123us/sample - loss: 0.0099 - accuracy: 0.9979 - f1_m: 0.9512 - val_loss: 0.2058 - val_accuracy: 0.9740 - val_f1_m: 0.9647\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 91us/sample - loss: 0.0050 - accuracy: 0.9989 - f1_m: 0.9503 - val_loss: 0.2058 - val_accuracy: 0.9765 - val_f1_m: 0.9617\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 90us/sample - loss: 0.0036 - accuracy: 0.9990 - f1_m: 0.9500 - val_loss: 0.1973 - val_accuracy: 0.9732 - val_f1_m: 0.9661\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 94us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9488 - val_loss: 0.2382 - val_accuracy: 0.9700 - val_f1_m: 0.9640\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 95us/sample - loss: 0.0023 - accuracy: 0.9996 - f1_m: 0.9493 - val_loss: 0.1979 - val_accuracy: 0.9768 - val_f1_m: 0.9637\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 93us/sample - loss: 0.0069 - accuracy: 0.9974 - f1_m: 0.9526 - val_loss: 0.2582 - val_accuracy: 0.9703 - val_f1_m: 0.9659\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 92us/sample - loss: 0.0047 - accuracy: 0.9985 - f1_m: 0.9509 - val_loss: 0.2217 - val_accuracy: 0.9715 - val_f1_m: 0.9671\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 91us/sample - loss: 0.0044 - accuracy: 0.9987 - f1_m: 0.9508 - val_loss: 0.1921 - val_accuracy: 0.9760 - val_f1_m: 0.9637\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 90us/sample - loss: 3.9054e-04 - accuracy: 0.9999 - f1_m: 0.9488 - val_loss: 0.1992 - val_accuracy: 0.9765 - val_f1_m: 0.9633\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 95us/sample - loss: 9.4725e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2004 - val_accuracy: 0.9762 - val_f1_m: 0.9614\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 3s 157us/sample - loss: 0.0085 - accuracy: 0.9976 - f1_m: 0.9505 - val_loss: 0.1676 - val_accuracy: 0.9820 - val_f1_m: 0.9645\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 113us/sample - loss: 0.0071 - accuracy: 0.9976 - f1_m: 0.9504 - val_loss: 0.1701 - val_accuracy: 0.9810 - val_f1_m: 0.9644\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 115us/sample - loss: 0.0032 - accuracy: 0.9987 - f1_m: 0.9505 - val_loss: 0.1527 - val_accuracy: 0.9805 - val_f1_m: 0.9618\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 114us/sample - loss: 0.0054 - accuracy: 0.9981 - f1_m: 0.9500 - val_loss: 0.1216 - val_accuracy: 0.9815 - val_f1_m: 0.9620\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 114us/sample - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9491 - val_loss: 0.1825 - val_accuracy: 0.9812 - val_f1_m: 0.9639\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 114us/sample - loss: 0.0028 - accuracy: 0.9989 - f1_m: 0.9494 - val_loss: 0.2395 - val_accuracy: 0.9790 - val_f1_m: 0.9614\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 114us/sample - loss: 0.0069 - accuracy: 0.9981 - f1_m: 0.9510 - val_loss: 0.1472 - val_accuracy: 0.9793 - val_f1_m: 0.9611\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 113us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9492 - val_loss: 0.1573 - val_accuracy: 0.9812 - val_f1_m: 0.9580\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 115us/sample - loss: 0.0025 - accuracy: 0.9990 - f1_m: 0.9490 - val_loss: 0.2825 - val_accuracy: 0.9720 - val_f1_m: 0.9649\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 114us/sample - loss: 0.0051 - accuracy: 0.9984 - f1_m: 0.9498 - val_loss: 0.1602 - val_accuracy: 0.9810 - val_f1_m: 0.9603\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 3s 205us/sample - loss: 0.0128 - accuracy: 0.9971 - f1_m: 0.9528 - val_loss: 0.1280 - val_accuracy: 0.9772 - val_f1_m: 0.9676\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 151us/sample - loss: 0.0021 - accuracy: 0.9994 - f1_m: 0.9506 - val_loss: 0.1774 - val_accuracy: 0.9787 - val_f1_m: 0.9599\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 153us/sample - loss: 0.0128 - accuracy: 0.9961 - f1_m: 0.9531 - val_loss: 0.1462 - val_accuracy: 0.9732 - val_f1_m: 0.9773\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 152us/sample - loss: 0.0133 - accuracy: 0.9960 - f1_m: 0.9569 - val_loss: 0.1615 - val_accuracy: 0.9772 - val_f1_m: 0.9659\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 152us/sample - loss: 0.0087 - accuracy: 0.9976 - f1_m: 0.9526 - val_loss: 0.1397 - val_accuracy: 0.9783 - val_f1_m: 0.9625\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 152us/sample - loss: 0.0040 - accuracy: 0.9990 - f1_m: 0.9504 - val_loss: 0.1512 - val_accuracy: 0.9765 - val_f1_m: 0.9672\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 152us/sample - loss: 0.0065 - accuracy: 0.9981 - f1_m: 0.9503 - val_loss: 0.1625 - val_accuracy: 0.9793 - val_f1_m: 0.9654\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 151us/sample - loss: 0.0031 - accuracy: 0.9992 - f1_m: 0.9505 - val_loss: 0.1414 - val_accuracy: 0.9787 - val_f1_m: 0.9679\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 152us/sample - loss: 0.0124 - accuracy: 0.9968 - f1_m: 0.9539 - val_loss: 0.1398 - val_accuracy: 0.9758 - val_f1_m: 0.9642\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 153us/sample - loss: 0.0043 - accuracy: 0.9985 - f1_m: 0.9518 - val_loss: 0.1671 - val_accuracy: 0.9790 - val_f1_m: 0.9625\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 111us/sample - loss: 0.0081 - accuracy: 0.9982 - f1_m: 0.9507 - val_loss: 0.2707 - val_accuracy: 0.9638 - val_f1_m: 0.9703\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 0.0018 - accuracy: 0.9997 - f1_m: 0.9501 - val_loss: 0.2574 - val_accuracy: 0.9668 - val_f1_m: 0.9722\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 2.3735e-04 - accuracy: 0.9999 - f1_m: 0.9480 - val_loss: 0.2680 - val_accuracy: 0.9665 - val_f1_m: 0.9709\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 81us/sample - loss: 1.9434e-04 - accuracy: 0.9999 - f1_m: 0.9479 - val_loss: 0.2553 - val_accuracy: 0.9660 - val_f1_m: 0.9689\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 80us/sample - loss: 0.0053 - accuracy: 0.9983 - f1_m: 0.9502 - val_loss: 0.2664 - val_accuracy: 0.9635 - val_f1_m: 0.9743\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 79us/sample - loss: 0.0025 - accuracy: 0.9994 - f1_m: 0.9495 - val_loss: 0.3483 - val_accuracy: 0.9588 - val_f1_m: 0.9693\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 80us/sample - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9495 - val_loss: 0.2523 - val_accuracy: 0.9643 - val_f1_m: 0.9747\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 83us/sample - loss: 0.0019 - accuracy: 0.9996 - f1_m: 0.9496 - val_loss: 0.2735 - val_accuracy: 0.9638 - val_f1_m: 0.9701\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 80us/sample - loss: 4.0282e-04 - accuracy: 0.9999 - f1_m: 0.9485 - val_loss: 0.2655 - val_accuracy: 0.9650 - val_f1_m: 0.9694\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 80us/sample - loss: 0.0035 - accuracy: 0.9992 - f1_m: 0.9499 - val_loss: 0.2397 - val_accuracy: 0.9628 - val_f1_m: 0.9743\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 125us/sample - loss: 0.0072 - accuracy: 0.9988 - f1_m: 0.9491 - val_loss: 0.1394 - val_accuracy: 0.9793 - val_f1_m: 0.9683\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 91us/sample - loss: 0.0036 - accuracy: 0.9991 - f1_m: 0.9498 - val_loss: 0.1320 - val_accuracy: 0.9803 - val_f1_m: 0.9628\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 93us/sample - loss: 2.2855e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1234 - val_accuracy: 0.9825 - val_f1_m: 0.9615\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 93us/sample - loss: 2.8497e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1241 - val_accuracy: 0.9825 - val_f1_m: 0.9578\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 93us/sample - loss: 1.0819e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1252 - val_accuracy: 0.9825 - val_f1_m: 0.9588\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 94us/sample - loss: 7.3990e-06 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1264 - val_accuracy: 0.9825 - val_f1_m: 0.9590\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 93us/sample - loss: 5.7431e-06 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1276 - val_accuracy: 0.9825 - val_f1_m: 0.9582\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 92us/sample - loss: 4.5794e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1288 - val_accuracy: 0.9822 - val_f1_m: 0.9587\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 93us/sample - loss: 3.6508e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1301 - val_accuracy: 0.9822 - val_f1_m: 0.9586\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 92us/sample - loss: 2.9343e-06 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1316 - val_accuracy: 0.9818 - val_f1_m: 0.9587\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 3s 160us/sample - loss: 0.0044 - accuracy: 0.9992 - f1_m: 0.9488 - val_loss: 0.1180 - val_accuracy: 0.9808 - val_f1_m: 0.9646\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 121us/sample - loss: 0.0042 - accuracy: 0.9991 - f1_m: 0.9499 - val_loss: 0.1801 - val_accuracy: 0.9805 - val_f1_m: 0.9590\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 121us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9489 - val_loss: 0.1748 - val_accuracy: 0.9847 - val_f1_m: 0.9567\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 129us/sample - loss: 6.9428e-04 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.2490 - val_accuracy: 0.9812 - val_f1_m: 0.9578\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 120us/sample - loss: 0.0098 - accuracy: 0.9976 - f1_m: 0.9510 - val_loss: 0.1350 - val_accuracy: 0.9808 - val_f1_m: 0.9630\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 120us/sample - loss: 3.5653e-04 - accuracy: 0.9999 - f1_m: 0.9481 - val_loss: 0.1497 - val_accuracy: 0.9803 - val_f1_m: 0.9592\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 120us/sample - loss: 6.1117e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1495 - val_accuracy: 0.9820 - val_f1_m: 0.9601\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 121us/sample - loss: 5.6068e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1504 - val_accuracy: 0.9820 - val_f1_m: 0.9596\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 120us/sample - loss: 3.8222e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1513 - val_accuracy: 0.9822 - val_f1_m: 0.9596\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 120us/sample - loss: 2.8873e-06 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1523 - val_accuracy: 0.9825 - val_f1_m: 0.9590\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 4s 222us/sample - loss: 0.0138 - accuracy: 0.9972 - f1_m: 0.9514 - val_loss: 0.1037 - val_accuracy: 0.9875 - val_f1_m: 0.9599\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 3s 169us/sample - loss: 0.0045 - accuracy: 0.9987 - f1_m: 0.9504 - val_loss: 0.1096 - val_accuracy: 0.9835 - val_f1_m: 0.9682\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 3s 167us/sample - loss: 0.0076 - accuracy: 0.9982 - f1_m: 0.9501 - val_loss: 0.1029 - val_accuracy: 0.9887 - val_f1_m: 0.9541\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 3s 168us/sample - loss: 0.0090 - accuracy: 0.9981 - f1_m: 0.9514 - val_loss: 0.1066 - val_accuracy: 0.9852 - val_f1_m: 0.9587\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 3s 168us/sample - loss: 0.0082 - accuracy: 0.9979 - f1_m: 0.9506 - val_loss: 0.1350 - val_accuracy: 0.9827 - val_f1_m: 0.9634\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 3s 168us/sample - loss: 0.0097 - accuracy: 0.9979 - f1_m: 0.9511 - val_loss: 0.1914 - val_accuracy: 0.9768 - val_f1_m: 0.9647\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 3s 171us/sample - loss: 0.0131 - accuracy: 0.9975 - f1_m: 0.9515 - val_loss: 0.1349 - val_accuracy: 0.9850 - val_f1_m: 0.9595\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 3s 171us/sample - loss: 0.0104 - accuracy: 0.9976 - f1_m: 0.9508 - val_loss: 0.1363 - val_accuracy: 0.9815 - val_f1_m: 0.9579\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 3s 169us/sample - loss: 0.0048 - accuracy: 0.9991 - f1_m: 0.9498 - val_loss: 0.1271 - val_accuracy: 0.9843 - val_f1_m: 0.9578\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 3s 168us/sample - loss: 0.0043 - accuracy: 0.9991 - f1_m: 0.9484 - val_loss: 0.1620 - val_accuracy: 0.9830 - val_f1_m: 0.9597\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 118us/sample - loss: 0.0087 - accuracy: 0.9984 - f1_m: 0.9519 - val_loss: 0.3231 - val_accuracy: 0.9571 - val_f1_m: 0.9738\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 0.0072 - accuracy: 0.9979 - f1_m: 0.9534 - val_loss: 0.3589 - val_accuracy: 0.9520 - val_f1_m: 0.9713\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 0.0041 - accuracy: 0.9987 - f1_m: 0.9514 - val_loss: 0.3029 - val_accuracy: 0.9600 - val_f1_m: 0.9754\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9521 - val_loss: 0.3118 - val_accuracy: 0.9571 - val_f1_m: 0.9776\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 1s 86us/sample - loss: 0.0031 - accuracy: 0.9990 - f1_m: 0.9507 - val_loss: 0.3395 - val_accuracy: 0.9594 - val_f1_m: 0.9705\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 1s 87us/sample - loss: 0.0018 - accuracy: 0.9994 - f1_m: 0.9508 - val_loss: 0.3330 - val_accuracy: 0.9611 - val_f1_m: 0.9690\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 1s 86us/sample - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9503 - val_loss: 0.3252 - val_accuracy: 0.9594 - val_f1_m: 0.9743\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 0.0040 - accuracy: 0.9984 - f1_m: 0.9528 - val_loss: 0.3142 - val_accuracy: 0.9606 - val_f1_m: 0.9760\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 1s 87us/sample - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9515 - val_loss: 0.3238 - val_accuracy: 0.9606 - val_f1_m: 0.9768\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 1s 87us/sample - loss: 5.7329e-04 - accuracy: 1.0000 - f1_m: 0.9488 - val_loss: 0.3072 - val_accuracy: 0.9623 - val_f1_m: 0.9763\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 131us/sample - loss: 0.0077 - accuracy: 0.9982 - f1_m: 0.9514 - val_loss: 0.1992 - val_accuracy: 0.9757 - val_f1_m: 0.9556\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 0.0027 - accuracy: 0.9990 - f1_m: 0.9505 - val_loss: 0.1983 - val_accuracy: 0.9757 - val_f1_m: 0.9580\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 6.9127e-04 - accuracy: 0.9999 - f1_m: 0.9486 - val_loss: 0.1913 - val_accuracy: 0.9786 - val_f1_m: 0.9572\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9494 - val_loss: 0.2024 - val_accuracy: 0.9771 - val_f1_m: 0.9549\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 0.0056 - accuracy: 0.9985 - f1_m: 0.9510 - val_loss: 0.2049 - val_accuracy: 0.9766 - val_f1_m: 0.9598\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 0.0106 - accuracy: 0.9971 - f1_m: 0.9530 - val_loss: 0.2038 - val_accuracy: 0.9751 - val_f1_m: 0.9622\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 0.0021 - accuracy: 0.9992 - f1_m: 0.9502 - val_loss: 0.2100 - val_accuracy: 0.9731 - val_f1_m: 0.9618\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 96us/sample - loss: 0.0011 - accuracy: 0.9998 - f1_m: 0.9492 - val_loss: 0.1788 - val_accuracy: 0.9786 - val_f1_m: 0.9576\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 97us/sample - loss: 1.1871e-04 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.1844 - val_accuracy: 0.9794 - val_f1_m: 0.9570\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 98us/sample - loss: 4.6591e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1837 - val_accuracy: 0.9791 - val_f1_m: 0.9580\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 0.0064 - accuracy: 0.9982 - f1_m: 0.9501 - val_loss: 0.1400 - val_accuracy: 0.9826 - val_f1_m: 0.9595\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 0.0037 - accuracy: 0.9991 - f1_m: 0.9500 - val_loss: 0.1492 - val_accuracy: 0.9786 - val_f1_m: 0.9601\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 0.0038 - accuracy: 0.9990 - f1_m: 0.9507 - val_loss: 0.1816 - val_accuracy: 0.9814 - val_f1_m: 0.9591\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 0.0051 - accuracy: 0.9985 - f1_m: 0.9506 - val_loss: 0.1692 - val_accuracy: 0.9774 - val_f1_m: 0.9569\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 0.0027 - accuracy: 0.9992 - f1_m: 0.9491 - val_loss: 0.1622 - val_accuracy: 0.9820 - val_f1_m: 0.9557\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 8.0665e-05 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.1484 - val_accuracy: 0.9846 - val_f1_m: 0.9558\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 124us/sample - loss: 1.2261e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1484 - val_accuracy: 0.9849 - val_f1_m: 0.9549\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 122us/sample - loss: 7.8329e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1490 - val_accuracy: 0.9843 - val_f1_m: 0.9546\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 5.9227e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1493 - val_accuracy: 0.9843 - val_f1_m: 0.9537\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 123us/sample - loss: 4.8451e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1510 - val_accuracy: 0.9843 - val_f1_m: 0.9546\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 4s 216us/sample - loss: 0.0090 - accuracy: 0.9980 - f1_m: 0.9517 - val_loss: 0.1268 - val_accuracy: 0.9783 - val_f1_m: 0.9680\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 3s 162us/sample - loss: 0.0118 - accuracy: 0.9971 - f1_m: 0.9533 - val_loss: 0.1243 - val_accuracy: 0.9723 - val_f1_m: 0.9780\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 0.0073 - accuracy: 0.9976 - f1_m: 0.9530 - val_loss: 0.1326 - val_accuracy: 0.9751 - val_f1_m: 0.9640\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 0.0064 - accuracy: 0.9980 - f1_m: 0.9520 - val_loss: 0.1795 - val_accuracy: 0.9774 - val_f1_m: 0.9611\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 0.0090 - accuracy: 0.9969 - f1_m: 0.9523 - val_loss: 0.1230 - val_accuracy: 0.9811 - val_f1_m: 0.9574\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 3s 163us/sample - loss: 0.0063 - accuracy: 0.9982 - f1_m: 0.9508 - val_loss: 0.1325 - val_accuracy: 0.9797 - val_f1_m: 0.9626\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 0.0071 - accuracy: 0.9979 - f1_m: 0.9514 - val_loss: 0.1461 - val_accuracy: 0.9780 - val_f1_m: 0.9633\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 0.0051 - accuracy: 0.9985 - f1_m: 0.9513 - val_loss: 0.1781 - val_accuracy: 0.9743 - val_f1_m: 0.9597\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 3s 160us/sample - loss: 0.0063 - accuracy: 0.9979 - f1_m: 0.9515 - val_loss: 0.1266 - val_accuracy: 0.9800 - val_f1_m: 0.9586\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 3s 161us/sample - loss: 0.0059 - accuracy: 0.9980 - f1_m: 0.9505 - val_loss: 0.1551 - val_accuracy: 0.9783 - val_f1_m: 0.9637\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 5s 293us/sample - loss: 0.0064 - accuracy: 0.9989 - f1_m: 0.9500 - val_loss: 0.2630 - val_accuracy: 0.9643 - val_f1_m: 0.9666\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 1s 89us/sample - loss: 0.0017 - accuracy: 0.9998 - f1_m: 0.9484 - val_loss: 0.2559 - val_accuracy: 0.9649 - val_f1_m: 0.9682\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 1s 87us/sample - loss: 3.2301e-04 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.2411 - val_accuracy: 0.9663 - val_f1_m: 0.9665\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 1s 89us/sample - loss: 1.8356e-04 - accuracy: 0.9999 - f1_m: 0.9481 - val_loss: 0.2528 - val_accuracy: 0.9651 - val_f1_m: 0.9660\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 3.3133e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2524 - val_accuracy: 0.9666 - val_f1_m: 0.9664\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 1.2573e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2525 - val_accuracy: 0.9666 - val_f1_m: 0.9647\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 8.8560e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2526 - val_accuracy: 0.9666 - val_f1_m: 0.9637\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 7.2308e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2536 - val_accuracy: 0.9666 - val_f1_m: 0.9636\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 5.9710e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2554 - val_accuracy: 0.9669 - val_f1_m: 0.9621\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 1s 88us/sample - loss: 5.0921e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2557 - val_accuracy: 0.9671 - val_f1_m: 0.9627\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 2s 138us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9499 - val_loss: 0.1487 - val_accuracy: 0.9809 - val_f1_m: 0.9580\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 0.0020 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.1290 - val_accuracy: 0.9817 - val_f1_m: 0.9585\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 1.8737e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1248 - val_accuracy: 0.9831 - val_f1_m: 0.9555\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 7.7359e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1248 - val_accuracy: 0.9831 - val_f1_m: 0.9564\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 5.6823e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1249 - val_accuracy: 0.9831 - val_f1_m: 0.9562\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 108us/sample - loss: 4.4862e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1252 - val_accuracy: 0.9834 - val_f1_m: 0.9568\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 106us/sample - loss: 3.6294e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1255 - val_accuracy: 0.9834 - val_f1_m: 0.9565\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 2.9555e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1259 - val_accuracy: 0.9840 - val_f1_m: 0.9560\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 104us/sample - loss: 2.4107e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1265 - val_accuracy: 0.9840 - val_f1_m: 0.9563\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 105us/sample - loss: 1.9606e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1270 - val_accuracy: 0.9840 - val_f1_m: 0.9563\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 3s 171us/sample - loss: 0.0042 - accuracy: 0.9992 - f1_m: 0.9490 - val_loss: 0.1901 - val_accuracy: 0.9811 - val_f1_m: 0.9555\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 2s 131us/sample - loss: 0.0034 - accuracy: 0.9993 - f1_m: 0.9487 - val_loss: 0.1309 - val_accuracy: 0.9826 - val_f1_m: 0.9564\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 2s 130us/sample - loss: 0.0055 - accuracy: 0.9987 - f1_m: 0.9495 - val_loss: 0.1793 - val_accuracy: 0.9791 - val_f1_m: 0.9579\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 2s 129us/sample - loss: 0.0027 - accuracy: 0.9991 - f1_m: 0.9488 - val_loss: 0.1869 - val_accuracy: 0.9809 - val_f1_m: 0.9610\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 2s 131us/sample - loss: 0.0032 - accuracy: 0.9992 - f1_m: 0.9492 - val_loss: 0.2158 - val_accuracy: 0.9826 - val_f1_m: 0.9522\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 2s 130us/sample - loss: 0.0045 - accuracy: 0.9990 - f1_m: 0.9486 - val_loss: 0.1649 - val_accuracy: 0.9854 - val_f1_m: 0.9568\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 2s 130us/sample - loss: 0.0034 - accuracy: 0.9991 - f1_m: 0.9488 - val_loss: 0.1762 - val_accuracy: 0.9826 - val_f1_m: 0.9583\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 2s 131us/sample - loss: 8.8459e-04 - accuracy: 0.9996 - f1_m: 0.9484 - val_loss: 0.1921 - val_accuracy: 0.9786 - val_f1_m: 0.9583\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 2s 130us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9485 - val_loss: 0.2282 - val_accuracy: 0.9803 - val_f1_m: 0.9592\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 2s 130us/sample - loss: 0.0077 - accuracy: 0.9982 - f1_m: 0.9497 - val_loss: 0.1722 - val_accuracy: 0.9800 - val_f1_m: 0.9582\n",
      "Train on 16500 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "16500/16500 [==============================] - 4s 228us/sample - loss: 0.0090 - accuracy: 0.9978 - f1_m: 0.9503 - val_loss: 0.1534 - val_accuracy: 0.9811 - val_f1_m: 0.9546\n",
      "Epoch 2/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 0.0095 - accuracy: 0.9981 - f1_m: 0.9504 - val_loss: 0.1462 - val_accuracy: 0.9837 - val_f1_m: 0.9552\n",
      "Epoch 3/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 0.0047 - accuracy: 0.9986 - f1_m: 0.9494 - val_loss: 0.1799 - val_accuracy: 0.9814 - val_f1_m: 0.9560\n",
      "Epoch 4/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 0.0024 - accuracy: 0.9993 - f1_m: 0.9493 - val_loss: 0.1169 - val_accuracy: 0.9851 - val_f1_m: 0.9542\n",
      "Epoch 5/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 0.0076 - accuracy: 0.9978 - f1_m: 0.9523 - val_loss: 0.1487 - val_accuracy: 0.9843 - val_f1_m: 0.9557\n",
      "Epoch 6/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 0.0106 - accuracy: 0.9976 - f1_m: 0.9505 - val_loss: 0.0943 - val_accuracy: 0.9857 - val_f1_m: 0.9558\n",
      "Epoch 7/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 0.0030 - accuracy: 0.9992 - f1_m: 0.9507 - val_loss: 0.1007 - val_accuracy: 0.9889 - val_f1_m: 0.9548\n",
      "Epoch 8/10\n",
      "16500/16500 [==============================] - 3s 175us/sample - loss: 3.4027e-04 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.1224 - val_accuracy: 0.9891 - val_f1_m: 0.9523\n",
      "Epoch 9/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 1.3318e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1242 - val_accuracy: 0.9874 - val_f1_m: 0.9526\n",
      "Epoch 10/10\n",
      "16500/16500 [==============================] - 3s 174us/sample - loss: 1.0766e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.1267 - val_accuracy: 0.9877 - val_f1_m: 0.9511\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 116us/sample - loss: 0.0098 - accuracy: 0.9980 - f1_m: 0.9521 - val_loss: 0.3492 - val_accuracy: 0.9610 - val_f1_m: 0.9745\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 1s 88us/sample - loss: 0.0058 - accuracy: 0.9989 - f1_m: 0.9504 - val_loss: 0.3802 - val_accuracy: 0.9550 - val_f1_m: 0.9750\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 1s 88us/sample - loss: 0.0043 - accuracy: 0.9986 - f1_m: 0.9512 - val_loss: 0.3898 - val_accuracy: 0.9547 - val_f1_m: 0.9741\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 1s 88us/sample - loss: 0.0069 - accuracy: 0.9977 - f1_m: 0.9538 - val_loss: 0.3963 - val_accuracy: 0.9530 - val_f1_m: 0.9727\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 1s 87us/sample - loss: 0.0026 - accuracy: 0.9991 - f1_m: 0.9502 - val_loss: 0.3530 - val_accuracy: 0.9590 - val_f1_m: 0.9687\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 8.9596e-04 - accuracy: 0.9998 - f1_m: 0.9491 - val_loss: 0.3368 - val_accuracy: 0.9597 - val_f1_m: 0.9719\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 2.0495e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.3395 - val_accuracy: 0.9590 - val_f1_m: 0.9718\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 1.4795e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.3377 - val_accuracy: 0.9583 - val_f1_m: 0.9737\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 1.2210e-04 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.3382 - val_accuracy: 0.9577 - val_f1_m: 0.9734\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 1.0982e-04 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.3388 - val_accuracy: 0.9590 - val_f1_m: 0.9713\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 129us/sample - loss: 0.0074 - accuracy: 0.9979 - f1_m: 0.9510 - val_loss: 0.2212 - val_accuracy: 0.9760 - val_f1_m: 0.9630\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 97us/sample - loss: 0.0031 - accuracy: 0.9992 - f1_m: 0.9499 - val_loss: 0.2097 - val_accuracy: 0.9740 - val_f1_m: 0.9628\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 2s 98us/sample - loss: 0.0054 - accuracy: 0.9985 - f1_m: 0.9505 - val_loss: 0.2173 - val_accuracy: 0.9733 - val_f1_m: 0.9617\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 97us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9489 - val_loss: 0.2029 - val_accuracy: 0.9757 - val_f1_m: 0.9574\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 97us/sample - loss: 1.6733e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2028 - val_accuracy: 0.9767 - val_f1_m: 0.9595\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 97us/sample - loss: 9.3249e-04 - accuracy: 0.9997 - f1_m: 0.9482 - val_loss: 0.2210 - val_accuracy: 0.9767 - val_f1_m: 0.9666\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 96us/sample - loss: 0.0080 - accuracy: 0.9975 - f1_m: 0.9531 - val_loss: 0.2021 - val_accuracy: 0.9777 - val_f1_m: 0.9613\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 96us/sample - loss: 7.7876e-04 - accuracy: 0.9998 - f1_m: 0.9488 - val_loss: 0.2112 - val_accuracy: 0.9777 - val_f1_m: 0.9613\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 95us/sample - loss: 2.0589e-04 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 0.2152 - val_accuracy: 0.9773 - val_f1_m: 0.9592\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 2s 96us/sample - loss: 4.0402e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2122 - val_accuracy: 0.9773 - val_f1_m: 0.9616\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 3s 160us/sample - loss: 0.0058 - accuracy: 0.9986 - f1_m: 0.9497 - val_loss: 0.2069 - val_accuracy: 0.9810 - val_f1_m: 0.9588\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0031 - accuracy: 0.9990 - f1_m: 0.9494 - val_loss: 0.2233 - val_accuracy: 0.9783 - val_f1_m: 0.9553\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0073 - accuracy: 0.9980 - f1_m: 0.9506 - val_loss: 0.2074 - val_accuracy: 0.9810 - val_f1_m: 0.9605\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9491 - val_loss: 0.1583 - val_accuracy: 0.9783 - val_f1_m: 0.9608\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0021 - accuracy: 0.9992 - f1_m: 0.9487 - val_loss: 0.3013 - val_accuracy: 0.9733 - val_f1_m: 0.9549\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0109 - accuracy: 0.9977 - f1_m: 0.9508 - val_loss: 0.1922 - val_accuracy: 0.9737 - val_f1_m: 0.9599\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0029 - accuracy: 0.9989 - f1_m: 0.9495 - val_loss: 0.2230 - val_accuracy: 0.9783 - val_f1_m: 0.9575\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0050 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1853 - val_accuracy: 0.9767 - val_f1_m: 0.9581\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 120us/sample - loss: 0.0036 - accuracy: 0.9990 - f1_m: 0.9491 - val_loss: 0.1784 - val_accuracy: 0.9787 - val_f1_m: 0.9583\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 2s 121us/sample - loss: 0.0012 - accuracy: 0.9995 - f1_m: 0.9480 - val_loss: 0.1521 - val_accuracy: 0.9820 - val_f1_m: 0.9576\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 4s 210us/sample - loss: 0.0128 - accuracy: 0.9966 - f1_m: 0.9522 - val_loss: 0.1630 - val_accuracy: 0.9767 - val_f1_m: 0.9599\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 3s 159us/sample - loss: 0.0119 - accuracy: 0.9966 - f1_m: 0.9524 - val_loss: 0.1704 - val_accuracy: 0.9770 - val_f1_m: 0.9637\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 3s 159us/sample - loss: 0.0056 - accuracy: 0.9982 - f1_m: 0.9504 - val_loss: 0.2457 - val_accuracy: 0.9767 - val_f1_m: 0.9595\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 3s 158us/sample - loss: 0.0099 - accuracy: 0.9969 - f1_m: 0.9522 - val_loss: 0.1835 - val_accuracy: 0.9810 - val_f1_m: 0.9593\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 3s 158us/sample - loss: 0.0074 - accuracy: 0.9980 - f1_m: 0.9506 - val_loss: 0.1981 - val_accuracy: 0.9783 - val_f1_m: 0.9624\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 3s 159us/sample - loss: 0.0071 - accuracy: 0.9982 - f1_m: 0.9509 - val_loss: 0.1664 - val_accuracy: 0.9790 - val_f1_m: 0.9610\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 3s 158us/sample - loss: 0.0045 - accuracy: 0.9988 - f1_m: 0.9498 - val_loss: 0.2304 - val_accuracy: 0.9743 - val_f1_m: 0.9632\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 3s 158us/sample - loss: 0.0151 - accuracy: 0.9966 - f1_m: 0.9533 - val_loss: 0.1226 - val_accuracy: 0.9780 - val_f1_m: 0.9634\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 3s 157us/sample - loss: 0.0041 - accuracy: 0.9986 - f1_m: 0.9506 - val_loss: 0.1742 - val_accuracy: 0.9783 - val_f1_m: 0.9613\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 3s 159us/sample - loss: 0.0039 - accuracy: 0.9989 - f1_m: 0.9501 - val_loss: 0.1630 - val_accuracy: 0.9797 - val_f1_m: 0.9592\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 116us/sample - loss: 0.0085 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.2635 - val_accuracy: 0.9583 - val_f1_m: 0.9674\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 0.0039 - accuracy: 0.9993 - f1_m: 0.9485 - val_loss: 0.2447 - val_accuracy: 0.9633 - val_f1_m: 0.9676\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 0.0014 - accuracy: 0.9994 - f1_m: 0.9489 - val_loss: 0.2722 - val_accuracy: 0.9630 - val_f1_m: 0.9652\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 1s 87us/sample - loss: 3.4425e-04 - accuracy: 0.9999 - f1_m: 0.9482 - val_loss: 0.2438 - val_accuracy: 0.9663 - val_f1_m: 0.9692\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 4.7020e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2475 - val_accuracy: 0.9680 - val_f1_m: 0.9657\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 1.9328e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2478 - val_accuracy: 0.9673 - val_f1_m: 0.9654\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 1s 87us/sample - loss: 1.5058e-05 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2488 - val_accuracy: 0.9677 - val_f1_m: 0.9640\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 1.2354e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2500 - val_accuracy: 0.9677 - val_f1_m: 0.9654\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 1.0294e-05 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2511 - val_accuracy: 0.9673 - val_f1_m: 0.9647\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 1s 86us/sample - loss: 8.6202e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2529 - val_accuracy: 0.9673 - val_f1_m: 0.9647\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 2s 133us/sample - loss: 0.0039 - accuracy: 0.9990 - f1_m: 0.9491 - val_loss: 0.1570 - val_accuracy: 0.9803 - val_f1_m: 0.9592\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 102us/sample - loss: 0.0032 - accuracy: 0.9991 - f1_m: 0.9491 - val_loss: 0.1913 - val_accuracy: 0.9753 - val_f1_m: 0.9600\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 2s 102us/sample - loss: 0.0026 - accuracy: 0.9990 - f1_m: 0.9499 - val_loss: 0.1663 - val_accuracy: 0.9800 - val_f1_m: 0.9589\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 102us/sample - loss: 0.0054 - accuracy: 0.9985 - f1_m: 0.9501 - val_loss: 0.1466 - val_accuracy: 0.9813 - val_f1_m: 0.9616\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 101us/sample - loss: 3.6335e-04 - accuracy: 0.9998 - f1_m: 0.9481 - val_loss: 0.1518 - val_accuracy: 0.9787 - val_f1_m: 0.9571\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 104us/sample - loss: 0.0014 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.1987 - val_accuracy: 0.9787 - val_f1_m: 0.9578\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 103us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9484 - val_loss: 0.1978 - val_accuracy: 0.9773 - val_f1_m: 0.9594\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 103us/sample - loss: 0.0078 - accuracy: 0.9981 - f1_m: 0.9498 - val_loss: 0.1947 - val_accuracy: 0.9743 - val_f1_m: 0.9594\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 103us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9485 - val_loss: 0.1706 - val_accuracy: 0.9817 - val_f1_m: 0.9579\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 2s 102us/sample - loss: 4.3988e-04 - accuracy: 0.9999 - f1_m: 0.9475 - val_loss: 0.1442 - val_accuracy: 0.9827 - val_f1_m: 0.9576\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 3s 167us/sample - loss: 0.0086 - accuracy: 0.9985 - f1_m: 0.9493 - val_loss: 0.1231 - val_accuracy: 0.9810 - val_f1_m: 0.9645\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 2s 137us/sample - loss: 3.0502e-04 - accuracy: 0.9998 - f1_m: 0.9481 - val_loss: 0.1431 - val_accuracy: 0.9837 - val_f1_m: 0.9605\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 2s 128us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9498 - val_loss: 0.2267 - val_accuracy: 0.9797 - val_f1_m: 0.9565\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 2s 128us/sample - loss: 0.0075 - accuracy: 0.9983 - f1_m: 0.9505 - val_loss: 0.1667 - val_accuracy: 0.9790 - val_f1_m: 0.9608\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 2s 127us/sample - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9485 - val_loss: 0.1503 - val_accuracy: 0.9843 - val_f1_m: 0.9581\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 2s 126us/sample - loss: 5.4453e-04 - accuracy: 0.9999 - f1_m: 0.9480 - val_loss: 0.1792 - val_accuracy: 0.9840 - val_f1_m: 0.9559\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 2s 126us/sample - loss: 0.0033 - accuracy: 0.9994 - f1_m: 0.9485 - val_loss: 0.1634 - val_accuracy: 0.9833 - val_f1_m: 0.9602\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 2s 126us/sample - loss: 0.0056 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1754 - val_accuracy: 0.9793 - val_f1_m: 0.9598\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 2s 125us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9480 - val_loss: 0.1584 - val_accuracy: 0.9823 - val_f1_m: 0.9606\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 2s 128us/sample - loss: 6.0747e-04 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.1863 - val_accuracy: 0.9813 - val_f1_m: 0.9568\n",
      "Train on 17000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "17000/17000 [==============================] - 4s 220us/sample - loss: 0.0119 - accuracy: 0.9975 - f1_m: 0.9507 - val_loss: 0.1389 - val_accuracy: 0.9873 - val_f1_m: 0.9546\n",
      "Epoch 2/10\n",
      "17000/17000 [==============================] - 3s 170us/sample - loss: 0.0027 - accuracy: 0.9991 - f1_m: 0.9492 - val_loss: 0.1516 - val_accuracy: 0.9877 - val_f1_m: 0.9520\n",
      "Epoch 3/10\n",
      "17000/17000 [==============================] - 3s 170us/sample - loss: 0.0127 - accuracy: 0.9977 - f1_m: 0.9494 - val_loss: 0.1554 - val_accuracy: 0.9780 - val_f1_m: 0.9662\n",
      "Epoch 4/10\n",
      "17000/17000 [==============================] - 3s 170us/sample - loss: 0.0130 - accuracy: 0.9968 - f1_m: 0.9518 - val_loss: 0.1539 - val_accuracy: 0.9840 - val_f1_m: 0.9557\n",
      "Epoch 5/10\n",
      "17000/17000 [==============================] - 3s 169us/sample - loss: 0.0166 - accuracy: 0.9965 - f1_m: 0.9518 - val_loss: 0.1215 - val_accuracy: 0.9833 - val_f1_m: 0.9597\n",
      "Epoch 6/10\n",
      "17000/17000 [==============================] - 3s 177us/sample - loss: 0.0068 - accuracy: 0.9978 - f1_m: 0.9515 - val_loss: 0.1215 - val_accuracy: 0.9867 - val_f1_m: 0.9571\n",
      "Epoch 7/10\n",
      "17000/17000 [==============================] - 3s 171us/sample - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9491 - val_loss: 0.1343 - val_accuracy: 0.9827 - val_f1_m: 0.9569\n",
      "Epoch 8/10\n",
      "17000/17000 [==============================] - 3s 170us/sample - loss: 0.0080 - accuracy: 0.9983 - f1_m: 0.9497 - val_loss: 0.0992 - val_accuracy: 0.9850 - val_f1_m: 0.9594\n",
      "Epoch 9/10\n",
      "17000/17000 [==============================] - 3s 170us/sample - loss: 0.0069 - accuracy: 0.9982 - f1_m: 0.9514 - val_loss: 0.1306 - val_accuracy: 0.9810 - val_f1_m: 0.9604\n",
      "Epoch 10/10\n",
      "17000/17000 [==============================] - 3s 170us/sample - loss: 0.0138 - accuracy: 0.9967 - f1_m: 0.9519 - val_loss: 0.1166 - val_accuracy: 0.9853 - val_f1_m: 0.9620\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 2s 112us/sample - loss: 0.0121 - accuracy: 0.9982 - f1_m: 0.9528 - val_loss: 0.3111 - val_accuracy: 0.9596 - val_f1_m: 0.9698\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 0.0065 - accuracy: 0.9986 - f1_m: 0.9525 - val_loss: 0.3304 - val_accuracy: 0.9624 - val_f1_m: 0.9699\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 0.0063 - accuracy: 0.9984 - f1_m: 0.9521 - val_loss: 0.3438 - val_accuracy: 0.9592 - val_f1_m: 0.9728\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 0.0044 - accuracy: 0.9986 - f1_m: 0.9530 - val_loss: 0.3394 - val_accuracy: 0.9640 - val_f1_m: 0.9693\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 0.0031 - accuracy: 0.9990 - f1_m: 0.9506 - val_loss: 0.3396 - val_accuracy: 0.9596 - val_f1_m: 0.9698\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 1s 82us/sample - loss: 6.7647e-04 - accuracy: 0.9998 - f1_m: 0.9486 - val_loss: 0.3295 - val_accuracy: 0.9624 - val_f1_m: 0.9697\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 0.0011 - accuracy: 0.9998 - f1_m: 0.9491 - val_loss: 0.3321 - val_accuracy: 0.9620 - val_f1_m: 0.9712\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 1s 81us/sample - loss: 8.8788e-04 - accuracy: 0.9998 - f1_m: 0.9485 - val_loss: 0.3061 - val_accuracy: 0.9600 - val_f1_m: 0.9710\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 9.5598e-04 - accuracy: 0.9998 - f1_m: 0.9489 - val_loss: 0.3808 - val_accuracy: 0.9624 - val_f1_m: 0.9712\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 0.0113 - accuracy: 0.9962 - f1_m: 0.9558 - val_loss: 0.3213 - val_accuracy: 0.9600 - val_f1_m: 0.9733\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 2s 122us/sample - loss: 0.0061 - accuracy: 0.9992 - f1_m: 0.9506 - val_loss: 0.1827 - val_accuracy: 0.9760 - val_f1_m: 0.9618\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 93us/sample - loss: 0.0047 - accuracy: 0.9985 - f1_m: 0.9506 - val_loss: 0.1922 - val_accuracy: 0.9768 - val_f1_m: 0.9638\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 2s 119us/sample - loss: 0.0040 - accuracy: 0.9986 - f1_m: 0.9508 - val_loss: 0.2013 - val_accuracy: 0.9788 - val_f1_m: 0.9628\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 111us/sample - loss: 0.0024 - accuracy: 0.9993 - f1_m: 0.9495 - val_loss: 0.1963 - val_accuracy: 0.9756 - val_f1_m: 0.9659\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 97us/sample - loss: 8.0651e-04 - accuracy: 0.9997 - f1_m: 0.9493 - val_loss: 0.1911 - val_accuracy: 0.9776 - val_f1_m: 0.9617\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 2s 96us/sample - loss: 0.0025 - accuracy: 0.9993 - f1_m: 0.9506 - val_loss: 0.2041 - val_accuracy: 0.9752 - val_f1_m: 0.9683\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 101us/sample - loss: 0.0053 - accuracy: 0.9985 - f1_m: 0.9509 - val_loss: 0.1674 - val_accuracy: 0.9768 - val_f1_m: 0.9623\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 97us/sample - loss: 0.0053 - accuracy: 0.9985 - f1_m: 0.9513 - val_loss: 0.2381 - val_accuracy: 0.9724 - val_f1_m: 0.9624\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 2s 97us/sample - loss: 0.0013 - accuracy: 0.9996 - f1_m: 0.9497 - val_loss: 0.1918 - val_accuracy: 0.9780 - val_f1_m: 0.9606\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 94us/sample - loss: 7.7308e-05 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.1934 - val_accuracy: 0.9776 - val_f1_m: 0.9610\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 3s 161us/sample - loss: 0.0079 - accuracy: 0.9983 - f1_m: 0.9501 - val_loss: 0.1592 - val_accuracy: 0.9788 - val_f1_m: 0.9575\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 129us/sample - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9493 - val_loss: 0.2049 - val_accuracy: 0.9792 - val_f1_m: 0.9584\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 3s 144us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9491 - val_loss: 0.2403 - val_accuracy: 0.9796 - val_f1_m: 0.9615\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 130us/sample - loss: 0.0103 - accuracy: 0.9975 - f1_m: 0.9506 - val_loss: 0.2926 - val_accuracy: 0.9720 - val_f1_m: 0.9599\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 132us/sample - loss: 0.0078 - accuracy: 0.9979 - f1_m: 0.9509 - val_loss: 0.2509 - val_accuracy: 0.9764 - val_f1_m: 0.9581\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 2s 136us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_m: 0.9490 - val_loss: 0.2050 - val_accuracy: 0.9784 - val_f1_m: 0.9592\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 133us/sample - loss: 0.0031 - accuracy: 0.9992 - f1_m: 0.9493 - val_loss: 0.2031 - val_accuracy: 0.9796 - val_f1_m: 0.9575\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 134us/sample - loss: 0.0040 - accuracy: 0.9988 - f1_m: 0.9502 - val_loss: 0.2620 - val_accuracy: 0.9716 - val_f1_m: 0.9615\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 2s 133us/sample - loss: 0.0055 - accuracy: 0.9986 - f1_m: 0.9506 - val_loss: 0.1875 - val_accuracy: 0.9768 - val_f1_m: 0.9691\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 126us/sample - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9486 - val_loss: 0.1902 - val_accuracy: 0.9796 - val_f1_m: 0.9603\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 4s 208us/sample - loss: 0.0126 - accuracy: 0.9969 - f1_m: 0.9531 - val_loss: 0.1622 - val_accuracy: 0.9784 - val_f1_m: 0.9619\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 3s 154us/sample - loss: 0.0012 - accuracy: 0.9995 - f1_m: 0.9492 - val_loss: 0.2002 - val_accuracy: 0.9796 - val_f1_m: 0.9565\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 3s 154us/sample - loss: 0.0148 - accuracy: 0.9962 - f1_m: 0.9521 - val_loss: 0.1957 - val_accuracy: 0.9736 - val_f1_m: 0.9641\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 3s 155us/sample - loss: 0.0081 - accuracy: 0.9976 - f1_m: 0.9526 - val_loss: 0.1843 - val_accuracy: 0.9724 - val_f1_m: 0.9611\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 3s 154us/sample - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9500 - val_loss: 0.1527 - val_accuracy: 0.9768 - val_f1_m: 0.9653\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 3s 156us/sample - loss: 0.0065 - accuracy: 0.9983 - f1_m: 0.9517 - val_loss: 0.1625 - val_accuracy: 0.9748 - val_f1_m: 0.9715\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 3s 154us/sample - loss: 0.0113 - accuracy: 0.9967 - f1_m: 0.9539 - val_loss: 0.1436 - val_accuracy: 0.9780 - val_f1_m: 0.9711\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 3s 155us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9508 - val_loss: 0.2388 - val_accuracy: 0.9772 - val_f1_m: 0.9555\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 3s 154us/sample - loss: 0.0087 - accuracy: 0.9976 - f1_m: 0.9516 - val_loss: 0.1863 - val_accuracy: 0.9772 - val_f1_m: 0.9667\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 3s 155us/sample - loss: 0.0078 - accuracy: 0.9980 - f1_m: 0.9518 - val_loss: 0.1347 - val_accuracy: 0.9772 - val_f1_m: 0.9698\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 2s 112us/sample - loss: 0.0094 - accuracy: 0.9982 - f1_m: 0.9504 - val_loss: 0.2376 - val_accuracy: 0.9688 - val_f1_m: 0.9688\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 1s 85us/sample - loss: 0.0021 - accuracy: 0.9998 - f1_m: 0.9490 - val_loss: 0.2519 - val_accuracy: 0.9660 - val_f1_m: 0.9710\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 1s 84us/sample - loss: 1.0516e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2447 - val_accuracy: 0.9660 - val_f1_m: 0.9714\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 3.3180e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2415 - val_accuracy: 0.9672 - val_f1_m: 0.9713\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 1s 84us/sample - loss: 1.8965e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2415 - val_accuracy: 0.9680 - val_f1_m: 0.9700\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 1s 84us/sample - loss: 1.5204e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2421 - val_accuracy: 0.9680 - val_f1_m: 0.9696\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 1s 83us/sample - loss: 1.2554e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2427 - val_accuracy: 0.9680 - val_f1_m: 0.9687\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 1s 84us/sample - loss: 1.0350e-05 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2433 - val_accuracy: 0.9680 - val_f1_m: 0.9691\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 1s 84us/sample - loss: 8.5796e-06 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2451 - val_accuracy: 0.9684 - val_f1_m: 0.9679\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 1s 84us/sample - loss: 7.1836e-06 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2461 - val_accuracy: 0.9680 - val_f1_m: 0.9691\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 2s 129us/sample - loss: 0.0065 - accuracy: 0.9986 - f1_m: 0.9495 - val_loss: 0.1625 - val_accuracy: 0.9784 - val_f1_m: 0.9587\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 100us/sample - loss: 0.0014 - accuracy: 0.9995 - f1_m: 0.9488 - val_loss: 0.1563 - val_accuracy: 0.9808 - val_f1_m: 0.9632\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 2s 99us/sample - loss: 4.5705e-04 - accuracy: 0.9999 - f1_m: 0.9484 - val_loss: 0.1609 - val_accuracy: 0.9808 - val_f1_m: 0.9564\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 99us/sample - loss: 0.0041 - accuracy: 0.9987 - f1_m: 0.9495 - val_loss: 0.1683 - val_accuracy: 0.9784 - val_f1_m: 0.9579\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 99us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9486 - val_loss: 0.1518 - val_accuracy: 0.9816 - val_f1_m: 0.9546\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 2s 100us/sample - loss: 0.0010 - accuracy: 0.9998 - f1_m: 0.9482 - val_loss: 0.1739 - val_accuracy: 0.9784 - val_f1_m: 0.9593\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 99us/sample - loss: 0.0049 - accuracy: 0.9989 - f1_m: 0.9497 - val_loss: 0.1752 - val_accuracy: 0.9768 - val_f1_m: 0.9584\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 100us/sample - loss: 0.0054 - accuracy: 0.9983 - f1_m: 0.9503 - val_loss: 0.1646 - val_accuracy: 0.9836 - val_f1_m: 0.9558\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 2s 99us/sample - loss: 0.0014 - accuracy: 0.9993 - f1_m: 0.9488 - val_loss: 0.1474 - val_accuracy: 0.9836 - val_f1_m: 0.9542\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 100us/sample - loss: 0.0011 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.1356 - val_accuracy: 0.9840 - val_f1_m: 0.9584\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 3s 164us/sample - loss: 0.0063 - accuracy: 0.9989 - f1_m: 0.9495 - val_loss: 0.1093 - val_accuracy: 0.9832 - val_f1_m: 0.9652\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 2s 124us/sample - loss: 0.0020 - accuracy: 0.9995 - f1_m: 0.9489 - val_loss: 0.1933 - val_accuracy: 0.9788 - val_f1_m: 0.9604\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 2s 125us/sample - loss: 0.0028 - accuracy: 0.9993 - f1_m: 0.9487 - val_loss: 0.2732 - val_accuracy: 0.9784 - val_f1_m: 0.9566\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 2s 125us/sample - loss: 0.0042 - accuracy: 0.9987 - f1_m: 0.9497 - val_loss: 0.1610 - val_accuracy: 0.9804 - val_f1_m: 0.9621\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 2s 124us/sample - loss: 0.0014 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 0.1999 - val_accuracy: 0.9816 - val_f1_m: 0.9596\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 2s 125us/sample - loss: 9.0309e-04 - accuracy: 0.9997 - f1_m: 0.9483 - val_loss: 0.1790 - val_accuracy: 0.9828 - val_f1_m: 0.9612\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 2s 124us/sample - loss: 0.0048 - accuracy: 0.9987 - f1_m: 0.9492 - val_loss: 0.1878 - val_accuracy: 0.9776 - val_f1_m: 0.9576\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 2s 127us/sample - loss: 0.0045 - accuracy: 0.9990 - f1_m: 0.9495 - val_loss: 0.2175 - val_accuracy: 0.9804 - val_f1_m: 0.9564\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 2s 124us/sample - loss: 0.0024 - accuracy: 0.9991 - f1_m: 0.9495 - val_loss: 0.1783 - val_accuracy: 0.9840 - val_f1_m: 0.9568\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 2s 124us/sample - loss: 0.0040 - accuracy: 0.9986 - f1_m: 0.9489 - val_loss: 0.2072 - val_accuracy: 0.9836 - val_f1_m: 0.9562\n",
      "Train on 17500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 4s 218us/sample - loss: 0.0108 - accuracy: 0.9976 - f1_m: 0.9505 - val_loss: 0.1619 - val_accuracy: 0.9820 - val_f1_m: 0.9598\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 3s 168us/sample - loss: 0.0074 - accuracy: 0.9985 - f1_m: 0.9503 - val_loss: 0.1335 - val_accuracy: 0.9856 - val_f1_m: 0.9586\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 3s 169us/sample - loss: 0.0094 - accuracy: 0.9978 - f1_m: 0.9503 - val_loss: 0.1473 - val_accuracy: 0.9828 - val_f1_m: 0.9551\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 3s 168us/sample - loss: 0.0128 - accuracy: 0.9971 - f1_m: 0.9523 - val_loss: 0.1170 - val_accuracy: 0.9844 - val_f1_m: 0.9638\n",
      "Epoch 5/10\n",
      "17500/17500 [==============================] - 3s 167us/sample - loss: 0.0062 - accuracy: 0.9985 - f1_m: 0.9501 - val_loss: 0.1560 - val_accuracy: 0.9816 - val_f1_m: 0.9555\n",
      "Epoch 6/10\n",
      "17500/17500 [==============================] - 3s 166us/sample - loss: 0.0036 - accuracy: 0.9991 - f1_m: 0.9502 - val_loss: 0.2205 - val_accuracy: 0.9788 - val_f1_m: 0.9586\n",
      "Epoch 7/10\n",
      "17500/17500 [==============================] - 3s 168us/sample - loss: 0.0074 - accuracy: 0.9975 - f1_m: 0.9508 - val_loss: 0.1492 - val_accuracy: 0.9820 - val_f1_m: 0.9563\n",
      "Epoch 8/10\n",
      "17500/17500 [==============================] - 3s 170us/sample - loss: 0.0020 - accuracy: 0.9993 - f1_m: 0.9495 - val_loss: 0.1678 - val_accuracy: 0.9840 - val_f1_m: 0.9534\n",
      "Epoch 9/10\n",
      "17500/17500 [==============================] - 3s 169us/sample - loss: 0.0159 - accuracy: 0.9967 - f1_m: 0.9515 - val_loss: 0.1722 - val_accuracy: 0.9828 - val_f1_m: 0.9608\n",
      "Epoch 10/10\n",
      "17500/17500 [==============================] - 3s 168us/sample - loss: 0.0095 - accuracy: 0.9978 - f1_m: 0.9525 - val_loss: 0.2348 - val_accuracy: 0.9812 - val_f1_m: 0.9589\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 2s 109us/sample - loss: 0.0079 - accuracy: 0.9979 - f1_m: 0.9538 - val_loss: 0.3413 - val_accuracy: 0.9605 - val_f1_m: 0.9722\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 1s 83us/sample - loss: 0.0012 - accuracy: 0.9999 - f1_m: 0.9492 - val_loss: 0.3535 - val_accuracy: 0.9595 - val_f1_m: 0.9686\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9504 - val_loss: 0.3180 - val_accuracy: 0.9635 - val_f1_m: 0.9741\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 0.0062 - accuracy: 0.9982 - f1_m: 0.9539 - val_loss: 0.3340 - val_accuracy: 0.9605 - val_f1_m: 0.9650\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 0.0021 - accuracy: 0.9993 - f1_m: 0.9500 - val_loss: 0.3187 - val_accuracy: 0.9630 - val_f1_m: 0.9703\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 5.0721e-04 - accuracy: 1.0000 - f1_m: 0.9489 - val_loss: 0.3229 - val_accuracy: 0.9615 - val_f1_m: 0.9694\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 1.9481e-04 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.3221 - val_accuracy: 0.9615 - val_f1_m: 0.9671\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 1.3276e-04 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.3257 - val_accuracy: 0.9630 - val_f1_m: 0.9644\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 1.0324e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.3301 - val_accuracy: 0.9630 - val_f1_m: 0.9675\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 9.2828e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.3287 - val_accuracy: 0.9635 - val_f1_m: 0.9667\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 2s 122us/sample - loss: 0.0046 - accuracy: 0.9988 - f1_m: 0.9506 - val_loss: 0.1909 - val_accuracy: 0.9740 - val_f1_m: 0.9623\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 93us/sample - loss: 0.0049 - accuracy: 0.9982 - f1_m: 0.9508 - val_loss: 0.2312 - val_accuracy: 0.9765 - val_f1_m: 0.9638\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 90us/sample - loss: 7.0158e-04 - accuracy: 0.9998 - f1_m: 0.9491 - val_loss: 0.1821 - val_accuracy: 0.9800 - val_f1_m: 0.9633\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 90us/sample - loss: 1.0858e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1846 - val_accuracy: 0.9785 - val_f1_m: 0.9607\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 91us/sample - loss: 3.4286e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1862 - val_accuracy: 0.9785 - val_f1_m: 0.9602\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 90us/sample - loss: 2.3527e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1880 - val_accuracy: 0.9785 - val_f1_m: 0.9597\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 90us/sample - loss: 1.9025e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1890 - val_accuracy: 0.9785 - val_f1_m: 0.9597\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 92us/sample - loss: 1.5795e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1901 - val_accuracy: 0.9785 - val_f1_m: 0.9602\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 91us/sample - loss: 1.3038e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1916 - val_accuracy: 0.9780 - val_f1_m: 0.9597\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 90us/sample - loss: 1.0872e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1929 - val_accuracy: 0.9780 - val_f1_m: 0.9591\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 3s 151us/sample - loss: 0.0025 - accuracy: 0.9993 - f1_m: 0.9495 - val_loss: 0.2169 - val_accuracy: 0.9745 - val_f1_m: 0.9606\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 114us/sample - loss: 0.0090 - accuracy: 0.9976 - f1_m: 0.9510 - val_loss: 0.2003 - val_accuracy: 0.9760 - val_f1_m: 0.9575\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 115us/sample - loss: 8.1534e-04 - accuracy: 0.9998 - f1_m: 0.9491 - val_loss: 0.1968 - val_accuracy: 0.9800 - val_f1_m: 0.9570\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 115us/sample - loss: 8.5562e-05 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.2067 - val_accuracy: 0.9800 - val_f1_m: 0.9559\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 115us/sample - loss: 1.6752e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2089 - val_accuracy: 0.9800 - val_f1_m: 0.9564\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 114us/sample - loss: 1.1524e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2111 - val_accuracy: 0.9800 - val_f1_m: 0.9554\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 2s 115us/sample - loss: 8.2869e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2133 - val_accuracy: 0.9795 - val_f1_m: 0.9564\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 115us/sample - loss: 6.2835e-06 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2158 - val_accuracy: 0.9795 - val_f1_m: 0.9564\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 115us/sample - loss: 4.6577e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2181 - val_accuracy: 0.9795 - val_f1_m: 0.9574\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 115us/sample - loss: 3.5766e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2205 - val_accuracy: 0.9795 - val_f1_m: 0.9574\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 4s 202us/sample - loss: 0.0124 - accuracy: 0.9971 - f1_m: 0.9514 - val_loss: 0.1991 - val_accuracy: 0.9735 - val_f1_m: 0.9663\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 3s 152us/sample - loss: 0.0044 - accuracy: 0.9984 - f1_m: 0.9507 - val_loss: 0.1906 - val_accuracy: 0.9775 - val_f1_m: 0.9637\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 3s 152us/sample - loss: 0.0056 - accuracy: 0.9979 - f1_m: 0.9514 - val_loss: 0.1807 - val_accuracy: 0.9775 - val_f1_m: 0.9627\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 3s 156us/sample - loss: 0.0125 - accuracy: 0.9968 - f1_m: 0.9529 - val_loss: 0.1809 - val_accuracy: 0.9745 - val_f1_m: 0.9722\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 3s 152us/sample - loss: 0.0064 - accuracy: 0.9977 - f1_m: 0.9521 - val_loss: 0.2235 - val_accuracy: 0.9760 - val_f1_m: 0.9627\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 3s 152us/sample - loss: 0.0096 - accuracy: 0.9976 - f1_m: 0.9527 - val_loss: 0.2056 - val_accuracy: 0.9805 - val_f1_m: 0.9603\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 3s 153us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9502 - val_loss: 0.1832 - val_accuracy: 0.9755 - val_f1_m: 0.9590\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 3s 153us/sample - loss: 0.0064 - accuracy: 0.9980 - f1_m: 0.9512 - val_loss: 0.1707 - val_accuracy: 0.9790 - val_f1_m: 0.9625\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 3s 152us/sample - loss: 0.0108 - accuracy: 0.9971 - f1_m: 0.9527 - val_loss: 0.1695 - val_accuracy: 0.9755 - val_f1_m: 0.9624\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 3s 153us/sample - loss: 0.0054 - accuracy: 0.9981 - f1_m: 0.9508 - val_loss: 0.2379 - val_accuracy: 0.9715 - val_f1_m: 0.9648\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 5s 285us/sample - loss: 0.0064 - accuracy: 0.9980 - f1_m: 0.9509 - val_loss: 0.2774 - val_accuracy: 0.9655 - val_f1_m: 0.9669\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 0.0014 - accuracy: 0.9997 - f1_m: 0.9490 - val_loss: 0.2791 - val_accuracy: 0.9615 - val_f1_m: 0.9680\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 4.1325e-04 - accuracy: 0.9998 - f1_m: 0.9486 - val_loss: 0.2488 - val_accuracy: 0.9660 - val_f1_m: 0.9702\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 3.1170e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2480 - val_accuracy: 0.9675 - val_f1_m: 0.9683\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 1.4483e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2482 - val_accuracy: 0.9675 - val_f1_m: 0.9678\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 1.1229e-05 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2480 - val_accuracy: 0.9675 - val_f1_m: 0.9691\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 9.1337e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2478 - val_accuracy: 0.9675 - val_f1_m: 0.9686\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 7.6266e-06 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.2485 - val_accuracy: 0.9675 - val_f1_m: 0.9694\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 1s 82us/sample - loss: 6.4151e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2489 - val_accuracy: 0.9680 - val_f1_m: 0.9696\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 1s 81us/sample - loss: 5.4161e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2493 - val_accuracy: 0.9685 - val_f1_m: 0.9691\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 2s 127us/sample - loss: 0.0027 - accuracy: 0.9994 - f1_m: 0.9487 - val_loss: 0.1507 - val_accuracy: 0.9830 - val_f1_m: 0.9553\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 98us/sample - loss: 0.0018 - accuracy: 0.9994 - f1_m: 0.9491 - val_loss: 0.1718 - val_accuracy: 0.9820 - val_f1_m: 0.9533\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 98us/sample - loss: 5.1183e-04 - accuracy: 0.9998 - f1_m: 0.9489 - val_loss: 0.1534 - val_accuracy: 0.9850 - val_f1_m: 0.9582\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 101us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9485 - val_loss: 0.2304 - val_accuracy: 0.9805 - val_f1_m: 0.9559\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 108us/sample - loss: 0.0059 - accuracy: 0.9981 - f1_m: 0.9508 - val_loss: 0.1928 - val_accuracy: 0.9830 - val_f1_m: 0.9575\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 100us/sample - loss: 0.0010 - accuracy: 0.9997 - f1_m: 0.9487 - val_loss: 0.1864 - val_accuracy: 0.9840 - val_f1_m: 0.9544\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 2s 98us/sample - loss: 6.6356e-05 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.1865 - val_accuracy: 0.9850 - val_f1_m: 0.9518\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 99us/sample - loss: 4.7139e-06 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1851 - val_accuracy: 0.9850 - val_f1_m: 0.9523\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 98us/sample - loss: 1.9850e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1844 - val_accuracy: 0.9850 - val_f1_m: 0.9523\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 98us/sample - loss: 1.5492e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1839 - val_accuracy: 0.9850 - val_f1_m: 0.9523\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 3s 160us/sample - loss: 0.0045 - accuracy: 0.9991 - f1_m: 0.9497 - val_loss: 0.1904 - val_accuracy: 0.9820 - val_f1_m: 0.9605\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 2s 123us/sample - loss: 0.0025 - accuracy: 0.9994 - f1_m: 0.9487 - val_loss: 0.2848 - val_accuracy: 0.9805 - val_f1_m: 0.9570\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 2s 123us/sample - loss: 0.0034 - accuracy: 0.9995 - f1_m: 0.9487 - val_loss: 0.2194 - val_accuracy: 0.9820 - val_f1_m: 0.9606\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 2s 123us/sample - loss: 0.0037 - accuracy: 0.9991 - f1_m: 0.9492 - val_loss: 0.2697 - val_accuracy: 0.9810 - val_f1_m: 0.9583\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 2s 123us/sample - loss: 0.0017 - accuracy: 0.9997 - f1_m: 0.9486 - val_loss: 0.2495 - val_accuracy: 0.9795 - val_f1_m: 0.9595\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 2s 122us/sample - loss: 0.0038 - accuracy: 0.9992 - f1_m: 0.9489 - val_loss: 0.3372 - val_accuracy: 0.9780 - val_f1_m: 0.9536\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 2s 124us/sample - loss: 0.0049 - accuracy: 0.9988 - f1_m: 0.9500 - val_loss: 0.3207 - val_accuracy: 0.9795 - val_f1_m: 0.9527\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 2s 123us/sample - loss: 0.0021 - accuracy: 0.9994 - f1_m: 0.9488 - val_loss: 0.2614 - val_accuracy: 0.9840 - val_f1_m: 0.9554\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 2s 123us/sample - loss: 7.6437e-05 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.2772 - val_accuracy: 0.9845 - val_f1_m: 0.9538\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 2s 123us/sample - loss: 5.2036e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2739 - val_accuracy: 0.9845 - val_f1_m: 0.9559\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "18000/18000 [==============================] - 4s 214us/sample - loss: 0.0086 - accuracy: 0.9980 - f1_m: 0.9512 - val_loss: 0.2385 - val_accuracy: 0.9790 - val_f1_m: 0.9574\n",
      "Epoch 2/10\n",
      "18000/18000 [==============================] - 3s 165us/sample - loss: 0.0111 - accuracy: 0.9976 - f1_m: 0.9511 - val_loss: 0.2305 - val_accuracy: 0.9845 - val_f1_m: 0.9590\n",
      "Epoch 3/10\n",
      "18000/18000 [==============================] - 3s 165us/sample - loss: 0.0104 - accuracy: 0.9974 - f1_m: 0.9510 - val_loss: 0.1682 - val_accuracy: 0.9805 - val_f1_m: 0.9598\n",
      "Epoch 4/10\n",
      "18000/18000 [==============================] - 3s 166us/sample - loss: 0.0139 - accuracy: 0.9971 - f1_m: 0.9509 - val_loss: 0.1517 - val_accuracy: 0.9825 - val_f1_m: 0.9603\n",
      "Epoch 5/10\n",
      "18000/18000 [==============================] - 3s 165us/sample - loss: 0.0050 - accuracy: 0.9986 - f1_m: 0.9504 - val_loss: 0.1746 - val_accuracy: 0.9820 - val_f1_m: 0.9608\n",
      "Epoch 6/10\n",
      "18000/18000 [==============================] - 3s 166us/sample - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9497 - val_loss: 0.2023 - val_accuracy: 0.9830 - val_f1_m: 0.9572\n",
      "Epoch 7/10\n",
      "18000/18000 [==============================] - 3s 166us/sample - loss: 0.0153 - accuracy: 0.9967 - f1_m: 0.9521 - val_loss: 0.1981 - val_accuracy: 0.9760 - val_f1_m: 0.9747\n",
      "Epoch 8/10\n",
      "18000/18000 [==============================] - 3s 165us/sample - loss: 0.0099 - accuracy: 0.9972 - f1_m: 0.9519 - val_loss: 0.2523 - val_accuracy: 0.9790 - val_f1_m: 0.9600\n",
      "Epoch 9/10\n",
      "18000/18000 [==============================] - 3s 165us/sample - loss: 0.0086 - accuracy: 0.9979 - f1_m: 0.9511 - val_loss: 0.3306 - val_accuracy: 0.9740 - val_f1_m: 0.9616\n",
      "Epoch 10/10\n",
      "18000/18000 [==============================] - 3s 167us/sample - loss: 0.0147 - accuracy: 0.9969 - f1_m: 0.9522 - val_loss: 0.1985 - val_accuracy: 0.9840 - val_f1_m: 0.9543\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 107us/sample - loss: 0.0092 - accuracy: 0.9984 - f1_m: 0.9522 - val_loss: 0.3431 - val_accuracy: 0.9627 - val_f1_m: 0.9708\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 1s 81us/sample - loss: 0.0053 - accuracy: 0.9989 - f1_m: 0.9512 - val_loss: 0.3571 - val_accuracy: 0.9620 - val_f1_m: 0.9713\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9513 - val_loss: 0.3625 - val_accuracy: 0.9580 - val_f1_m: 0.9771\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 81us/sample - loss: 0.0020 - accuracy: 0.9996 - f1_m: 0.9509 - val_loss: 0.3489 - val_accuracy: 0.9580 - val_f1_m: 0.9634\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 4.6393e-04 - accuracy: 1.0000 - f1_m: 0.9489 - val_loss: 0.3463 - val_accuracy: 0.9580 - val_f1_m: 0.9674\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 1s 81us/sample - loss: 5.8085e-04 - accuracy: 0.9999 - f1_m: 0.9486 - val_loss: 0.3485 - val_accuracy: 0.9620 - val_f1_m: 0.9663\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 1.6408e-04 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.3547 - val_accuracy: 0.9613 - val_f1_m: 0.9671\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 1.4050e-04 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.3587 - val_accuracy: 0.9607 - val_f1_m: 0.9704\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 1.0492e-04 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.3517 - val_accuracy: 0.9633 - val_f1_m: 0.9715\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 8.3450e-05 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.3537 - val_accuracy: 0.9627 - val_f1_m: 0.9641\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 118us/sample - loss: 0.0067 - accuracy: 0.9989 - f1_m: 0.9504 - val_loss: 0.2266 - val_accuracy: 0.9747 - val_f1_m: 0.9652\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 90us/sample - loss: 0.0043 - accuracy: 0.9988 - f1_m: 0.9500 - val_loss: 0.1717 - val_accuracy: 0.9813 - val_f1_m: 0.9621\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 2s 90us/sample - loss: 8.5162e-04 - accuracy: 0.9998 - f1_m: 0.9488 - val_loss: 0.1811 - val_accuracy: 0.9807 - val_f1_m: 0.9604\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 90us/sample - loss: 6.9491e-04 - accuracy: 0.9997 - f1_m: 0.9489 - val_loss: 0.1652 - val_accuracy: 0.9813 - val_f1_m: 0.9654\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 91us/sample - loss: 0.0046 - accuracy: 0.9986 - f1_m: 0.9505 - val_loss: 0.2171 - val_accuracy: 0.9773 - val_f1_m: 0.9557\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 90us/sample - loss: 0.0029 - accuracy: 0.9988 - f1_m: 0.9507 - val_loss: 0.1783 - val_accuracy: 0.9793 - val_f1_m: 0.9631\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 2s 90us/sample - loss: 0.0065 - accuracy: 0.9981 - f1_m: 0.9516 - val_loss: 0.2217 - val_accuracy: 0.9767 - val_f1_m: 0.9657\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 90us/sample - loss: 0.0038 - accuracy: 0.9990 - f1_m: 0.9503 - val_loss: 0.2130 - val_accuracy: 0.9780 - val_f1_m: 0.9635\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 88us/sample - loss: 0.0012 - accuracy: 0.9995 - f1_m: 0.9491 - val_loss: 0.2140 - val_accuracy: 0.9773 - val_f1_m: 0.9614\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 89us/sample - loss: 1.2130e-04 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.2048 - val_accuracy: 0.9807 - val_f1_m: 0.9579\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 3s 150us/sample - loss: 0.0084 - accuracy: 0.9985 - f1_m: 0.9493 - val_loss: 0.2358 - val_accuracy: 0.9747 - val_f1_m: 0.9593\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 114us/sample - loss: 0.0030 - accuracy: 0.9992 - f1_m: 0.9489 - val_loss: 0.2714 - val_accuracy: 0.9780 - val_f1_m: 0.9536\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18500/18500 [==============================] - 2s 114us/sample - loss: 0.0056 - accuracy: 0.9990 - f1_m: 0.9490 - val_loss: 0.2378 - val_accuracy: 0.9773 - val_f1_m: 0.9579\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 113us/sample - loss: 0.0066 - accuracy: 0.9983 - f1_m: 0.9501 - val_loss: 0.2235 - val_accuracy: 0.9780 - val_f1_m: 0.9571\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 113us/sample - loss: 0.0049 - accuracy: 0.9985 - f1_m: 0.9495 - val_loss: 0.2545 - val_accuracy: 0.9753 - val_f1_m: 0.9627\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 113us/sample - loss: 0.0055 - accuracy: 0.9986 - f1_m: 0.9501 - val_loss: 0.2342 - val_accuracy: 0.9813 - val_f1_m: 0.9550\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 2s 114us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9493 - val_loss: 0.2131 - val_accuracy: 0.9820 - val_f1_m: 0.9556\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 113us/sample - loss: 0.0062 - accuracy: 0.9987 - f1_m: 0.9495 - val_loss: 0.1880 - val_accuracy: 0.9807 - val_f1_m: 0.9563\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 116us/sample - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9498 - val_loss: 0.2348 - val_accuracy: 0.9767 - val_f1_m: 0.9557\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 114us/sample - loss: 0.0011 - accuracy: 0.9996 - f1_m: 0.9490 - val_loss: 0.2080 - val_accuracy: 0.9780 - val_f1_m: 0.9592\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 4s 197us/sample - loss: 0.0093 - accuracy: 0.9973 - f1_m: 0.9524 - val_loss: 0.2340 - val_accuracy: 0.9780 - val_f1_m: 0.9555\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 3s 150us/sample - loss: 0.0084 - accuracy: 0.9974 - f1_m: 0.9516 - val_loss: 0.1485 - val_accuracy: 0.9787 - val_f1_m: 0.9663\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 3s 151us/sample - loss: 0.0080 - accuracy: 0.9981 - f1_m: 0.9517 - val_loss: 0.1828 - val_accuracy: 0.9760 - val_f1_m: 0.9600\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 3s 149us/sample - loss: 0.0079 - accuracy: 0.9981 - f1_m: 0.9512 - val_loss: 0.2427 - val_accuracy: 0.9700 - val_f1_m: 0.9713\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 3s 150us/sample - loss: 0.0049 - accuracy: 0.9984 - f1_m: 0.9513 - val_loss: 0.2145 - val_accuracy: 0.9767 - val_f1_m: 0.9557\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 3s 149us/sample - loss: 0.0100 - accuracy: 0.9975 - f1_m: 0.9513 - val_loss: 0.1478 - val_accuracy: 0.9767 - val_f1_m: 0.9746\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 3s 152us/sample - loss: 0.0060 - accuracy: 0.9979 - f1_m: 0.9523 - val_loss: 0.1618 - val_accuracy: 0.9780 - val_f1_m: 0.9681\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 3s 150us/sample - loss: 0.0078 - accuracy: 0.9981 - f1_m: 0.9522 - val_loss: 0.1427 - val_accuracy: 0.9833 - val_f1_m: 0.9676\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 3s 151us/sample - loss: 0.0075 - accuracy: 0.9982 - f1_m: 0.9514 - val_loss: 0.1382 - val_accuracy: 0.9820 - val_f1_m: 0.9585\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 3s 150us/sample - loss: 0.0082 - accuracy: 0.9978 - f1_m: 0.9526 - val_loss: 0.1564 - val_accuracy: 0.9800 - val_f1_m: 0.9634\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 105us/sample - loss: 0.0047 - accuracy: 0.9990 - f1_m: 0.9501 - val_loss: 0.2840 - val_accuracy: 0.9660 - val_f1_m: 0.9666\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 1s 81us/sample - loss: 0.0032 - accuracy: 0.9992 - f1_m: 0.9497 - val_loss: 0.2776 - val_accuracy: 0.9640 - val_f1_m: 0.9712\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 1s 79us/sample - loss: 0.0018 - accuracy: 0.9994 - f1_m: 0.9493 - val_loss: 0.2601 - val_accuracy: 0.9640 - val_f1_m: 0.9703\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 1s 81us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9500 - val_loss: 0.2574 - val_accuracy: 0.9680 - val_f1_m: 0.9719\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 1s 79us/sample - loss: 7.1714e-04 - accuracy: 0.9998 - f1_m: 0.9490 - val_loss: 0.2696 - val_accuracy: 0.9660 - val_f1_m: 0.9736\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 8.9674e-04 - accuracy: 0.9998 - f1_m: 0.9490 - val_loss: 0.2419 - val_accuracy: 0.9707 - val_f1_m: 0.9688\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 1s 79us/sample - loss: 5.4131e-05 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.2430 - val_accuracy: 0.9700 - val_f1_m: 0.9672\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 1.0567e-05 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.2446 - val_accuracy: 0.9700 - val_f1_m: 0.9658\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 8.2016e-06 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.2463 - val_accuracy: 0.9700 - val_f1_m: 0.9651\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 1s 80us/sample - loss: 6.7170e-06 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.2483 - val_accuracy: 0.9707 - val_f1_m: 0.9644\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 2s 123us/sample - loss: 0.0043 - accuracy: 0.9990 - f1_m: 0.9494 - val_loss: 0.2108 - val_accuracy: 0.9800 - val_f1_m: 0.9529\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 95us/sample - loss: 8.6864e-04 - accuracy: 0.9997 - f1_m: 0.9486 - val_loss: 0.1863 - val_accuracy: 0.9833 - val_f1_m: 0.9544\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 2s 95us/sample - loss: 4.6782e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1783 - val_accuracy: 0.9820 - val_f1_m: 0.9554\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 94us/sample - loss: 7.7053e-06 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1786 - val_accuracy: 0.9847 - val_f1_m: 0.9536\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 95us/sample - loss: 1.9294e-06 - accuracy: 1.0000 - f1_m: 0.9479 - val_loss: 0.1787 - val_accuracy: 0.9847 - val_f1_m: 0.9522\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 96us/sample - loss: 1.4729e-06 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1788 - val_accuracy: 0.9847 - val_f1_m: 0.9522\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 2s 94us/sample - loss: 1.1511e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1790 - val_accuracy: 0.9847 - val_f1_m: 0.9523\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 96us/sample - loss: 9.2435e-07 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1793 - val_accuracy: 0.9847 - val_f1_m: 0.9523\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 96us/sample - loss: 7.4729e-07 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1798 - val_accuracy: 0.9847 - val_f1_m: 0.9522\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 95us/sample - loss: 6.0797e-07 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.1803 - val_accuracy: 0.9847 - val_f1_m: 0.9522\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 3s 156us/sample - loss: 0.0044 - accuracy: 0.9993 - f1_m: 0.9491 - val_loss: 0.2346 - val_accuracy: 0.9820 - val_f1_m: 0.9621\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 1.7911e-04 - accuracy: 0.9999 - f1_m: 0.9481 - val_loss: 0.2883 - val_accuracy: 0.9813 - val_f1_m: 0.9523\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 0.0068 - accuracy: 0.9986 - f1_m: 0.9495 - val_loss: 0.2719 - val_accuracy: 0.9780 - val_f1_m: 0.9529\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 2s 121us/sample - loss: 0.0072 - accuracy: 0.9978 - f1_m: 0.9501 - val_loss: 0.2588 - val_accuracy: 0.9813 - val_f1_m: 0.9522\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9486 - val_loss: 0.2740 - val_accuracy: 0.9833 - val_f1_m: 0.9501\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 2s 121us/sample - loss: 0.0024 - accuracy: 0.9993 - f1_m: 0.9487 - val_loss: 0.2893 - val_accuracy: 0.9813 - val_f1_m: 0.9523\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 0.0017 - accuracy: 0.9996 - f1_m: 0.9484 - val_loss: 0.3137 - val_accuracy: 0.9840 - val_f1_m: 0.9529\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 0.0027 - accuracy: 0.9992 - f1_m: 0.9490 - val_loss: 0.2427 - val_accuracy: 0.9807 - val_f1_m: 0.9522\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 0.0021 - accuracy: 0.9994 - f1_m: 0.9485 - val_loss: 0.2786 - val_accuracy: 0.9807 - val_f1_m: 0.9508\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 2s 120us/sample - loss: 0.0045 - accuracy: 0.9992 - f1_m: 0.9492 - val_loss: 0.2992 - val_accuracy: 0.9780 - val_f1_m: 0.9558\n",
      "Train on 18500 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "18500/18500 [==============================] - 4s 209us/sample - loss: 0.0091 - accuracy: 0.9979 - f1_m: 0.9508 - val_loss: 0.1701 - val_accuracy: 0.9787 - val_f1_m: 0.9657\n",
      "Epoch 2/10\n",
      "18500/18500 [==============================] - 3s 163us/sample - loss: 0.0059 - accuracy: 0.9984 - f1_m: 0.9503 - val_loss: 0.2311 - val_accuracy: 0.9773 - val_f1_m: 0.9607\n",
      "Epoch 3/10\n",
      "18500/18500 [==============================] - 3s 162us/sample - loss: 0.0107 - accuracy: 0.9977 - f1_m: 0.9505 - val_loss: 0.2461 - val_accuracy: 0.9840 - val_f1_m: 0.9592\n",
      "Epoch 4/10\n",
      "18500/18500 [==============================] - 3s 163us/sample - loss: 0.0095 - accuracy: 0.9978 - f1_m: 0.9511 - val_loss: 0.2117 - val_accuracy: 0.9773 - val_f1_m: 0.9543\n",
      "Epoch 5/10\n",
      "18500/18500 [==============================] - 3s 169us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9489 - val_loss: 0.2051 - val_accuracy: 0.9853 - val_f1_m: 0.9522\n",
      "Epoch 6/10\n",
      "18500/18500 [==============================] - 3s 163us/sample - loss: 0.0097 - accuracy: 0.9976 - f1_m: 0.9512 - val_loss: 0.1636 - val_accuracy: 0.9847 - val_f1_m: 0.9530\n",
      "Epoch 7/10\n",
      "18500/18500 [==============================] - 3s 163us/sample - loss: 0.0137 - accuracy: 0.9969 - f1_m: 0.9516 - val_loss: 0.2098 - val_accuracy: 0.9793 - val_f1_m: 0.9554\n",
      "Epoch 8/10\n",
      "18500/18500 [==============================] - 3s 162us/sample - loss: 0.0074 - accuracy: 0.9981 - f1_m: 0.9513 - val_loss: 0.1646 - val_accuracy: 0.9813 - val_f1_m: 0.9602\n",
      "Epoch 9/10\n",
      "18500/18500 [==============================] - 3s 163us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9501 - val_loss: 0.1981 - val_accuracy: 0.9820 - val_f1_m: 0.9515\n",
      "Epoch 10/10\n",
      "18500/18500 [==============================] - 3s 163us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9490 - val_loss: 0.1806 - val_accuracy: 0.9827 - val_f1_m: 0.9600\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 2s 105us/sample - loss: 0.0175 - accuracy: 0.9982 - f1_m: 0.9516 - val_loss: 0.2839 - val_accuracy: 0.9670 - val_f1_m: 0.9699\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 80us/sample - loss: 0.0115 - accuracy: 0.9982 - f1_m: 0.9518 - val_loss: 0.3169 - val_accuracy: 0.9660 - val_f1_m: 0.9684\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 1s 78us/sample - loss: 0.0078 - accuracy: 0.9980 - f1_m: 0.9537 - val_loss: 0.3310 - val_accuracy: 0.9650 - val_f1_m: 0.9708\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 1s 78us/sample - loss: 0.0038 - accuracy: 0.9990 - f1_m: 0.9510 - val_loss: 0.3137 - val_accuracy: 0.9640 - val_f1_m: 0.9661\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 1s 78us/sample - loss: 0.0035 - accuracy: 0.9988 - f1_m: 0.9519 - val_loss: 0.2768 - val_accuracy: 0.9620 - val_f1_m: 0.9844\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 80us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9505 - val_loss: 0.2730 - val_accuracy: 0.9690 - val_f1_m: 0.9697\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 1s 78us/sample - loss: 9.6628e-04 - accuracy: 0.9997 - f1_m: 0.9492 - val_loss: 0.3361 - val_accuracy: 0.9640 - val_f1_m: 0.9744\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 1s 78us/sample - loss: 0.0047 - accuracy: 0.9985 - f1_m: 0.9519 - val_loss: 0.2830 - val_accuracy: 0.9630 - val_f1_m: 0.9689\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 81us/sample - loss: 0.0019 - accuracy: 0.9993 - f1_m: 0.9507 - val_loss: 0.2909 - val_accuracy: 0.9670 - val_f1_m: 0.9724\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 1s 79us/sample - loss: 0.0011 - accuracy: 0.9996 - f1_m: 0.9507 - val_loss: 0.3062 - val_accuracy: 0.9630 - val_f1_m: 0.9724\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 2s 116us/sample - loss: 0.0086 - accuracy: 0.9979 - f1_m: 0.9518 - val_loss: 0.1328 - val_accuracy: 0.9830 - val_f1_m: 0.9633\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 88us/sample - loss: 0.0047 - accuracy: 0.9990 - f1_m: 0.9502 - val_loss: 0.1617 - val_accuracy: 0.9770 - val_f1_m: 0.9662\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 87us/sample - loss: 0.0059 - accuracy: 0.9986 - f1_m: 0.9503 - val_loss: 0.1521 - val_accuracy: 0.9850 - val_f1_m: 0.9649\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 86us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9503 - val_loss: 0.1396 - val_accuracy: 0.9810 - val_f1_m: 0.9617\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 87us/sample - loss: 0.0020 - accuracy: 0.9994 - f1_m: 0.9499 - val_loss: 0.1284 - val_accuracy: 0.9860 - val_f1_m: 0.9650\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 88us/sample - loss: 4.1872e-04 - accuracy: 0.9999 - f1_m: 0.9488 - val_loss: 0.1315 - val_accuracy: 0.9870 - val_f1_m: 0.9681\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 87us/sample - loss: 4.1726e-05 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1306 - val_accuracy: 0.9860 - val_f1_m: 0.9677\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 87us/sample - loss: 2.5151e-05 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.1293 - val_accuracy: 0.9850 - val_f1_m: 0.9682\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 87us/sample - loss: 2.0171e-05 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.1296 - val_accuracy: 0.9860 - val_f1_m: 0.9671\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 2s 87us/sample - loss: 1.6778e-05 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1279 - val_accuracy: 0.9860 - val_f1_m: 0.9655\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 3s 146us/sample - loss: 0.0115 - accuracy: 0.9976 - f1_m: 0.9498 - val_loss: 0.1864 - val_accuracy: 0.9850 - val_f1_m: 0.9565\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 110us/sample - loss: 0.0026 - accuracy: 0.9994 - f1_m: 0.9491 - val_loss: 0.2397 - val_accuracy: 0.9800 - val_f1_m: 0.9617\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 117us/sample - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9493 - val_loss: 0.1995 - val_accuracy: 0.9830 - val_f1_m: 0.9576\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 114us/sample - loss: 0.0049 - accuracy: 0.9986 - f1_m: 0.9497 - val_loss: 0.2162 - val_accuracy: 0.9830 - val_f1_m: 0.9589\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 116us/sample - loss: 0.0082 - accuracy: 0.9983 - f1_m: 0.9506 - val_loss: 0.1355 - val_accuracy: 0.9810 - val_f1_m: 0.9615\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 115us/sample - loss: 8.6572e-04 - accuracy: 0.9996 - f1_m: 0.9489 - val_loss: 0.1560 - val_accuracy: 0.9820 - val_f1_m: 0.9656\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 114us/sample - loss: 0.0057 - accuracy: 0.9986 - f1_m: 0.9497 - val_loss: 0.1572 - val_accuracy: 0.9830 - val_f1_m: 0.9672\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 112us/sample - loss: 0.0023 - accuracy: 0.9993 - f1_m: 0.9496 - val_loss: 0.1782 - val_accuracy: 0.9860 - val_f1_m: 0.9616\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000/19000 [==============================] - 2s 115us/sample - loss: 0.0038 - accuracy: 0.9991 - f1_m: 0.9499 - val_loss: 0.1559 - val_accuracy: 0.9880 - val_f1_m: 0.9585\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 2s 113us/sample - loss: 0.0016 - accuracy: 0.9994 - f1_m: 0.9497 - val_loss: 0.1873 - val_accuracy: 0.9850 - val_f1_m: 0.9524\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 4s 200us/sample - loss: 0.0114 - accuracy: 0.9973 - f1_m: 0.9527 - val_loss: 0.1593 - val_accuracy: 0.9800 - val_f1_m: 0.9605\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 3s 153us/sample - loss: 0.0063 - accuracy: 0.9981 - f1_m: 0.9515 - val_loss: 0.1950 - val_accuracy: 0.9760 - val_f1_m: 0.9615\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 3s 152us/sample - loss: 0.0092 - accuracy: 0.9974 - f1_m: 0.9523 - val_loss: 0.1737 - val_accuracy: 0.9790 - val_f1_m: 0.9653\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 4s 189us/sample - loss: 0.0070 - accuracy: 0.9978 - f1_m: 0.9515 - val_loss: 0.1861 - val_accuracy: 0.9790 - val_f1_m: 0.9615\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 4s 218us/sample - loss: 0.0070 - accuracy: 0.9978 - f1_m: 0.9519 - val_loss: 0.1532 - val_accuracy: 0.9820 - val_f1_m: 0.9632\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 3s 169us/sample - loss: 0.0113 - accuracy: 0.9968 - f1_m: 0.9537 - val_loss: 0.1122 - val_accuracy: 0.9810 - val_f1_m: 0.9723\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 3s 156us/sample - loss: 0.0058 - accuracy: 0.9980 - f1_m: 0.9513 - val_loss: 0.1906 - val_accuracy: 0.9830 - val_f1_m: 0.9585\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 3s 156us/sample - loss: 0.0097 - accuracy: 0.9976 - f1_m: 0.9519 - val_loss: 0.1526 - val_accuracy: 0.9800 - val_f1_m: 0.9638\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 3s 155us/sample - loss: 0.0037 - accuracy: 0.9986 - f1_m: 0.9512 - val_loss: 0.1347 - val_accuracy: 0.9830 - val_f1_m: 0.9677\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 3s 155us/sample - loss: 0.0034 - accuracy: 0.9991 - f1_m: 0.9500 - val_loss: 0.2183 - val_accuracy: 0.9820 - val_f1_m: 0.9641\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 2s 111us/sample - loss: 0.0123 - accuracy: 0.9983 - f1_m: 0.9504 - val_loss: 0.2730 - val_accuracy: 0.9640 - val_f1_m: 0.9671\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 84us/sample - loss: 0.0026 - accuracy: 0.9995 - f1_m: 0.9494 - val_loss: 0.2479 - val_accuracy: 0.9700 - val_f1_m: 0.9595\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 87us/sample - loss: 0.0011 - accuracy: 0.9995 - f1_m: 0.9490 - val_loss: 0.2925 - val_accuracy: 0.9660 - val_f1_m: 0.9688\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 0.0024 - accuracy: 0.9992 - f1_m: 0.9505 - val_loss: 0.2874 - val_accuracy: 0.9700 - val_f1_m: 0.9605\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 84us/sample - loss: 0.0019 - accuracy: 0.9993 - f1_m: 0.9494 - val_loss: 0.2683 - val_accuracy: 0.9720 - val_f1_m: 0.9689\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 5.3020e-04 - accuracy: 0.9997 - f1_m: 0.9492 - val_loss: 0.2481 - val_accuracy: 0.9740 - val_f1_m: 0.9718\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 5.5147e-05 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.2458 - val_accuracy: 0.9730 - val_f1_m: 0.9714\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 84us/sample - loss: 1.9036e-05 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.2438 - val_accuracy: 0.9750 - val_f1_m: 0.9744\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 1.0813e-05 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.2452 - val_accuracy: 0.9730 - val_f1_m: 0.9754\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 2s 83us/sample - loss: 8.7438e-06 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.2474 - val_accuracy: 0.9730 - val_f1_m: 0.9754\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 2s 127us/sample - loss: 0.0052 - accuracy: 0.9990 - f1_m: 0.9496 - val_loss: 0.1759 - val_accuracy: 0.9850 - val_f1_m: 0.9580\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 97us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_m: 0.9491 - val_loss: 0.1543 - val_accuracy: 0.9870 - val_f1_m: 0.9574\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 116us/sample - loss: 3.0897e-04 - accuracy: 0.9999 - f1_m: 0.9483 - val_loss: 0.1734 - val_accuracy: 0.9850 - val_f1_m: 0.9545\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 2s 122us/sample - loss: 0.0042 - accuracy: 0.9992 - f1_m: 0.9495 - val_loss: 0.1293 - val_accuracy: 0.9820 - val_f1_m: 0.9574\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 2s 116us/sample - loss: 0.0047 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1280 - val_accuracy: 0.9850 - val_f1_m: 0.9555\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 2s 117us/sample - loss: 3.7916e-04 - accuracy: 0.9999 - f1_m: 0.9486 - val_loss: 0.1440 - val_accuracy: 0.9870 - val_f1_m: 0.9565\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 2s 110us/sample - loss: 1.1200e-05 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1387 - val_accuracy: 0.9860 - val_f1_m: 0.9555\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 99us/sample - loss: 2.8220e-06 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.1389 - val_accuracy: 0.9860 - val_f1_m: 0.9544\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 2s 119us/sample - loss: 2.1479e-06 - accuracy: 1.0000 - f1_m: 0.9483 - val_loss: 0.1391 - val_accuracy: 0.9860 - val_f1_m: 0.9565\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 3s 138us/sample - loss: 1.6922e-06 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1390 - val_accuracy: 0.9860 - val_f1_m: 0.9575\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 4s 185us/sample - loss: 0.0111 - accuracy: 0.9983 - f1_m: 0.9498 - val_loss: 0.2149 - val_accuracy: 0.9840 - val_f1_m: 0.9554\n",
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 2s 125us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9486 - val_loss: 0.1843 - val_accuracy: 0.9880 - val_f1_m: 0.9544\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 2s 123us/sample - loss: 1.0915e-04 - accuracy: 0.9999 - f1_m: 0.9482 - val_loss: 0.1918 - val_accuracy: 0.9860 - val_f1_m: 0.9534\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 3s 153us/sample - loss: 8.8781e-04 - accuracy: 0.9998 - f1_m: 0.9483 - val_loss: 0.3759 - val_accuracy: 0.9790 - val_f1_m: 0.9544\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 3s 164us/sample - loss: 0.0107 - accuracy: 0.9982 - f1_m: 0.9498 - val_loss: 0.2219 - val_accuracy: 0.9800 - val_f1_m: 0.9673\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 3s 148us/sample - loss: 3.3688e-04 - accuracy: 0.9999 - f1_m: 0.9487 - val_loss: 0.1883 - val_accuracy: 0.9850 - val_f1_m: 0.9564\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 3s 150us/sample - loss: 0.0043 - accuracy: 0.9993 - f1_m: 0.9490 - val_loss: 0.2184 - val_accuracy: 0.9770 - val_f1_m: 0.9555\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 2s 128us/sample - loss: 0.0034 - accuracy: 0.9994 - f1_m: 0.9489 - val_loss: 0.2220 - val_accuracy: 0.9830 - val_f1_m: 0.9594\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 3s 139us/sample - loss: 0.0029 - accuracy: 0.9995 - f1_m: 0.9490 - val_loss: 0.2164 - val_accuracy: 0.9820 - val_f1_m: 0.9605\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 3s 168us/sample - loss: 7.3645e-04 - accuracy: 0.9998 - f1_m: 0.9484 - val_loss: 0.2408 - val_accuracy: 0.9780 - val_f1_m: 0.9656\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "19000/19000 [==============================] - 5s 261us/sample - loss: 0.0120 - accuracy: 0.9979 - f1_m: 0.9505 - val_loss: 0.1015 - val_accuracy: 0.9850 - val_f1_m: 0.9559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "19000/19000 [==============================] - 3s 169us/sample - loss: 0.0046 - accuracy: 0.9987 - f1_m: 0.9506 - val_loss: 0.0654 - val_accuracy: 0.9900 - val_f1_m: 0.9574\n",
      "Epoch 3/10\n",
      "19000/19000 [==============================] - 4s 210us/sample - loss: 0.0079 - accuracy: 0.9985 - f1_m: 0.9497 - val_loss: 0.1085 - val_accuracy: 0.9880 - val_f1_m: 0.9555\n",
      "Epoch 4/10\n",
      "19000/19000 [==============================] - 4s 209us/sample - loss: 0.0105 - accuracy: 0.9981 - f1_m: 0.9514 - val_loss: 0.1438 - val_accuracy: 0.9880 - val_f1_m: 0.9544\n",
      "Epoch 5/10\n",
      "19000/19000 [==============================] - 4s 218us/sample - loss: 0.0107 - accuracy: 0.9975 - f1_m: 0.9515 - val_loss: 0.0608 - val_accuracy: 0.9850 - val_f1_m: 0.9616\n",
      "Epoch 6/10\n",
      "19000/19000 [==============================] - 4s 209us/sample - loss: 0.0051 - accuracy: 0.9986 - f1_m: 0.9499 - val_loss: 0.0746 - val_accuracy: 0.9880 - val_f1_m: 0.9616\n",
      "Epoch 7/10\n",
      "19000/19000 [==============================] - 4s 206us/sample - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9497 - val_loss: 0.1336 - val_accuracy: 0.9840 - val_f1_m: 0.9564\n",
      "Epoch 8/10\n",
      "19000/19000 [==============================] - 4s 213us/sample - loss: 0.0060 - accuracy: 0.9985 - f1_m: 0.9509 - val_loss: 0.0719 - val_accuracy: 0.9850 - val_f1_m: 0.9635\n",
      "Epoch 9/10\n",
      "19000/19000 [==============================] - 4s 203us/sample - loss: 0.0111 - accuracy: 0.9976 - f1_m: 0.9511 - val_loss: 0.1026 - val_accuracy: 0.9820 - val_f1_m: 0.9636\n",
      "Epoch 10/10\n",
      "19000/19000 [==============================] - 3s 168us/sample - loss: 0.0074 - accuracy: 0.9982 - f1_m: 0.9509 - val_loss: 0.0734 - val_accuracy: 0.9890 - val_f1_m: 0.9569\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 2s 107us/sample - loss: 0.0190 - accuracy: 0.9977 - f1_m: 0.9524 - val_loss: 0.2978 - val_accuracy: 0.9600 - val_f1_m: 0.9758\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 80us/sample - loss: 0.0125 - accuracy: 0.9978 - f1_m: 0.9533 - val_loss: 0.2322 - val_accuracy: 0.9660 - val_f1_m: 0.9634\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 0.0094 - accuracy: 0.9979 - f1_m: 0.9530 - val_loss: 0.2875 - val_accuracy: 0.9540 - val_f1_m: 0.9697\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 81us/sample - loss: 0.0084 - accuracy: 0.9983 - f1_m: 0.9533 - val_loss: 0.2440 - val_accuracy: 0.9600 - val_f1_m: 0.9696\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 83us/sample - loss: 0.0061 - accuracy: 0.9982 - f1_m: 0.9536 - val_loss: 0.2454 - val_accuracy: 0.9580 - val_f1_m: 0.9737\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 81us/sample - loss: 0.0038 - accuracy: 0.9991 - f1_m: 0.9512 - val_loss: 0.2327 - val_accuracy: 0.9660 - val_f1_m: 0.9686\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 104us/sample - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9504 - val_loss: 0.2306 - val_accuracy: 0.9660 - val_f1_m: 0.9716\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 113us/sample - loss: 0.0049 - accuracy: 0.9985 - f1_m: 0.9529 - val_loss: 0.2593 - val_accuracy: 0.9680 - val_f1_m: 0.9624\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 116us/sample - loss: 0.0028 - accuracy: 0.9990 - f1_m: 0.9519 - val_loss: 0.2521 - val_accuracy: 0.9700 - val_f1_m: 0.9612\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 108us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9497 - val_loss: 0.2554 - val_accuracy: 0.9640 - val_f1_m: 0.9779\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 3s 154us/sample - loss: 0.0118 - accuracy: 0.9982 - f1_m: 0.9506 - val_loss: 0.1190 - val_accuracy: 0.9880 - val_f1_m: 0.9542\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 117us/sample - loss: 0.0036 - accuracy: 0.9988 - f1_m: 0.9503 - val_loss: 0.0916 - val_accuracy: 0.9840 - val_f1_m: 0.9613\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 123us/sample - loss: 0.0019 - accuracy: 0.9994 - f1_m: 0.9498 - val_loss: 0.1155 - val_accuracy: 0.9840 - val_f1_m: 0.9562\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 117us/sample - loss: 0.0024 - accuracy: 0.9991 - f1_m: 0.9502 - val_loss: 0.1323 - val_accuracy: 0.9880 - val_f1_m: 0.9480\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 120us/sample - loss: 0.0030 - accuracy: 0.9992 - f1_m: 0.9498 - val_loss: 0.1334 - val_accuracy: 0.9880 - val_f1_m: 0.9437\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 118us/sample - loss: 0.0056 - accuracy: 0.9983 - f1_m: 0.9518 - val_loss: 0.2029 - val_accuracy: 0.9780 - val_f1_m: 0.9520\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 124us/sample - loss: 0.0014 - accuracy: 0.9997 - f1_m: 0.9498 - val_loss: 0.1099 - val_accuracy: 0.9860 - val_f1_m: 0.9529\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 120us/sample - loss: 2.4233e-04 - accuracy: 0.9999 - f1_m: 0.9485 - val_loss: 0.1136 - val_accuracy: 0.9900 - val_f1_m: 0.9499\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 116us/sample - loss: 4.8401e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1126 - val_accuracy: 0.9900 - val_f1_m: 0.9540\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 117us/sample - loss: 3.2247e-05 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.1115 - val_accuracy: 0.9920 - val_f1_m: 0.9529\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 4s 196us/sample - loss: 0.0134 - accuracy: 0.9977 - f1_m: 0.9504 - val_loss: 0.2789 - val_accuracy: 0.9780 - val_f1_m: 0.9582\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 3s 159us/sample - loss: 0.0032 - accuracy: 0.9992 - f1_m: 0.9495 - val_loss: 0.2513 - val_accuracy: 0.9840 - val_f1_m: 0.9539\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 115us/sample - loss: 0.0010 - accuracy: 0.9997 - f1_m: 0.9490 - val_loss: 0.2423 - val_accuracy: 0.9840 - val_f1_m: 0.9540\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 124us/sample - loss: 0.0048 - accuracy: 0.9986 - f1_m: 0.9500 - val_loss: 0.1740 - val_accuracy: 0.9840 - val_f1_m: 0.9581\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 122us/sample - loss: 0.0061 - accuracy: 0.9986 - f1_m: 0.9500 - val_loss: 0.3230 - val_accuracy: 0.9780 - val_f1_m: 0.9561\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 127us/sample - loss: 0.0036 - accuracy: 0.9986 - f1_m: 0.9506 - val_loss: 0.1789 - val_accuracy: 0.9900 - val_f1_m: 0.9499\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 119us/sample - loss: 0.0021 - accuracy: 0.9995 - f1_m: 0.9488 - val_loss: 0.1811 - val_accuracy: 0.9860 - val_f1_m: 0.9540\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 124us/sample - loss: 0.0045 - accuracy: 0.9989 - f1_m: 0.9500 - val_loss: 0.2260 - val_accuracy: 0.9860 - val_f1_m: 0.9540\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 3s 131us/sample - loss: 0.0085 - accuracy: 0.9978 - f1_m: 0.9509 - val_loss: 0.1741 - val_accuracy: 0.9820 - val_f1_m: 0.9580\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 3s 130us/sample - loss: 0.0011 - accuracy: 0.9995 - f1_m: 0.9492 - val_loss: 0.1835 - val_accuracy: 0.9820 - val_f1_m: 0.9539\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 5s 240us/sample - loss: 0.0113 - accuracy: 0.9974 - f1_m: 0.9515 - val_loss: 0.1462 - val_accuracy: 0.9820 - val_f1_m: 0.9633\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 3s 164us/sample - loss: 0.0078 - accuracy: 0.9976 - f1_m: 0.9522 - val_loss: 0.1677 - val_accuracy: 0.9860 - val_f1_m: 0.9531\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 3s 158us/sample - loss: 0.0063 - accuracy: 0.9984 - f1_m: 0.9506 - val_loss: 0.1373 - val_accuracy: 0.9800 - val_f1_m: 0.9500\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 3s 156us/sample - loss: 0.0073 - accuracy: 0.9976 - f1_m: 0.9520 - val_loss: 0.1660 - val_accuracy: 0.9800 - val_f1_m: 0.9541\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0063 - accuracy: 0.9982 - f1_m: 0.9510 - val_loss: 0.1654 - val_accuracy: 0.9880 - val_f1_m: 0.9539\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0078 - accuracy: 0.9977 - f1_m: 0.9519 - val_loss: 0.1877 - val_accuracy: 0.9840 - val_f1_m: 0.9540\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 3s 158us/sample - loss: 0.0111 - accuracy: 0.9968 - f1_m: 0.9538 - val_loss: 0.1654 - val_accuracy: 0.9780 - val_f1_m: 0.9702\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0049 - accuracy: 0.9986 - f1_m: 0.9514 - val_loss: 0.2177 - val_accuracy: 0.9800 - val_f1_m: 0.9613\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 3s 151us/sample - loss: 0.0059 - accuracy: 0.9981 - f1_m: 0.9512 - val_loss: 0.2228 - val_accuracy: 0.9800 - val_f1_m: 0.9621\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 3s 152us/sample - loss: 0.0109 - accuracy: 0.9967 - f1_m: 0.9532 - val_loss: 0.1728 - val_accuracy: 0.9860 - val_f1_m: 0.9518\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 2s 111us/sample - loss: 0.0105 - accuracy: 0.9984 - f1_m: 0.9506 - val_loss: 0.3280 - val_accuracy: 0.9580 - val_f1_m: 0.9635\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 101us/sample - loss: 0.0032 - accuracy: 0.9991 - f1_m: 0.9503 - val_loss: 0.2640 - val_accuracy: 0.9660 - val_f1_m: 0.9635\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 97us/sample - loss: 8.5092e-04 - accuracy: 0.9998 - f1_m: 0.9488 - val_loss: 0.2504 - val_accuracy: 0.9620 - val_f1_m: 0.9674\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 7.9848e-05 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.2421 - val_accuracy: 0.9680 - val_f1_m: 0.9653\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 86us/sample - loss: 2.2092e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2508 - val_accuracy: 0.9680 - val_f1_m: 0.9653\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 99us/sample - loss: 1.3931e-05 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.2536 - val_accuracy: 0.9680 - val_f1_m: 0.9632\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 93us/sample - loss: 1.1020e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2553 - val_accuracy: 0.9680 - val_f1_m: 0.9663\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 85us/sample - loss: 8.8219e-06 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.2545 - val_accuracy: 0.9680 - val_f1_m: 0.9601\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 82us/sample - loss: 7.2823e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2585 - val_accuracy: 0.9700 - val_f1_m: 0.9642\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 84us/sample - loss: 6.0590e-06 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.2596 - val_accuracy: 0.9700 - val_f1_m: 0.9663\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 4s 191us/sample - loss: 0.0059 - accuracy: 0.9988 - f1_m: 0.9494 - val_loss: 0.2252 - val_accuracy: 0.9760 - val_f1_m: 0.9519\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 124us/sample - loss: 0.0026 - accuracy: 0.9994 - f1_m: 0.9492 - val_loss: 0.1378 - val_accuracy: 0.9820 - val_f1_m: 0.9539\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 2.6627e-04 - accuracy: 0.9999 - f1_m: 0.9485 - val_loss: 0.1698 - val_accuracy: 0.9820 - val_f1_m: 0.9477\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 2s 102us/sample - loss: 1.4557e-05 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1625 - val_accuracy: 0.9820 - val_f1_m: 0.9518\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 103us/sample - loss: 2.9574e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1628 - val_accuracy: 0.9820 - val_f1_m: 0.9518\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 120us/sample - loss: 2.0943e-06 - accuracy: 1.0000 - f1_m: 0.9482 - val_loss: 0.1630 - val_accuracy: 0.9820 - val_f1_m: 0.9498\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 128us/sample - loss: 1.5953e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1634 - val_accuracy: 0.9820 - val_f1_m: 0.9498\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 2s 110us/sample - loss: 1.2540e-06 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.1636 - val_accuracy: 0.9820 - val_f1_m: 0.9498\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 2s 104us/sample - loss: 1.0060e-06 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.1635 - val_accuracy: 0.9820 - val_f1_m: 0.9477\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 105us/sample - loss: 8.1711e-07 - accuracy: 1.0000 - f1_m: 0.9481 - val_loss: 0.1638 - val_accuracy: 0.9820 - val_f1_m: 0.9477\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 7s 361us/sample - loss: 0.0073 - accuracy: 0.9985 - f1_m: 0.9497 - val_loss: 0.1723 - val_accuracy: 0.9860 - val_f1_m: 0.9508\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 2s 127us/sample - loss: 0.0020 - accuracy: 0.9992 - f1_m: 0.9491 - val_loss: 0.2046 - val_accuracy: 0.9840 - val_f1_m: 0.9498\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 3s 165us/sample - loss: 0.0018 - accuracy: 0.9994 - f1_m: 0.9486 - val_loss: 0.2325 - val_accuracy: 0.9820 - val_f1_m: 0.9498\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 3s 164us/sample - loss: 0.0042 - accuracy: 0.9991 - f1_m: 0.9494 - val_loss: 0.2025 - val_accuracy: 0.9880 - val_f1_m: 0.9498\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 2s 127us/sample - loss: 5.4730e-04 - accuracy: 0.9998 - f1_m: 0.9482 - val_loss: 0.2651 - val_accuracy: 0.9820 - val_f1_m: 0.9539\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 2s 126us/sample - loss: 0.0088 - accuracy: 0.9985 - f1_m: 0.9499 - val_loss: 0.1992 - val_accuracy: 0.9840 - val_f1_m: 0.9519\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 2s 127us/sample - loss: 5.4184e-04 - accuracy: 0.9997 - f1_m: 0.9484 - val_loss: 0.3148 - val_accuracy: 0.9820 - val_f1_m: 0.9541\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 3s 144us/sample - loss: 0.0048 - accuracy: 0.9991 - f1_m: 0.9495 - val_loss: 0.1905 - val_accuracy: 0.9860 - val_f1_m: 0.9519\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 3s 147us/sample - loss: 6.6174e-04 - accuracy: 0.9998 - f1_m: 0.9483 - val_loss: 0.1975 - val_accuracy: 0.9860 - val_f1_m: 0.9519\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 2s 126us/sample - loss: 7.4398e-04 - accuracy: 0.9997 - f1_m: 0.9483 - val_loss: 0.2655 - val_accuracy: 0.9820 - val_f1_m: 0.9519\n",
      "Train on 19500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 4s 216us/sample - loss: 0.0120 - accuracy: 0.9978 - f1_m: 0.9509 - val_loss: 0.1011 - val_accuracy: 0.9840 - val_f1_m: 0.9601\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 3s 166us/sample - loss: 0.0056 - accuracy: 0.9985 - f1_m: 0.9514 - val_loss: 0.1918 - val_accuracy: 0.9840 - val_f1_m: 0.9580\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 3s 165us/sample - loss: 0.0158 - accuracy: 0.9969 - f1_m: 0.9517 - val_loss: 0.1722 - val_accuracy: 0.9820 - val_f1_m: 0.9590\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 3s 169us/sample - loss: 0.0073 - accuracy: 0.9983 - f1_m: 0.9502 - val_loss: 0.1554 - val_accuracy: 0.9840 - val_f1_m: 0.9539\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 4s 193us/sample - loss: 0.0024 - accuracy: 0.9990 - f1_m: 0.9499 - val_loss: 0.1299 - val_accuracy: 0.9820 - val_f1_m: 0.9551\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 3s 179us/sample - loss: 0.0068 - accuracy: 0.9983 - f1_m: 0.9505 - val_loss: 0.1515 - val_accuracy: 0.9820 - val_f1_m: 0.9642\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 4s 193us/sample - loss: 0.0075 - accuracy: 0.9985 - f1_m: 0.9510 - val_loss: 0.1065 - val_accuracy: 0.9860 - val_f1_m: 0.9519\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19500/19500 [==============================] - 3s 177us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9493 - val_loss: 0.0695 - val_accuracy: 0.9840 - val_f1_m: 0.9591\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 4s 218us/sample - loss: 0.0133 - accuracy: 0.9969 - f1_m: 0.9524 - val_loss: 0.1622 - val_accuracy: 0.9860 - val_f1_m: 0.9498\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 3s 178us/sample - loss: 0.0120 - accuracy: 0.9975 - f1_m: 0.9511 - val_loss: 0.1243 - val_accuracy: 0.9820 - val_f1_m: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>ratio</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN 1 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>4.481547e-01</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>1.805640</td>\n",
       "      <td>0.586960</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>1.896804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN 2 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3.456758e-01</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>1.566302</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>1.620826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN 5 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3.570064e-01</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>1.443486</td>\n",
       "      <td>0.463584</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>1.462498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2.144957e-01</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>1.244244</td>\n",
       "      <td>0.540796</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>1.299899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>500</td>\n",
       "      <td>19500</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2.106491e-01</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>1.378442</td>\n",
       "      <td>0.434352</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>1.482956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.091827e-02</td>\n",
       "      <td>0.996718</td>\n",
       "      <td>0.953227</td>\n",
       "      <td>0.172776</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.951843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>6.058978e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948051</td>\n",
       "      <td>0.259572</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.966325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>CNN 2 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>8.171054e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948051</td>\n",
       "      <td>0.163758</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.947712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>CNN 5 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>7.439827e-04</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>0.948324</td>\n",
       "      <td>0.265549</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.951910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>CNN 10 L</td>\n",
       "      <td>19500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.199936e-02</td>\n",
       "      <td>0.997538</td>\n",
       "      <td>0.951134</td>\n",
       "      <td>0.124310</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.958207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  train_samples  test_samples  ratio          loss  accuracy  \\\n",
       "0     CNN 1 S            500         19500  0.025  4.481547e-01  0.876000   \n",
       "1     CNN 2 S            500         19500  0.025  3.456758e-01  0.904000   \n",
       "2     CNN 5 S            500         19500  0.025  3.570064e-01  0.882000   \n",
       "3    CNN 10 S            500         19500  0.025  2.144957e-01  0.936000   \n",
       "4     CNN 1 L            500         19500  0.025  2.106491e-01  0.958000   \n",
       "..        ...            ...           ...    ...           ...       ...   \n",
       "307  CNN 10 S          19500           500  0.975  1.091827e-02  0.996718   \n",
       "308   CNN 1 L          19500           500  0.975  6.058978e-06  1.000000   \n",
       "309   CNN 2 L          19500           500  0.975  8.171054e-07  1.000000   \n",
       "310   CNN 5 L          19500           500  0.975  7.439827e-04  0.999744   \n",
       "311  CNN 10 L          19500           500  0.975  1.199936e-02  0.997538   \n",
       "\n",
       "           f1  val_loss  val_accuracy    val_f1  \n",
       "0    1.805640  0.586960        0.8281  1.896804  \n",
       "1    1.566302  0.463130        0.8573  1.620826  \n",
       "2    1.443486  0.463584        0.8610  1.462498  \n",
       "3    1.244244  0.540796        0.8586  1.299899  \n",
       "4    1.378442  0.434352        0.8742  1.482956  \n",
       "..        ...       ...           ...       ...  \n",
       "307  0.953227  0.172776        0.9860  0.951843  \n",
       "308  0.948051  0.259572        0.9700  0.966325  \n",
       "309  0.948051  0.163758        0.9820  0.947712  \n",
       "310  0.948324  0.265549        0.9820  0.951910  \n",
       "311  0.951134  0.124310        0.9820  0.958207  \n",
       "\n",
       "[312 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_3a_cnn():\n",
    "    total_samples = 20000\n",
    "    epochs = 10\n",
    "    ratios = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "    \n",
    "#     total_samples = 300\n",
    "#     epochs = 1\n",
    "#     ratios = [0.2, 0.8]\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        train_samples, test_samples = calc_train_test_samples(total_samples, ratio)\n",
    "        \n",
    "        for name, layers in cnns.items():   \n",
    "            loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm = evaluate_cnn(layers, train_samples, test_samples, epochs)\n",
    "            \n",
    "            yield name, train_samples, test_samples, ratio, loss, accuracy, f1, val_loss, val_accuracy, val_f1\n",
    "            \n",
    "            codename = name.lower().replace(' ', '_')\n",
    "            roc.savefig(f'plots/3a/{codename}_r{ratio}_roc.svg')\n",
    "            pr.savefig(f'plots/3a/{codename}_r{ratio}_pr.svg')\n",
    "            cm.savefig(f'plots/3a/{codename}_r{ratio}_cm.svg')             \n",
    "            plt.close('all')\n",
    "            \n",
    "results_3a_cnn = pd.DataFrame(gen_3a_cnn(), columns=[    \n",
    "    'model',\n",
    "    'train_samples', 'test_samples', 'ratio',\n",
    "    'loss', 'accuracy', 'f1', 'val_loss', 'val_accuracy', 'val_f1'\n",
    "])\n",
    "results_3a_cnn.to_csv('results/3a_cnn.csv')\n",
    "results_3a_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1296 - accuracy: 0.9816 - f1_m: 0.9651 - val_loss: 0.2412 - val_accuracy: 0.9660 - val_f1_m: 0.9774\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.0670 - accuracy: 0.9885 - f1_m: 0.9596 - val_loss: 0.1154 - val_accuracy: 0.9785 - val_f1_m: 0.9734\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0386 - accuracy: 0.9914 - f1_m: 0.9639 - val_loss: 0.0604 - val_accuracy: 0.9823 - val_f1_m: 0.9813\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.0370 - accuracy: 0.9913 - f1_m: 0.9652 - val_loss: 0.0593 - val_accuracy: 0.9841 - val_f1_m: 0.9822\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0798 - accuracy: 0.9870 - f1_m: 0.9614 - val_loss: 0.1226 - val_accuracy: 0.9734 - val_f1_m: 0.9791\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 0.0410 - accuracy: 0.9928 - f1_m: 0.9570 - val_loss: 0.0479 - val_accuracy: 0.9851 - val_f1_m: 0.9779\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.0312 - accuracy: 0.9935 - f1_m: 0.9600 - val_loss: 0.0595 - val_accuracy: 0.9833 - val_f1_m: 0.9847\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "48000/48000 [==============================] - 10s 200us/sample - loss: 0.0371 - accuracy: 0.9922 - f1_m: 0.9629 - val_loss: 0.0692 - val_accuracy: 0.9821 - val_f1_m: 0.9924\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0829 - accuracy: 0.9846 - f1_m: 0.9701 - val_loss: 0.2173 - val_accuracy: 0.9650 - val_f1_m: 0.9784\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0620 - accuracy: 0.9865 - f1_m: 0.9714 - val_loss: 0.2057 - val_accuracy: 0.9626 - val_f1_m: 0.9832\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0364 - accuracy: 0.9914 - f1_m: 0.9648 - val_loss: 0.0977 - val_accuracy: 0.9787 - val_f1_m: 0.9752\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.0253 - accuracy: 0.9937 - f1_m: 0.9634 - val_loss: 0.0929 - val_accuracy: 0.9805 - val_f1_m: 0.9768\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.0221 - accuracy: 0.9941 - f1_m: 0.9633 - val_loss: 0.0596 - val_accuracy: 0.9853 - val_f1_m: 0.9771\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 0.0157 - accuracy: 0.9951 - f1_m: 0.9593 - val_loss: 0.0698 - val_accuracy: 0.9855 - val_f1_m: 0.9668\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 9s 192us/sample - loss: 0.0244 - accuracy: 0.9928 - f1_m: 0.9641 - val_loss: 0.0583 - val_accuracy: 0.9864 - val_f1_m: 0.9733\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0196 - accuracy: 0.9945 - f1_m: 0.9615 - val_loss: 0.0679 - val_accuracy: 0.9815 - val_f1_m: 0.9751\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0330 - accuracy: 0.9923 - f1_m: 0.9638 - val_loss: 0.1136 - val_accuracy: 0.9734 - val_f1_m: 0.9821\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0180 - accuracy: 0.9955 - f1_m: 0.9609 - val_loss: 0.1217 - val_accuracy: 0.9738 - val_f1_m: 0.9778\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0160 - accuracy: 0.9961 - f1_m: 0.9567 - val_loss: 0.0518 - val_accuracy: 0.9844 - val_f1_m: 0.9699\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0081 - accuracy: 0.9979 - f1_m: 0.9543 - val_loss: 0.0556 - val_accuracy: 0.9866 - val_f1_m: 0.9683\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 7s 148us/sample - loss: 0.0140 - accuracy: 0.9960 - f1_m: 0.9566 - val_loss: 0.0567 - val_accuracy: 0.9844 - val_f1_m: 0.9796\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 0.0092 - accuracy: 0.9974 - f1_m: 0.9543 - val_loss: 0.0743 - val_accuracy: 0.9874 - val_f1_m: 0.9605\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 10s 200us/sample - loss: 0.0216 - accuracy: 0.9942 - f1_m: 0.9607 - val_loss: 0.0608 - val_accuracy: 0.9867 - val_f1_m: 0.9725\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 9s 180us/sample - loss: 0.0154 - accuracy: 0.9954 - f1_m: 0.9584 - val_loss: 0.0722 - val_accuracy: 0.9862 - val_f1_m: 0.9627\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0475 - accuracy: 0.9891 - f1_m: 0.9717 - val_loss: 0.2024 - val_accuracy: 0.9640 - val_f1_m: 0.9800\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0390 - accuracy: 0.9901 - f1_m: 0.9728 - val_loss: 0.1916 - val_accuracy: 0.9639 - val_f1_m: 0.9829\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0326 - accuracy: 0.9911 - f1_m: 0.9706 - val_loss: 0.1800 - val_accuracy: 0.9662 - val_f1_m: 0.9854\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0199 - accuracy: 0.9943 - f1_m: 0.9624 - val_loss: 0.1011 - val_accuracy: 0.9781 - val_f1_m: 0.9751\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0166 - accuracy: 0.9953 - f1_m: 0.9603 - val_loss: 0.0939 - val_accuracy: 0.9798 - val_f1_m: 0.9713\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0128 - accuracy: 0.9962 - f1_m: 0.9593 - val_loss: 0.1032 - val_accuracy: 0.9801 - val_f1_m: 0.9707\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.0121 - accuracy: 0.9966 - f1_m: 0.9558 - val_loss: 0.0644 - val_accuracy: 0.9824 - val_f1_m: 0.9783\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0100 - accuracy: 0.9969 - f1_m: 0.9558 - val_loss: 0.0835 - val_accuracy: 0.9849 - val_f1_m: 0.9673\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 0.0099 - accuracy: 0.9970 - f1_m: 0.9545 - val_loss: 0.0833 - val_accuracy: 0.9845 - val_f1_m: 0.9645\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 9s 187us/sample - loss: 0.0179 - accuracy: 0.9948 - f1_m: 0.9602 - val_loss: 0.0627 - val_accuracy: 0.9841 - val_f1_m: 0.9728\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0161 - accuracy: 0.9949 - f1_m: 0.9594 - val_loss: 0.0563 - val_accuracy: 0.9861 - val_f1_m: 0.9678\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0148 - accuracy: 0.9953 - f1_m: 0.9579 - val_loss: 0.0902 - val_accuracy: 0.9837 - val_f1_m: 0.9648\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0128 - accuracy: 0.9967 - f1_m: 0.9581 - val_loss: 0.1211 - val_accuracy: 0.9767 - val_f1_m: 0.9757\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0072 - accuracy: 0.9982 - f1_m: 0.9546 - val_loss: 0.1393 - val_accuracy: 0.9757 - val_f1_m: 0.9732\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0057 - accuracy: 0.9983 - f1_m: 0.9537 - val_loss: 0.1396 - val_accuracy: 0.9732 - val_f1_m: 0.9767\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0064 - accuracy: 0.9981 - f1_m: 0.9525 - val_loss: 0.0616 - val_accuracy: 0.9852 - val_f1_m: 0.9685\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9507 - val_loss: 0.0746 - val_accuracy: 0.9854 - val_f1_m: 0.9635\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0053 - accuracy: 0.9983 - f1_m: 0.9510 - val_loss: 0.0704 - val_accuracy: 0.9859 - val_f1_m: 0.9611\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0071 - accuracy: 0.9980 - f1_m: 0.9516 - val_loss: 0.0701 - val_accuracy: 0.9850 - val_f1_m: 0.9690\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 0.0045 - accuracy: 0.9989 - f1_m: 0.9501 - val_loss: 0.0707 - val_accuracy: 0.9877 - val_f1_m: 0.9593\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 0.0064 - accuracy: 0.9982 - f1_m: 0.9511 - val_loss: 0.0703 - val_accuracy: 0.9871 - val_f1_m: 0.9616\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 10s 201us/sample - loss: 0.0157 - accuracy: 0.9958 - f1_m: 0.9552 - val_loss: 0.0863 - val_accuracy: 0.9845 - val_f1_m: 0.9690\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 9s 180us/sample - loss: 0.0157 - accuracy: 0.9955 - f1_m: 0.9565 - val_loss: 0.0875 - val_accuracy: 0.9836 - val_f1_m: 0.9686\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 9s 183us/sample - loss: 0.0140 - accuracy: 0.9957 - f1_m: 0.9562 - val_loss: 0.0834 - val_accuracy: 0.9853 - val_f1_m: 0.9684\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0281 - accuracy: 0.9925 - f1_m: 0.9685 - val_loss: 0.1896 - val_accuracy: 0.9666 - val_f1_m: 0.9812\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0228 - accuracy: 0.9939 - f1_m: 0.9688 - val_loss: 0.1890 - val_accuracy: 0.9654 - val_f1_m: 0.9837\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0200 - accuracy: 0.9942 - f1_m: 0.9688 - val_loss: 0.1780 - val_accuracy: 0.9670 - val_f1_m: 0.9801\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0177 - accuracy: 0.9949 - f1_m: 0.9673 - val_loss: 0.1768 - val_accuracy: 0.9685 - val_f1_m: 0.9830\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0117 - accuracy: 0.9966 - f1_m: 0.9583 - val_loss: 0.1171 - val_accuracy: 0.9768 - val_f1_m: 0.9714\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0095 - accuracy: 0.9971 - f1_m: 0.9568 - val_loss: 0.1068 - val_accuracy: 0.9808 - val_f1_m: 0.9696\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0078 - accuracy: 0.9979 - f1_m: 0.9555 - val_loss: 0.1235 - val_accuracy: 0.9780 - val_f1_m: 0.9685\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0088 - accuracy: 0.9972 - f1_m: 0.9559 - val_loss: 0.1244 - val_accuracy: 0.9807 - val_f1_m: 0.9673\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 18s 377us/sample - loss: 0.0087 - accuracy: 0.9976 - f1_m: 0.9536 - val_loss: 0.0802 - val_accuracy: 0.9838 - val_f1_m: 0.9659\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 0.0069 - accuracy: 0.9979 - f1_m: 0.9533 - val_loss: 0.1150 - val_accuracy: 0.9823 - val_f1_m: 0.9636\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 0.0079 - accuracy: 0.9974 - f1_m: 0.9530 - val_loss: 0.1033 - val_accuracy: 0.9828 - val_f1_m: 0.9667\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.0068 - accuracy: 0.9978 - f1_m: 0.9526 - val_loss: 0.0905 - val_accuracy: 0.9837 - val_f1_m: 0.9630\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 10s 201us/sample - loss: 0.0151 - accuracy: 0.9953 - f1_m: 0.9568 - val_loss: 0.0623 - val_accuracy: 0.9854 - val_f1_m: 0.9638\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 9s 183us/sample - loss: 0.0127 - accuracy: 0.9961 - f1_m: 0.9574 - val_loss: 0.0689 - val_accuracy: 0.9847 - val_f1_m: 0.9710\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 9s 182us/sample - loss: 0.0119 - accuracy: 0.9965 - f1_m: 0.9562 - val_loss: 0.0804 - val_accuracy: 0.9820 - val_f1_m: 0.9694\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.0136 - accuracy: 0.9957 - f1_m: 0.9563 - val_loss: 0.0676 - val_accuracy: 0.9851 - val_f1_m: 0.9668\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.0052 - accuracy: 0.9984 - f1_m: 0.9526 - val_loss: 0.1366 - val_accuracy: 0.9752 - val_f1_m: 0.9706\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.0027 - accuracy: 0.9993 - f1_m: 0.9508 - val_loss: 0.1444 - val_accuracy: 0.9750 - val_f1_m: 0.9687\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0028 - accuracy: 0.9991 - f1_m: 0.9509 - val_loss: 0.1507 - val_accuracy: 0.9740 - val_f1_m: 0.9729\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9504 - val_loss: 0.1380 - val_accuracy: 0.9779 - val_f1_m: 0.9666\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0039 - accuracy: 0.9989 - f1_m: 0.9500 - val_loss: 0.0849 - val_accuracy: 0.9839 - val_f1_m: 0.9630\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9496 - val_loss: 0.0778 - val_accuracy: 0.9867 - val_f1_m: 0.9618\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0042 - accuracy: 0.9986 - f1_m: 0.9501 - val_loss: 0.0849 - val_accuracy: 0.9857 - val_f1_m: 0.9618\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0036 - accuracy: 0.9990 - f1_m: 0.9494 - val_loss: 0.0925 - val_accuracy: 0.9834 - val_f1_m: 0.9598\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.0060 - accuracy: 0.9986 - f1_m: 0.9500 - val_loss: 0.0872 - val_accuracy: 0.9861 - val_f1_m: 0.9594\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 7s 146us/sample - loss: 0.0042 - accuracy: 0.9988 - f1_m: 0.9497 - val_loss: 0.1183 - val_accuracy: 0.9856 - val_f1_m: 0.9567\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0054 - accuracy: 0.9982 - f1_m: 0.9500 - val_loss: 0.1097 - val_accuracy: 0.9855 - val_f1_m: 0.9571\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 0.0046 - accuracy: 0.9989 - f1_m: 0.9492 - val_loss: 0.1046 - val_accuracy: 0.9857 - val_f1_m: 0.9584\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "48000/48000 [==============================] - 9s 194us/sample - loss: 0.0136 - accuracy: 0.9962 - f1_m: 0.9548 - val_loss: 0.0780 - val_accuracy: 0.9853 - val_f1_m: 0.9644\n",
      "Epoch 2/4\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0150 - accuracy: 0.9956 - f1_m: 0.9556 - val_loss: 0.0826 - val_accuracy: 0.9861 - val_f1_m: 0.9644\n",
      "Epoch 3/4\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.0111 - accuracy: 0.9969 - f1_m: 0.9539 - val_loss: 0.0865 - val_accuracy: 0.9868 - val_f1_m: 0.9614\n",
      "Epoch 4/4\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0143 - accuracy: 0.9964 - f1_m: 0.9550 - val_loss: 0.0894 - val_accuracy: 0.9838 - val_f1_m: 0.9714\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0164 - accuracy: 0.9956 - f1_m: 0.9659 - val_loss: 0.1875 - val_accuracy: 0.9670 - val_f1_m: 0.9798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0144 - accuracy: 0.9959 - f1_m: 0.9639 - val_loss: 0.1973 - val_accuracy: 0.9652 - val_f1_m: 0.9795\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0122 - accuracy: 0.9964 - f1_m: 0.9632 - val_loss: 0.1838 - val_accuracy: 0.9666 - val_f1_m: 0.9798\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0108 - accuracy: 0.9971 - f1_m: 0.9628 - val_loss: 0.1945 - val_accuracy: 0.9677 - val_f1_m: 0.9807\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0102 - accuracy: 0.9969 - f1_m: 0.9610 - val_loss: 0.1922 - val_accuracy: 0.9674 - val_f1_m: 0.9784\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 0.0070 - accuracy: 0.9978 - f1_m: 0.9543 - val_loss: 0.1452 - val_accuracy: 0.9774 - val_f1_m: 0.9656\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0071 - accuracy: 0.9978 - f1_m: 0.9543 - val_loss: 0.1168 - val_accuracy: 0.9803 - val_f1_m: 0.9631\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.0058 - accuracy: 0.9981 - f1_m: 0.9541 - val_loss: 0.1296 - val_accuracy: 0.9801 - val_f1_m: 0.9652\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0052 - accuracy: 0.9981 - f1_m: 0.9531 - val_loss: 0.1317 - val_accuracy: 0.9810 - val_f1_m: 0.9648\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0056 - accuracy: 0.9983 - f1_m: 0.9530 - val_loss: 0.1256 - val_accuracy: 0.9802 - val_f1_m: 0.9632\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.0068 - accuracy: 0.9979 - f1_m: 0.9518 - val_loss: 0.0989 - val_accuracy: 0.9847 - val_f1_m: 0.9635\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0060 - accuracy: 0.9980 - f1_m: 0.9517 - val_loss: 0.1089 - val_accuracy: 0.9854 - val_f1_m: 0.9608\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0078 - accuracy: 0.9979 - f1_m: 0.9514 - val_loss: 0.0952 - val_accuracy: 0.9842 - val_f1_m: 0.9606\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9507 - val_loss: 0.1196 - val_accuracy: 0.9828 - val_f1_m: 0.9631\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 0.0097 - accuracy: 0.9970 - f1_m: 0.9521 - val_loss: 0.1077 - val_accuracy: 0.9834 - val_f1_m: 0.9623\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 10s 200us/sample - loss: 0.0129 - accuracy: 0.9959 - f1_m: 0.9561 - val_loss: 0.0656 - val_accuracy: 0.9843 - val_f1_m: 0.9694\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 8s 169us/sample - loss: 0.0110 - accuracy: 0.9969 - f1_m: 0.9550 - val_loss: 0.0730 - val_accuracy: 0.9851 - val_f1_m: 0.9687\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.0116 - accuracy: 0.9962 - f1_m: 0.9556 - val_loss: 0.0827 - val_accuracy: 0.9847 - val_f1_m: 0.9639\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.0125 - accuracy: 0.9960 - f1_m: 0.9554 - val_loss: 0.0751 - val_accuracy: 0.9869 - val_f1_m: 0.9601\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.0092 - accuracy: 0.9971 - f1_m: 0.9544 - val_loss: 0.0792 - val_accuracy: 0.9877 - val_f1_m: 0.9608\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0024 - accuracy: 0.9992 - f1_m: 0.9509 - val_loss: 0.1614 - val_accuracy: 0.9749 - val_f1_m: 0.9671\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_m: 0.9495 - val_loss: 0.1530 - val_accuracy: 0.9762 - val_f1_m: 0.9623\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_m: 0.9499 - val_loss: 0.1443 - val_accuracy: 0.9780 - val_f1_m: 0.9651\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9488 - val_loss: 0.1606 - val_accuracy: 0.9754 - val_f1_m: 0.9721\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0029 - accuracy: 0.9989 - f1_m: 0.9506 - val_loss: 0.1574 - val_accuracy: 0.9772 - val_f1_m: 0.9608\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0029 - accuracy: 0.9990 - f1_m: 0.9492 - val_loss: 0.0726 - val_accuracy: 0.9873 - val_f1_m: 0.9610\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0033 - accuracy: 0.9989 - f1_m: 0.9496 - val_loss: 0.0976 - val_accuracy: 0.9853 - val_f1_m: 0.9586\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0019 - accuracy: 0.9994 - f1_m: 0.9486 - val_loss: 0.0965 - val_accuracy: 0.9838 - val_f1_m: 0.9588\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9486 - val_loss: 0.1206 - val_accuracy: 0.9844 - val_f1_m: 0.9574\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9491 - val_loss: 0.1016 - val_accuracy: 0.9851 - val_f1_m: 0.9577\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.0047 - accuracy: 0.9986 - f1_m: 0.9500 - val_loss: 0.1028 - val_accuracy: 0.9850 - val_f1_m: 0.9589\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0042 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1054 - val_accuracy: 0.9847 - val_f1_m: 0.9592\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0061 - accuracy: 0.9985 - f1_m: 0.9498 - val_loss: 0.0956 - val_accuracy: 0.9866 - val_f1_m: 0.9574\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0020 - accuracy: 0.9993 - f1_m: 0.9488 - val_loss: 0.0998 - val_accuracy: 0.9866 - val_f1_m: 0.9580\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0052 - accuracy: 0.9985 - f1_m: 0.9493 - val_loss: 0.0851 - val_accuracy: 0.9882 - val_f1_m: 0.9606\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.0111 - accuracy: 0.9968 - f1_m: 0.9535 - val_loss: 0.0953 - val_accuracy: 0.9850 - val_f1_m: 0.9606\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0097 - accuracy: 0.9975 - f1_m: 0.9528 - val_loss: 0.0997 - val_accuracy: 0.9856 - val_f1_m: 0.9596\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0126 - accuracy: 0.9964 - f1_m: 0.9533 - val_loss: 0.0857 - val_accuracy: 0.9853 - val_f1_m: 0.9622\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0127 - accuracy: 0.9967 - f1_m: 0.9535 - val_loss: 0.0738 - val_accuracy: 0.9870 - val_f1_m: 0.9680\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 8s 177us/sample - loss: 0.0105 - accuracy: 0.9968 - f1_m: 0.9525 - val_loss: 0.0835 - val_accuracy: 0.9878 - val_f1_m: 0.9583\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0102 - accuracy: 0.9967 - f1_m: 0.9604 - val_loss: 0.1954 - val_accuracy: 0.9691 - val_f1_m: 0.9770\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0074 - accuracy: 0.9978 - f1_m: 0.9590 - val_loss: 0.1999 - val_accuracy: 0.9676 - val_f1_m: 0.9783\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0075 - accuracy: 0.9977 - f1_m: 0.9591 - val_loss: 0.2055 - val_accuracy: 0.9663 - val_f1_m: 0.9803\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0069 - accuracy: 0.9981 - f1_m: 0.9586 - val_loss: 0.2063 - val_accuracy: 0.9681 - val_f1_m: 0.9738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0063 - accuracy: 0.9981 - f1_m: 0.9572 - val_loss: 0.2090 - val_accuracy: 0.9675 - val_f1_m: 0.9733\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0067 - accuracy: 0.9977 - f1_m: 0.9573 - val_loss: 0.2265 - val_accuracy: 0.9676 - val_f1_m: 0.9742\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0054 - accuracy: 0.9983 - f1_m: 0.9524 - val_loss: 0.1454 - val_accuracy: 0.9811 - val_f1_m: 0.9654\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0038 - accuracy: 0.9990 - f1_m: 0.9512 - val_loss: 0.1284 - val_accuracy: 0.9800 - val_f1_m: 0.9619\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0038 - accuracy: 0.9987 - f1_m: 0.9514 - val_loss: 0.1465 - val_accuracy: 0.9792 - val_f1_m: 0.9637\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0049 - accuracy: 0.9984 - f1_m: 0.9517 - val_loss: 0.1363 - val_accuracy: 0.9818 - val_f1_m: 0.9620\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0044 - accuracy: 0.9984 - f1_m: 0.9519 - val_loss: 0.1416 - val_accuracy: 0.9818 - val_f1_m: 0.9622\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0020 - accuracy: 0.9994 - f1_m: 0.9500 - val_loss: 0.1386 - val_accuracy: 0.9814 - val_f1_m: 0.9613\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 7s 135us/sample - loss: 0.0072 - accuracy: 0.9978 - f1_m: 0.9514 - val_loss: 0.1021 - val_accuracy: 0.9840 - val_f1_m: 0.9618\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_m: 0.9502 - val_loss: 0.1036 - val_accuracy: 0.9878 - val_f1_m: 0.9559\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.0049 - accuracy: 0.9985 - f1_m: 0.9510 - val_loss: 0.1079 - val_accuracy: 0.9838 - val_f1_m: 0.9620\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0058 - accuracy: 0.9985 - f1_m: 0.9506 - val_loss: 0.1128 - val_accuracy: 0.9860 - val_f1_m: 0.9571\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0050 - accuracy: 0.9984 - f1_m: 0.9509 - val_loss: 0.1000 - val_accuracy: 0.9858 - val_f1_m: 0.9586\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9500 - val_loss: 0.1128 - val_accuracy: 0.9825 - val_f1_m: 0.9609\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 9s 179us/sample - loss: 0.0131 - accuracy: 0.9957 - f1_m: 0.9545 - val_loss: 0.0894 - val_accuracy: 0.9859 - val_f1_m: 0.9626\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.0099 - accuracy: 0.9969 - f1_m: 0.9532 - val_loss: 0.0824 - val_accuracy: 0.9870 - val_f1_m: 0.9635\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.0098 - accuracy: 0.9969 - f1_m: 0.9542 - val_loss: 0.0827 - val_accuracy: 0.9874 - val_f1_m: 0.9582\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.0125 - accuracy: 0.9962 - f1_m: 0.9553 - val_loss: 0.0896 - val_accuracy: 0.9830 - val_f1_m: 0.9662\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.0102 - accuracy: 0.9969 - f1_m: 0.9541 - val_loss: 0.0785 - val_accuracy: 0.9861 - val_f1_m: 0.9625\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0125 - accuracy: 0.9963 - f1_m: 0.9542 - val_loss: 0.0850 - val_accuracy: 0.9839 - val_f1_m: 0.9634\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0021 - accuracy: 0.9993 - f1_m: 0.9496 - val_loss: 0.1632 - val_accuracy: 0.9774 - val_f1_m: 0.9639\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0015 - accuracy: 0.9995 - f1_m: 0.9492 - val_loss: 0.1895 - val_accuracy: 0.9754 - val_f1_m: 0.9635\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0010 - accuracy: 0.9997 - f1_m: 0.9485 - val_loss: 0.1671 - val_accuracy: 0.9778 - val_f1_m: 0.9628\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 3.4331e-04 - accuracy: 0.9999 - f1_m: 0.9476 - val_loss: 0.1704 - val_accuracy: 0.9796 - val_f1_m: 0.9620\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0034 - accuracy: 0.9988 - f1_m: 0.9497 - val_loss: 0.1758 - val_accuracy: 0.9775 - val_f1_m: 0.9615\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9488 - val_loss: 0.1724 - val_accuracy: 0.9768 - val_f1_m: 0.9633\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9489 - val_loss: 0.1353 - val_accuracy: 0.9846 - val_f1_m: 0.9575\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9487 - val_loss: 0.0889 - val_accuracy: 0.9869 - val_f1_m: 0.9569\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9491 - val_loss: 0.0800 - val_accuracy: 0.9871 - val_f1_m: 0.9601\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 6.2933e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.0840 - val_accuracy: 0.9862 - val_f1_m: 0.9596\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9485 - val_loss: 0.0923 - val_accuracy: 0.9865 - val_f1_m: 0.9606\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0020 - accuracy: 0.9994 - f1_m: 0.9484 - val_loss: 0.1041 - val_accuracy: 0.9868 - val_f1_m: 0.9558\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 0.0048 - accuracy: 0.9988 - f1_m: 0.9493 - val_loss: 0.1398 - val_accuracy: 0.9867 - val_f1_m: 0.9560\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0041 - accuracy: 0.9992 - f1_m: 0.9485 - val_loss: 0.1168 - val_accuracy: 0.9869 - val_f1_m: 0.9571\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 0.0034 - accuracy: 0.9991 - f1_m: 0.9487 - val_loss: 0.1025 - val_accuracy: 0.9877 - val_f1_m: 0.9601\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0052 - accuracy: 0.9988 - f1_m: 0.9490 - val_loss: 0.0968 - val_accuracy: 0.9871 - val_f1_m: 0.9573\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0018 - accuracy: 0.9994 - f1_m: 0.9484 - val_loss: 0.1032 - val_accuracy: 0.9881 - val_f1_m: 0.9564\n",
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 0.0051 - accuracy: 0.9989 - f1_m: 0.9489 - val_loss: 0.1430 - val_accuracy: 0.9840 - val_f1_m: 0.9567\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "48000/48000 [==============================] - 10s 210us/sample - loss: 0.0108 - accuracy: 0.9971 - f1_m: 0.9524 - val_loss: 0.0743 - val_accuracy: 0.9888 - val_f1_m: 0.9622\n",
      "Epoch 2/6\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0110 - accuracy: 0.9971 - f1_m: 0.9522 - val_loss: 0.1077 - val_accuracy: 0.9857 - val_f1_m: 0.9612\n",
      "Epoch 3/6\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0101 - accuracy: 0.9971 - f1_m: 0.9520 - val_loss: 0.1151 - val_accuracy: 0.9862 - val_f1_m: 0.9585\n",
      "Epoch 4/6\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0131 - accuracy: 0.9968 - f1_m: 0.9527 - val_loss: 0.1026 - val_accuracy: 0.9836 - val_f1_m: 0.9655\n",
      "Epoch 5/6\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0095 - accuracy: 0.9972 - f1_m: 0.9520 - val_loss: 0.1082 - val_accuracy: 0.9861 - val_f1_m: 0.9572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6\n",
      "48000/48000 [==============================] - 8s 169us/sample - loss: 0.0100 - accuracy: 0.9975 - f1_m: 0.9520 - val_loss: 0.0870 - val_accuracy: 0.9867 - val_f1_m: 0.9608\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9567 - val_loss: 0.2231 - val_accuracy: 0.9671 - val_f1_m: 0.9768\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0051 - accuracy: 0.9983 - f1_m: 0.9548 - val_loss: 0.2444 - val_accuracy: 0.9634 - val_f1_m: 0.9755\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.0051 - accuracy: 0.9985 - f1_m: 0.9548 - val_loss: 0.2167 - val_accuracy: 0.9703 - val_f1_m: 0.9770\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.0033 - accuracy: 0.9992 - f1_m: 0.9536 - val_loss: 0.2211 - val_accuracy: 0.9684 - val_f1_m: 0.9746\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0051 - accuracy: 0.9985 - f1_m: 0.9551 - val_loss: 0.2203 - val_accuracy: 0.9682 - val_f1_m: 0.9722\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.0046 - accuracy: 0.9987 - f1_m: 0.9540 - val_loss: 0.2561 - val_accuracy: 0.9660 - val_f1_m: 0.9714\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9530 - val_loss: 0.2408 - val_accuracy: 0.9668 - val_f1_m: 0.9718\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9508 - val_loss: 0.1746 - val_accuracy: 0.9786 - val_f1_m: 0.9610\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0039 - accuracy: 0.9988 - f1_m: 0.9516 - val_loss: 0.1495 - val_accuracy: 0.9830 - val_f1_m: 0.9603\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9497 - val_loss: 0.1878 - val_accuracy: 0.9762 - val_f1_m: 0.9644\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0042 - accuracy: 0.9986 - f1_m: 0.9509 - val_loss: 0.1633 - val_accuracy: 0.9802 - val_f1_m: 0.9619\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0032 - accuracy: 0.9989 - f1_m: 0.9505 - val_loss: 0.1531 - val_accuracy: 0.9812 - val_f1_m: 0.9634\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0028 - accuracy: 0.9991 - f1_m: 0.9493 - val_loss: 0.1702 - val_accuracy: 0.9794 - val_f1_m: 0.9596\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0026 - accuracy: 0.9990 - f1_m: 0.9500 - val_loss: 0.1903 - val_accuracy: 0.9791 - val_f1_m: 0.9610\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0057 - accuracy: 0.9984 - f1_m: 0.9507 - val_loss: 0.1601 - val_accuracy: 0.9823 - val_f1_m: 0.9586\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0059 - accuracy: 0.9984 - f1_m: 0.9501 - val_loss: 0.1126 - val_accuracy: 0.9857 - val_f1_m: 0.9587\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9489 - val_loss: 0.1439 - val_accuracy: 0.9837 - val_f1_m: 0.9571\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0056 - accuracy: 0.9983 - f1_m: 0.9502 - val_loss: 0.1247 - val_accuracy: 0.9835 - val_f1_m: 0.9589\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0038 - accuracy: 0.9987 - f1_m: 0.9499 - val_loss: 0.1388 - val_accuracy: 0.9850 - val_f1_m: 0.9580\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9497 - val_loss: 0.1023 - val_accuracy: 0.9850 - val_f1_m: 0.9591\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0053 - accuracy: 0.9986 - f1_m: 0.9498 - val_loss: 0.1049 - val_accuracy: 0.9843 - val_f1_m: 0.9599\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0138 - accuracy: 0.9958 - f1_m: 0.9555 - val_loss: 0.0782 - val_accuracy: 0.9848 - val_f1_m: 0.9666\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0083 - accuracy: 0.9974 - f1_m: 0.9529 - val_loss: 0.0840 - val_accuracy: 0.9843 - val_f1_m: 0.9652\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0116 - accuracy: 0.9962 - f1_m: 0.9542 - val_loss: 0.0745 - val_accuracy: 0.9840 - val_f1_m: 0.9682\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0110 - accuracy: 0.9964 - f1_m: 0.9541 - val_loss: 0.0949 - val_accuracy: 0.9855 - val_f1_m: 0.9607\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0114 - accuracy: 0.9963 - f1_m: 0.9533 - val_loss: 0.0890 - val_accuracy: 0.9829 - val_f1_m: 0.9573\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.0084 - accuracy: 0.9972 - f1_m: 0.9524 - val_loss: 0.0938 - val_accuracy: 0.9838 - val_f1_m: 0.9614\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0092 - accuracy: 0.9973 - f1_m: 0.9531 - val_loss: 0.1028 - val_accuracy: 0.9812 - val_f1_m: 0.9631\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0020 - accuracy: 0.9994 - f1_m: 0.9488 - val_loss: 0.2027 - val_accuracy: 0.9761 - val_f1_m: 0.9606\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 8.4314e-04 - accuracy: 0.9997 - f1_m: 0.9482 - val_loss: 0.1939 - val_accuracy: 0.9771 - val_f1_m: 0.9611\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_m: 0.9487 - val_loss: 0.1938 - val_accuracy: 0.9763 - val_f1_m: 0.9630\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9489 - val_loss: 0.1827 - val_accuracy: 0.9777 - val_f1_m: 0.9610\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 6.6320e-04 - accuracy: 0.9999 - f1_m: 0.9482 - val_loss: 0.1662 - val_accuracy: 0.9794 - val_f1_m: 0.9596\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9482 - val_loss: 0.1798 - val_accuracy: 0.9766 - val_f1_m: 0.9626\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0011 - accuracy: 0.9996 - f1_m: 0.9487 - val_loss: 0.1787 - val_accuracy: 0.9766 - val_f1_m: 0.9618\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_m: 0.9484 - val_loss: 0.1251 - val_accuracy: 0.9847 - val_f1_m: 0.9592\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_m: 0.9484 - val_loss: 0.1052 - val_accuracy: 0.9858 - val_f1_m: 0.9598\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.0025 - accuracy: 0.9995 - f1_m: 0.9485 - val_loss: 0.1253 - val_accuracy: 0.9847 - val_f1_m: 0.9574\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9484 - val_loss: 0.1230 - val_accuracy: 0.9846 - val_f1_m: 0.9568\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9480 - val_loss: 0.1412 - val_accuracy: 0.9850 - val_f1_m: 0.9561\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9486 - val_loss: 0.1351 - val_accuracy: 0.9872 - val_f1_m: 0.9552\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0014 - accuracy: 0.9997 - f1_m: 0.9479 - val_loss: 0.1110 - val_accuracy: 0.9870 - val_f1_m: 0.9546\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0046 - accuracy: 0.9988 - f1_m: 0.9488 - val_loss: 0.1086 - val_accuracy: 0.9881 - val_f1_m: 0.9544\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 0.0042 - accuracy: 0.9989 - f1_m: 0.9486 - val_loss: 0.1228 - val_accuracy: 0.9868 - val_f1_m: 0.9545\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 0.0029 - accuracy: 0.9992 - f1_m: 0.9484 - val_loss: 0.1431 - val_accuracy: 0.9870 - val_f1_m: 0.9528\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 0.0033 - accuracy: 0.9993 - f1_m: 0.9484 - val_loss: 0.1341 - val_accuracy: 0.9849 - val_f1_m: 0.9559\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 0.0043 - accuracy: 0.9992 - f1_m: 0.9483 - val_loss: 0.2758 - val_accuracy: 0.9877 - val_f1_m: 0.9533\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.0064 - accuracy: 0.9987 - f1_m: 0.9487 - val_loss: 0.1365 - val_accuracy: 0.9880 - val_f1_m: 0.9543\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 0.0047 - accuracy: 0.9989 - f1_m: 0.9486 - val_loss: 0.1355 - val_accuracy: 0.9880 - val_f1_m: 0.9533\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "48000/48000 [==============================] - 10s 208us/sample - loss: 0.0126 - accuracy: 0.9965 - f1_m: 0.9530 - val_loss: 0.1168 - val_accuracy: 0.9852 - val_f1_m: 0.9605\n",
      "Epoch 2/7\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.0100 - accuracy: 0.9974 - f1_m: 0.9520 - val_loss: 0.1211 - val_accuracy: 0.9872 - val_f1_m: 0.9561\n",
      "Epoch 3/7\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.0088 - accuracy: 0.9977 - f1_m: 0.9507 - val_loss: 0.1251 - val_accuracy: 0.9875 - val_f1_m: 0.9585\n",
      "Epoch 4/7\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.0121 - accuracy: 0.9971 - f1_m: 0.9518 - val_loss: 0.1236 - val_accuracy: 0.9832 - val_f1_m: 0.9628\n",
      "Epoch 5/7\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.0109 - accuracy: 0.9976 - f1_m: 0.9514 - val_loss: 0.0940 - val_accuracy: 0.9867 - val_f1_m: 0.9570\n",
      "Epoch 6/7\n",
      "48000/48000 [==============================] - 9s 194us/sample - loss: 0.0088 - accuracy: 0.9974 - f1_m: 0.9517 - val_loss: 0.1170 - val_accuracy: 0.9862 - val_f1_m: 0.9599\n",
      "Epoch 7/7\n",
      "48000/48000 [==============================] - 9s 190us/sample - loss: 0.0103 - accuracy: 0.9974 - f1_m: 0.9511 - val_loss: 0.1436 - val_accuracy: 0.9830 - val_f1_m: 0.9601\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9538 - val_loss: 0.2279 - val_accuracy: 0.9693 - val_f1_m: 0.9679\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0036 - accuracy: 0.9989 - f1_m: 0.9524 - val_loss: 0.2390 - val_accuracy: 0.9682 - val_f1_m: 0.9713\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9523 - val_loss: 0.2166 - val_accuracy: 0.9698 - val_f1_m: 0.9732\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0037 - accuracy: 0.9989 - f1_m: 0.9528 - val_loss: 0.2360 - val_accuracy: 0.9695 - val_f1_m: 0.9691\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0022 - accuracy: 0.9993 - f1_m: 0.9510 - val_loss: 0.2459 - val_accuracy: 0.9660 - val_f1_m: 0.9702\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0037 - accuracy: 0.9987 - f1_m: 0.9520 - val_loss: 0.2433 - val_accuracy: 0.9710 - val_f1_m: 0.9688\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0040 - accuracy: 0.9986 - f1_m: 0.9526 - val_loss: 0.2443 - val_accuracy: 0.9699 - val_f1_m: 0.9716\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0023 - accuracy: 0.9993 - f1_m: 0.9509 - val_loss: 0.2814 - val_accuracy: 0.9655 - val_f1_m: 0.9705\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0049 - accuracy: 0.9983 - f1_m: 0.9510 - val_loss: 0.1828 - val_accuracy: 0.9806 - val_f1_m: 0.9602\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.0030 - accuracy: 0.9991 - f1_m: 0.9494 - val_loss: 0.1975 - val_accuracy: 0.9769 - val_f1_m: 0.9623\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0028 - accuracy: 0.9991 - f1_m: 0.9500 - val_loss: 0.1977 - val_accuracy: 0.9786 - val_f1_m: 0.9615\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0038 - accuracy: 0.9986 - f1_m: 0.9503 - val_loss: 0.1776 - val_accuracy: 0.9806 - val_f1_m: 0.9587\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9492 - val_loss: 0.1919 - val_accuracy: 0.9789 - val_f1_m: 0.9613\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0034 - accuracy: 0.9990 - f1_m: 0.9504 - val_loss: 0.1895 - val_accuracy: 0.9810 - val_f1_m: 0.9612\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0024 - accuracy: 0.9992 - f1_m: 0.9497 - val_loss: 0.1977 - val_accuracy: 0.9810 - val_f1_m: 0.9586\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.0037 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1837 - val_accuracy: 0.9799 - val_f1_m: 0.9603\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 0.0050 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1156 - val_accuracy: 0.9833 - val_f1_m: 0.9600\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0053 - accuracy: 0.9984 - f1_m: 0.9500 - val_loss: 0.1471 - val_accuracy: 0.9825 - val_f1_m: 0.9602\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0059 - accuracy: 0.9983 - f1_m: 0.9498 - val_loss: 0.1318 - val_accuracy: 0.9838 - val_f1_m: 0.9590\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0037 - accuracy: 0.9989 - f1_m: 0.9492 - val_loss: 0.1661 - val_accuracy: 0.9822 - val_f1_m: 0.9558\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0056 - accuracy: 0.9984 - f1_m: 0.9499 - val_loss: 0.1235 - val_accuracy: 0.9859 - val_f1_m: 0.9578\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 0.0045 - accuracy: 0.9986 - f1_m: 0.9501 - val_loss: 0.1326 - val_accuracy: 0.9854 - val_f1_m: 0.9567\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0047 - accuracy: 0.9987 - f1_m: 0.9491 - val_loss: 0.1409 - val_accuracy: 0.9836 - val_f1_m: 0.9583\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0053 - accuracy: 0.9986 - f1_m: 0.9498 - val_loss: 0.1327 - val_accuracy: 0.9835 - val_f1_m: 0.9583\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 9s 192us/sample - loss: 0.0111 - accuracy: 0.9965 - f1_m: 0.9543 - val_loss: 0.0910 - val_accuracy: 0.9839 - val_f1_m: 0.9615\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0102 - accuracy: 0.9968 - f1_m: 0.9536 - val_loss: 0.0823 - val_accuracy: 0.9855 - val_f1_m: 0.9672\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0094 - accuracy: 0.9970 - f1_m: 0.9534 - val_loss: 0.0770 - val_accuracy: 0.9868 - val_f1_m: 0.9640\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0110 - accuracy: 0.9965 - f1_m: 0.9542 - val_loss: 0.0746 - val_accuracy: 0.9834 - val_f1_m: 0.9667\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.0090 - accuracy: 0.9972 - f1_m: 0.9534 - val_loss: 0.0677 - val_accuracy: 0.9857 - val_f1_m: 0.9640\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.0096 - accuracy: 0.9973 - f1_m: 0.9538 - val_loss: 0.0751 - val_accuracy: 0.9854 - val_f1_m: 0.9635\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 8s 170us/sample - loss: 0.0107 - accuracy: 0.9971 - f1_m: 0.9531 - val_loss: 0.0769 - val_accuracy: 0.9866 - val_f1_m: 0.9625\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 8s 169us/sample - loss: 0.0070 - accuracy: 0.9976 - f1_m: 0.9524 - val_loss: 0.0712 - val_accuracy: 0.9884 - val_f1_m: 0.9594\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0016 - accuracy: 0.9994 - f1_m: 0.9487 - val_loss: 0.1683 - val_accuracy: 0.9770 - val_f1_m: 0.9635\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 7.0844e-04 - accuracy: 0.9998 - f1_m: 0.9483 - val_loss: 0.1850 - val_accuracy: 0.9784 - val_f1_m: 0.9609\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 5.5569e-04 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.1605 - val_accuracy: 0.9793 - val_f1_m: 0.9605\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 8.7024e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1624 - val_accuracy: 0.9799 - val_f1_m: 0.9594\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9494 - val_loss: 0.1748 - val_accuracy: 0.9771 - val_f1_m: 0.9632\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 3.2893e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1689 - val_accuracy: 0.9801 - val_f1_m: 0.9591\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 9.4902e-04 - accuracy: 0.9997 - f1_m: 0.9478 - val_loss: 0.1981 - val_accuracy: 0.9768 - val_f1_m: 0.9603\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0014 - accuracy: 0.9996 - f1_m: 0.9484 - val_loss: 0.1760 - val_accuracy: 0.9805 - val_f1_m: 0.9567\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0028 - accuracy: 0.9994 - f1_m: 0.9482 - val_loss: 0.1497 - val_accuracy: 0.9860 - val_f1_m: 0.9549\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 5.4989e-04 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.1551 - val_accuracy: 0.9848 - val_f1_m: 0.9567\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0024 - accuracy: 0.9992 - f1_m: 0.9484 - val_loss: 0.1152 - val_accuracy: 0.9881 - val_f1_m: 0.9546\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9481 - val_loss: 0.1235 - val_accuracy: 0.9871 - val_f1_m: 0.9538\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0020 - accuracy: 0.9995 - f1_m: 0.9483 - val_loss: 0.1183 - val_accuracy: 0.9869 - val_f1_m: 0.9551\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0014 - accuracy: 0.9996 - f1_m: 0.9481 - val_loss: 0.1212 - val_accuracy: 0.9901 - val_f1_m: 0.9533\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0027 - accuracy: 0.9993 - f1_m: 0.9480 - val_loss: 0.1055 - val_accuracy: 0.9862 - val_f1_m: 0.9547\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0025 - accuracy: 0.9993 - f1_m: 0.9482 - val_loss: 0.1379 - val_accuracy: 0.9864 - val_f1_m: 0.9544\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.0032 - accuracy: 0.9994 - f1_m: 0.9481 - val_loss: 0.1694 - val_accuracy: 0.9854 - val_f1_m: 0.9544\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 0.0062 - accuracy: 0.9986 - f1_m: 0.9490 - val_loss: 0.1372 - val_accuracy: 0.9856 - val_f1_m: 0.9579\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.0056 - accuracy: 0.9986 - f1_m: 0.9490 - val_loss: 0.1541 - val_accuracy: 0.9863 - val_f1_m: 0.9562\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 0.0025 - accuracy: 0.9994 - f1_m: 0.9485 - val_loss: 0.1441 - val_accuracy: 0.9874 - val_f1_m: 0.9555\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 7s 151us/sample - loss: 0.0055 - accuracy: 0.9989 - f1_m: 0.9485 - val_loss: 0.1661 - val_accuracy: 0.9861 - val_f1_m: 0.9533\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 8s 171us/sample - loss: 0.0037 - accuracy: 0.9991 - f1_m: 0.9487 - val_loss: 0.1532 - val_accuracy: 0.9859 - val_f1_m: 0.9561\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.0067 - accuracy: 0.9987 - f1_m: 0.9486 - val_loss: 0.1393 - val_accuracy: 0.9883 - val_f1_m: 0.9546\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9485 - val_loss: 0.1872 - val_accuracy: 0.9868 - val_f1_m: 0.9532\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "48000/48000 [==============================] - 10s 212us/sample - loss: 0.0131 - accuracy: 0.9969 - f1_m: 0.9514 - val_loss: 0.0885 - val_accuracy: 0.9845 - val_f1_m: 0.9666\n",
      "Epoch 2/8\n",
      "48000/48000 [==============================] - 10s 211us/sample - loss: 0.0114 - accuracy: 0.9970 - f1_m: 0.9520 - val_loss: 0.0793 - val_accuracy: 0.9865 - val_f1_m: 0.9599\n",
      "Epoch 3/8\n",
      "48000/48000 [==============================] - 9s 193us/sample - loss: 0.0077 - accuracy: 0.9982 - f1_m: 0.9508 - val_loss: 0.1502 - val_accuracy: 0.9817 - val_f1_m: 0.9662\n",
      "Epoch 4/8\n",
      "48000/48000 [==============================] - 9s 197us/sample - loss: 0.0106 - accuracy: 0.9969 - f1_m: 0.9518 - val_loss: 0.1043 - val_accuracy: 0.9872 - val_f1_m: 0.9567\n",
      "Epoch 5/8\n",
      "48000/48000 [==============================] - 9s 192us/sample - loss: 0.0123 - accuracy: 0.9967 - f1_m: 0.9525 - val_loss: 0.1159 - val_accuracy: 0.9862 - val_f1_m: 0.9559\n",
      "Epoch 6/8\n",
      "48000/48000 [==============================] - 9s 190us/sample - loss: 0.0126 - accuracy: 0.9967 - f1_m: 0.9520 - val_loss: 0.1334 - val_accuracy: 0.9868 - val_f1_m: 0.9567\n",
      "Epoch 7/8\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.0082 - accuracy: 0.9979 - f1_m: 0.9509 - val_loss: 0.1073 - val_accuracy: 0.9865 - val_f1_m: 0.9591\n",
      "Epoch 8/8\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.0116 - accuracy: 0.9975 - f1_m: 0.9517 - val_loss: 0.1354 - val_accuracy: 0.9833 - val_f1_m: 0.9605\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9515 - val_loss: 0.2559 - val_accuracy: 0.9673 - val_f1_m: 0.9676\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9512 - val_loss: 0.2463 - val_accuracy: 0.9692 - val_f1_m: 0.9711\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0016 - accuracy: 0.9997 - f1_m: 0.9502 - val_loss: 0.2471 - val_accuracy: 0.9693 - val_f1_m: 0.9683\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9520 - val_loss: 0.2703 - val_accuracy: 0.9675 - val_f1_m: 0.9709\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9509 - val_loss: 0.2462 - val_accuracy: 0.9700 - val_f1_m: 0.9690\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0034 - accuracy: 0.9989 - f1_m: 0.9515 - val_loss: 0.2748 - val_accuracy: 0.9685 - val_f1_m: 0.9657\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9514 - val_loss: 0.2678 - val_accuracy: 0.9697 - val_f1_m: 0.9696\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0013 - accuracy: 0.9996 - f1_m: 0.9493 - val_loss: 0.2550 - val_accuracy: 0.9698 - val_f1_m: 0.9696\n",
      "Epoch 9/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0040 - accuracy: 0.9988 - f1_m: 0.9505 - val_loss: 0.2571 - val_accuracy: 0.9716 - val_f1_m: 0.9665\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 0.0029 - accuracy: 0.9991 - f1_m: 0.9498 - val_loss: 0.1918 - val_accuracy: 0.9808 - val_f1_m: 0.9585\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0031 - accuracy: 0.9991 - f1_m: 0.9497 - val_loss: 0.1757 - val_accuracy: 0.9816 - val_f1_m: 0.9603\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9491 - val_loss: 0.1905 - val_accuracy: 0.9789 - val_f1_m: 0.9601\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0031 - accuracy: 0.9990 - f1_m: 0.9499 - val_loss: 0.1677 - val_accuracy: 0.9807 - val_f1_m: 0.9582\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0020 - accuracy: 0.9993 - f1_m: 0.9490 - val_loss: 0.1960 - val_accuracy: 0.9785 - val_f1_m: 0.9610\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0038 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.1859 - val_accuracy: 0.9811 - val_f1_m: 0.9580\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0022 - accuracy: 0.9993 - f1_m: 0.9488 - val_loss: 0.1902 - val_accuracy: 0.9812 - val_f1_m: 0.9603\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 7.0117e-04 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.1927 - val_accuracy: 0.9816 - val_f1_m: 0.9572\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0049 - accuracy: 0.9986 - f1_m: 0.9504 - val_loss: 0.1898 - val_accuracy: 0.9808 - val_f1_m: 0.9584\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 0.0058 - accuracy: 0.9984 - f1_m: 0.9497 - val_loss: 0.1406 - val_accuracy: 0.9833 - val_f1_m: 0.9594\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.0046 - accuracy: 0.9989 - f1_m: 0.9492 - val_loss: 0.1242 - val_accuracy: 0.9842 - val_f1_m: 0.9599\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9490 - val_loss: 0.1487 - val_accuracy: 0.9833 - val_f1_m: 0.9552\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0073 - accuracy: 0.9981 - f1_m: 0.9505 - val_loss: 0.1171 - val_accuracy: 0.9869 - val_f1_m: 0.9549\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 0.0030 - accuracy: 0.9991 - f1_m: 0.9492 - val_loss: 0.1362 - val_accuracy: 0.9830 - val_f1_m: 0.9579\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0057 - accuracy: 0.9985 - f1_m: 0.9504 - val_loss: 0.1141 - val_accuracy: 0.9866 - val_f1_m: 0.9563\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 0.0042 - accuracy: 0.9987 - f1_m: 0.9494 - val_loss: 0.1174 - val_accuracy: 0.9868 - val_f1_m: 0.9564\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.0047 - accuracy: 0.9987 - f1_m: 0.9496 - val_loss: 0.1256 - val_accuracy: 0.9861 - val_f1_m: 0.9561\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 7s 140us/sample - loss: 0.0038 - accuracy: 0.9989 - f1_m: 0.9491 - val_loss: 0.1299 - val_accuracy: 0.9835 - val_f1_m: 0.9575\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 11s 234us/sample - loss: 0.0102 - accuracy: 0.9969 - f1_m: 0.9524 - val_loss: 0.0967 - val_accuracy: 0.9859 - val_f1_m: 0.9590\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 9s 182us/sample - loss: 0.0093 - accuracy: 0.9972 - f1_m: 0.9525 - val_loss: 0.1002 - val_accuracy: 0.9855 - val_f1_m: 0.9561\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 9s 181us/sample - loss: 0.0089 - accuracy: 0.9973 - f1_m: 0.9524 - val_loss: 0.0792 - val_accuracy: 0.9857 - val_f1_m: 0.9636\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0101 - accuracy: 0.9970 - f1_m: 0.9529 - val_loss: 0.0827 - val_accuracy: 0.9851 - val_f1_m: 0.9643\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.0098 - accuracy: 0.9970 - f1_m: 0.9522 - val_loss: 0.0629 - val_accuracy: 0.9886 - val_f1_m: 0.9624\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 9s 182us/sample - loss: 0.0081 - accuracy: 0.9975 - f1_m: 0.9526 - val_loss: 0.0935 - val_accuracy: 0.9865 - val_f1_m: 0.9581\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0088 - accuracy: 0.9974 - f1_m: 0.9519 - val_loss: 0.1049 - val_accuracy: 0.9828 - val_f1_m: 0.9633\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.0115 - accuracy: 0.9967 - f1_m: 0.9533 - val_loss: 0.0908 - val_accuracy: 0.9858 - val_f1_m: 0.9648\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0099 - accuracy: 0.9969 - f1_m: 0.9526 - val_loss: 0.0861 - val_accuracy: 0.9845 - val_f1_m: 0.9613\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9485 - val_loss: 0.1892 - val_accuracy: 0.9774 - val_f1_m: 0.9612\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 7.1196e-04 - accuracy: 0.9997 - f1_m: 0.9480 - val_loss: 0.1985 - val_accuracy: 0.9785 - val_f1_m: 0.9583\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 6.7874e-04 - accuracy: 0.9998 - f1_m: 0.9481 - val_loss: 0.1763 - val_accuracy: 0.9787 - val_f1_m: 0.9598\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 1.9641e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1738 - val_accuracy: 0.9799 - val_f1_m: 0.9591\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 4.8722e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1753 - val_accuracy: 0.9799 - val_f1_m: 0.9594\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 2.8238e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1751 - val_accuracy: 0.9805 - val_f1_m: 0.9587\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 1.7575e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1768 - val_accuracy: 0.9806 - val_f1_m: 0.9587\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 1.2327e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1815 - val_accuracy: 0.9806 - val_f1_m: 0.9591\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 7.1324e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1839 - val_accuracy: 0.9806 - val_f1_m: 0.9592\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0028 - accuracy: 0.9995 - f1_m: 0.9483 - val_loss: 0.1356 - val_accuracy: 0.9853 - val_f1_m: 0.9567\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9480 - val_loss: 0.1519 - val_accuracy: 0.9857 - val_f1_m: 0.9555\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.0016 - accuracy: 0.9996 - f1_m: 0.9478 - val_loss: 0.1291 - val_accuracy: 0.9864 - val_f1_m: 0.9546\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0030 - accuracy: 0.9993 - f1_m: 0.9481 - val_loss: 0.1204 - val_accuracy: 0.9878 - val_f1_m: 0.9559\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0014 - accuracy: 0.9996 - f1_m: 0.9481 - val_loss: 0.1315 - val_accuracy: 0.9864 - val_f1_m: 0.9548\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0032 - accuracy: 0.9995 - f1_m: 0.9481 - val_loss: 0.1403 - val_accuracy: 0.9857 - val_f1_m: 0.9550\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9478 - val_loss: 0.1744 - val_accuracy: 0.9847 - val_f1_m: 0.9554\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0028 - accuracy: 0.9993 - f1_m: 0.9482 - val_loss: 0.1856 - val_accuracy: 0.9851 - val_f1_m: 0.9545\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9479 - val_loss: 0.1719 - val_accuracy: 0.9840 - val_f1_m: 0.9557\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.0062 - accuracy: 0.9991 - f1_m: 0.9481 - val_loss: 0.1534 - val_accuracy: 0.9846 - val_f1_m: 0.9574\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9482 - val_loss: 0.1447 - val_accuracy: 0.9886 - val_f1_m: 0.9542\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0064 - accuracy: 0.9990 - f1_m: 0.9485 - val_loss: 0.1277 - val_accuracy: 0.9885 - val_f1_m: 0.9536\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0036 - accuracy: 0.9992 - f1_m: 0.9483 - val_loss: 0.1570 - val_accuracy: 0.9877 - val_f1_m: 0.9553\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 0.0055 - accuracy: 0.9990 - f1_m: 0.9484 - val_loss: 0.1792 - val_accuracy: 0.9884 - val_f1_m: 0.9526\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_m: 0.9485 - val_loss: 0.1365 - val_accuracy: 0.9869 - val_f1_m: 0.9535\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0022 - accuracy: 0.9994 - f1_m: 0.9479 - val_loss: 0.1286 - val_accuracy: 0.9886 - val_f1_m: 0.9539\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0044 - accuracy: 0.9991 - f1_m: 0.9486 - val_loss: 0.1579 - val_accuracy: 0.9894 - val_f1_m: 0.9520\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0059 - accuracy: 0.9989 - f1_m: 0.9482 - val_loss: 0.2085 - val_accuracy: 0.9856 - val_f1_m: 0.9538\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "48000/48000 [==============================] - 9s 196us/sample - loss: 0.0127 - accuracy: 0.9969 - f1_m: 0.9519 - val_loss: 0.1294 - val_accuracy: 0.9832 - val_f1_m: 0.9625\n",
      "Epoch 2/9\n",
      "48000/48000 [==============================] - 8s 171us/sample - loss: 0.0134 - accuracy: 0.9969 - f1_m: 0.9519 - val_loss: 0.1939 - val_accuracy: 0.9837 - val_f1_m: 0.9574\n",
      "Epoch 3/9\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0088 - accuracy: 0.9980 - f1_m: 0.9515 - val_loss: 0.1334 - val_accuracy: 0.9849 - val_f1_m: 0.9611\n",
      "Epoch 4/9\n",
      "48000/48000 [==============================] - 10s 211us/sample - loss: 0.0090 - accuracy: 0.9979 - f1_m: 0.9510 - val_loss: 0.0845 - val_accuracy: 0.9862 - val_f1_m: 0.9597\n",
      "Epoch 5/9\n",
      "48000/48000 [==============================] - 9s 180us/sample - loss: 0.0103 - accuracy: 0.9972 - f1_m: 0.9521 - val_loss: 0.1206 - val_accuracy: 0.9841 - val_f1_m: 0.9582\n",
      "Epoch 6/9\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0146 - accuracy: 0.9969 - f1_m: 0.9512 - val_loss: 0.1130 - val_accuracy: 0.9859 - val_f1_m: 0.9598\n",
      "Epoch 7/9\n",
      "48000/48000 [==============================] - 9s 198us/sample - loss: 0.0065 - accuracy: 0.9981 - f1_m: 0.9506 - val_loss: 0.1049 - val_accuracy: 0.9855 - val_f1_m: 0.9601\n",
      "Epoch 8/9\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.0140 - accuracy: 0.9969 - f1_m: 0.9515 - val_loss: 0.1197 - val_accuracy: 0.9840 - val_f1_m: 0.9626\n",
      "Epoch 9/9\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.0105 - accuracy: 0.9974 - f1_m: 0.9513 - val_loss: 0.1211 - val_accuracy: 0.9836 - val_f1_m: 0.9688\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.0031 - accuracy: 0.9989 - f1_m: 0.9512 - val_loss: 0.2753 - val_accuracy: 0.9695 - val_f1_m: 0.9668\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.0020 - accuracy: 0.9994 - f1_m: 0.9501 - val_loss: 0.2821 - val_accuracy: 0.9674 - val_f1_m: 0.9694\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0023 - accuracy: 0.9994 - f1_m: 0.9503 - val_loss: 0.2632 - val_accuracy: 0.9710 - val_f1_m: 0.9657\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9495 - val_loss: 0.3056 - val_accuracy: 0.9692 - val_f1_m: 0.9654\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9515 - val_loss: 0.2588 - val_accuracy: 0.9716 - val_f1_m: 0.9655\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 2.4956e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2637 - val_accuracy: 0.9723 - val_f1_m: 0.9648\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0031 - accuracy: 0.9991 - f1_m: 0.9499 - val_loss: 0.3051 - val_accuracy: 0.9696 - val_f1_m: 0.9643\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0021 - accuracy: 0.9993 - f1_m: 0.9499 - val_loss: 0.3133 - val_accuracy: 0.9680 - val_f1_m: 0.9671\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0022 - accuracy: 0.9994 - f1_m: 0.9502 - val_loss: 0.2858 - val_accuracy: 0.9716 - val_f1_m: 0.9635\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 2.3144e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.2839 - val_accuracy: 0.9718 - val_f1_m: 0.9659\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_m: 0.9492 - val_loss: 0.2087 - val_accuracy: 0.9813 - val_f1_m: 0.9582\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0031 - accuracy: 0.9993 - f1_m: 0.9485 - val_loss: 0.2340 - val_accuracy: 0.9744 - val_f1_m: 0.9621\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0029 - accuracy: 0.9991 - f1_m: 0.9494 - val_loss: 0.1918 - val_accuracy: 0.9808 - val_f1_m: 0.9585\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.0033 - accuracy: 0.9989 - f1_m: 0.9496 - val_loss: 0.2275 - val_accuracy: 0.9769 - val_f1_m: 0.9612\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0013 - accuracy: 0.9995 - f1_m: 0.9488 - val_loss: 0.1866 - val_accuracy: 0.9816 - val_f1_m: 0.9579\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_m: 0.9488 - val_loss: 0.1933 - val_accuracy: 0.9803 - val_f1_m: 0.9572\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0022 - accuracy: 0.9992 - f1_m: 0.9494 - val_loss: 0.2017 - val_accuracy: 0.9813 - val_f1_m: 0.9574\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0040 - accuracy: 0.9988 - f1_m: 0.9496 - val_loss: 0.2082 - val_accuracy: 0.9818 - val_f1_m: 0.9576\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9487 - val_loss: 0.2040 - val_accuracy: 0.9810 - val_f1_m: 0.9591\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0026 - accuracy: 0.9991 - f1_m: 0.9496 - val_loss: 0.2118 - val_accuracy: 0.9824 - val_f1_m: 0.9600\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0045 - accuracy: 0.9987 - f1_m: 0.9492 - val_loss: 0.1337 - val_accuracy: 0.9859 - val_f1_m: 0.9587\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.0052 - accuracy: 0.9987 - f1_m: 0.9493 - val_loss: 0.1517 - val_accuracy: 0.9854 - val_f1_m: 0.9549\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 7s 137us/sample - loss: 0.0045 - accuracy: 0.9986 - f1_m: 0.9492 - val_loss: 0.1488 - val_accuracy: 0.9827 - val_f1_m: 0.9594\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 7s 138us/sample - loss: 0.0049 - accuracy: 0.9988 - f1_m: 0.9490 - val_loss: 0.1553 - val_accuracy: 0.9863 - val_f1_m: 0.9560\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9487 - val_loss: 0.1436 - val_accuracy: 0.9834 - val_f1_m: 0.9599\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0055 - accuracy: 0.9985 - f1_m: 0.9492 - val_loss: 0.1426 - val_accuracy: 0.9846 - val_f1_m: 0.9554\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0043 - accuracy: 0.9988 - f1_m: 0.9490 - val_loss: 0.1838 - val_accuracy: 0.9826 - val_f1_m: 0.9567\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0038 - accuracy: 0.9989 - f1_m: 0.9489 - val_loss: 0.1598 - val_accuracy: 0.9835 - val_f1_m: 0.9576\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0038 - accuracy: 0.9990 - f1_m: 0.9487 - val_loss: 0.1462 - val_accuracy: 0.9847 - val_f1_m: 0.9585\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0040 - accuracy: 0.9990 - f1_m: 0.9491 - val_loss: 0.1362 - val_accuracy: 0.9815 - val_f1_m: 0.9616\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 9s 198us/sample - loss: 0.0116 - accuracy: 0.9966 - f1_m: 0.9533 - val_loss: 0.0813 - val_accuracy: 0.9848 - val_f1_m: 0.9636\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0078 - accuracy: 0.9977 - f1_m: 0.9522 - val_loss: 0.0612 - val_accuracy: 0.9890 - val_f1_m: 0.9611\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.0116 - accuracy: 0.9965 - f1_m: 0.9533 - val_loss: 0.0940 - val_accuracy: 0.9845 - val_f1_m: 0.9648\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0104 - accuracy: 0.9967 - f1_m: 0.9529 - val_loss: 0.0692 - val_accuracy: 0.9879 - val_f1_m: 0.9656\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.0075 - accuracy: 0.9978 - f1_m: 0.9525 - val_loss: 0.0871 - val_accuracy: 0.9866 - val_f1_m: 0.9595\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.0103 - accuracy: 0.9969 - f1_m: 0.9533 - val_loss: 0.0927 - val_accuracy: 0.9840 - val_f1_m: 0.9659\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.0100 - accuracy: 0.9970 - f1_m: 0.9535 - val_loss: 0.1025 - val_accuracy: 0.9844 - val_f1_m: 0.9589\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.0082 - accuracy: 0.9970 - f1_m: 0.9522 - val_loss: 0.0878 - val_accuracy: 0.9850 - val_f1_m: 0.9611\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0112 - accuracy: 0.9968 - f1_m: 0.9528 - val_loss: 0.0655 - val_accuracy: 0.9884 - val_f1_m: 0.9598\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0104 - accuracy: 0.9973 - f1_m: 0.9525 - val_loss: 0.0806 - val_accuracy: 0.9854 - val_f1_m: 0.9666\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0011 - accuracy: 0.9996 - f1_m: 0.9482 - val_loss: 0.2063 - val_accuracy: 0.9786 - val_f1_m: 0.9578\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9484 - val_loss: 0.2272 - val_accuracy: 0.9741 - val_f1_m: 0.9602\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 7.7983e-04 - accuracy: 0.9998 - f1_m: 0.9481 - val_loss: 0.1925 - val_accuracy: 0.9790 - val_f1_m: 0.9578\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 7.6854e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1887 - val_accuracy: 0.9790 - val_f1_m: 0.9603\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 2.8303e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1899 - val_accuracy: 0.9786 - val_f1_m: 0.9605\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 1.7390e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1903 - val_accuracy: 0.9786 - val_f1_m: 0.9601\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 1.1705e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.1912 - val_accuracy: 0.9788 - val_f1_m: 0.9610\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 7.8239e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1937 - val_accuracy: 0.9785 - val_f1_m: 0.9602\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 4.8250e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1957 - val_accuracy: 0.9792 - val_f1_m: 0.9579\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 3.2049e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1981 - val_accuracy: 0.9791 - val_f1_m: 0.9585\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9478 - val_loss: 0.1904 - val_accuracy: 0.9854 - val_f1_m: 0.9514\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0022 - accuracy: 0.9995 - f1_m: 0.9478 - val_loss: 0.1812 - val_accuracy: 0.9873 - val_f1_m: 0.9521\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 2.2054e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1899 - val_accuracy: 0.9862 - val_f1_m: 0.9536\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0045 - accuracy: 0.9992 - f1_m: 0.9481 - val_loss: 0.1763 - val_accuracy: 0.9845 - val_f1_m: 0.9541\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 6.7511e-04 - accuracy: 0.9999 - f1_m: 0.9478 - val_loss: 0.1892 - val_accuracy: 0.9852 - val_f1_m: 0.9539\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0035 - accuracy: 0.9992 - f1_m: 0.9482 - val_loss: 0.1613 - val_accuracy: 0.9861 - val_f1_m: 0.9533\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0016 - accuracy: 0.9996 - f1_m: 0.9479 - val_loss: 0.1633 - val_accuracy: 0.9859 - val_f1_m: 0.9544\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9477 - val_loss: 0.1510 - val_accuracy: 0.9864 - val_f1_m: 0.9542\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0014 - accuracy: 0.9996 - f1_m: 0.9480 - val_loss: 0.1573 - val_accuracy: 0.9871 - val_f1_m: 0.9544\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9482 - val_loss: 0.1710 - val_accuracy: 0.9856 - val_f1_m: 0.9534\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 0.0033 - accuracy: 0.9995 - f1_m: 0.9479 - val_loss: 0.2138 - val_accuracy: 0.9876 - val_f1_m: 0.9541\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0066 - accuracy: 0.9987 - f1_m: 0.9484 - val_loss: 0.1990 - val_accuracy: 0.9897 - val_f1_m: 0.9523\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0036 - accuracy: 0.9992 - f1_m: 0.9481 - val_loss: 0.1930 - val_accuracy: 0.9875 - val_f1_m: 0.9532\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0035 - accuracy: 0.9994 - f1_m: 0.9479 - val_loss: 0.2349 - val_accuracy: 0.9863 - val_f1_m: 0.9518\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0072 - accuracy: 0.9990 - f1_m: 0.9482 - val_loss: 0.1584 - val_accuracy: 0.9895 - val_f1_m: 0.9542\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0055 - accuracy: 0.9991 - f1_m: 0.9479 - val_loss: 0.1962 - val_accuracy: 0.9872 - val_f1_m: 0.9527\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0042 - accuracy: 0.9994 - f1_m: 0.9478 - val_loss: 0.2248 - val_accuracy: 0.9881 - val_f1_m: 0.9534\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0067 - accuracy: 0.9987 - f1_m: 0.9485 - val_loss: 0.2206 - val_accuracy: 0.9892 - val_f1_m: 0.9533\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0036 - accuracy: 0.9994 - f1_m: 0.9477 - val_loss: 0.1918 - val_accuracy: 0.9878 - val_f1_m: 0.9534\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0044 - accuracy: 0.9992 - f1_m: 0.9480 - val_loss: 0.2125 - val_accuracy: 0.9857 - val_f1_m: 0.9528\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 9s 193us/sample - loss: 0.0119 - accuracy: 0.9972 - f1_m: 0.9513 - val_loss: 0.1261 - val_accuracy: 0.9840 - val_f1_m: 0.9598\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.0155 - accuracy: 0.9963 - f1_m: 0.9520 - val_loss: 0.1130 - val_accuracy: 0.9844 - val_f1_m: 0.9643\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 9s 179us/sample - loss: 0.0086 - accuracy: 0.9979 - f1_m: 0.9512 - val_loss: 0.1081 - val_accuracy: 0.9857 - val_f1_m: 0.9612\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.0107 - accuracy: 0.9975 - f1_m: 0.9508 - val_loss: 0.1420 - val_accuracy: 0.9830 - val_f1_m: 0.9605\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.0081 - accuracy: 0.9980 - f1_m: 0.9514 - val_loss: 0.1419 - val_accuracy: 0.9870 - val_f1_m: 0.9568\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.0100 - accuracy: 0.9975 - f1_m: 0.9510 - val_loss: 0.1412 - val_accuracy: 0.9858 - val_f1_m: 0.9569\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.0091 - accuracy: 0.9976 - f1_m: 0.9506 - val_loss: 0.1433 - val_accuracy: 0.9845 - val_f1_m: 0.9604\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 177us/sample - loss: 0.0100 - accuracy: 0.9976 - f1_m: 0.9509 - val_loss: 0.1302 - val_accuracy: 0.9867 - val_f1_m: 0.9571\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0135 - accuracy: 0.9970 - f1_m: 0.9513 - val_loss: 0.1118 - val_accuracy: 0.9850 - val_f1_m: 0.9594\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 9s 180us/sample - loss: 0.0091 - accuracy: 0.9976 - f1_m: 0.9511 - val_loss: 0.0971 - val_accuracy: 0.9834 - val_f1_m: 0.9643\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0019 - accuracy: 0.9994 - f1_m: 0.9495 - val_loss: 0.3169 - val_accuracy: 0.9674 - val_f1_m: 0.9652\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0029 - accuracy: 0.9991 - f1_m: 0.9503 - val_loss: 0.2926 - val_accuracy: 0.9693 - val_f1_m: 0.9630\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9500 - val_loss: 0.2953 - val_accuracy: 0.9682 - val_f1_m: 0.9671\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0035 - accuracy: 0.9989 - f1_m: 0.9509 - val_loss: 0.2774 - val_accuracy: 0.9693 - val_f1_m: 0.9644\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 2.9629e-04 - accuracy: 1.0000 - f1_m: 0.9480 - val_loss: 0.2744 - val_accuracy: 0.9699 - val_f1_m: 0.9654\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 1.0915e-04 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2809 - val_accuracy: 0.9706 - val_f1_m: 0.9641\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0058 - accuracy: 0.9981 - f1_m: 0.9516 - val_loss: 0.2939 - val_accuracy: 0.9697 - val_f1_m: 0.9643\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 6.4287e-04 - accuracy: 0.9999 - f1_m: 0.9486 - val_loss: 0.2896 - val_accuracy: 0.9704 - val_f1_m: 0.9656\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 2.7947e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2868 - val_accuracy: 0.9714 - val_f1_m: 0.9624\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0054 - accuracy: 0.9982 - f1_m: 0.9521 - val_loss: 0.2948 - val_accuracy: 0.9697 - val_f1_m: 0.9654\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9490 - val_loss: 0.3045 - val_accuracy: 0.9695 - val_f1_m: 0.9625\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0023 - accuracy: 0.9993 - f1_m: 0.9490 - val_loss: 0.2532 - val_accuracy: 0.9788 - val_f1_m: 0.9586\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.0020 - accuracy: 0.9995 - f1_m: 0.9490 - val_loss: 0.2175 - val_accuracy: 0.9789 - val_f1_m: 0.9588\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.0028 - accuracy: 0.9989 - f1_m: 0.9493 - val_loss: 0.2372 - val_accuracy: 0.9766 - val_f1_m: 0.9576\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_m: 0.9486 - val_loss: 0.2300 - val_accuracy: 0.9788 - val_f1_m: 0.9590\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0038 - accuracy: 0.9989 - f1_m: 0.9496 - val_loss: 0.2119 - val_accuracy: 0.9807 - val_f1_m: 0.9587\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 8.2140e-04 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.2074 - val_accuracy: 0.9807 - val_f1_m: 0.9594\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.0037 - accuracy: 0.9990 - f1_m: 0.9491 - val_loss: 0.2141 - val_accuracy: 0.9801 - val_f1_m: 0.9576\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 3.9538e-04 - accuracy: 0.9998 - f1_m: 0.9478 - val_loss: 0.2335 - val_accuracy: 0.9799 - val_f1_m: 0.9590\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.0042 - accuracy: 0.9986 - f1_m: 0.9497 - val_loss: 0.2213 - val_accuracy: 0.9799 - val_f1_m: 0.9578\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 8.0786e-04 - accuracy: 0.9997 - f1_m: 0.9481 - val_loss: 0.2274 - val_accuracy: 0.9826 - val_f1_m: 0.9574\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0038 - accuracy: 0.9992 - f1_m: 0.9489 - val_loss: 0.2281 - val_accuracy: 0.9806 - val_f1_m: 0.9586\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 0.0059 - accuracy: 0.9986 - f1_m: 0.9493 - val_loss: 0.1436 - val_accuracy: 0.9837 - val_f1_m: 0.9580\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0049 - accuracy: 0.9986 - f1_m: 0.9495 - val_loss: 0.1593 - val_accuracy: 0.9846 - val_f1_m: 0.9560\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0048 - accuracy: 0.9986 - f1_m: 0.9490 - val_loss: 0.1661 - val_accuracy: 0.9843 - val_f1_m: 0.9556\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0031 - accuracy: 0.9990 - f1_m: 0.9490 - val_loss: 0.1955 - val_accuracy: 0.9839 - val_f1_m: 0.9556\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0051 - accuracy: 0.9987 - f1_m: 0.9492 - val_loss: 0.1705 - val_accuracy: 0.9844 - val_f1_m: 0.9568\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.0057 - accuracy: 0.9986 - f1_m: 0.9489 - val_loss: 0.1698 - val_accuracy: 0.9853 - val_f1_m: 0.9555\n",
      "Epoch 7/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0066 - accuracy: 0.9985 - f1_m: 0.9492 - val_loss: 0.1449 - val_accuracy: 0.9859 - val_f1_m: 0.9587\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 9.0201e-04 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.1727 - val_accuracy: 0.9851 - val_f1_m: 0.9561\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0057 - accuracy: 0.9985 - f1_m: 0.9492 - val_loss: 0.1461 - val_accuracy: 0.9857 - val_f1_m: 0.9555\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0039 - accuracy: 0.9987 - f1_m: 0.9491 - val_loss: 0.1921 - val_accuracy: 0.9834 - val_f1_m: 0.9559\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0059 - accuracy: 0.9985 - f1_m: 0.9491 - val_loss: 0.1847 - val_accuracy: 0.9827 - val_f1_m: 0.9569\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 9s 182us/sample - loss: 0.0099 - accuracy: 0.9970 - f1_m: 0.9528 - val_loss: 0.0913 - val_accuracy: 0.9879 - val_f1_m: 0.9581\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.0087 - accuracy: 0.9971 - f1_m: 0.9522 - val_loss: 0.0912 - val_accuracy: 0.9834 - val_f1_m: 0.9622\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.0089 - accuracy: 0.9975 - f1_m: 0.9521 - val_loss: 0.0846 - val_accuracy: 0.9840 - val_f1_m: 0.9644\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.0077 - accuracy: 0.9976 - f1_m: 0.9524 - val_loss: 0.1036 - val_accuracy: 0.9846 - val_f1_m: 0.9592\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.0092 - accuracy: 0.9973 - f1_m: 0.9521 - val_loss: 0.0765 - val_accuracy: 0.9847 - val_f1_m: 0.9638\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0097 - accuracy: 0.9969 - f1_m: 0.9532 - val_loss: 0.0898 - val_accuracy: 0.9845 - val_f1_m: 0.9631\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0067 - accuracy: 0.9979 - f1_m: 0.9514 - val_loss: 0.1107 - val_accuracy: 0.9813 - val_f1_m: 0.9618\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.0102 - accuracy: 0.9970 - f1_m: 0.9531 - val_loss: 0.0890 - val_accuracy: 0.9869 - val_f1_m: 0.9586\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 8s 168us/sample - loss: 0.0109 - accuracy: 0.9966 - f1_m: 0.9532 - val_loss: 0.0839 - val_accuracy: 0.9863 - val_f1_m: 0.9629\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.0099 - accuracy: 0.9970 - f1_m: 0.9526 - val_loss: 0.0884 - val_accuracy: 0.9857 - val_f1_m: 0.9635\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.0086 - accuracy: 0.9977 - f1_m: 0.9517 - val_loss: 0.0873 - val_accuracy: 0.9862 - val_f1_m: 0.9617\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 6.9523e-04 - accuracy: 0.9998 - f1_m: 0.9479 - val_loss: 0.2343 - val_accuracy: 0.9783 - val_f1_m: 0.9581\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0012 - accuracy: 0.9996 - f1_m: 0.9483 - val_loss: 0.2289 - val_accuracy: 0.9778 - val_f1_m: 0.9575\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0017 - accuracy: 0.9994 - f1_m: 0.9482 - val_loss: 0.2214 - val_accuracy: 0.9804 - val_f1_m: 0.9573\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 1.6479e-04 - accuracy: 0.9999 - f1_m: 0.9476 - val_loss: 0.2158 - val_accuracy: 0.9799 - val_f1_m: 0.9597\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 1.9652e-05 - accuracy: 1.0000 - f1_m: 0.9475 - val_loss: 0.2147 - val_accuracy: 0.9806 - val_f1_m: 0.9577\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 8.2776e-04 - accuracy: 0.9998 - f1_m: 0.9477 - val_loss: 0.2836 - val_accuracy: 0.9711 - val_f1_m: 0.9626\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0025 - accuracy: 0.9993 - f1_m: 0.9486 - val_loss: 0.2525 - val_accuracy: 0.9756 - val_f1_m: 0.9619\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 4.1378e-04 - accuracy: 0.9999 - f1_m: 0.9479 - val_loss: 0.2279 - val_accuracy: 0.9790 - val_f1_m: 0.9588\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 3.1562e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2201 - val_accuracy: 0.9797 - val_f1_m: 0.9587\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0016 - accuracy: 0.9996 - f1_m: 0.9480 - val_loss: 0.2201 - val_accuracy: 0.9776 - val_f1_m: 0.9589\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 7.3004e-04 - accuracy: 0.9997 - f1_m: 0.9482 - val_loss: 0.2346 - val_accuracy: 0.9775 - val_f1_m: 0.9570\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.0013 - accuracy: 0.9997 - f1_m: 0.9477 - val_loss: 0.2051 - val_accuracy: 0.9859 - val_f1_m: 0.9538\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0029 - accuracy: 0.9993 - f1_m: 0.9480 - val_loss: 0.1930 - val_accuracy: 0.9853 - val_f1_m: 0.9536\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0011 - accuracy: 0.9998 - f1_m: 0.9477 - val_loss: 0.1582 - val_accuracy: 0.9858 - val_f1_m: 0.9545\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 2.3759e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.1686 - val_accuracy: 0.9870 - val_f1_m: 0.9534\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0066 - accuracy: 0.9990 - f1_m: 0.9482 - val_loss: 0.1630 - val_accuracy: 0.9862 - val_f1_m: 0.9537\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 9.4072e-04 - accuracy: 0.9998 - f1_m: 0.9478 - val_loss: 0.1678 - val_accuracy: 0.9858 - val_f1_m: 0.9540\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9477 - val_loss: 0.1759 - val_accuracy: 0.9861 - val_f1_m: 0.9542\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 1.8992e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.1886 - val_accuracy: 0.9864 - val_f1_m: 0.9528\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0016 - accuracy: 0.9996 - f1_m: 0.9478 - val_loss: 0.2349 - val_accuracy: 0.9837 - val_f1_m: 0.9554\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0027 - accuracy: 0.9994 - f1_m: 0.9481 - val_loss: 0.1703 - val_accuracy: 0.9877 - val_f1_m: 0.9535\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0018 - accuracy: 0.9996 - f1_m: 0.9477 - val_loss: 0.1988 - val_accuracy: 0.9849 - val_f1_m: 0.9540\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.0060 - accuracy: 0.9991 - f1_m: 0.9480 - val_loss: 0.2808 - val_accuracy: 0.9851 - val_f1_m: 0.9523\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0060 - accuracy: 0.9990 - f1_m: 0.9481 - val_loss: 0.2752 - val_accuracy: 0.9857 - val_f1_m: 0.9510\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0055 - accuracy: 0.9991 - f1_m: 0.9481 - val_loss: 0.2270 - val_accuracy: 0.9850 - val_f1_m: 0.9526\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0054 - accuracy: 0.9990 - f1_m: 0.9479 - val_loss: 0.1671 - val_accuracy: 0.9862 - val_f1_m: 0.9539\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0035 - accuracy: 0.9995 - f1_m: 0.9481 - val_loss: 0.2221 - val_accuracy: 0.9876 - val_f1_m: 0.9529\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0054 - accuracy: 0.9992 - f1_m: 0.9481 - val_loss: 0.2507 - val_accuracy: 0.9840 - val_f1_m: 0.9533\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0063 - accuracy: 0.9990 - f1_m: 0.9482 - val_loss: 0.2440 - val_accuracy: 0.9872 - val_f1_m: 0.9521\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0034 - accuracy: 0.9995 - f1_m: 0.9479 - val_loss: 0.2473 - val_accuracy: 0.9863 - val_f1_m: 0.9536\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0049 - accuracy: 0.9992 - f1_m: 0.9481 - val_loss: 0.2198 - val_accuracy: 0.9877 - val_f1_m: 0.9529\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0065 - accuracy: 0.9989 - f1_m: 0.9480 - val_loss: 0.2345 - val_accuracy: 0.9875 - val_f1_m: 0.9536\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0018 - accuracy: 0.9996 - f1_m: 0.9475 - val_loss: 0.2154 - val_accuracy: 0.9884 - val_f1_m: 0.9513\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 9s 192us/sample - loss: 0.0119 - accuracy: 0.9975 - f1_m: 0.9511 - val_loss: 0.1523 - val_accuracy: 0.9831 - val_f1_m: 0.9603\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0128 - accuracy: 0.9971 - f1_m: 0.9518 - val_loss: 0.1824 - val_accuracy: 0.9826 - val_f1_m: 0.9605\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0094 - accuracy: 0.9978 - f1_m: 0.9508 - val_loss: 0.1329 - val_accuracy: 0.9859 - val_f1_m: 0.9601\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0128 - accuracy: 0.9970 - f1_m: 0.9517 - val_loss: 0.1304 - val_accuracy: 0.9825 - val_f1_m: 0.9652\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.0116 - accuracy: 0.9972 - f1_m: 0.9516 - val_loss: 0.1889 - val_accuracy: 0.9835 - val_f1_m: 0.9566\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0105 - accuracy: 0.9976 - f1_m: 0.9511 - val_loss: 0.1320 - val_accuracy: 0.9847 - val_f1_m: 0.9613\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.0066 - accuracy: 0.9983 - f1_m: 0.9505 - val_loss: 0.1444 - val_accuracy: 0.9859 - val_f1_m: 0.9536\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.0149 - accuracy: 0.9969 - f1_m: 0.9521 - val_loss: 0.1762 - val_accuracy: 0.9815 - val_f1_m: 0.9592\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.0161 - accuracy: 0.9968 - f1_m: 0.9515 - val_loss: 0.1388 - val_accuracy: 0.9835 - val_f1_m: 0.9601\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0086 - accuracy: 0.9983 - f1_m: 0.9503 - val_loss: 0.1759 - val_accuracy: 0.9808 - val_f1_m: 0.9581\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0114 - accuracy: 0.9974 - f1_m: 0.9514 - val_loss: 0.1322 - val_accuracy: 0.9833 - val_f1_m: 0.9689\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0032 - accuracy: 0.9989 - f1_m: 0.9500 - val_loss: 0.2977 - val_accuracy: 0.9712 - val_f1_m: 0.9650\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9484 - val_loss: 0.3053 - val_accuracy: 0.9705 - val_f1_m: 0.9636\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.0030 - accuracy: 0.9989 - f1_m: 0.9505 - val_loss: 0.3012 - val_accuracy: 0.9700 - val_f1_m: 0.9629\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 2.2450e-04 - accuracy: 1.0000 - f1_m: 0.9477 - val_loss: 0.2935 - val_accuracy: 0.9700 - val_f1_m: 0.9642\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 6.5613e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2957 - val_accuracy: 0.9703 - val_f1_m: 0.9630\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 4.9551e-05 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.3044 - val_accuracy: 0.9709 - val_f1_m: 0.9620\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.0051 - accuracy: 0.9984 - f1_m: 0.9514 - val_loss: 0.3389 - val_accuracy: 0.9687 - val_f1_m: 0.9627\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 0.0019 - accuracy: 0.9993 - f1_m: 0.9495 - val_loss: 0.3002 - val_accuracy: 0.9688 - val_f1_m: 0.9642\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 1.8151e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.3125 - val_accuracy: 0.9684 - val_f1_m: 0.9637\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0036 - accuracy: 0.9987 - f1_m: 0.9504 - val_loss: 0.3163 - val_accuracy: 0.9700 - val_f1_m: 0.9633\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 6.1121e-04 - accuracy: 0.9998 - f1_m: 0.9483 - val_loss: 0.3083 - val_accuracy: 0.9697 - val_f1_m: 0.9641\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 1.7726e-04 - accuracy: 1.0000 - f1_m: 0.9478 - val_loss: 0.3103 - val_accuracy: 0.9715 - val_f1_m: 0.9650\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.0022 - accuracy: 0.9993 - f1_m: 0.9489 - val_loss: 0.2402 - val_accuracy: 0.9789 - val_f1_m: 0.9582\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0037 - accuracy: 0.9989 - f1_m: 0.9493 - val_loss: 0.2407 - val_accuracy: 0.9810 - val_f1_m: 0.9571\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0012 - accuracy: 0.9997 - f1_m: 0.9484 - val_loss: 0.2275 - val_accuracy: 0.9817 - val_f1_m: 0.9569\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 1.0545e-04 - accuracy: 1.0000 - f1_m: 0.9476 - val_loss: 0.2188 - val_accuracy: 0.9828 - val_f1_m: 0.9561\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0052 - accuracy: 0.9988 - f1_m: 0.9492 - val_loss: 0.2318 - val_accuracy: 0.9817 - val_f1_m: 0.9578\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 6.0254e-04 - accuracy: 0.9999 - f1_m: 0.9480 - val_loss: 0.2313 - val_accuracy: 0.9815 - val_f1_m: 0.9563\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0026 - accuracy: 0.9992 - f1_m: 0.9488 - val_loss: 0.2339 - val_accuracy: 0.9808 - val_f1_m: 0.9584\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0038 - accuracy: 0.9991 - f1_m: 0.9490 - val_loss: 0.2006 - val_accuracy: 0.9816 - val_f1_m: 0.9579\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9484 - val_loss: 0.2280 - val_accuracy: 0.9809 - val_f1_m: 0.9569\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0028 - accuracy: 0.9992 - f1_m: 0.9486 - val_loss: 0.2152 - val_accuracy: 0.9804 - val_f1_m: 0.9580\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_m: 0.9485 - val_loss: 0.2124 - val_accuracy: 0.9832 - val_f1_m: 0.9565\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0024 - accuracy: 0.9992 - f1_m: 0.9486 - val_loss: 0.2671 - val_accuracy: 0.9801 - val_f1_m: 0.9558\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 0.0050 - accuracy: 0.9989 - f1_m: 0.9486 - val_loss: 0.1811 - val_accuracy: 0.9840 - val_f1_m: 0.9552\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0066 - accuracy: 0.9985 - f1_m: 0.9488 - val_loss: 0.1488 - val_accuracy: 0.9849 - val_f1_m: 0.9561\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0047 - accuracy: 0.9990 - f1_m: 0.9487 - val_loss: 0.1776 - val_accuracy: 0.9830 - val_f1_m: 0.9549\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.0024 - accuracy: 0.9993 - f1_m: 0.9486 - val_loss: 0.1593 - val_accuracy: 0.9841 - val_f1_m: 0.9564\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0060 - accuracy: 0.9987 - f1_m: 0.9487 - val_loss: 0.1212 - val_accuracy: 0.9857 - val_f1_m: 0.9580\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0041 - accuracy: 0.9990 - f1_m: 0.9487 - val_loss: 0.1357 - val_accuracy: 0.9876 - val_f1_m: 0.9547\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0038 - accuracy: 0.9989 - f1_m: 0.9491 - val_loss: 0.1672 - val_accuracy: 0.9865 - val_f1_m: 0.9572\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0035 - accuracy: 0.9992 - f1_m: 0.9488 - val_loss: 0.1891 - val_accuracy: 0.9836 - val_f1_m: 0.9544\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.0048 - accuracy: 0.9987 - f1_m: 0.9490 - val_loss: 0.1734 - val_accuracy: 0.9862 - val_f1_m: 0.9571\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0056 - accuracy: 0.9987 - f1_m: 0.9492 - val_loss: 0.1760 - val_accuracy: 0.9864 - val_f1_m: 0.9554\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0042 - accuracy: 0.9990 - f1_m: 0.9486 - val_loss: 0.1901 - val_accuracy: 0.9845 - val_f1_m: 0.9556\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.0036 - accuracy: 0.9991 - f1_m: 0.9485 - val_loss: 0.1678 - val_accuracy: 0.9849 - val_f1_m: 0.9553\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 9s 179us/sample - loss: 0.0089 - accuracy: 0.9976 - f1_m: 0.9522 - val_loss: 0.0944 - val_accuracy: 0.9842 - val_f1_m: 0.9649\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0071 - accuracy: 0.9978 - f1_m: 0.9516 - val_loss: 0.0932 - val_accuracy: 0.9859 - val_f1_m: 0.9598\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0081 - accuracy: 0.9980 - f1_m: 0.9519 - val_loss: 0.0966 - val_accuracy: 0.9851 - val_f1_m: 0.9610\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0108 - accuracy: 0.9967 - f1_m: 0.9534 - val_loss: 0.0862 - val_accuracy: 0.9852 - val_f1_m: 0.9633\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0097 - accuracy: 0.9970 - f1_m: 0.9530 - val_loss: 0.0673 - val_accuracy: 0.9871 - val_f1_m: 0.9612\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.0085 - accuracy: 0.9974 - f1_m: 0.9517 - val_loss: 0.0742 - val_accuracy: 0.9871 - val_f1_m: 0.9605\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0070 - accuracy: 0.9979 - f1_m: 0.9518 - val_loss: 0.0758 - val_accuracy: 0.9883 - val_f1_m: 0.9597\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 8s 160us/sample - loss: 0.0109 - accuracy: 0.9968 - f1_m: 0.9528 - val_loss: 0.0954 - val_accuracy: 0.9868 - val_f1_m: 0.9607\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 8s 161us/sample - loss: 0.0072 - accuracy: 0.9979 - f1_m: 0.9509 - val_loss: 0.0705 - val_accuracy: 0.9849 - val_f1_m: 0.9633\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.0110 - accuracy: 0.9968 - f1_m: 0.9530 - val_loss: 0.0976 - val_accuracy: 0.9859 - val_f1_m: 0.9638\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0098 - accuracy: 0.9971 - f1_m: 0.9517 - val_loss: 0.1124 - val_accuracy: 0.9813 - val_f1_m: 0.9613\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 8s 159us/sample - loss: 0.0082 - accuracy: 0.9974 - f1_m: 0.9523 - val_loss: 0.0901 - val_accuracy: 0.9852 - val_f1_m: 0.9575\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0016 - accuracy: 0.9996 - f1_m: 0.9480 - val_loss: 0.2525 - val_accuracy: 0.9779 - val_f1_m: 0.9580\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 7.8187e-04 - accuracy: 0.9998 - f1_m: 0.9480 - val_loss: 0.2254 - val_accuracy: 0.9795 - val_f1_m: 0.9571\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9479 - val_loss: 0.2224 - val_accuracy: 0.9790 - val_f1_m: 0.9593\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 8.6684e-04 - accuracy: 0.9996 - f1_m: 0.9481 - val_loss: 0.2537 - val_accuracy: 0.9777 - val_f1_m: 0.9557\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0012 - accuracy: 0.9995 - f1_m: 0.9483 - val_loss: 0.2256 - val_accuracy: 0.9780 - val_f1_m: 0.9564\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 2.5144e-04 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 0.2217 - val_accuracy: 0.9801 - val_f1_m: 0.9576\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 4.9326e-06 - accuracy: 1.0000 - f1_m: 0.9473 - val_loss: 0.2186 - val_accuracy: 0.9802 - val_f1_m: 0.9574\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 1.6757e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2185 - val_accuracy: 0.9798 - val_f1_m: 0.9571\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 1.1337e-06 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2180 - val_accuracy: 0.9804 - val_f1_m: 0.9570\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 7.5925e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2189 - val_accuracy: 0.9807 - val_f1_m: 0.9571\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 4.6446e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2194 - val_accuracy: 0.9807 - val_f1_m: 0.9565\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 2.8839e-07 - accuracy: 1.0000 - f1_m: 0.9474 - val_loss: 0.2210 - val_accuracy: 0.9809 - val_f1_m: 0.9565\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0017 - accuracy: 0.9997 - f1_m: 0.9477 - val_loss: 0.1945 - val_accuracy: 0.9856 - val_f1_m: 0.9526\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0032 - accuracy: 0.9994 - f1_m: 0.9480 - val_loss: 0.1916 - val_accuracy: 0.9867 - val_f1_m: 0.9521\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 2.3543e-04 - accuracy: 0.9999 - f1_m: 0.9476 - val_loss: 0.1838 - val_accuracy: 0.9869 - val_f1_m: 0.9523\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0012 - accuracy: 0.9998 - f1_m: 0.9477 - val_loss: 0.1876 - val_accuracy: 0.9867 - val_f1_m: 0.9529\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0026 - accuracy: 0.9996 - f1_m: 0.9477 - val_loss: 0.2098 - val_accuracy: 0.9867 - val_f1_m: 0.9538\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0012 - accuracy: 0.9997 - f1_m: 0.9478 - val_loss: 0.2316 - val_accuracy: 0.9854 - val_f1_m: 0.9528\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0019 - accuracy: 0.9996 - f1_m: 0.9478 - val_loss: 0.2093 - val_accuracy: 0.9864 - val_f1_m: 0.9525\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 9.6055e-04 - accuracy: 0.9997 - f1_m: 0.9478 - val_loss: 0.2300 - val_accuracy: 0.9856 - val_f1_m: 0.9521\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 4.6757e-04 - accuracy: 0.9999 - f1_m: 0.9475 - val_loss: 0.2267 - val_accuracy: 0.9870 - val_f1_m: 0.9529\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0027 - accuracy: 0.9995 - f1_m: 0.9479 - val_loss: 0.2171 - val_accuracy: 0.9850 - val_f1_m: 0.9537\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0020 - accuracy: 0.9997 - f1_m: 0.9476 - val_loss: 0.2542 - val_accuracy: 0.9854 - val_f1_m: 0.9523\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 5.4593e-04 - accuracy: 0.9999 - f1_m: 0.9477 - val_loss: 0.2405 - val_accuracy: 0.9863 - val_f1_m: 0.9522\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 7s 143us/sample - loss: 0.0036 - accuracy: 0.9992 - f1_m: 0.9481 - val_loss: 0.2275 - val_accuracy: 0.9899 - val_f1_m: 0.9514\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.0032 - accuracy: 0.9995 - f1_m: 0.9477 - val_loss: 0.2327 - val_accuracy: 0.9875 - val_f1_m: 0.9525\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.0078 - accuracy: 0.9991 - f1_m: 0.9477 - val_loss: 0.2407 - val_accuracy: 0.9865 - val_f1_m: 0.9520\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0078 - accuracy: 0.9991 - f1_m: 0.9479 - val_loss: 0.2271 - val_accuracy: 0.9872 - val_f1_m: 0.9519\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 0.0038 - accuracy: 0.9993 - f1_m: 0.9482 - val_loss: 0.2670 - val_accuracy: 0.9879 - val_f1_m: 0.9521\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 0.0030 - accuracy: 0.9996 - f1_m: 0.9477 - val_loss: 0.2159 - val_accuracy: 0.9848 - val_f1_m: 0.9542\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.0052 - accuracy: 0.9991 - f1_m: 0.9482 - val_loss: 0.1673 - val_accuracy: 0.9881 - val_f1_m: 0.9534\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0049 - accuracy: 0.9990 - f1_m: 0.9480 - val_loss: 0.2307 - val_accuracy: 0.9882 - val_f1_m: 0.9520\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0048 - accuracy: 0.9992 - f1_m: 0.9479 - val_loss: 0.2152 - val_accuracy: 0.9875 - val_f1_m: 0.9528\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_m: 0.9479 - val_loss: 0.2932 - val_accuracy: 0.9859 - val_f1_m: 0.9530\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0093 - accuracy: 0.9989 - f1_m: 0.9481 - val_loss: 0.2252 - val_accuracy: 0.9874 - val_f1_m: 0.9509\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0044 - accuracy: 0.9995 - f1_m: 0.9479 - val_loss: 0.1733 - val_accuracy: 0.9875 - val_f1_m: 0.9527\n",
      "Train on 48000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 9s 196us/sample - loss: 0.0090 - accuracy: 0.9979 - f1_m: 0.9512 - val_loss: 0.1524 - val_accuracy: 0.9825 - val_f1_m: 0.9612\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.0160 - accuracy: 0.9965 - f1_m: 0.9531 - val_loss: 0.1257 - val_accuracy: 0.9858 - val_f1_m: 0.9645\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0080 - accuracy: 0.9980 - f1_m: 0.9507 - val_loss: 0.1094 - val_accuracy: 0.9867 - val_f1_m: 0.9581\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0143 - accuracy: 0.9966 - f1_m: 0.9517 - val_loss: 0.1428 - val_accuracy: 0.9865 - val_f1_m: 0.9570\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0119 - accuracy: 0.9974 - f1_m: 0.9505 - val_loss: 0.1478 - val_accuracy: 0.9846 - val_f1_m: 0.9592\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0150 - accuracy: 0.9967 - f1_m: 0.9519 - val_loss: 0.1406 - val_accuracy: 0.9832 - val_f1_m: 0.9632\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0099 - accuracy: 0.9974 - f1_m: 0.9516 - val_loss: 0.1486 - val_accuracy: 0.9861 - val_f1_m: 0.9573\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 8s 177us/sample - loss: 0.0149 - accuracy: 0.9964 - f1_m: 0.9520 - val_loss: 0.1358 - val_accuracy: 0.9850 - val_f1_m: 0.9589\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.0088 - accuracy: 0.9978 - f1_m: 0.9511 - val_loss: 0.1231 - val_accuracy: 0.9855 - val_f1_m: 0.9603\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.0085 - accuracy: 0.9978 - f1_m: 0.9511 - val_loss: 0.1668 - val_accuracy: 0.9839 - val_f1_m: 0.9611\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 8s 171us/sample - loss: 0.0134 - accuracy: 0.9970 - f1_m: 0.9522 - val_loss: 0.1161 - val_accuracy: 0.9849 - val_f1_m: 0.9601\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 8s 172us/sample - loss: 0.0089 - accuracy: 0.9977 - f1_m: 0.9506 - val_loss: 0.2185 - val_accuracy: 0.9843 - val_f1_m: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN 1 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.295529e-01</td>\n",
       "      <td>0.981625</td>\n",
       "      <td>0.965081</td>\n",
       "      <td>0.241234</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.977447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN 2 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.697066e-02</td>\n",
       "      <td>0.988479</td>\n",
       "      <td>0.959567</td>\n",
       "      <td>0.115441</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.973423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN 5 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.861985e-02</td>\n",
       "      <td>0.991354</td>\n",
       "      <td>0.963869</td>\n",
       "      <td>0.060402</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.981332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.696564e-02</td>\n",
       "      <td>0.991271</td>\n",
       "      <td>0.965156</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.982180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.984055e-02</td>\n",
       "      <td>0.986958</td>\n",
       "      <td>0.961433</td>\n",
       "      <td>0.122633</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.979105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>CNN 10 S</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>8.170074e-03</td>\n",
       "      <td>0.997375</td>\n",
       "      <td>0.952287</td>\n",
       "      <td>0.090072</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.957454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CNN 1 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>2.883923e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947438</td>\n",
       "      <td>0.220995</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.956510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CNN 2 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>5.459276e-04</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.947679</td>\n",
       "      <td>0.240479</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.952213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CNN 5 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>4.425797e-03</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.947895</td>\n",
       "      <td>0.173264</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.952734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CNN 10 L</td>\n",
       "      <td>48000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12</td>\n",
       "      <td>8.889140e-03</td>\n",
       "      <td>0.997708</td>\n",
       "      <td>0.950554</td>\n",
       "      <td>0.218536</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.954507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  train_samples  test_samples  epochs          loss  accuracy  \\\n",
       "0    CNN 1 S          48000         12000       1  1.295529e-01  0.981625   \n",
       "1    CNN 2 S          48000         12000       1  6.697066e-02  0.988479   \n",
       "2    CNN 5 S          48000         12000       1  3.861985e-02  0.991354   \n",
       "3   CNN 10 S          48000         12000       1  3.696564e-02  0.991271   \n",
       "4    CNN 1 L          48000         12000       1  7.984055e-02  0.986958   \n",
       "..       ...            ...           ...     ...           ...       ...   \n",
       "91  CNN 10 S          48000         12000      12  8.170074e-03  0.997375   \n",
       "92   CNN 1 L          48000         12000      12  2.883923e-07  1.000000   \n",
       "93   CNN 2 L          48000         12000      12  5.459276e-04  0.999896   \n",
       "94   CNN 5 L          48000         12000      12  4.425797e-03  0.999521   \n",
       "95  CNN 10 L          48000         12000      12  8.889140e-03  0.997708   \n",
       "\n",
       "          f1  val_loss  val_accuracy    val_f1  \n",
       "0   0.965081  0.241234        0.9660  0.977447  \n",
       "1   0.959567  0.115441        0.9785  0.973423  \n",
       "2   0.963869  0.060402        0.9823  0.981332  \n",
       "3   0.965156  0.059290        0.9841  0.982180  \n",
       "4   0.961433  0.122633        0.9734  0.979105  \n",
       "..       ...       ...           ...       ...  \n",
       "91  0.952287  0.090072        0.9852  0.957454  \n",
       "92  0.947438  0.220995        0.9809  0.956510  \n",
       "93  0.947679  0.240479        0.9863  0.952213  \n",
       "94  0.947895  0.173264        0.9875  0.952734  \n",
       "95  0.950554  0.218536        0.9843  0.954507  \n",
       "\n",
       "[96 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_3b_cnn():\n",
    "    total_samples = 60000\n",
    "    epochses = range(1, 13)\n",
    "    ratio = 0.8\n",
    "    \n",
    "#     total_samples = 2000\n",
    "#     epochses = [1, 2]\n",
    "#     ratio = 0.8\n",
    "    \n",
    "    train_samples, test_samples = calc_train_test_samples(total_samples, ratio)\n",
    "    \n",
    "    for epochs in epochses:        \n",
    "        for name, layers in cnns.items():   \n",
    "            loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm = evaluate_cnn(layers, train_samples, test_samples, epochs)\n",
    "            \n",
    "            yield name, train_samples, test_samples, epochs, loss, accuracy, f1, val_loss, val_accuracy, val_f1\n",
    "            \n",
    "            codename = name.lower().replace(' ', '_')            \n",
    "            roc.savefig(f'plots/3b/{codename}_e{epochs}_roc.svg')\n",
    "            pr.savefig(f'plots/3b/{codename}_e{epochs}_pr.svg')\n",
    "            cm.savefig(f'plots/3b/{codename}_e{epochs}_cm.svg')            \n",
    "            plt.close('all')\n",
    "            \n",
    "results_3b_cnn = pd.DataFrame(gen_3b_cnn(), columns=[    \n",
    "    'model',\n",
    "    'train_samples', 'test_samples', 'epochs',\n",
    "    'loss', 'accuracy', 'f1', 'val_loss', 'val_accuracy', 'val_f1'\n",
    "])\n",
    "results_3b_cnn.to_csv('results/3b_cnn.csv')\n",
    "results_3b_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x245c85d0f88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAFgCAYAAAAFPlYaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAACZSUlEQVR4nOz9eZgcZ32vjd9PLb13z/Tso9Ey2jdL1urdkmwLJ+CQ2D4kLG8gxr8kYIcQchKfEMIh5PqFHJ8kZCEQEjiO4c0JMRCwEyAQI2Pwrl1eZe2Stcy+9t5V9TzvH9Xd0z1rj2ZGluW6r0vXaKqrq57u6a5PfXehlFJ4eHh4eHhcxmhv9gI8PDw8PDymwhMrDw8PD4/LHk+sPDw8PDwuezyx8vDw8PC47PHEysPDw8Pjssd4sxcwl1y4cGHMtrq6Ovr7+9+E1Xjr8NbhreNKXse8efMu8WreXrztLCtNuzxesreOSrx1VOKtoxJvHR7eO+/h4eHhcdnjiZWHh4eHx2WPJ1YeHh4eHpc9nlh5eHh4eFz2eGLl4eHh4XHZ44mVh4eHh8dljydWHh4eHh6XPZ5YeXh4eHhc9nhi5eHh4eFx2eOJlYeHh4fHZY8nVh4eHh4elz2eWHl4eHh4XPZ4YuXh4eHhcdnjiZWHh4eHx2WPJ1YeHh4eHpc9nlh5eHh4eFz2eGLl4eHh4XHZ44mVh4eHh8dljydWHh4eHjNFWm/2Cq54jEtxkr//+7/nwIED1NTU8PnPf37M40opHn74YQ4ePIjf7+f+++9nyZIlABw6dIiHH34YKSW33XYbd95556VYsoeHh8fkSAshcwiVRygHWPRmr+iK5pJYVjt27OBTn/rUhI8fPHiQzs5OvvCFL/Cbv/mb/J//838AkFLy0EMP8alPfYq//uu/5tlnn+XcuXOXYskeHh4elSgFTg5hJ9CtPnR7EE1mCkLlMddcErFas2YNkUhkwsf37dvHtm3bEEKwYsUKUqkUAwMDHD9+nJaWFpqbmzEMgxtuuIG9e/deiiV7eHh4gFIImUOzh9GtPsgPoMksKPlmr+xtxyVxA05Ff38/DQ0Npd/r6+vp7++nv7+f+vr6iu3Hjh2b8Di7du1i165dADz44IMVxyxiGMa42y813jq8dXjruEzXoRTIPDhZkDlQOhACQuiGQTwevzTr8KjgshArpdSYbUKICbdPxM6dO9m5c2fp997e3jH7NDQ0jLv9UuOtw1uHt47LaB1KgbLQZA4hc8DYaw9APB5nYGBgzFMdx6atZuHcrc/j8hCr+vr6ig9iX18f8Xgc27bp6+sbs93Dw8NjxlQpUBM91bYtLNvGtm0c23MLzjWXRer6li1beOqpp1BKcfToUUKhEPF4nKVLl9LR0UF3dze2bfPcc8+xZcuWN3u5Hh4eb1UKLj5hJ9DtfnR7CCGzVCNUSkE+nyedTjOcGCaZTJNO5cimHfK56oXO4+K4JJbV3/zN3/Daa6+RSCT46Ec/yq/8yq9g2zYAt99+Oxs3buTAgQN8/OMfx+fzcf/99wOg6zr33nsvn/vc55BScsstt7BgwYJLsWQPD48rhYIFJWQOTeWrTo4oWk+24yAdB9txcKQilcqjpPu4x6XjkojVJz7xiUkfF0Lw67/+6+M+tmnTJjZt2jQHq/Lw8LiikflpC5SUyhUo23ZFSkqUA7ajUA4YuoP0MtXfFC6LmJWHh4fHrKBshMwiZL6q+qdicoRl2zi2jSMlSqkKgfIMqMsDT6w8PDze2ijpdpKQWYSyp9x9tPWklEIphXTAcZRnOV2meGLl4eHx1kMpt82RzCKkxVT2j+042JaNbVs40nUJKukKky1dC8rj8sYTKw8Pj7cO0kLI7JRxqHL3nm3ZSOW695CuOElnlptQeNkWc44nVh4eHpc3ygE7hWYNTOrmK7n3HAfbtl33XkGYHDnL8SelMEkQlh2EVCdh2QHsmK2je4yDJ1YeHh6XH0oW3Hw5hMyDpcYIlZQKx3HjTsXkCADlqNm3npTCJEk4e4aYfZqw7MQkNUsH96gGT6w8PDwuD0odJdxsvtF20HiZe+72suy9Wax/MlWSkOwgrDoIyQ58pGDU2CobP2nRQlprYf7snNZjAjyx8vDweHMppJtrMjfGFHKkxLZsEokkiWSi1C9USYXjKBzJrCVHGCpJWHYQVp0FcUqO2UcKP0maSWutpEQLOVEHhX6lnljNLZ5YeXh4XFqURCjLLdpV1ph6qPEy93w+H44tS6nls2E9GSpVEXPykRizj4OPtGgmpbWSFi0YsYUkk+mRl6Ign9NIJr1L6VzjvcMeHh5zj5KFQt3cmFTz8sQIx3aQqiy1XLq1TxndnnH/PUOly9x6nfgZHrOPg0laFC2nVrKiDsRIC1Uzr9Hf7yOVMkgmDVIpE8tyH7/ljhktz2MKPLHy8PCYG6RVSJKwXEuquHkCcQJKxbnF7hGl7Rdxel2lCcvOUsxpfHEyCjEn162XFfUlcbIsURAlsyBMBvm8jlIBbCdJ3u4ibw+U/sGai1ilR7V4YuXh4TF7yHzBghppd6QU2OMkRhQpT5CYSfcIXWUq3Hp+hsYuD6Pg1mshLVrJiAYQGrYtSCWNkiglkya5nI6UFnl7kLzdXyZMgyhljbMCj7nEEysPD4+ZIYsdzUcSJIqJEcW40+hBqhX1TxeZwaerTEmYQqqTgBocu7RxxMmRGqmUay0VxSmT0QvWUn+FtWQ7Y+NYpfNrGjWxKLWxKLU10em/AI9p4YmVh4fH9FHKjT85GYSyXetJjk2MKO0uFbKYvXfR4pQdJU4DY/aR6KRFUynmlJINpDL+UnzJ/SnJ20Oj3HiTW0uhYIDaWJSmxnrCgQC1NVGi4RCadlmMBHxb4ImVh4dH9Sin0I8vh3JsrFENYUu7KUUgd5ba/EuYMkFeROnT15PSqk/w1lSulEYeHezG54wday/RyYtYIbvQoSu7iLOZjfSnG0kkDIYTmTI3nvvTdsampBcpWkvxmoLFVLCa/D4fAJFohGRi7PMt6bVbmms8sfLw8JicsqaxjpXBth1s2+L8hQscP3aMdDpNKBRi6bJlNDY04ziKoHWORvs5FDoOfkyVodV+jg7jhgkFS1M5QqqrUOvUgV/1I0btI9HIiCZSopW+fBuDw0HsZIruRD3dCY2sNUTevkDefpW8PYCapD1T0VqK18SoLYhTNBJGE6PPOj5SKfIO5BwHT6vmHk+sPDxmidOnT3PgwAGGh4eJxWJs2rSJ9vb2N3tZF0dBoJxMP06qo5S9V7Seurq66D/1ArcuHCbmdxjK6rx4ug8rfw2NDc3UOy+h0JGFS4zEQAPqnZdKYqWpfMGt10lIdRBQfWPESaGRFo2ktUVcGGrh/OA8egcdhoYT5KwB8nZ3IbZ0cMKXomlaQZRGLKV4LIbPZ17UW+MoRc6GrOOKp8RA4bkD5xpPrDw8ZoHTp0/z05/+FF3X8fv9pFIpfvrTn7Jjx45pCZYvdYTQ4FOIs0PUajWka7eRD6+ck/WOEdZFC1FOFiefRtoZHNtGsyNkspnS84qJEcnzB7mpvR9HaWRtQcgnuam9nz0XXoSG2/GpBA7+inNKNPxqgCZ7D2HVWRAnNWaftGqkLz+f80OtHO+M0D+cJmcNkbdPkbcPTmotRf3QXOPQErVRdddO21oajUJDCQ2FTt4R5HIhenMKPHG65Hhi5fGW53KwaA4cOICu65ime7de/HngwIGKtRTFSLcGcMx4hRj5UkeI9Pw7CAPMMJqVINLz7yT5pVkVrHJhDQVM7OwQ+559HJVeT2NTY8W+ShUawzpugW6xJGp1fQ+O0nCkKwKOBDSN1fU9DAN5EUVYw9h2HkOT+HSFoSmEgAb5StnxBcNOEx3JZk721nCs0ySVSxaspQsTvgZN06mJRlgQG6Q1atEUEzRFFQETNGwsEeQNsxWAsDxHvf0SPjV+7GxEkFxRqvwpyDuKjCWxlSLq0ykKlcD9r4BZnjfiMR6eWHlcNJNdeC8Vs2XRzJTh4WH8/kpLwjAMhodHClHLxUhqQTS7UoxCg0+BMFCaD4RAaT6EhNDgU9N6XycVb6V48eAeIn5JwAcCC6UUjg1Hjx6hsakRpRSdHV2cOH6cTDZDIBCkvX0pjQ3NpXPUBBwylqDcYHEcRV3QImDvQ9gJQnoaMeoKI5VgIFfHmYFajncHOdknSeUSKNUD9Iz7egL+IPV1cWqjwZIrL1KwlsLyHK2F2JhER8NB4NCnrweoeNwhgKGytNjPc864hYS+BIUO41hdUilyjiJn2yghSA079HfYOPkBdJ+iYb5BtN5ASRsyGcjneONUgoWLvRT2ucITK4+LYqoL76WiWotmrq2vWCxGKpUqnR/Atm1isVjp99DgU2RzkkQ6hZIOQtOJhsySGOnWAFILVhxXCRPdqkzRnuwmYVzxfvInbL/5Otpa6pFWFpnpI2CaoFTJCafrGul0mlxO0t3VxeuvvwxCw/T5yeay7u+rKAmWpcUwtCGEAJ+uKiynkHwJdPe4UkFvKszJvjDHewxO9jnkHQ1IF/6NoAlBTVAnGgnR2Dy/JEw+nzlhFl5Km0+HcQP1zkuYKoklovTom0joi1Fo1DmvITGRws3mUxhoyqJJHiTpX4EuXK0Smiu8tlRkHUnOVijdfV8SfQ6nDp9nOHkMW6YxtBBDg8tZuixOJJQHIJnQeebJTj7gidWc4YmVx0VRYQUASoxvBcy19VWNRVON9dXVkefE63lymST+ICxd5aO51Vdx3MkEb9OmTfz0pz8tnd+2bRzHYdOmTaXn26luhpN5t52PECglGU5mqBXdADhmHM1OoMTIeYWycMx46fepbhIOHDjAkroU17T1U+PPk8ybvNgZ5egre2msvQmAUChENptD13VAgQLLcQgEQigHTp8+AULD0HWEEBi6ju3A2TPHaK9zCMkOQqbEbzhjjBKpoHM4yMk+g5N9BmcGfOTsYnxnJNbjM0PEA5LWaIbmWJLGiE1NUOLXJBnHx1DDjeP+vctjSEVX3cmhFTxzdhm5nMLv15i30KCuwQQB/vwwjgiUt/cDZeBnmEBgZOPLL5/m6OuHyeXT+HwhFi1bxcLlrqvwzJFz1BnP8e6NQ9QGbQYzBs+e6uHMqWu5am0NQhP09wYIBi8uLuZRHZ5YeVwU1VgB1VhfM00oqMaimcr66urI8/xTx+kbfgXLTmIaEbq7r+L6bctKgjWV4LW3t7Nh/U0cPHiQZCJBwB9l48aNFdZbzxCETLDLwhuG7m4PAunabQQ6vkM6O0zeBp8BoYCPbMNIh9TQ4FNYtmudScdB03UiIRN/30/ply006W9w25I+HCXIO4KgaXPTon6ePqVQjsKRivb2Zbz22ktIpdA1HacwpbC9fSkAmUwawzDRhaQ5nKY5nKQ1kqEpnEW3j44sXrgxrY5hg5N9fk71+zjT7yNra2W76PiMEKZuoAkbn+Fwy7Yb8PlM2oa+7u5bpniWFETMHINoKKETcs7T6Bwk0J8kS5Qu41pSxmIQbqxocMDm9AkLIcA0wbIkZ45b+AMa9Y0mVq4WQyZRmGVrsrG0GqRUZGzF4dfOcOy1Awh0dN3EtnIcP3wAXTdYvHoRtdpBfn5lL47UyNgaEb/Du9b08qPXXyISead7UBnGMDyxmks8sfKYkMmsIseM42T6SKSt0kUzGjLRg/Wl5493YS13e81GQkE1Fs1U1tf+PSfp6HsBTdPRNT+2k6Gj7wX279F41y+tAgrCVpPimvkD1AbyDGZ97DkXrxA8cyjBPVv6CPsGSeXzvNafoKsjXxK8p09GedfqXgQSSwpMTaFpiqdPRrl9Kxzt8XPypSjXzh+kNmgxmDZ5/GiUJYaf9rC7bpnpZjCRRykBSiCVzXDCojach1wv1y9K4EhwVFnig1JsaksxUOhaXl/XxMZljczTXiPqz5PI+bgg1xCtbyAoO7huUZrGUILmSB5DG5Wtp6Bz2OBUv59TfT5Ol4mToYcJmDEWNcewMg653Bl0DTTNRhVaMTXEV5dSxodzPkKmhSW1UkcLQ5P0Z/zYDbVE7VO05J8kk7NJ2gqfkWWe/7/o8/88af8SADresNE0gV4QCkMDx1a8cdKiocnHUPg66ob+i1weLEfH1B38Pklv9CYyWhDlF5w5fgxNmGh64XKogXRsTh97nZUr53P9wk4cqWFJDYErqADXL+qkeGvm80vqzWPA0qo+tx7TxxOrtylFl1YymSQSiYyJ4UxlFZ3KraQpswsNgdI0NGyyGYtu7QaKTiuZ6WEokQOhITQNKSVDiQy1hUB6tQkFk7nf2tvb2bFjx6TxqKmsrwtdL6EJHU0zEAg0YYByt4MrVrXqPDuX9eBIQcbSCJsWO5d28fgx10xKnD7MlubH3Y4KMkDATLKl+XFePq3R3Ho1AOeTrfzwdZ0b2weoDeYZzPh49nSc88kmAF54fh+DAzGO99ShCYEjJdKx6Xx2Dw0NDTiOQ3ZIEdQlDjpCSBBgCkV/SiBrFLUhxXBa4Lr3BAiFVILakCpdWEXiDGsiryOVjiRI2G+xSrxIKHfAFaeWys+KK04+Tvb5XXGyfPjMGgJmjNpomHAgRCQQwNA1HAfWXB1kaNDm+NEAifQZHCeDECGCoSW0LV6IrQVQms5LPZu4vm03upBYSsPUJLoGhwc2snS5Rm33M6SzeWypoWk6li1RMkdYPU22ZRmappHP6vhME6FpCARCaCgDbEtQW1tLV8dajpyFNXW7CfsGSeZr2NtxLcaipdQ06Qggn0+h65UuXyE08rkEpFPUhW1SOdeUK0q35UBd2C69p6vajrLU9zTw81N88zwuFk+s3oaUu7SCweC4MZyprKInD/XSYLRw7fwBYv4cwzk/u8/F6bV7udu96aUvAX595C5fCIGuudtNXFdi1tZIpQeQUqJpGuFQsKLnWzXxpqIbbiI2bdrEE088STotQeqgORiG5OabXevLdpIIUXmxQugVbXmuXziMIwW2dK0IWwpAcv1C1zpbEnoOqXScgrvJUWZpO7hitXHjRp5/4SlO9EXQhI5UDko5XH/dRpRSDAwMIYQJyEJHBAWaYHh4CCeXRJDn4Nkg25fm0KXEUmAK0DTYeyrE8npFTsbw6QnyjgNIQMOn6+RUFCufxUmdJZY5QMJn0xDOY+pjWy90JgxO9fk41e/j3GAdihriYZ3a2jqubW+kscHPmeM5LEui6SOuL+kofD4NEETjARavWMz5c+2ksxr+gMHCJSYNTSai4PaLL72GZ44q1je9SE0gx1DWz8s9G2hadQM+nw/DHiAlCxakoxAILKkRtgeoqakBIFYjyGYkRtk6bFsRjrh/pxOv58ikl9CZW1pSGsdRmKdsaprcy5/fH8HKZxC6UWpaqJSDzxcBwNJqMfXBQksl90bA1BWWVls65+LwAfx6pfXuMbt4YvU2pDyGI4QYN4NuKqtoeHiYnD/Oo0frSsdVSpHLjSQ2PHsmxu3LehBKYkuBoSl0AT85GWPHRkg6QaxUD1LpaIVzZFLD2JHGirUqpZHLamQciaZr6IYak+03GUH/POoj19I3/Ap5mcSnRaiPXEXQPw+A2toYgwMplDAQhTiMkg618ZG4VzykSOYqj2tJd3sWiPqHyNkBylswOMog6h8iVfh9w6ZlKKU4ePAg2VyCgD/C2qvWsmRZE0NDQ+haEEdmQemYOhiagy4sfIYPYSeRUnF+uI6fnRBsaksQC9gMZw0OnI9yfjjOcuBwz2rW1u0lk/XTlTCwbBufoagPDbG69l/xhRWEK19HV8LgdH+As4N1dKZaCfv8tMSyXDUvxS3L+wiYA/hMB2WEeMN8FwCNrTrnz0iko0BoWI6O7Rg0LglBIICuCxrC0LhAIIRA07QxPxcsChEM3sqBo9vIdEnCEZOlm0YSW/rTOmHTwVIgECiUa0WmdUKFtS9d5eOV/VlsW6Hr4LjhN9pX+BjK2iQSknTuHP2Dr5K3kvjMCHW1awlJN3lCScmyFavJXXiSGxcPliVQ1OJvWAfAgO8a5ulPks055B2JTxcE/CYX9GtK76GfYczAyHfBY/bxxOptSDUZdFNZRdUkNvTLeew6qY2xvvql62d6+kSYm+b1IJTCUe7dqi7c7dcUXP8D/UPYlllMoHMnx2Y1Bpyxs4om4sTreWLR+dTFF5StVXHidTeedN31W3jiiSexbRspdZRwMP2S667fUto/pxoI+gbIWhZKSYTQCJgBcsp1eipfHZo9jCxYVEopdGHhmDUkk0mklEgpaV/SQPuSd1Ssz7EtNGWxqGUhff0vo2uiZHmhJPFYe2lKbjzWzhsDGd4YDCGEjiNtbFviD0TYc/AlVKqb5LDOorocG+Yl8BtjLaeepMnZwTgdiUaS+TriIVhQ08+1tUkSjWtZkv0m6Zyv9HdXCnJ5nZBIuKacrlPTGEAZ8MYZRToD4bDB8mUBmlsDaJqGrrs3IEVxmoi2BX7aFoz/2J6z89i57I1CjE/Dp0k0TbHn7Dx2bHX3aW71wWb3b5xOOQRCGi2LDVQUknlJ1j5PZ89uhNDRNB+WnaGzZzfzWkClWiCbZsO8IVobh8nmJBlLEPVL7rx6mA4zQwJIaIu4wC00hw4RE0kyKsIFNpDQFo18Pojhl/kJX6fHzLlkYnXo0CEefvhhpJTcdttt3HnnnRWPJ5NJvvzlL9PV1YVpmtx3330sXLgQgO9///v85Cc/QQjBggULuP/++/H5fOOcxaMaqhGaqayiahIbiu63wx3hCvfbbbe5+7x2QcOy2tjS2kuNP89Qzse+jgaO9WgU71k1EUGRduNIuIaLxEETkapfbzrlYJqVF0xdd7eD60a87bZbymJ40TFxr2TNTTQkfkDQF3ItQWx0zaEncC2+dBo7eg118kfkcg6WY2DqNn6foid8DZY1avSEcgpdwm2EtFHSxpGwYlk9R19f6cZ5ZAZdCxINLaJ9SQtSKRLJFL4IWP1xUpl+HJmnOZpnZWuexXU9tNflxxWnvnSQ80NNDFgLyJuLCeppVtQ+w9KGN3C4gCFsNCE5q64DIJEN49cz2Kr4ngs0YTOYrcFsakA3DHRdJ1qn0b5CRy+kuM82A9b1/PD1NDe0DxEPWgxkTJ47XUNSXV+xXzp7nvN9bswyFIkSbNlAEPfaMZx+FdDdz48AgYGjFMOJlyDjft6bOYRumgTNEMX8Vg2LZg6RwBWkhLaIBIuoicUYKrupA7eA+GfDW3h34LlZfw88RrgkYiWl5KGHHuLTn/409fX1/OEf/iFbtmxh/vyRliePPvoo7e3tPPDAA5w/f56HHnqIz3zmM/T39/PDH/6Qv/7rv8bn8/FXf/VXPPfcc+zYseNSLP2ypFgTlE45hML6uDVBhw4cL3M3uWnUGzYtAyqFRtd1LMsaIzRTWUXVJDZM5X6LxWIc7U5y+EI7SrrlR7rhUFMzIkS1kTVExBPjXLBGrJ6p3o9QWHfjGmWfdsdxt7v/d2hra6O1tZV4PE5vby9SShKJhDvFVilUdD5nMzuoz+4lpA+TdmL0+baix9vJ5XLkjEU4kXdQZ+whKIewtBp6AltJmotRto2QVmFIoY1SctzuPNGYwbIVrXSci5NIJck5SdKyn+cPnWVwOIGSDq0xm9WNORbX52mP5wmYY8VpMBOhMzmP3vQCejON5B2D+e0ajfHiG1BDX+IqGpyXCRopMnaYXn0dKroIhODVnqvY3LIHDYUUBrpw0DXB4Z4bWbu+dvwP5RzQ3LSInt6dfPOlV8hbKXxmmPqaq2hudIXIkYojx0/y/LNPITQdw+cnk0lz8IWn2XjdzbTMX0gun8Qf9OFYIKVCE+D3a+TyqdJ5/Axjj+lj6NZiTUZXRrKnx2ZPr01/rpZfuuGDs/8meJS4JGJ1/PhxWlpaaG52q99vuOEG9u7dWyFW586d46677gKgra2Nnp4eBgcHAVfs8vk8uq6Tz+eJx+NjzvF2oasjzyv7swgNTNMNLr+yPwubKV2gDx04zvMvPIUQOrrmI5dP8/wLTwFu3KRcaCbKBpzKKoKpExumcr8taV9fWKdC11zrzLIcNl69vrT/uoU2V8US5G2HtCWI+h3evTbBK8P2lO9HU4uJUor25Tr9R15nTcMeIuYQyXyMV3o3E1mwnMFBu2IOk9/vJ5cbFZwqoDeuYJAVDBZ/x70AotyU7kEWMeibD8oB6SAsB5EfQCBLWWTl0lK0lgaHEwwOJRgYGmZwOEE6kwVAoGiJ2ayqz7F4aZ72ujzBccQpkY8xaM0nKVqw/M0kpUnvsEM+L/H5NBYs1Kiprfyqq+gieljkdm7QTXQzgOEPYPoCvH60kf09DYUMuiFS+Rpe67mWIZZP+LeeC5au8pHZP59oeD5+v0EuZ6MkLFxu0pe2yNqKFw8ddIXKcL0EhmFiA0dfOURz2wLCoTCZdAq/Xy8d17ZtwqFQ6fccMUxSyLJaLA2bHCOehiKJvORnnRa7e2zOJCvvOLS6q2f5HfAo55KIVX9/P/X1I/U39fX1HDt2rGKfRYsWsXv3blatWsXx48fp6emhv7+fJUuW8O53v5v77rsPn8/H1VdfzdVXj/+h2LVrF7t27QLgwQcfpKGhYcw+hmGMu/1Sc7Hr2PvMeUxTxzDdbCfTBNuSvHFCsXade7xDh/6NZQ2ZMSnShw4dYuftrqunoaGBLVu2lFx4o8mmgjTGsvQOvkxeJvBpURpi62hpXE1DgxuhP3cmxcsHB0kOW0RiJus21jJ/0Uj0PpdJ4vcbFS4iXVfkMpKGhgasdI75zTfQO/iyewfsi9BQuw4rvaD03kTb9pFP+NH0KEHDjQUpLDbO24uI3czzPzuHEBa6Dgq3bsmSDkdezdLc2oQQgvb4G6xuf4JsTpB1fAR9KW5e/DMyLfEx9VyGYRCPx10RwhUjJV0xUqogTI5EKQclLYTmIJTbj04YTuEoAverNfL1yuXy9A0O0d8/6P4cGKR/cAjHGbngCRTNUZur2/Msqc/RXmcRNMeaYGknRlItwPK3oSJtSMNt8VN852uB+QvHfnZE4fWZgQCmL4gZDGH6QujGKCG7LsULT+n0dqzAMDVsSyKl4rptjaW//aWgoQFqYoXPWMImFPGxcHWY2pYA4BZSu0IUqPyMaYJMKkGNk2fDmrW8sHe3G0PUdRzHQQAb1l1NTcHtnczfQGP2x0gkCgOBjQYMBG6gxhfDkoqD3Vme7chwqKcLp+x+oUHkuXngVW45ugu49ZK9N29HLolYld+5Fhnt477zzjv52te+xgMPPMDChQtZvHgxmqaRTCbZu3cvX/rSlwiFQvzVX/0VTz31FNu2bRtzzJ07d7Jz587S7729YyeLNjQ0jLv9UnOx6xgazGKaArusDYJCMTRol443L3yBd67qRRZqgiI+i3eu6uI/DztjzjnROg7sSRIJz6O2pq20zbYVB/b0EAhnKiwaXYfEcI5nn+ziqs2BkoXnD0I2Y1dU9tu2IhDU6O3tZWgwSywyj1hkHrqhY1t5pJL09w9z7pxCSkmb04Pj9+NkHRxHoWmg+zR0p5dTZ87Q35dw3w+r7POkFIlhxcCAmwI/f+gnIDT8QRM/uG16lIXR/QTnwg2lMetKQSxaw+DQUMWxBA4atnsRKwjTREgpSaTSDA4lGBweay2VUxSnJfU2Sxski+JpguY4Nw5OhKSYR9ZoJqO3YPnK+s9lAMaffCs0gc/UMX0Ghi+I4Q+B7kcKnZyCXDoP6bFJAYEwrN7gK7SfckrtpwLhDL29mXHONHfoAcXyLTqBSB19/QMoMgwMjKwhGAqXOm4U0jix83mCgQBDg4NEIzHWrV3HsRPHSKXThEMhlq9aQzQyEnsaopGUvJFmDuFnmBwxOtUGXuqpY3dPDwd6bdJlf/IADtclT3LLiSdZO3ACrWAvv/7666xateqSvj9vJy6JWNXX19PX11f6va+vb4wrLxQKcf/99wOuuH3sYx+jqamJF198kaamplLw/9prr+Xo0aPjitXbganiLwA3L0lU1ARZUmAguXlJourzTJWUcOL1PEKjJESGMeLia2w2UEqxaLnGqwdyrsjoCsdRSEeyeJWPRCKBbqZJZxx0AwypYzsOjq3wBzQyGfeClBc1mFoSI2xSzAsXysLS3DqbYEgnl5XoBqUaGbtwDMtyY0OGM4hDoMIHp5SByRBW4VodtU/Q7OwhkEnSQJhefQNprW1SYcrnrZIYDRTEaWg4gSMnGhehaI35WN4oaK/LsqB2gKA5VizyKkzeN59h2UhKa8Eyo+N2Bh+NbuiYpo7PZ6L7Ahi+IEoYboeQaSZANLe6cb834+ZOKUXWVqQsh5zt/tF8E0ziXXHVBg6+8DS246BrGo7jIJVk+dIRl2VLUwstTS3jH6BAMYGiN+vGoXb32PTmRm4wNBTr8p3ceupprul6Eb90k2akL0B65QYutC1l73/8hydWc8glEaulS5fS0dFBd3c3dXV1PPfcc3z84x+v2CeVSuH3+zEMgyeeeILVq1cTCoVoaGjg2LFj5HI5fD4fL7/8MkuXXr4tTWaju/dkx5iormTpqpGEgsYaGExQUfNjOe728e/BxxIMaWQLQuJ251aFFGlBJpNheDiJYUDeAigkISjJwIBkaMj9IofCsGSVwxsnLTJph2BIZ+FKk9q4wLZtFizWOfqKjWODXmiToyQsXDISO+gPXENz+sfuTTMGQtmAQ7e+lWxW0tKmc/Ko4wbPNTe1XSloaTNKQpQXNZgyWYhJuFc9DQtLRDDVEFHnzMiYCc2HT6Zos58qjWAvWktFYSpaTeNZS0WEMPAZtbTG/Cyuz7MoPkxbrIugOdYysQiR0lpJixZSWisWUSKx6LhdxkeOL9B1HcM08Pk0fH4fwgigND8I0+0IUuXf+nLBkYq0JUnlnQpX20SofJ7maJQNa66qtJyWLp9SnMpJ24oDfTZ7emxOJCpvNBY5Q+w4t5tt518gnnf/HkrTyS5fT2btVrLLrgLTx4Hnny40BvaYKy6JWOm6zr333svnPvc5pJTccsstLFiwgMcffxyA22+/nfPnz/PFL34RTdOYP38+H/3oRwFYvnw51113HX/wB3+Aruu0t7dXuPouJ2ZjttLp06cLNT8aSIOeXIInnniS2267hfb2dppbfXTMe2NMpl9z67LSMYxwEzHl9u1zR1FoRENB9FAdlmUhpSxluSWTSVKpVMU2pRTN8/McfSWHsKgQxcUr/GSzWXx+p2DRjCii4yiCocovbH2jSX3j+OPD6xtNlq91+7jlsw6mX9C2yCQS1clmJUhIq3Zy+k6anT345BB5rYYu/RoSYjE4UBM3aV8GHWdt8jmbYEAxb74gXmeByiFw6NfW0CqfRSBHzTy6Ck05FSPYc5agY9CkZ9igI/ES55NnGBpOTmItgaFH8RlxfEYtzVGDRfEE82u6aI2eIGimx+xvESSttZISLaS1VvLEJrV8hKah6xqacC0nN2apo+kaSvO77ao031tOnIpYjiKVd0hbsqrXoHIZyKShEGutxnIajSMVrw067O6xeXnAwS47ca3Ksa3nRW458wyLUp2l7blghIwZItMwD7V5B2LxiPWWSqepjddOaw0e00Oo8QJKVwgXLoydNDqXbo3vfve7Y+qXLMsiHA5z9913A1P35HvkX/+NwYEUmm4UGru4TTVr42He9/73lARR07SK+qabbrqJ+fPno5TCnz5GQ+JHSPSCNWIhcOgKvaPUADSUO0lddg8BEmSJ0h+4pvRYkb4eq9IqWjIiPH09litmWqWYrbjKT12DUWpMWggjFESQMf+KxGpiDA9NnirsHlC6yQyU/5SFJIeJP8pheY56Z2RabI9YR2cmzsDQMGJgD53DBt0JjUR2YtHQhIFpxAvCVIfPqKUxopgX66A1+gbzomfGFSebQMFyaiWltZCnZgpxEtTW1JLOZPCZOoZhoBluUTaa20tRCR9o498EzCZz+X3JWLLC1TcZtbW1DHRcgEzKNZ8vAqUUb6Qku3ts9vfaJMvCg34crhk6xq2nn+KqgRPohc+S1TiPzLzFZM6fx/EFEP4AKpd1P/C33FESrKeffxo0we/93u9d1No8psbrYDGLTNUZYryefE8++STbt28vFUAPDAyxrCHLDe39ZXVFdRzvtRgeHmbPnj0ApfZExZ8HDhwoZdDl9IXYwZ3UZfdgFmp+ysUolDvputbQkUYQw07SnP4xXbyjQrBGW0VKqVKWXG3cYMkqxbnTFtmsxO/XaFtoEArrZNIzvP9RCoGNQJasIKFcUeIi7IdcPk/XUJD9Q6tdN95wgqHh18qspbE93fxGEMOox9TrXXEy4xhamFhgiHnRM8yLvU5r9A2CRmrMc20CJZdeSmudUpw03S2s1XUdXXMtp7q6GEZCoWkCpZko4UdqJoi3tqvJkaokUnYVmqMcB3IZpJ2DVPUx13L6c4V6qB6bruzI50eguCpzgR2nn+a63lcIOq7f2InFSa7ZQmbtVuymNtS/PQy+AJg+t6OH6QPysP8ZKIjV8qXLef34kYtan0d1eGI1CxRdZ9FolFQqhVGW/VC0rFKpFHv37sVxIJ9TpFMZhADdgL1795YSTpY3WPz8KnckQdrSiPhs3rmqkx+93objOCQSiTHdO3RdJ5msjG+k/UvGWEpF6rJ73Iy4QmxDChOhIJ7ZzbDW7jZRLbd+iv8fdZxozGD1+lFpz9VqSSHLrmgZ6VLDVImChXRxd85SShLJFAPFuqXhBINDw2Sy49dNAeiaQcBXg6HVYuiNJXeeprnxrahviLbaM8yvOUhz+CwBfTxx8pesprRoJSdqpxAnDV030HXDHXCoCQxdlKwnIQRmMAhZiaP5qJwc+NbEciSpvKze1Wfn3XHxxSQHY2zN02RkbMWhfjdR4thw5edpvj3ELWefZ1vHPurz7o2kDARJr7uRzNqt5BcsrXzPhwfAH6o4Bobpbi/Q0tRCuzlxMo7HzPHEqoBrNVTGbab6Jwt35kVP6sqVK9m9ezdSylJNh+M4rF69mnw+z+DAMLbtNkvVhEBKhZPTGC7r7r19eRpHisLMHIElAQTbl6dJApFIhEwmUyGIjuMQiYxtP6SkO7Z8tCuuIjvOUYXH3Oy4/Gy1N1OqIDpyHJedHCNImtTQlDX+scYhm8sXkh1GsvGGEsnS32Q8Av4IfrMWXdRhaHUFaylSUUZRG+xmad3zNMW6qQt0EdDGJjm44tRCWmshJVrJifiUbj3XcjIxCj3zXIFixL0nNJTwoTQfUpjgi6P0t/7FL2tLkvnqXH1KKchnXZGyq/8sFHGU4vVBhz09Ni8OOIXvjktM5ri56yC3nH+BxckLrotdN8is2khm7VZyS9a4AjQesTikkmCW3STalru9uPZTx2j46bfh3XdPe90e1XFFi1U+nx8jMIlEgkTCdSeUi9Ns0NbWxrXXXsurr75aikmtXbuWtja3VkkTISCDKPa5E+4oAne7S30kx3AqhCBfapiqCFAfyZEE1q5dy+7duwHXorJtBykdVq5cQz4nS1bRZG59Nzsu5V4UC2jY5Avp4FMyRohGXHQTidHFIqVkuLzLQxXWkqHrhIK1+Iw4GvXoWh0+vWgtjaBpisaaPhbEz9AcPkvcPI9fjBUnB18pGSIlWsiJuikTIgxdR9MNDN2dxYRwi1V1Q6Bp7lgPVZjl5Vyi+NOlQilFxpYkclW6+qTr6iOTmXY8SinFubTr5tvb65CwRr7LpnLYOniEW86+wIaBo+hKohDk21e6mXwrNqACwUmOXmDzTfDkD4A8SguAlQfHQWy+iaAOAV1g7v7hxGLnMStc0WKVSo112eRyuXE7NswWbW1tJXEaTTS0jL6hF5HKRsNAYgOSaGgkk88xa4mEE2RykVK/vIDPxjYi5LKS+rpWNmzYytEjr5FKpwiHwqxYsYbGhnlU+7K69GtYIHehKUC5Fo3AoUu/piRERUvIFaQRESr+Phe41tJwWUHt1NZSJBgg5jcw9Tok81BiHoYWHlN0LoQiHLaojw3QFjtDQ/AcNdoFfOMk8zuYpZhTWrSSFfFJXXFCCHRDL7n1KsRJF2i6K04ASugozY+j+d36pysIpRQpS5LMVZl6bltuVl9u4hKAiRjMS/YW+vJdGBUjXZM6xy1nn+O6nlcIO+6xrZYFpNZuJbN6MzJaO61zicXLUdyB2P8MvuE+fJEIvuveQeCqqxD+APj8yKF+RLx+6oN5XDRX1rflMqehfh5CwFDiGJaTxtRD1ESWE69tLaVqd4itLBC7CAccJEahc4LkrHYNTsEr1NLcRkvz+II4JUqR1BZyJHsTzc4BwsYwaSdKj7YOfHH8ZYMP54qStVTW5WEokZy0bsk0DCLhGEF/LaYeB9kAqg6twjos/BQONcEBfNEw8cgQLZE3iJvnCavOcZuTuuLUTFprRUaWMpAOTBkn0g1XmHTDQNd017U7jjiBa0FJzVeogbryvnKOdEUqlXcKQyMnR+WykE3D6G70U5BzFC/2u26+14ecilumeflBtp97ge3dB2nKup9hu7aexJodZNduxW6YXmp7EUNAQIfAqhX4rl5LQ0srfckU+HwIrSzZpbEFdZEJIB7VceV9c94kivGh3m6Ls6fcDLlAQGPeQpN4vQESmufpxLUc61b3EfMnGM5FeblnIWazgSwIUUJfzFnGqSvSF09nMZUxoqKlVHDPDQ3anD8T45jYgWHq2JaDUtC2KD+m4elMyeZyIx0eil0eEolSVuF4RMIhoqEa/L5aDK0OZAO2FRuxloqGlgCBpCY4QF2ol/pwDw3hTuoC3ZhaBpvQiDiVnc7BqIg5ZUV9SZwiRgTGcQVquj5KnASaLtB1XIEapW2ui69QA3UFChSALUfqo6YSqYt19UmlODosOXRmkN2dGfJlT404WW7uOsiOjn0sS5xFAE4wQmrTNjJrt2K1La66c4c6dczN7hsawB+LErj2ZoJr1mEEAuDzgc+P0HS02jrEOL5N8XN3w7f+T9Wvy2P6XJnfolmimJAAk9cKFfcZ6LM4fTzvZvlpkMtKTh7J0b5MEa83WVBzjnmBp8nnNbK2n5CZ5ub2p7ngD5BgRIwS+uLJxUkpKKV1yzJ3XVGQJr9y9HQ4riWgCwTuT+koejqcixarcmtpoMyVN1lsyTQMamNRwqEawqFGlB1D2vXkcn5AgE2p2ZF7zVEEgw7hsE0kYhOJWKwy/4OQNlRIc7fQymJlekGoJAZp0VzqEpERDVNaTsW4U1GctIIa6bobd9L10dfBYoq5ryBQb+0U88mwHEkyL8lUkdmnnIKrLzs9V9+FUhzKZjA/chZDOWzpf50dF/aysf8IpnKQpo9sIdU8t3i1W/g3HU4dI/jEowSExG9qaMPd8KNvIerrEOs2V3UIbd1m4vXepOC55G0pVhVZcoVu2qVmpuCmasvpV/R0nLVdodLdq5hbLKvoOGsTrzdpdvagaQa+oElA15GOjqYsmp09Y8VJjbKKKopfZ5a8kM/LMd9nTXO3V8NYa2m4EFua+B2LRsLURqOEgzX4zDgadeRzMbJZE2UJ0uMM/g0E7DJhcv/v09KEVCdh2UFYduIvDewYQQFZUc+w1k5atFYpTqJQ/xZCSUriJDQq0spHPcst0C0W6V4BKeaTMZ0iXtfVl6HU86oKEpZiX6+bbn42VflZXJk8x44Le7ix+0UidgYlNHKLV5Fcu5XcivUoX2Bar8UQ4Dd1gqEAxr7HEZoNxWQLw4RcFvVf34UqxQrgYN1KbpjWKjymwxUtVlZejrGADMMik5mbBIFcbnwRyOXcL55PDrkp41BakETDJwcxVAo3m64662gm+Hxuk9dyl7uU7vZypJQMJ1IVltLAUILsBPOeAEzTIB6LUhuLEQrUYBpxUHVk0gHSaYNcSjDeswMBSShkEYlYJYEyDIWusiVxCskOAs7gmOdKNCQGoMgTpUffREofZ0ZGGaWkCM0o/NQL742PXDbrWk+TCpS/UKd2ZQuUIxWJnEO6iiJeJWXB1Zeu2tWXdxQvD7hxqNcGnYrbsOb8INsv7GV71wFaM24j7Py8xQyt3UJ29WZkODr+QcfBp7ni5PP7MYN+dL8fUcjecwZ6YfSxfH7o7ar6+PvPJ3noYC+P/eabP37oSuXKFqvpl2rMCL9fK1ktAokm3LlHoSAYCiwRxlRppDIQ6KXRE5YIo6uJBWC2aWzVOX9GIgsjN6SjsOw8vkiWw8fTpUGAw4kkcoK0fkHBWqqJUhuNEgrWYuhx7HyUdNpHKmUwlB4/XmCaTpm1ZBGJ2MTrwiQTSTSVI6w6CMlOwlYHgXESPiQ6GdFUKsLNiEZUFW630UkR5RTjT6Gw6fZlHPVqlWYWBOrKt6CgzNU3lGU4N3m9l+vqy7hCVfZxeXXAYtcFm96spCGgsXOewdq4iVSKEwnXzXegzyZbdviQk+PGroPs6NzPquEzCMCuayJ/490MLl2HU9dU1foF4DMEgaCfYDCAHgiUxGkMDc0wNAD+Mussn3O3V8mjh/sxx97ZeMwiV7RYzRnjFrwq2hfmOH8mhy7kSAdwAW3zTXSl6NPX0Wo/52atKa2Q6efQp6+f4oSzhyMlSmRQ/kE6u4ZJZ5Nk8kksJw9vjP8c11qKucIUixIK1qATJ5MJkEoZJIcMEgPjf1ENQ1aIUiRi4/ON3D9rKkdIdVKb6qPJegO/6me0xLni1FgWc2p0R19MwUjcyS3GLU9n13TXatIKyRHFh0auNyNtjtQV0kWiGkYX8Y5tRDWCsvOQTjFeJfmrAxbfPJlH1yBkuKnm3ziRZ2nM5nRS0ZcbUTVdSTb1vc72rv1s6TuMT9o44RiprbeQXbsVq2UhNTU1OMOT9440BAQCJv5AAH8ogPD5x5QwjIf4ubtR3/hHIOtaVPkc2LabNFElXUmLuvBk75bHTPHEajxG1RpVCNMkBa/xWtDQ6emgNFK8sVUvJS2ktPl0GDdQ77yEX6XIiTB9+npS2vw5eRmZbK5ipMW0rKWCKy8crMGxI6TTPpJJg/5ugx5n/Au3rstSbCkSsUrCVH690FTetZpkByHVSUD1ueJUViOm0EiLxkILo9bqxUlQsJoMDKNQ71R8TCuIU6ml0QQH0XxIPfq2EiipRkZzVFXEm8+7DWUniUftumCja2BokLQhbUNewv6+kRMsS5xjR+c+bux+kRorhfQFyK7dTGLtVvKLVjImxXIUGuD3GfiDPgJF60mbfmKLtm4z8gMfcWNUvV3Q0Iz4ubvRyuJV+88nefRwP72ZUzQEde5aXcfmtpGuMc0Rk4Q1s1iyx+S8PcVqmq2ApkNNrTFpRl1Km09Km08kGpl0XtF0cKRkOJEc6fJQaEGUzU18MSlaS02NdYQCAeI1UYKBGrIZP8mkQSpl0HFuPJeYi6apCmspErHw++UYEXDFqYuQ7CCsOgio/jHxOIVGzmgmIZtIa62kRVNV4gTFlHI37mTolc8pZe5pk+uOm2YecAXKX4fS39oXneKFtStp0Rwxx1xYi/t897U+OpMWdUGDdyytYW3z5CPrVT7nWlKFVkgTufksqbiQltiKChcfQF1uiFs697G96yDz090oTSe3dA0Da7eSXbausqXROJi6RiAUwB/04wsE0IzZuYQdrFvJoxs+MvKe1dVRlKr955P8474uDE0Q9Zv0Zyz+cV8XH4HS+3rX6joeOvjmTyC/krmixcodjVGZVWfYNn5VxSiKy5RMNkd28CTZwVP0Dlt0Jkz6kloV1lLMTXwoWE2mESSV8mFZIfr7Jad6DSxr/LtSV5hGXHnhsE0w6IxrnWgqT0h1udaT6ihYTqPFSbhuvUILo7RoIhyLVy3eumFgGAaGbpSy9kqvVxOY5nip5ZUUWx1daYW65RfWiE+jP2OPubC+8MYwX93fjSYEAUMwmHV45JU+3gfjCpbKZQvzo0aCwKPdfAM5yf89nmdBxOZUQlaOgXdy3ND9Eju69rNm8BQaityCpQxtu5WDLev4Ub+f3rSk4ajDznkWa+OVsSW/36SuoY5gNIjhn1zMxmPvs4d47MgA3SJIk8pw58o4W2/cUPV79ujhfgxNEDA0hHB/Zm3Jo4f7S+/p5rYI9V7q+pxy5XxLx8GnxlaUz8RqGhq06elwxnXxzTYla6msH16ltSSA4he3MPrbNF33XU2UeI3rxquJRUC5llIyaZAcMum6YJDLjS9MQihCIbsiASIUGl+YwL0hCKkuN5V8UnFqKLn1XMup+j5qI41gxxcocK0owzde9l7ZOoReSDP3X1Qvvqkslmosmrmm/MIKEDBE6cK6uilIMif5zmv9aELgLwzO9BuQs+HHJ4ZKYqWUglwW2WdBYmxdQdHNpwsYtlw3n63g1UH3+yWUZEP/UXZ0HeCa3lfxS4vz4WZOXHsHNZuvwampLxM8WYprffNknvct09jcFsEfDBIIBjAMnZqGOFbv+Ikek73ve589xFePZDGUjwgWA8rHV49kgUMlwZrsPdvcFqEraREZlSnr1wVdycoMrhuWeJmAc8kVLVazidv1wSrUUYFlSc6fcb+YMxUsN7Y0XHDhufGlyWNLirowNMckTVFFS8ymLuZnIHobUmolYerrMXjjtEE2O9H6FNGoIhjMlSymUMieNFTgilN3KeYUVD3jilNW1JMSraS1FtKipaJp7lRouuYW4pY3gh2HiQt0y9Yi9EKh7uQCNVVMYqq772osmtlisovz6AurUgpDwIXhPAMZ92Lfm7YJmZVvmE93txfTz189P8Su83n681Dno+TiA3cM/LmU6+YbXZrXnrzAjs793NR9iLp8gsFADT9ZeCNHF21i7aoFrK3zlQq9i4Ln1wVCaIQMQV7CU30at2+s7sI/1fv+2JEBDOUjINyFBoQkq+CxIwNsvZFx3zOoFKPmiEl/xiZQNhU75yiaI17j2kuJJ1ZVUt71AUDTmXbXh3JrKZXN0t3TN2VsyWeaBSspSm1NjHWh56mLmJi6wJY6A+kG+tMNHOmoo+NkHZmMDmPy6aDY/aE8My8UsqmpnTx2JpRNSHWXYk5B1TvGOnXFqa4gTq2kRTNSVO+u0XQdvz+AbcsxWXujmU2BKlJNTGKqu++pHq+WmYpm8cLq00EqN3kiZyvqQyOf0YaQwWDWwV/2sc07ioaAgIFeXu3Pl1x8EdNgMG/zyIk81zVLOjKKl/srx8DHc8Ns6zrI9q79tKc6kYEg2TWb6CvMhtogNDaMfqGGQW8Oon4DTdfQCkHFgFJjLJbJePRwP4aVJZAYBNsiYJhko7Wl971bBIlQeTy/kHSLkW7rU4nRXavr+Md9XWRtSVhXZG2JLRV3rfbcfpcST6yqZLpdH4rWUmVPvOSE40iEEMQi4ZIbrzYWLSQ9BBBCICWk0waDQ1lOn62lL93EUCaOYnwzaGz3B6uqLjRC2QRVT8Fy6iCoeipaGMFIh4iRzuTNSFF92q47y8ko1D0ZbhwgECA/nmgLRg0mnPCoKM2P1PygTS+uUU1MYqq772pdRZNZRTMVzU3zwrxzeS3/dKAbyxH4dMg77pyndywdGf/yjqU1PPJKHznbLZbN2w6OlOxc4AOlShaPT4O8VKRtSNnwn+dGUjb9Tp7rel5me9cB1g0cR2o6LzWsZuimd9G0fv3YcRlCgOlD8/sJhAKE/CbzavIMZB0CZdkv07VYuvqTRIZ7cNvc6+DY+Ad76JLuB6VJZRgos6wAckqjiUzp93Ix8uuCnKMqxGhzW4SPFN773oxNQ9B4U1y8b3c8sSpjspjURF0fDAMGBocr4krVWEsNdbVu4kNBlGqiEfSCmigF6bROYtiks8N16aXTBkoJ4Poxxwv7hglHHAIRs+TOM4wqO2Aom1DBpReWRXGqjA244lRXFnOanjiBW/NkGiMCNfm+I7OfphLYkW4Sk6eaT8d1BmOFZqq772pcRbMRyB9vrT4NOhJ5OpMW7fEA772qnh+fGKI3bdMQGpvpt6YpxHtX5dl1MuHuE9DYOc9XcvN1Zdyef/05sNXIZ0EoxbrB42zvPMB1va8QcPKcaFjK/7v2PZxZuJ6bFkUrkyM0DfwBV6CCAQKGIFh4bQB3r6mfVCSqoSnZxYAoEyNNc8Uo2QWs4c6Vcb56JEtWuRZVTmnYQufOlSODE8vFaKJ44+a2CJvbIjQ0NNDb62X9vRl4YlVgqphUQ4vGmZMZsukUWStJOpckk0uRs9OoY1NYSyVLKUZtLEow4Ccai5JMJFEKMhmd/v5CAkTSJJUqCtNYfD6HmnCC5uApmkJniYXTJAMrC7VaUw+0EsohqHoIKbe3XrC/e4w4AWRFvBRzSonWaYsTFCwowyxl7k2GrglMnxi3g/moo5Y1jPWD0ApC1D1p4kM1rrPJhGaqu++pHofZCeSXr1UqhVSQtRR1QaPU+Xxtc3j8rD7puP36MmnW+hVrV/splv1mHcXz3RZ7emyGRnnhFqQ62d51gG1dB2nIDWE1LyCz/V0Mr9lCOFrLz5fvbJjg96H7A/hPHsb/5H/g7zmPKNQulTeGrUYk5Mv7Uf/1XXoGepHxhjH1T3deeJavzr+drHLwK5ucMLA1nTvPPQncUkiiKMsGZGw2YHEtnqV0eeOJVYHymJSUkqyVIpVN0vliCmW4LYhyk8x89/tMagtdHoop4uXWErgWUzar09dncKHDYKC/hlTKRMrxhcnt/mCVFdqWd3+YT4b5Zc6MCSiIU1h1FiyoqcUpLVpwxPQagxYRmuaKUzUCVVYHFQob5PIT+fgmbndUTWLDVCJRTUxiqgtrNRfe2Qjk37W6ji/v7cSWClMb380nj74CTz8OA30Qr4cbdiIWLnZnSJXdV0mleH3I7ct3qH/UGPh8kpu7D7Gjcz9Lkufp89cw3L4GtW3n2NlQpgk+P0YgSChgEjAExmsHUd/+R9f1EI7C0ADqG/+I/MBHKsRmY/8RNhwqK8Ztvhva3Mfly/vdzhKGgYjExj3GpkCG3+j8CY81bKXbiNJkJ7izdy+bAiPfjK03biglU3i8dXlbi5VSqtTl4Wx3PzkrSTqfIptPM1HP9XJrKR6LUlOwmIKBytYuSkE+rzE4OGItJZMGzhTdH8oTIEZ3f6juRUmCqrfQX6+DkOoaV5xy1JLSWnBCi+nP1eKIKsZ7j0Opa8QkaeUjOxfce+ZU8afCSxHmSLHuBC6+ahIbphKJamMSU919T/X4TAL5xS4T82t8/Mraid188ugr8L1HQDfcLuJDA/C9f0Xdcgdi8XIAzqcku3ss9vU6DJWPgZcWW3tfY0fnfjYMHCWn+9jdcBX/teAmlue7WSsTI0JVECjN78afgqaG3xh5j53/+q4rVMV+e/4AUNnJvFyMxhM0VXYMIcS4xxA/dzebvvGPbEq9Udkq6QMfmfDv4PHW5G0jVl3dHRw9fpxUOoNER9P9pDJZcvmJM490TScciNHaWjOhtVQkl3NTxvOJDJmkzUC6npw9vgDouiQWUwQCuUm7P1RFQZxKnclVF9o47sAcNaXeeimttSROEX8EJz+9ThpCCAzDGLfn3ph9tZEBhdUkeIwU6waqmgk1G/EmuDQxiYsJ5P/iyjjL6gN0Ja0p3XwAPPVfbqxILzSnNExQisGD+9jvb2dPj835dGXCzJrBk2zvOsANPS8RwiGj+xlqWEAuGGON4bAqfdi9+8plIBxG+IME/SZBQyNgiPH//r1dU3YyV1MJWm8XBxpW81jtBrrNGE3WMHcOHmJT7+HSMappleRxZXBFi9Vrx04yMDRMb/8AqXT58DcHGHHpCSEI+P0oO4ehaRiGjiEUmpAsW76I9kWtAITlOeqdZ3GyNl3pRZzPrGUgXUcyWd79oYZydGERCecIRrSS5RQIOERjEZKJ1PRflJIEVF+pM3lIdaKPK04x0lorKdHqWlAiNP1zlVEUKMM0S5NyJ8IVprHj3SdCCR2MMI7JtLtJzEa86VIxnUB+KBbnjc5ucrYiWcWcMWVbbjyqvxv8IVCQEzovhRawO7KEI8EW1JmRz/y8dA/bu/azrcsdA59rWUT253+FrhVXI7/3r5BKuqavwP0jWhaBujrCdTUEDA1NCOTL+5ETiUQ1ncynELQD8zbw1ehWDCRRmWNAD/HV+pv4DZ+frWVP0dZtntbcKY+3Jle0WB169ciYbZom8BkCQxeEAz42Xr2RmmiEAwd3k05LpNRRyv2eappDd/c5amsWkk+ksZIxelN3k7bGn6OjCYd4sI+6cC91oR7qw73UBnpxtABvmO+6uBehJAHVX+HW0xlrDbri1FKqdbJnKE4wkmJumOaU8SdNFxhT1D+NOjhS+EdqocwoiOmPSalGiKoRiWooBvsnuoOf6vHiWiY6r1SKdN4dcBjV81MOOVRSugKQzZRaIclYnGMyyp7aFRwKLyRXVmcWsVLc1P0iOzr3szxxFssMkInE6apZhlQCInUIfwC23AxP/gDhWARNDV9uCH8+g373e9BMfeS1TuLCq6qT+RSC9tjCHRh9gwSUA5pGQObJCp3HFu6oECuPtwdXtFjVxCLEYzEG+jsJ+Ex8poZpGijpoBTYtkVdrWsJZTJpTDOIoBaIA3Uo4jh2hMOHAWorji2Q1Ab7iIcHINZKJGJzlf6vhSLU8qu1Nm7bpwkpiNOIW69zXHHKE61w69li8iak1aLpGoZujtsYdjTVFOiOpujicxMlLsbvWUm1QjTTbK+pLs5TPT4RSilyjhuPytmSSYYtl/Ynn4VctmI0R0dhDPyeBf+NQTniPjWkzea+w2zvOsDmvtcRtfWkTYPupiU4wbL3w8rDgecQ6zcTuPZGgnUx/Lu+iz7QVcjC+1DF65jKhVeNe24qQesmSKRWwPAgODboBv5YLd1cXPKPx1ubK1qs7rj1ZgD27kuRzWUxdNe/rgBHQsDfRkdHkGTSwDR+AYhQLjRl6RLUBPqpD/dSF+qlLtxLPNiPrtno5Djuey8AjhXGVJnC1FoXDYe8mGSiqVL4VX8pWy+sOtEZm3WYJzJKnGYnzVYIDcM0MAzXvTdZgkR5/EmrIkGiyEybxk7Vc+9SpB1PdXGeMv4yipwtyViSzCiBKmby9Q8PoGJxuPl2tBVXuQMOs4VR8YXC8uIY+D09Nm+UxsC7QrVy6DTbuw5wY/eLhAxB9qprGbrjDqzWhaiH/9p1FRbRNEy/j+BAB5H6GLomYMNm2LB54hheFTGpqdxzUwma6+IVBFrCGIaBbdvkbElz8Iq+bHlMwCX7qx86dIiHH34YKSW33XYbd955Z8XjyWSSL3/5y3R1dWGaJvfddx8LF7qjyVOpFP/wD//A2bNnEUJw3333sWLFiqrPvWjhMo4cPYfjNAANKFmDLmI4jsbp08W9Ru7WIr5+agNd1Ic6yPlqiLUsZLH8zymFqE9fXxquKNHRcMYOV1QKvxogkjlOrXWGkOrEGGfQe55wKeaU1lqwJhO8aVI+MTcWi02U+OjuO834U5Fqm8bOtL3QJWOqi3MVF2/LkaReOkjqp48jB/rdtPKCGEFlJp8IRVCJIfj3f0XufDdiwWL3GFLxUr/Dnl6b1wZGjYHP9JXqoVqcBNkVG8jc/P8j2b6Cimr2WBzSKTSfjxA2QZnFzKWhLu4KVTXMwnRdmFzQvDZHHuVcErGSUvLQQw/x6U9/mvr6ev7wD/+QLVu2MH/+yNDBRx99lPb2dh544AHOnz/PQw89xGc+8xkAHn74YTZs2MDv/d7vuXdXuepiGydOREilDNLpBgx9rbtRVVoEfr9DJGIxP/gKdb6zBI0OdJFF0zSCPgNlRnlDX0ifmFqIyocr+lSCvIjSp63DJkzcea3k1jPIjanftQiXxrSntFYsIrPiJoPK2qepkiPg4tx7hRMhSz35pm55NBs9+S4ZU12cJ3jcbmghnXPIWJLc6y/D977pppWHwpAYhu89gnz3+1zBevpxtyLdNMBxXIHRHOTun3KqZiG7e2wO9tlkysfA2xluLIzfWJl4g/yStWRu/0W6lo8zG0rT0IIhfLe+i9B3/wm/w0VPxp2N6bpT4bU58ijnkojV8ePHaWlpobnZ/WLfcMMN7N27t0Kszp07x1133QVAW1sbPT09DA4O4vP5OHz4ML/1W7/lLrhw0a2G7u7K1HEhbEzDQiOHpuWZv1BS3+DecS7Lv4CDH3fsxsjoDb0QbxpXiMaZ8psSbVhGpNRbr815GoMso7FFmKRoKbn1LKKzJk5QbG9kYpiuQE2+r1v/NHX/vXGfPdKTT5jTevJs9OS7VEx1cS5/3PYFydiSjAhi77gbLVdQl6cfd4XKV+gG4vO7SalP/Rdqfjv0dYM/6PqodUG3EWVP7WL2htvpe3XkM6RLh439R9hRGAOv6prIXreN7lX3oUJjL+TC9BGIhAhGQm67o+YtSL+YUbr3pUoZ99oceRS5JGLV399PfX196ff6+nqOHTtWsc+iRYvYvXs3q1at4vjx4/T09NDf34+macRiMf7+7/+eM2fOsGTJEu655x4CgbFB1l27drFr1y4AHnzwQRoaHGIxSX/vMDg5TFMhECgUjqMYHtBYtNhNsHCG4ugyVTGhVigLR4sTiboXgM6OGE8fqyeV8hMOR1ixPEZLSxhDDhCwzuO3zhGwz6GrsX0lHBEia84na84nZ7YhjXqkcp04I01vZoau6xiGiWm4CRKT76thGIKA3yQane6oAwG6H/QAaP6LFtnezCmifhMhBEK4NyJhXbl30Q3uiIj58Q76UnkCZa8naznMjwdK+8wmhmGMf9xbfo5sLEb6sX/B6e5Ab2oldOf/Q2Cz26vR3n47g6Eovf/5GNn+PvSGJgLveDf+tRtLh+gfHkCEIm7cVEpQCmUaqIE+agydRF0Dw6kcB2qWsSe8mFP+ynUsHT7Ljq793Nj9ImFlk4nWMdjUjiN0gm1LiLXMG9lZ0zBDIaI1McLhAMZo994tP+f+u9j3YxrHmA0mXccl5HJZx9uRSyJW43UaH+2KuvPOO/na177GAw88wMKFC1m8eDGapuE4DqdOneLee+9l+fLlPPzwwzz22GO8733vG3PMnTt3snPnztLvy5f3A9DXmXEbMkuBrmk4UgKKTFqWxmMo1tAqnwNkyc0HDt3aGlKJJD29Xbz++ssgBPGQpCXcSV3iFM2Gg18b65a0CRQSIly3Xp4YIMACLIhE5YzH2gsh0A0dXXeLcyWKvJMfv3s5le4924ZcDny+OAMDA1Wdr7KjhM3+850zSgdvCOr0ZywChlYKoGdtSUPQKN1F/8KyKP+4rwvbcSpS039hWf207rSrTTvXJuhBB8Ci5fA7n0UAEhhwFNnzbkwl7yhobIdf+0Tp8TSQLry3SilUtBY1PFjZkdzKY0Vr+dmpfvYsfCevZHw4ZZZwQ3aAbV0H2dF1gFY9T0b3k65tJB0ss8StPOmnHyfT3AaGQSAcIhQJEfDpWLkUg7mLqOcrnv8ysWjeCuuYN2/euNs9ZodLIlb19fX09fWVfu/r6yMej1fsEwqFuP/++wH3i/2xj32MpqYm8vk89fX1LF/utoq57rrreOyxx6Z1/ok6pvvK3EsTuvlEG6Yaxhzez61LE8yLZgn7xrYvcsWppUycambVrVdE0/XCeI2pU8vd/adZ/zSKiTpKzEbiw2z05KuG6aSdT9SDDtzPZd5x1+mudYr3Tkqwcm6KeT4HV18LT/7AtagMk9NGLXtqlrC/fhXpozkgCBoE7BzX97zEjq4DrE6dI79mM5nr30/3gmWor/2Nm8lX/sc0TLThfiJNDYRD41hRHh5XAJdErJYuXUpHRwfd3d3U1dXx3HPP8fGPf7xin1Qqhd/vxzAMnnjiCVavXk0oFCIUClFfX8+FCxeYN28eL7/8ckWsazJ6ertobGimsVXn/BmJdBSa5g5NVAoaWytdZSltvitOJAjLTmrkCebJZzFJsXzUKTOWRmcyyLkhH/OW7SAnaudEnMab/TQVmu4WPev6pFMzJjtpZcHuOMxG4sPmtgi/cfp4oSN2iCaV5s6VcTa3LR2z32THnMpqmk7a+egedM7aTSVxyjtq6jooxyqIU96tXSpDLF5Oj/2L7D3Zwx7/fHr8tYUngaYk6weOsaNzP9cMHMFYeRXDt95Kz9K1lZZYLO52lygkTwRwCOWTBGpj6JGL6+/o4fFW4JKIla7r3HvvvXzuc59DSsktt9zCggULePzxxwG4/fbbOX/+PF/84hfRNI358+fz0Y9+tPT8e++9ly984QvYtk1TU1PJApuK06dP0NjQTE2tQa1+ngbnZYJGiowdpldfh4ouAsBUydIk3JDswMdYt0nW1uhIBOhMhuhIBBjI+rAdScAfoF6Lj9l/JpSnlk+VHFF6TiHF/KIFCoHSfEgtUFWixGwkPsiX97Pp+//IJsNAD4Vx0ik4ZiNjkxfSjj7GlMW400w7V0DOHyY9mMRKWpNl9rsubstyC3XzOddkH0XGVhzoc+uhjieaITaS3t2evMD2zgPc3H2IcGsLmS1bGVz5/xBraiE3PDz2hJtvwvjJ9wjJHEGfjp7PznoWnofH5cglq7PatGkTmzZtqth2++23l/6/YsUKvvCFL4z73Pb2dh588MFpnzOTSQNuT79W/24UOmghTJkhzjNkrcP41DA+xsaOHHylTL2UaOHcsMXrx14BoaFrOo50QEna25eOee50KXYuNwyzauupNEFXv3gXHwCaD6lHJ+1sPh7V9OSbimq6asPkllNVxbhVpJ3LoQFygQi2FiRlgMxbUF8/7hxm5Tju86286+YbR80cqTg85LC7x+blfhurbD5ZbW6Y7YUx8G0Rg8zarWTu/AP6o7UTvldCCIKREKEbb8TXVOM1bvV423FFl4IHg26VfoN9EIGDhoUuE4hCKWVEXSjt64pTcykpIiviFRfvxgZgleD06RNkMmmCwRDt7UtpnGYRZBGBKHSO8E3Zubz0HK1yBtTF4hbs+t04lL8OpU/dKHU0s9IctopC2iktpyqOMVHaufWOu0nlHLK3/Ddy//EIOAaaz0DmM257n5vdm6mS9WQVBMoef8ilUoqzKbft0d5em2RpN4HPyXNd7yts7zzAGtmPtXYzmdt+nd6G1knfIsM0CUfDBKNhjOIf3Wvc6vE25IoWq9tXpajPfxsfY3vzKQQKjW59U0Gc6qa0LBobmi9anKBQnKvr6IZJNFbIDpyCouU09QTdKU9eKNgNTNpRolpmpTlsFV0QprScqjhGeU2Q1ddDpmE+2R2/gFx8FeQcWH4VvPt98PTjqOEBNy50w07EgsWooQGw85N2+RjISfb22uzutunMjuwolOSqwRPs6DzANcmTsOIqMnfcQf/8pZOawkJAuCaKGQ4QCM5GUYOHx1ufK1qsWn1nS/9XgMQdh24rA4HCEiH69XVzuoaJinOnHLFRLNCdiUAV4lAjE3ZnNwFkpj35yi0epYfd5qyj4y9TWE5TFeuWMviWX0128boJM/jEsjXQvpzaYIDB3h63g0Rq4tKCrKM4VIhDHR12UGU3HvNTXW7bo96XiSxaRObmrQwv+ZBbEDwJhmm4VlQkTFNL02WRqu3hcblwRYtVUrSR0lqRaNQ7r6IwQPgQKo9AVvbsm0WK6eXVdI8oouvVT9CdCrceqpDNNzO1m1PKLR410Avj1TdNYTmN10lB3X43+VUbyWbcuq3xMviUUu5YDauQtWe5iSGKmCtU4yCV4kghDvVin02+FIcSxPJJbuo+xI6uA8xviJJdv5Xsil9g0D+2eL0cAQSCfsI1UQIhL5vPw2Mirmixejl1GzW17kvMi1rqnZfwqxQ5ER63VdJM0AttoKYc7V5AMIMefOMeUEMW41AX0dn8zaLYyHSiYstqetBp6zajrtpUGrWRtSQqUxlXKomTnYe8NSatfDLcMfA2+3ryDNkjAlUaA991gDW+LNbazWTfeT8DkZpJjwdue6twJEQoFsHwTd1H0cPj7c5b56p2EfR0OCWxSmnzSWnziUQjM+4cAReZwceIQIUjJpY9c7ecEiZKD7jdzcvWMNVYjbcKk/WgsxxFznHrn8abBaXsgtWUt6aMO41mKC/Z2+uwtyvPuVJbPvf9LY6BvyZ/AW31ejI3/wpDdU1VHddn6kSiEQLRMJpendXt4eFxhYtVvopx4NPhYgp0YXwLamaWlEBqAZQ+vhU1W2M1phK8aibjVrPPVJSPkcg77hyobDI/Jv6kHLtQjJtz3XrjtPmajLyjeO5ChifPpHl9WFbEoVrTPWzvOsBNQ0epWbaUzO3bSbcuquoPKYBgKEA4FsYfmvkEZw+PtyNXtFj5fDOP11xMgS7MvM3ReExkRY1mNrpLTCV41RTjXuz03HIc6VpPOdu1npwy/XFTyvMjNU8TxJomQyrF8WHJ7h6Lg70WOVX8zAgiVpobuw+xre9lFs6rJ3vdNeTbf4nhKj8HWsHVF45FMXwzz8D08Hg7c0WL1eh2StUy3fqnIjNuczQeFxGLmo3uElMJXjXFuNOdngsj4pS33Z9jrKdy19404k6j6cxIdndb7O3KMeAUPycahrTZ1Pc627sPclWNwF67mezyjzE8ejbUJPgMnXAsTDAa8Vx9Hh6zxBUtVsV41VQU40+6bmIa1bv3YI4EaoYp57PRXWJKwauiGLeafYqp5YMZi+6khTUq8KQqMvamF3caTXEM/N7ODGeyRRFxf64YOsP2rgNc708iVqwhs/NXSY4zG2oiBBAMmIRjUXzh0LQ+Qx4eHlNzRYvVZEx3em45rkC5P2dUqDuKSoG6+APPRneJ5ohJ/2CCQGLQzaIzTHLRWpprC+JTzVjzCfbJN7Ri55ySBaUAx29jSTXSCLaYTj7NuNNoLKl4ecBhT0eW1xIKB42iQDVl+tnedYAb829Qu3w52eveiW/hYobG68k3AYaAcDhAMBbFGGfGmoeHx+zwthIr3TAIBIJIqaYVf4I5FKhSTZSvYgTHTJiN7hK/FOznq29kySrw6zo5CfZwgl9qtYCFVaWUF/dxyJH1R8jZDnktjNxxV2l6brHPntRA9feM2wh2uiilOJGQ7O3KcaDXJo2Oa/sIQnaGG7pfYtvwERYubCZ361bspl8kNY2bFYHrFg1HQvhjUYThxaM8POaaK1qsxsve8/v95LJjhyWOx9y4+NwZURgRHFPMmkCNZqbdJTY9/21+w47yWMNWuvUoTXaCO3v2sqk/ATdumHKsueVIMis2kH7PR7GeehwG+iDeADe9A9G+HJVKuAJXSIpQupixUHVnJHu68+zrzNIjiwKioymHjf1H2d73Mlc1BnC2bCa/YAepad516AJCPp1wLIoeDiNm867Fw8NjUqoWq7/8y79k27ZtbNq0CcN4a2hcZHS8pApmtVC3AoHS/O4IDs0EMwIiO/XT5ohiWnpv5hQNQX2s5dXbxaZwmk2dPxjZphQMjvRZ1EY1VM3ZkmzWrhxMuPwqxOKVhaSIgntveHDWXkfKUhzos9hzPsXJfDEJwhWqpYlzbOs+xDXhHL4168n+/K+SuQgryK9BOOQnEI2gBb3Ucw+PN4OqVWflypV85zvf4R/+4R+4/vrr2bZtGytXrpzLtV0aiqM2jNlpdTT64G4cyjfjONRsUp6WHvWb9GessXVYVcSkLEeRdyS5UUW5I/VOxaSImcWdRmNLxauDDvvOJ3kpoWMLDXCFqj47yLbug9wgeqlfsZzsze9GBkNM97ZAA4IGhCNBzGgMMY1sQA8Pj9mnarF697vfzbvf/W7Onj3L008/zd/+7d+i6zrbt2/npptuoqWlZS7XOasIUWlBzfLRZyxQc9194tHD/RhWlkBiEMexCegG2WhtRR3WeDEpy1FYO+/Gytjky2qelOMURmcUrKdZiDuNRinF6aRk74UU+/slSUzABAEBJ8d1PS9zc/YMi9tbyb3zRmQsTuYizqMLQY0pCEWCaJEYwvTiUR4elwPT9uctWLCAD3zgA2zcuJF/+qd/4tvf/jbf+973WLZsGR/84Adpb2+fg2XOHDd+BaGwiW3PtoUjUJo5K5l8s9V9YrLOEV39SSLDPYAATQPHxj/YQ5ccMSu1dZvJve8jZHd9n/xAP/n6Bcibfw5tyVWonFWY75S/6GLcaunLSvZ2ZtnTmaVL+XEz+fTSGPibh4+wvjWCvGkzduP2ixIocLP6oj6NeU01DORCiLeIq9vD4+3CtL6RFy5c4KmnnuLZZ5/FMAxuvvlm/uAP/oBYLMbjjz/OX/zFX/ClL31prtY6bcabBTWToYWjmYvu5rPRfWKqzhFNyS4GhI+AkAghUJpGTmk0JrvI2qvIWtItyF28Dn5jHUpKsC2ElUcN9k04fHC2yNiKgz059p5LctQudiJ35zotSnawre9ltsYVgfXrsea/l/wM3vuABmG/RiASgVAEI16P8EZzeHhcdlQtVp/85Cfp6enh+uuv5+Mf/zjLly+vePwXfuEX+OEPfzjrC5wJgcAcFGbOcXfz2eg+MVXniDsvPMtX599OVjn4ccgIE0vT2d65l770jROOz5hLHKl4pd9i3xuDHEr7sYQOuEJVmxtmW8+LXBdM07RyOblb3w26wcWuqhSP8huYkSgEQ15mn4fHZU7VV9s777yTLVu2TJoJeDlZVbPL3A4xLGc2uk9M1jlCKsWaoMUHup/hB/Wb6DUi1Nspdva/xBoz7U7GnUEbo+lQHAO/741B9g0OMCR8QAgE+Jw81/a+yo2qm6VL5mFdvx3lD1Jd0cH4+DQIGYJQwEREooiAl9nn4fFWoWqxCgaDdHd3M2/evNK2Cxcu0Nvby/r1czPE8M1GCQOlBS7pEMPZ6D5RnskngbwwyNs2uabFyISFs/2XWPofj/DxzI8Q/gAqk3bjTrfccUmEajAn2XcuwZ7uHOcJA4Hi9A2uGjjOTdkzrG+rQezcgIzUMJMVCSCoQ9gQ+IJ+CEcRUwxE9PDwuPyoWqweeugh/uRP/qRiWyAQ4KGHHuJv//ZvZ31hbxpCQ4pCHEq79JlgM+0+4UhFdufdZP/t/yXvmNj+YCFDD7juNkRiCNHQjNr+87D/GVRiGKIx2HwTYvHyKY9/sWQdxUudafaeG+awE3ULowsfv7ZUF9uGj7K1QSd07Xqc+qtRzKgNoNsGyRAEDdCDIQhHvPRzD4+3MFWL1dDQEPF4vGJbPB5ncHBwttf0JlAs2PWDMOfUzVcNG/uPsOFQWSZf893QNnGX8rxTHKNRKMZdsg75ix+EZx6H/j6oqYVNNyJa2iDnVhyJxcth8XJqYrFp9cKbDlIpjvTl2He6n4O5MDnNAGIgIJZPcmP/a1wXs2hZvYLwql9mKJFgpnmFgYKrL2hqEAxBKOJl9nl4XAFU/S1ubm7mlVde4aqrripte/XVV2lqqm5C6uXHpYtDTYdqZkBlXtxPbtf3yQ4OYtU1w823I5atqUiKEA3NcOcH35TXcCFps+9kD3sSJgNaEKgBDUxpsaX/da43h1ixbD7OzdtA07FhRu+/BoQM15IyDB3CkULShDeew8PjSqFqsfrlX/5l/vIv/5Jbb72V5uZmurq6ePLJJ7n//vvncn2zjAA9gDRil5VAlTNeJp9Nntzj38Naup7say8jv/dN0HUIRmF4AB77BurWdyHa586NNxVDOcnBU73s6bU5o9cAMVdFgNVDp7jR6eTqRXXoWzeifP4ZW1Aw4uoLGaCZJoQKInUZ/l09PC5n2tvb2bdvHw0NDTPaZy6pWqy2bt3Kpz/9aX7yk59w4MAB6uvr+aM/+iOWLVs2l+ubBYoFuwGUMMFXi9Lmtk5oRvR2IcNR8sIgKwzymoFtaDCUQmRzqJ/90M0a0HS3U4RuglSw7xm4xGKVdxSvnBtg7/kUr1CLFOHi9A1aMr3cnD7FlpYA0W1XoUKuRT4bjZdKrj5DgM/nuvoCwamf6OHh8ZZlWs78ZcuWvQXEaQSpRy5pJt9MsBxJ1lakmxaTTyZBDwDKFaR8BiJRGByAgV7wj0q5NkzXwroESKU42ZNk38k+9tk1ZHQ/CLdgN2KluX74GNfGFW0bVyLjO4DZEagKV58mIBBwM/u8pAmPtymnT5/m53/+57npppt44YUXuPrqq/nwhz/MH//xH9Pd3c2//Mu/sGzZMu69915OnjxJKBTiK1/5CuvXr6evr4/3v//99PT0cM0117i1lQX+7//9v3zhC18gn89z7bXX8vd///fol8HE62mJ1enTpzl8+DCJRKLixb33ve+d9YXNBkq/fO+2balIWw45W5EtNIFVtoW67lb4z++4qeSG6cahHAc23+Q+MRaHVBLKL9K25W6fQ7qHs+w71snudJBeIwI0gg6GtNk4dILrQmlWrlyEaLkehGC2ugNWuPo0L2nCw6Oc48eP8+1vf5uvfOUrbN26lW984xs888wz/Md//Ad/9md/xoIFC9i4cSOPPfYYP/nJT/jQhz7EoUOH+JM/+RNuuukmPvOZz/CDH/yAr3zlKwAcPnyYb37zmzz77LOYpsn999/Pv/zLv/ChD33oTX6l0xCrXbt28fWvf53169dz6NAhNmzYwEsvvcSWLVuqev6hQ4d4+OGHkVJy2223ceedd1Y8nkwm+fKXv0xXVxemaXLfffexcOHC0uNSSj75yU9SV1fHJz/5yWqXfdkgC+Pbc7YkZyvSepb+ZLbQndwqdScXLfNRt7wL9j/jWkuxeGVa+eab4MkfAPnxxWwWSeZsXjx6gd0DcMKsBxpLn5hliXPcoPWyYUkT/us3MKsTKRmpjfLrhf6FoTCEwl7ShIdHGYsXL2bdunUArF27lttuuw0hBOvWreP06dOcOXOG73znOwDceuut9PX1MTQ0xFNPPcV3v/tdAO64445SpvcTTzzB/v372bp1KwCZTOaySaKrWqz+/d//nU996lOsXr2aD3/4wzzwwAMcPHiQZ599dsrnSil56KGH+PSnP019fT1/+Id/yJYtW5g/f35pn0cffZT29nYeeOABzp8/z0MPPcRnPvOZ0uP/+Z//SVtbG5nMxbYqvbSocnFyFJajkGWjMxwrBwPju+6KaeUTPaa4Y2IxmyGWIzl8spO9HRle1BtxtPrieCgasgPcZJ1na1uY2q0rwZjdETHFNkiRoqtPL2b2hb2kCQ+PcfD7/aX/a5pW+l3TNGzbHrfjUPG7NN53SinFr/3ar/G//tf/mqMVXzxVi9Xw8DCrV68G3BcppWTjxo184QtfmPK5x48fp6WlheZmdxbSDTfcwN69eyvE6ty5c9x1110AtLW10dPTw+DgILW1tfT19XHgwAHuvvtuvv/970/rBV4qiuJUrHnK2wpZHJ1R/Cclrw5Y7Lpg058fpM4HO+cZrI1Pr/h4MjG72LWfOd/LvtMD7FH1pIwaMGsACNkZrk2f4ZoGnQVXL0eE5k9xtOmjC6jxawSDAl0I18UZ9pImPDxmyrZt2/iXf/kX/uf//J/89Kc/paGhgVgsVtr+6U9/mh/+8IcMFG6cb7vtNn7pl36J3/3d36WpqYn+/n4SiQSLFi16k1/JNMSqrq6O7u5umpqaaG1tZd++fUSj0aqmBvf391NfX1/6vb6+nmPHjlXss2jRInbv3s2qVas4fvw4PT099Pf3U1tby9e+9jV+9Vd/dUqrateuXezatQuABx98cNwUS8MwZi310nXpSXK2Q86WOJpEqBwBO0dAWu4QQg3w+8Dv41BPlm8dH0bPpAjYOYYMP99Kh7lnfZgNjdW3ADrUk+UHp5L0ZBwagzp3LI5M6/lFurr7eXL/QZ5OBuny1YDuJm5oymFD6iw3xSUbt67ErLtl2seeCgEEDY2QKQgaGrqhI2va0MIxRNnd4qVmNj8f3jq8dbzZfPazn+XDH/4w69evJxQK8fWvfx2AP/7jP+b9738/mzZtYvv27aWQy5o1a/jTP/1Tbr/9dqSUmKbJl770pctCrIRS1Y1x/elPf0pNTQ0bN27k4MGD/NVf/RW2bfPhD3+Y22+/fdLnPv/887z44ot89KMfBeCpp57i+PHj3HvvvaV90uk0X/va1zh16hQLFy7kwoULfOQjH6Gvr4+DBw/y67/+67z66qt873vfqzpmdeHChTHbGhoa6L3IERBW2VTcvKNwpKqc62RbJcupNytpCGgVltPf7OtjKJnGrxw3Q1FJckKnJhLiE1vqpzi7y6sDFt88mUfX3MaseQmOhPcu8VVloWVSaV56/Sy7h02OBJorHluc7uB63zAbl7USam2d/htUBaYopp27gw4RAoJBGha00zc0NCfnnA4z+Xx463h7r6O8b6rH7FOVZaWUYvXq1aU7io0bN/Lwww9j2zaBwNR39PX19fT19ZV+7+vrG9O6KRQKlQqMlVJ87GMfo6mpieeee459+/Zx8OBB8vk8mUyGL3zhC3z84x+v+kVeLPmCOy/nuOJUzNjDyo+MbS/j1QGLbx5NoWfThJwcg0k/30yGeO+KMGvjJn0Zm1BRqACEhk859KWrr/vadcFG19yxIQB+HXIodl2wJxQr27I4duQ0u3tsDvrmYWvzofBnq8sPc73qYuvCWhoXL5mTNP9iM9mIKTC1gp98VNKEN5HXw8NjMqoSKyEEv//7v18yIcE1h6txAQIsXbqUjo4Ouru7qaur47nnnhsjNqlUCr/fj2EYPPHEE6xevZpQKMQHPvABPvCBDwCULKu5EKrymFO+XJwcC/Jl1tMkhuiPTwyjZwqWk6bhl3lyGYcfn3BYu6We+uwgQ74wfjWS2J3XDOpzg0DzhMctpzcrCY16232au73i9UiHCyfPsvdcghe0FhLmvJJABZwcW/IXuKbZz4Yt60lk5saK0oCwKQgXrShwu3N4nSY8PDymSdUxq/b2djo6Omhra5v2SXRd59577+Vzn/scUkpuueUWFixYwOOPPw7A7bffzvnz5/niF7+IpmnMnz+/5DKcCb7UEfLh8TPWpHIz9IpuPctRbqfvcZIiqmWs5SQqLKed2RN8y7eRXGF7Xug4aOzMngCqy6xrCGgM5iX+sgzuvHS3Awydv8CBEz0858S5EGgEf6O7FCVZm+3guhrJmtUL8Rc6SmimCbOcYakLN6MvZIBWFCSv04SHh8cMqDpm9cgjj/D000+zffv2MQHGW2+9dU4WN1PSe/+EwbbfANzu5JZUhGNxOnt6K8XJzo+49qYhTqP5mx8fGWM55YRGTT7FJ96xEnXqGK/uPcSuug30+WLU54fZ2X+ItVs3VJ16Pl7MKpIeZJPdzWtWiNfCldl683N93BBIsXHlPGLxmjHHm82u6z6tMJZDL0uLrbLTxFshJuGtw1uHF7N686jasjpy5AhNTU0cPnx4zGOXq1iJ/ACDWZu87QoVgGPkyKXTI4kRzmy0VHWZynISi5ezFli7/xkozpHaOr0aqbVxk/cugWdODRO6cJosOq9F2znpWwEFPaixklynDbB5cT3z5i2YU3ebRqGAtyIeJSAYduujvE4THh4es0DVV5I//uM/nst1zAlZrZZk1q4YnSHzGVco5oC1Vy3nV/Y+41pOZpR6K1GynIrMZI6UsvJ0HznGqY4Mb/jmM1i7qvSYz7HYLLvZMi/M8iWt6Fp1MbCLpaINUlEMdX0kHjXLHS08PDze3lQtVnIS95h2mV6YOuV66O+5ZOersJyK3SWmaTmNQUpSp05w4HQfz9HEG6F2KBsavDrfzbX1GletaCPoq53hK5gcAQTK2yAVKY7nCAS9pAkPj8uAz33uc3zjG99A13U0TaO1tZUNGzZUdKY4dOgQ73//+zl8+DDt7e0sWLCAp59+uvT4hg0bsG2bV1555c14CWOoWqze//73T/jYN7/5zVlZzGyTUNNPBpkMderYlG2OZqW7hFI4HWd59eh5ns9GeDnWjgqN+MNbrSGui+TYtLyVuujimZ2rCjQgXOh4rmtlYuTzu50m/NMvSPbw8HDJ7HuWxHf+GbvrAkbzPKL/7YMEt9x40cd7/vnn+f73v8+BAwfw+/309vby6quv8uEPf7hCrB555JFSpjVAIpHg7NmzLFiwYNxwz5tN1WL1xS9+seL3gYEBHnvssaob2b7VUaeOuQ1kdd0d0ZFKwpM/QHHHrPXlEwO9nH7tGC8M6eyJLSPrXw+FZg5RJ8M15jBbljayoL71klgw4yZMAASCrkh54zk8PGZEZt+zDHz5z8EwEZEYdn+v+/t9/+OiBaujo4OGhoZSn8CGhga2b99ObW0tu3fv5tprrwXgW9/6Fv/1X/9Vet6v/Mqv8M1vfpPf//3f51//9V95//vfzz//8z/P/EXOElX77xobGyv+rVixgo997GP8+7//+1yu7/Jh/zOuUJmFCcOmz/19/zMzOqyWTjCwdzc/+sEzfPrFHH+ureep+Fqyuh9D2mxRPdzXluNPb6jn7muXsLAhOqdCVSzgbfALGgMaIUO459OEW8Tb0IyorfOEysNjFkh855/BMNEKLnQtEATDdLdfJLfffjtnz55lxYoV3H///fzsZz8DXO/YI488AsALL7xAfX09y5eP3Gi/5z3vKXVi/973vse73/3uGbyy2WdGqVrpdJrhWUp7vuwZHpi1oYcinyOxfzcvHOvkGaONU9GroG7k8eXOANc0mWxY3EjIHJtuPhfohTZIYZ1KV5+mFTqfh7zxHB4es4zddQERiVVsE/4AdtfYVnHVEolE2L9/P08//TRPPvkk733ve3nwwQd53/vexw033MDnP/95HnnkkTGhnbq6OuLxOI888kipKcPlRNVi9Xd/93cVd/S5XI7Dhw9z8803z8nCLjtmOvRQOoiTR3j1RAfP23EOxZch4yPzupqcJNfWOGxe2kTjHHQ2nwifLqjzCQKjXX1epwkPjznHaJ6H3d9bUSyvclmM5pnVbOm6zo4dO9ixYwfr1q3j61//Ovfccw/t7e387Gc/4zvf+Q7PP//8mOe9973v5bd+67f42te+NqPzzwVVi1VLS0vF736/n3e84x2sX79+1hd1WXIxQw+VQj9/mjeOnOCFZIAX6laRjo10Lw7JHFsDGTYvrmdJvOmSiULR1Rc2BM0hg4FcedKEzy3i9ZImPDzmnOh/+yADX/5zZNa1qFQuC7ZF9L998KKPeeTIETRNK7n4Dh06VOqa/v73v5/f/d3fZenSpRUjmorcdddddHR08HM/93PjNgJ/M6larH75l395Ltdx2TOdoYd6XxeDr77Cnj7J07Wr6AldDwWLWleSdfow21a2sCQWwtTqxjx/rtCAUGG4YYWrD6ruNOHh4TF7BLfcCPf9j1nNBkwmk/z2b/82g4ODGIbBsmXLSmPrf/mXf5nf+Z3f4e/+7u/GfW40GuUP/uAPLvrcc0nV7Zb+6Z/+iRtvvJGVK0d62B05coTnn3+ee+65Z67WNyP2PLN7zLbZbC9UjpYcwnr1RQ5eSPJMaDHHYgsrHl9MgmtaAmycX0PUFHO2jvHQCwW84fICXgAhqGubT382hzDe3K7nb4V2Ot46vHV47ZbePKq2rJ599lk+9KEPVWxbsmQJf/EXf3HZitV0qaaOqhyRy6C//hKvn+7iGa2Fg3VXY7eMvKX1KsM1ccGW9jgtwfCleAkVGMIdyxEaHY/SBAQjEAqj19YhLoOLgIeHh8dkVC1WxVH25UgpqdIwu+ypuo7KsfGdeI1zx07yfC7Gcw3rSDZdVXo4oCw2h/NsWRRnWU2o0pK5RPg0iJqCgD7q3F47JA8Pj7coVYvVqlWreOSRR/jVX/1VNE1DSsm3v/1tVq1aNfWT3wqU11FB4Wfe3d6+FPPcSRKvvcruIYOnGq6is+4dpadqSrLGl2HrghjrG0L4RovEJSKou/GoMec3TTf93O+1Q/Lw8HhrUrVYffjDH+bBBx/kIx/5SMlvG4/HL9tg3GiKLr7BYrfz0S6+ceqoDOkgO89x6Jvf5anaVbxesxPKSiJaSXNDW5jNLWFqfNFL9EoqEUCoMIXXGJ004Q+4M6QKlexvBvvPJ3n0cD9dSYvmiMldq+vY3BaZ+okeHh4eZVQtVvX19fzv//2/OX78OH19fdTX17Ns2bLLtoltOeUuPhEMocZz8RXqqDQBZmqYY75Gnmm4hr0r1mBpI8kHQSdHSAfl85MnRHPUpMZ36d+DcafwgttdIxB0RepNHhW//3ySf9zXhaEJIj6N/ozNP+7r4iPgCZaHh8e0qFqsTp8+TSQSYcWKFaVtvb29JJNJ2tvb52Jts0eZi08IgSp38S1ejsimCdTW0tE7wHP1a3lm0QaGfSMXU59yqBEWlhkgEvKXXGk5R7Hrgs3a+KUTBaMss29s0kTYFSn98ug08ejhfgxNEDBcMQ8YgqwtefRwvydWHh4e06Jqk+Dv/u7vcEYNKrRte0yD28uS4QG3kLccXSfQfRbnsf/Ls9/9EZ/haj599Uf4z/k3MeyLIJRilRjmQ0t9/K9rozi+ABGzUiB8GvRmL36y8HTwaVDnEzQHNSKmGFmHrkO0BhpaENGay0aoALqSVuUoEcCvC7qS1pu0Ig+PtwednZ28733vY+nSpaxZs4Z3vetdHD16lNOnTyOEqKiz+tjHPlbqWHHPPffQ1tZGLpcDXINkImPk3nvvpampiauuumrcxwE++9nP8pd/+Zez8pqqtqx6e3tpbq4c6NfS0kJPz6WbF3XRFFslGSa+TAKZTPBieCE/a/8lXq1dghIjmj1Pz3PNvBBbGk3i/pG7/4aAxmBe4i/Tgrx0t88lwfHmR8FbYoZUc8SkP2MTMMradDmK5sib65708LiceO5kL/+85w0uDGWZVxPgg9cs5IYlDRd9PKUUd911F7/2a79Walx76NAhurq6WLBgAU1NTfzt3/4tH/nIR/D5xjYB0HWdf/qnf+K+++6b9Dz33HMPH/vYx8aUNM0VVV9p6+rqOHnyZMW2kydPEo9X2RvvzUIpjCUrCA92cSFl8/XarXxsw2/zpVW/zCvxZSihERM2tzYJ/mBdgE9treUd8/3E/ZVvzc55Bo50L7ZKKXKOwpHu9tlGAyIGNAcEdX6tUqh8fog3IOqbEJd53767VtdhS0XWdkscsrbEloq7Vl+6rh0eHpczz53s5c93HaU3lScWMOhN5fnzXUd57uTF1z4++eSTmKbJRz/60dK2DRs2lPq4NjY2ctttt/H1r3993Od/4hOf4K//+q+xbXvS82zbto26ukv3Xa76SnvHHXfwF3/xF/ziL/4izc3NdHV18b3vfY+77757Ltc3IyLP/ojOE6d4JtDO01f/FoP+kVQ+Uzmsr9W4pjXA6prQ2PZDo1gbN3nvEth1waY3K2kIaOycZ8xqvKrYaSJ0GSdNTIfNbRE+Al42oIfHBPzznjcwdY2g6bpsij//ec8bF21dvfLKK2zevHnSfT75yU/yzne+k3vvvXfMYwsXLuSmm27in//5ny+rMSFVi9XOnTsJh8P85Cc/KWUDfuhDH+K6666by/XNiM+kl3FmeWVX+FUR2NTkY1O9QdCYnlWyNm7OSTKFT3Pro8Z0Pr8Mkyamy+a2iCdOHh4TcGEoSyxQeRkOGBoXhrNzet7FixdzzTXX8I1vfGPcxz/1qU/xi7/4i9xxxx1zuo7pMC0f1vXXX8/1118/V2uZdc5EWgFoNhy2tgS4ptFgSVPthD35Xh2w5tRyKqe8PsocbdV5nSY8PN4WzKsJ0JvKlywqgKwtmRe7+KkHa9eu5d/+7d+m3O9Tn/oU73nPe9i2bduYx5YtW8aGDRv41re+ddHrmG2mJVaDg4McP36cRCJR0Wbp1ltvnfWFzQbbmnWubTRZFNGmjO28OmDxzZN5dM3tTD6Yl3zzZJ73LmFWBavY+bwlbJCwRwnRWyBpwsPDY/b44DUL+fNdRwHXosraEsuRfPCahVM8c2JuvfVWPvWpT/HVr36V3/iN3wBg7969pNPp0qgQcLsSrVmzhu9///tcc801Y47zR3/0R5eVZVX1bfuePXv47d/+bb71rW/xla98hR/96Ed89atf5emnn57L9c2I9y4J0B7Vq7rw77pgo2tuarUQbvadrrnbZwNDQI0paA4KanxaZbcJnw/i9W+JpAkPD4/Z44YlDfyPnStoCPsYztk0hH38j50rZpQNKITg0Ucf5cc//jFLly5l7dq1fPaznx23K/wf/dEfce7cuXGPs3btWjZt2jThed7//vdz/fXXc+TIEebPn89DDz007n5/+qd/yvz580v/LpaqR4T83u/9Hu95z3u4/vrr+fCHP8zDDz/Mk08+ydmzZy9Z6uJ0mc6IkP+5P0VoVKGtUoq0Df//zRffMb0YjxodH4vH4wykMxCOIHxvXjukt8LoBW8d3jreCuvwRoTMLVVbVr29vWPiVdu3b+epp56a9UW9GTQENPKj6ntnUkcV1KHRL2gMaGMTOQJB9KYWRLz+TRUqDw8Pj7cKVcesYrEYg4OD1NbW0tjYyNGjR4lGo2PGhkzEoUOHePjhh5FSctttt3HnnXdWPJ5MJvnyl79MV1cXpmly3333sXDhQnp7e/nSl77E4OAgQgh27tzJu971rmm9SBhJnujPZ6jzMSZ5Yuc8g2+ezJND4dNcobqYOqoJkyaEgGAQQlGEYXgTeT08PDymQdVX4ttuu43XX3+d6667jjvuuIM/+ZM/QQjBL/zCL0z5XCklDz30EJ/+9Kepr6/nD//wD9myZUuF//LRRx+lvb2dBx54gPPnz/PQQw/xmc98Bl3X+eAHP8iSJUvIZDJ88pOfZP369dPyfZYnT0RMg8G8PSZ5YiZ1VIKRcfFjOp9rmpt+Hg4jtLdm+rmHh4fHm03VYlVuCW3fvp21a9eSzWYrRKNYfzWa48eP09LSUmrXdMMNN7B3796K5547d4677roLgLa2Nnp6ehgcHCQej5e6ZASDQdra2ujv769KrNSpY4jFy8dNnsgxtgntdOuoJux8Dl76uYeHh8csctFX0YaGhjGC8d//+38fd9/+/v4KEauvr6e/v79in0WLFrF7t5sQcfz4cXp6esbs093dzalTp1i2bFl1i9z/DOA2mx09xWMmTWj1ssy+mCkqhco0oSYODc2IcMQTKg8PD49ZYFYb202UWDje9tHp2XfeeSdf+9rXeOCBB1i4cCGLFy+umJWVzWb5/Oc/zz333EMoFBp9OAB27drFrl27AHjwwQchMUxNLEZzOM9QXuLX3eMZukHOkTSHNWpisXGPNR6mJoj6NEKGGLN+4Q+gRWMIf3XFfIZh0NBw8emps4W3Dm8d3jreeut4OzKrYjVRfVB9fT19fX2l3/v6+sY0wA2FQtx///2AK24f+9jHaGpqAtxRJJ///Oe5+eabufbaayc8/86dO9m5c+fIhqibpn5Ls+CbJx1sxyFkGqQtG0fCLQv0CbtZlOPTIGq67sN8HvLlDwaCEI4i0CCRdP9VwVshFddbh7cObx3Vr+NySl3v7OzkE5/4BHv37sXv99Pe3s7f/M3f4PP5WLx4MV/4whf47d/+bcAdEbJlyxbuuece7rnnHn784x9z8uRJ/H4/vb29bNmyhdOnT1ccv1iy1NnZiaZp/OZv/ia/8zu/M2Ydn/3sZ4lEIvz+7//+jF/TJfFRLV26lI6ODrq7u7Ftm+eee44tW7ZU7JNKpUpdfp944glWr15NKBRCKcU//MM/0NbWVlUyRwWbbwKKyRM+an0aSUtS69N47xLflPGp8vTzwOgRHYEgNDQhauveUs1lPTw8Li/eOJXge98+zTceOsb3vn2aN04lZnS84oiQHTt2cOLECV577TX+7M/+jK6uLoDSiJB8Pj/u84sjQibDMAw+//nPc/jwYV544QW+9KUv8dprr81o3VMx+/MtxkHXde69914+97nPIaXklltuYcGCBTz++OMA3H777Zw/f54vfvGLaJrG/PnzS+3tjxw5wlNPPcXChQt54IEHALdyerLK6iKlkfWMJE9MVBRceg5u+nl4vPRzGLGkPIHy8PCYIW+cSvDMk51omsDn10ilbJ55spObgIWLoxd1zIlGhIA78b2xsZEbb7yRr3/966V2TOUUR4SM91iR1tZWWlvd3qvRaJTVq1dz/vx51qxZ8/+1d/9BTd/3H8CfnySkkQITggERBMUf0NVSW06sVW4IcnadSmd3tfOqlNVz/ljVWU6UnYdnVU7UdrbSao8D691cu3VTr3d6iKWiuK/SKgzXOqETJwYBEyi/5Efy+Xz/YKTGoA0YPvkQn487byR8kjxxNE8/P/J+DSqzM2Q5ZwUAzzzzjEPBJCcn276eNGkS9u7d6/C4qKgoWRZTVAF4XNM7osNhXIggACO8e1c/18jS70T0CKj4ygSVSoCXV+9BLi8vAT09Iiq+Mg26rOQeEVJTU4NLly498BSNK7j0nXfPnj2ufDpZqIXez0d5awBVv5efP/6/y8/5GSkicq3Wlh5o7xn0qtEIaG3pGdLXddWIkLa2NixcuBDvvvsu/AZwsdpgPLCsfmyscZ8PPvgAAIbVVTIaoXelCe97Z0gBXP2ciGTh6+eF9nYLvLx+eJ+xWCT4+g3+NINcI0J6enqwcOFCLF68WJYhvA8sq76rRTyJVi0gQOu4sCwA4DFd76G+x7heHxENvZhYPc4W30JPjwiNRoDFIkEUJcTEOi6u4Cw5RoRIkoTf/OY3iI6Ovu/na13tgWU1lCfL5KZT9e5JBXlr0NR1z8j4Ef8bGa/hRRNEJJ+x43wxE73nrlpbeuDr54WYWP2gz1cBP4wIWbt2LbKzs6HT6WyXrt8rMzMTU6dO7fd5+kaEXLx40eF7paWlOHToEKZMmWK7eGP79u39rtv69ttv2732/UaS/OjP5eyIEKD3RNq3337rMHzxlVdeGdSLD7Wys+cx4p6FZf39/dHU1OT281HD4XMjzMEczOF8DiV9zsoTOX2BRVFREQ4ePIinnnoK5eXlePrpp/HPf/7T4fNSShKkc7yyT+hbDonno4iIhg2nPxR89OhRbNq0Cenp6dBqtUhPT8fvf/97qNXKvUpO3c80XrVhNKfxEhENM06XVUtLC6KjowH0HhMVRRFTp07F119/PWThXEI3AtCPghAwyul1+4iISFmcPgwYEBCAhoYGGAwGjB49Gl999RV8fX2hUfKHZAOD+CFeIiIP4PQ7+YIFC3Dz5k0YDAa8/PLL2LNnDywWC15//fWhzPdQWFRERJ7B6XfzmpoazJzZuzDs1KlTkZ+fD4vFAp2Oh9aIiGhoDWjV9ZycHLz55pv49NNP0dDQwKIiIlKgW7duYdGiRYiMjMQTTzyBn//857h69SpqamogCALee+8927arV69GQUEBACA1NRVjxoxBV1cXAOD27duIiIjo9zUiIiJsn7O631XhWVlZ2LVrl0t+Jqf3rFJTU7FkyRJcvnwZZ8+eRWZmJgwGA2bNmjXw0R1ERAQAuHLlCkpKStDU1AR/f3/Ex8cjKipq0M/XNyJk6dKl+POf/wwAKC8vR319PcLCwmwjQpYvXw6tVuvw+L4RIc4st1dcXCzbMnsD2rNSqVR46qmnsHLlSuzevRu+vr44dOjQUGUjIvJoV65cwbFjx9Da2ooRI0agtbUVx44dw5UrVwb9nPcbETJr1iwAwKhRo5CYmIiDBw/2+/i+ESF98wWVYkBl1dnZiZKSEuzYsQNr1qyBWq3GqlWrhiobEZFHKykpgVqthlarhSAI0Gq1UKvVKCkpGfRzOjsiZPfu3bBarQ7fu3tEyIMIgoDk5GQ8++yzOHDgwKDzOsvpw4B79uzBpUuXMH78eDz//PNYtWrVkC8JT0TkyZqamjBixAi7+7y8vHqXhBtCrhgRUlpaipCQEDQ0NGDOnDmIiorqdwV3V3G6rMaPH48lS5YMqzEgRERK5u/vj9bWVrtzRz09PfD39x/0c8o1IqRvLUSDwYCXXnoJFy5cGNKycvowYEpKCouKiMiF4uPjYbVa0d3dDUmS0N3dDavV+lBv+rNnz0ZXVxc++ugj231lZWU4ffq03XZ3jwjpT2Zm5n2v5Gtvb0dra6vt68LCQjz55JODzuyMAZ2zGm6+vtnm7ghERPcVFRWF+fPnw9fXF3fu3IGvry/mz5//UFcD9o0IOXnyJCIjI/HTn/4UWVlZ/a4Kn5mZed+RHX0jQvpTX1+PmTNnIiYmBtOmTcOLL76IuXPn9rvt22+/jdDQUNufQf9cAxkRMtykffx/eDtprN19w2HUAHMwB3MMvxwcETK0PHrPqr6tx90RiIjIBTy6rIJ8OPmXiMgTeHRZvRQd4O4IRETkAh5dVs+O8XF3BCIicgGPLisiIvIMLCsiIlI8lhURkYeRY0RIWloaDAaDw4eBzWYz5syZg4kTJ2LOnDn9Lh1VU1Mz4A8Rs6yIiNxINFfAWpENy/n1sFZkQzRXPNTz9Y0I+dnPfobvvvsO33zzDbZv3476+noAsI0I6e7u7vfxfSNCfkxqaipOnDjhcH92djYSExNRVVWFxMREZGdnP9TP00e2siovL8eaNWvwu9/9DkeOHHH4fltbG3JycvDWW29h48aN+O9//+v0Y4mIhiPRXAGx+hCk7mZA8zik7maI1YceqrDkGhESHx+PgADHK66PHj2KpUuXAgCWLl3qsvdsWcpKFEXk5eVh06ZNeOedd1BaWuqwxMff//53REREYNeuXXa7pc48lohoOJJuHAcEDaB+DBCE//2vpvf+QZJrRMj91NfXY/To0QCA0aNHo6GhYVDPcy9Zyqq6uhrBwcEICgqCRqPBjBkzUFZWZrdNbW0tpkyZAgAYM2YMGhsb0dzc7NRjiYiGI6mzEVDdM61Xpe29fwg5MyIkJycHoigOaY6BcHpEyMMwm83Q6/W223q9HlVVVXbbhIeH4/z584iKikJ1dTUaGxthNpudemyfoqIiFBUVAeg9btrfKvEajUYRq8czB3MwB3MIulG9hwDVj/1wp9gNQTdq0M8p14iQ+wkKCkJdXR1Gjx6Nuro6GAyGAT9Hf2Qpq/7WyhUEwe52SkoKCgoKkJ6ejrFjx2LcuHFQqVROPbZPUlISkpKSbLf7W3ByOCyIyRzMwRzDL8dgFrIVwl6AVH0IsKJ3D0vsBiQLhLAXBp1x9uzZ2LRpEz766CMsW7YMQO+IkI6ODoSHh9u2u3tEyLRp0xyeJzMz84HDF+9n/vz5OHjwIDIyMnDw4EEsWLBg0D/L3WQ5DKjX62EymWy3TSaTw3Axb29vrFy5Ejk5OVi9ejVaWlpgMBiceiwR0XCkCoiBasJrELQjAUs7BO1IqCa8BlVAzKCfU44RIQDw6quv4rnnnsO///1vhIaGIi8vD0Dv+bCTJ09i4sSJOHnyJDIyMvp9fN/j+v785S9/eeDPJcueVWRkJOrq6tDQ0ICAgACcO3cOb775pt027e3teOyxx6DRaHDq1ClER0fD29vbqccSEQ1XqoAY4CHKqT8hISH3PYR3+fJl29cxMTF256X6Lmzr87e//e2+r3H48OF+79fr9Th16tQD80VERKCnZ2BTMWQpK7VajbS0NGzbtg2iKCIhIQFhYWEoLCwEACQnJ+PmzZt4//33oVKpEBoaarvs8n6PJSKiR4dHD180Go0O9w2HY9/MwRzMMfxycPji0OIKFkREpHgsKyIiUjyWFRERKR7LioiIFI9lRUREiseyIiIixWNZERGR4rGsiIhI8VhWRESkeCwrIiJSPJYVEREpHsuKiIgUj2VFRESKx7IiIiLFY1kREZHisayIiEjxWFZERKR4LCsiIlI8lhURESkey4qIiBSPZUVERIrHsiIiIsVjWRERkeKxrIiISPFYVkREpHgsKyIiUjyWFRERKR7LioiIFE8j1wuVl5cjPz8foigiMTERKSkpdt/v6OjA3r17YTKZYLVaMW/ePCQkJAAAPv/8c3zxxRcQBAFhYWFYuXIltFqtXNGJiMjNZNmzEkUReXl52LRpE9555x2UlpaitrbWbpsTJ04gNDQUOTk5yMrKwscffwyLxQKz2Yzjx48jOzsbu3fvhiiKOHfunByxiYhIIWQpq+rqagQHByMoKAgajQYzZsxAWVmZ3TaCIKCzsxOSJKGzsxM+Pj5QqXrjiaKI7u5uWK1WdHd3w9/fX47YRESkELIcBjSbzdDr9bbber0eVVVVdtvMnTsXO3fuxPLly3Hnzh2sW7cOKpUKAQEBmDdvHlasWAGtVouYmBjExMT0+zpFRUUoKioCAGRnZyMwMNBhG41G0+/9cmMO5mAO5iDnyVJWkiQ53CcIgt3tiooKhIeHY/Pmzaivr8fWrVsRFRUFURRRVlaGffv2wdvbG3v27EFJSQni4+MdnjMpKQlJSUm227dv33bYJjAwsN/75cYczMEcnpUjJCRE5jSPFlkOA+r1ephMJtttk8nkcCivuLgYcXFxEAQBwcHBMBgMMBqNqKyshMFggJ+fHzQaDeLi4nD16lU5YhMRkULIUlaRkZGoq6tDQ0MDLBYLzp07h9jYWLttAgMDUVlZCQBobm6G0WiEwWBAYGAgqqqq0NXVBUmSUFlZiTFjxsgRm4iIFEKWw4BqtRppaWnYtm0bRFFEQkICwsLCUFhYCABITk7GwoULkZubi/Xr1wMAFi9eDD8/P/j5+WH69OnYsGED1Go1IiIi7A71ERGR5xOk/k4oeQij0ehw33A49s0czMEcwy8Hz1kNLa5gQUREiseyIiIixWNZERGR4rGsiIhI8VhWRESkeCwrIiJSPJYVEREpHsuKiIgUj2VFRESKx7IiIiLFY1kREZHisayIiEjxWFZERKR4LCsiIlI8lhURESkey4qIiBSPZUVERIrHsiIiIsVjWRERkeKxrIiISPFYVkREpHgsKyIiUjyWFRERKR7LioiIFI9lRUREiseyIiIixWNZERGR4rGsiIhI8TRyvVB5eTny8/MhiiISExORkpJi9/2Ojg7s3bsXJpMJVqsV8+bNQ0JCAgCgvb0dH374IW7cuAFBELBixQpMmjRJruhERORmspSVKIrIy8vDH/7wB+j1emzcuBGxsbEIDQ21bXPixAmEhoYiIyMDLS0tWLNmDWbNmgWNRoP8/Hw8/fTTWL9+PSwWC7q6uuSITURECiHLYcDq6moEBwcjKCgIGo0GM2bMQFlZmd02giCgs7MTkiShs7MTPj4+UKlU6OjowLfffovZs2cDADQaDR5//HE5YhMRkULIsmdlNpuh1+ttt/V6Paqqquy2mTt3Lnbu3Inly5fjzp07WLduHVQqFRoaGuDn54fc3Fxcv34d48ePR2pqKnQ6ncPrFBUVoaioCACQnZ2NwMBAh200Gk2/98uNOZiDOZiDnCdLWUmS5HCfIAh2tysqKhAeHo7Nmzejvr4eW7duRVRUFKxWK65du4a0tDRMnDgR+fn5OHLkCBYtWuTwnElJSUhKSrLdvn37tsM2gYGB/d4vN+ZgDubwrBwhISEyp3m0yHIYUK/Xw2Qy2W6bTCb4+/vbbVNcXIy4uDgIgoDg4GAYDAYYjUbo9Xro9XpMnDgRADB9+nRcu3ZNjthERKQQspRVZGQk6urq0NDQAIvFgnPnziE2NtZum8DAQFRWVgIAmpubYTQaYTAYMHLkSOj1ehiNRgBAZWWl3YUZRETk+WQ5DKhWq5GWloZt27ZBFEUkJCQgLCwMhYWFAIDk5GQsXLgQubm5WL9+PQBg8eLF8PPzAwCkpaVh7969sFgsMBgMWLlypRyxiYhIIQSpvxNKHqJvb+xuw+HYN3MwB3MMvxw8ZzW0uIIFEREpHsuKiIgUj2VFRESKx7IiIiLFY1kREZHisayIiEjxWFZERKR4LCsiIlI8lhURESkey4qIiBSPZUVERIrHsiIiIsVjWRERkeKxrIiISPFYVkREpHgsKyIiUjyWFRERKZ5HTwomIiLP8MjtWWVkZLg7AgDmuBdz2GMOe8xBj1xZERHR8MOyIiIixXvkyiopKcndEQAwx72Ywx5z2GMO4gUWRESkeI/cnhUREQ0/LCsiIlI8jbsDDJXy8nLk5+dDFEUkJiYiJSXF7vs3b95Ebm4url27hkWLFmH+/PluyXHmzBkcPXoUAKDT6fDGG28gIiJC9hxlZWX45JNPIAgC1Go1UlNTERUVJXuOPtXV1cjMzMS6deswffp02XP861//ws6dO2EwGAAAcXFxePnll2XP0ZeloKAAVqsVvr6+2LJli+w5jh07hjNnzgAARFFEbW0t8vLy4OPjI2uOjo4O7N27FyaTCVarFfPmzUNCQoJLMziTo62tDR988AHq6+vh5eWFFStWYOzYsS7PQXeRPJDVapVWr14t3bp1S+rp6ZHeeust6caNG3bbNDc3S1VVVdKf/vQn6ejRo27LceXKFam1tVWSJEm6ePGitHHjRrfkuHPnjiSKoiRJklRTUyOtWbPGLTn6tsvKypK2b98u/eMf/3BLjsuXL0s7duxw+WsPNEdbW5u0du1aqbGxUZKk3t9bd+S4W1lZmZSVleWWHJ999pl06NAhSZIk6fvvv5dSU1Olnp4e2XN8/PHH0qeffipJkiTV1tZKW7ZscWkGcuSRhwGrq6sRHByMoKAgaDQazJgxA2VlZXbb/OQnP8GECROgVqvdmmPy5Mm2f51OnDgRJpPJLTl0Oh0EQQAAdHV12b6WOwcAHD9+HHFxcfDz83N5hoHkGGrO5Dh79izi4uIQGBgIoPf31h057lZaWornn3/eLTkEQUBnZyckSUJnZyd8fHygUrn2bcyZHLW1tZgyZQoAYMyYMWhsbERzc7NLc5A9jywrs9kMvV5vu63X62E2mxWf44svvsDUqVPdluPChQtYu3YtduzYgRUrVrglh9lsxoULF5CcnOzy1x9IDgC4evUq0tPTsX37dty4ccMtOerq6tDW1oasrCxs2LABp0+fdkuOPl1dXSgvLx+SQ7PO5Jg7dy5u3ryJ5cuXY/369Xj99dddXlbO5AgPD8f58+cB9JZbY2OjW95jHiUeWVZSP1fjD8WegitzXL58GcXFxVi8eLHbckybNg3vvvsu0tPT8cknn7glR0FBARYvXuzyN6CB5hg3bhxyc3ORk5ODuXPnIicnxy05rFYrrl27hoyMDGRmZuKzzz6D0WiUPUefr7/+2u5ogNw5KioqEB4ejv379yMnJwd5eXno6OiQPUdKSgra29uRnp6O48ePY9y4cUP6O0seeoGFXq+3O5xmMpng7++v2BzXr1/H/v37sXHjRvj6+rotR58nnngC+/btQ0tLi0sPxTmT47vvvsMf//hHAEBLSwsuXboElUqFadOmyZrD29vb9vUzzzyDvLw8t/x96PV6+Pr6QqfTQafTITo6GtevX0dISIisOfqUlpZi5syZLnvtgeYoLi5GSkoKBEFAcHAwDAYDjEYjJkyYIGsOb29vrFy5EkBvua1evdp2MQ4NDY/8p0BkZCTq6urQ0NAAi8WCc+fOITY2VpE5bt++jV27dmH16tUufQMaaI5bt27Z/kX5n//8BxaLxeXF6UyOffv22f5Mnz4db7zxhkuLytkczc3Ntr+P6upqiKLolr+P2NhYXLlyBVarFV1dXaiursaYMWNkzwH0Xon3zTffDNl/S87kCAwMRGVlJYDe/4+MRqPLS8KZHO3t7bBYLACAU6dOITo62u4fOOR6HruCxcWLF3Hw4EGIooiEhAT88pe/RGFhIQAgOTkZzc3NyMjIwJ07dyAIAnQ6Hfbs2ePyX7gfy/Hhhx/i/PnzthPoarUa2dnZLs3gTI4jR46gpKQEarUaWq0Wr7322pBcuv5jOe62b98+PPvss0NyfuTHcpw4cQKFhYW2v48lS5Zg8uTJsucAei8bLy4uhkqlwuzZs/Hiiy+6JceXX36J8vJyrF271uWv72wOs9mM3NxcNDU1AQAWLFiA+Ph42XNcvXoV77//PlQqFUJDQ/Hb3/52SA6N0g88tqyIiMhzeORhQCIi8iwsKyIiUjyWFRERKR7LioiIFI9lRUREiseyIrqPAwcO4K9//au7YxAReOk6EYDezxCdOnUKW7dudXcUIuoH96zokWC1Wt0dgYgeAvesyGOtWrUKc+bMwdmzZ2E0GrFw4UJ8+eWX+P7776HX6/Hqq69i2rRpqK2txYYNG2CxWKDVaqFWq1FQUIB9+/ZBr9dj0aJFAICioiIcPXoUbW1tiIqKwrJlyxAQEODmn5Lo0cA9K/JopaWlyMjIQEFBAUJCQrBlyxYUFBTgV7/6Fd577z00NTUhNDQUy5Ytw6RJk3Do0CEUFBQ4PM/ly5dx+PBhrFu3DgcOHMCoUaNsC+4S0dBjWZFHe+GFFxAYGAitVovnnnsOAQEBUKlUmDFjBoKDg1FdXe3U85w5cwYJCQkYP348vLy88Otf/xpXr15FQ0PDEP8ERAR46IgQoj59CwQDwOnTp/H555+jsbERANDZ2YnW1lannqepqQnjxo2z3dbpdPDx8YHZbOZoCCIZsKzokdDY2Ij9+/dj8+bNmDRpElQqFdLT0/sdtNcff39/3L5923a7s7MTbW1tPGdFJBMeBqRHQldXFwRBsA1PLC4uthtVP3LkSJjNZtuMonvNnDkTxcXFqKmpQU9PDw4fPowJEyZwr4pIJtyzokdCaGgofvGLXyAzMxMqlQrx8fF286mefPJJ24UWKpUKeXl5do+fMmUKXnnlFezevRttbW2YPHnykM51IiJ7vHSdiIgUj4cBiYhI8VhWRESkeCwrIiJSPJYVEREpHsuKiIgUj2VFRESKx7IiIiLFY1kREZHi/T/j54WvQ+enIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 442.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    select_size(results_3a_cnn, 'S')\n",
    ")))\n",
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    select_size(results_3a_cnn, 'L')\n",
    ")))\n",
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    results_3a_cnn,\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x245e4496848>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAFgCAYAAAAFPlYaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAACUvklEQVR4nOz9eZxcdZ3vjz8/55xau3pLdzp7SEIISdgxIAKyJWRURgzqMIPjBcTvyMBwHXUuXxW5jN7fyMVRxHFcZsYvIi5zFWcE7zijQkBBQSVsAhISAgmQhe703rWfcz6f3x/n1F6d9FJdVd39eT4elVN11s/pdJ9Xvd+f9yKUUgqNRqPRaJoYo9ED0Gg0Go3maGix0mg0Gk3To8VKo9FoNE2PFiuNRqPRND1arDQajUbT9FiNHkAjOHjw4Iyef8GCBQwODs7oNerFXLkXfR/Nx1y5l6VLlzZ6CPMCbVnNAIYxd36sc+Ve9H00H3PpXjQzj/5t0Wg0Gk3To8VKo9FoNE2PFiuNRqPRND1arDQajUbT9Gix0mg0Gk3To8VKo9FoNE2PFiuNRqPRND1arDQajUbT9Gix0mg0Gk3To8VKo9FoNE2PFiuNRqPRND1arDQajUbT9MzLqusazWzjieGX+FHvY/T/YZRuq413LzqbTR3HNXpYTcvAQYvXdgZJJwzCLZKVG7J0LXWmfV6l/JcEKUG6ogaj1UwELVYaTZPzxPBL/PNrP8USBm3BKEPZMf75tZ8CaMGqwsBBi91PhDFMhRVUZNOC3U+EWbcpPSHByomRUp4gKSny4qSUAFWHm9BUoMVK0zBm6tvvXONHvY9hCYOwGUQIQdgMknaz/Kj3MS1WVXhtZxDDVJj+081bKl7bGcz/flUTJG/pvdc0H1qsNA1hut9+5xO9mWFazXDJupARoC8z3JgBNTnphIEVVKgiC0gISMUN0kmhBWmWosVK0xAm8u13tjDTFuKiUAdD2THCZjC/LiNtekIdNbvGbKV4/ihnHQXDkmxGYJqF/VzHWy8dLVKzFR0NqGkI6YSBYZauM0xv/WwiZyFm06LEQhw4WLvvge9edDaOkqTdLEop0m4WR0nevejsml2jWZESXNcTGzsL2YwgkxKkE4LUmEFqzCCdMMimDOyMwLUFS9bYSFfgOp6YuQ5IKVh6rN3o29FMA21ZaRpCuEXSeijLmkNpImlJKmzwypIwY0uCRz+4iaiHhZibl/pR72P0O6N0B+dONKCSIFVhrqj881To6HFZfWKGgy8HyKQMQhHJ0mOzdPS40x+vUrhIXFV4aeqDFitNQzg+mqD9lSy2UMQNRSAt2fBKgpFjbWD2uGpy8yPFzISFuKnjODZ1HEd3dzf9/f01PXetyQUuFIIYhDd/pIrWK4hbilR8Zizpjh53yuLkKomLi6sUripeSqTSoYCNQouVpiGEnx1hLOBgqCimMsmaLmmRJPysBW/paPTwJky4RZJNi7xlBSBdb/1cpFSECtZQPqpuEqHdjXruS6WQuDhKIZWLoyRSyfxSy1FzosVK0xDkoEMykEIY6fw6JRXWYGRWTaSu3JBl9xNhQGGYnlBJV7ByQ6bRQzsqOeEpt3jwLaHKbbMvx0gqha0cbOXgSImtnJpZR8n+ECOvtnLf40m2/UW0JufUjM/8FCtXgVl7V1MuKiybsglGojpv6AgcahlhQbqFrFH4+YRkgEMtI6ygu4EjmxxdSx3WbUqXRQNmGvb/XiwyxZ/LrSAlRcMsm5nEUS62cslKB1s6MzanlOwPMfBiJ8JQRGMzcglNGfNSrLL7BQhQlidaygRlgrAAQyCEl5dBbgkgvL9skf/HX+2/Hzxk8dJTXt5QMASZlGDXjkLekJg90zB14eET9/AnvzsNsMiaDkHXwnINHj5xD+/n2EYPb1J0LXVmTJzKLRw7q7CzRWIzyy2f6ZCzmhzlYvviVC/n68irrQhDIUwQ+o+7LsxLscp/88x6v2S+LnkYyhevgohhAuLIzqlXXwgihMIwPH++t1Tsez5ItLXoT0jkBM8XP//CeXE0QAhVIZiiWDjnAOtPX8P/Z/+ad+06lUWJVnpbxvjx8c/w5tNPavTQZoQKt1pR4EF+PYXtKJH/XEw6BHZ6NjlKa0ex1eRIB6cBkXhKgXQEdsLy3L7acVI35qVYHREJQgK2Ko1Jy4mYJcAoFjFvr0zKwApURoVlUmUPlvxDSeQ+VmEcVRIw3Gd6IblJg3BUsnStTediJ2/xFUROVViBJacqEklPIKvvN1Ns6jgO3gxfW/Ur+jLD9IQ6GhqOXSIYUBANKpd5IfH3qzj+KIKjOTpKKWwcbOn6L7tmVpOSIB0DaRve0jFwbVG6rnyZf1/4apsfT1uNBqY5IlqsJoovYsIue/KYCmVAzHLIZgUiIMDw9pEuhCK1+/Y33Guy9/kQhqGwAl4C6ivPhlgtqRKmO0n1KbP4ciSCinSicK7cA3uq4lY8T3KCtY4Tlq0r2Z6KU1XIy8dW9fqi8mPuiORY4T4qRGeaYvKHkSwPHUozkJF0hQwuWhLmhPbZlS/WSKRSuHii5Ln0XFzlHvG/RboC6YhKMSkTGbd4H3+p3Fpapgo1Fyf/mhAtVtPFBeHCsiU2+18KIrKSQNAla7u4CJavySIyCmUx7aCOgy8HMIyyBFRHcfDlwPQTHsssvhy56LYqu9eV8rFN9vquMzPtHP4wkuXfXk1iCohaMGJL/u3VJByDFiyfykRaF1cqMnHB4MgYTk5YbAPpBJB2cByrxlu6jgG1rO0nFIYlMQIyvzQtiREoW1+2T2Y0wOjrMbJpHQlYD7RY1YjWLpflZOl7zcLOQjCo6Flp0xpzIeHvJJTvPhQoq9KVeDQm7GrU5MlZPUPOKJ0WNbd6HjqUxhQQ9L+IBE3IuoqHDqVrep2c+9fOOARCYZYea9ekIsN0yJUycmzhlUKyJdmsVxbJsQW2Da4jcG0TmXOzFQmP9+WjNqF0wpAYlioRk+oCVLafJRGmmpKnIBBxiS1Kc84p62tyD5ojo8WqhrR2ubR2ubS3hRgZTVTuoEA4gKMQxWk4lvICOo4iYKGIxM5UJqDW0tU4lyi2eloCFiO2U3OrZyAjiZb9FQUNb32tGO4ruH8DQbAzgr3Ph1h9YmbagiUluLbAsXNL7+U6/tLfVnhftHSgltVGhFkQF7PEmqm0fCosHvPo59fMbrRYNQMOiHIBM8sEzIKlx9rsfT4ETlECqhQsPTbbqJE3NQ8dSnPSYcHWfSZdKcFAxOL+VS4PBWtn9XSFDEZsSbDoYZmV3vpaUez+FaLS/StdCiJTLi6OKBIhKgSntq5RVV1cxnGxtXZESGXGChaOdhBojoAWqxqyZ8zmt4czjDhx2i04a2GIta2BqZ3MBeEqRJEOdYVsrDWSg68FSKdNgi2SJWudhruDmpXF+xV/9qKFIxRJC9rS8Gc7Lb6nHKiR5+aiJWH+7dUkWVcRNDyhcpW3fqIoRRXBEbi+6CRGTQzhudcEIKWJUpBOwOM/jdW2N5NQmCVi405IgLx1k3OnRduDOCOzM/Zb4vXL0qEV9WNeitVgxs1HvxmAkY+EExheZLqXe+V/zgWrGv4+1dgzZvOzgylMARHLYsxx+NnBFG9bytQFqxwX2ttc2k8sEicBatS/CT+kfrJzYXOVP37VxBYK2/L+/7IWKEfxx6/Wzmd0QnsQjoGHDqYZTUOPZXJWV5jldpCBQ9WtmgpBckRFYEs5pU7FokCTKt5Gw/AEJ/8qEhThC5CwJMJyEGXzPMKY2vzNbEKhUHjV3cH/suAvVdkytx7890WfNfVlXooVkI9+c/G+CedXlu9UjigsioXu131pBIWAP8uPm/5NX5q1MWvmhCM3D0ZRhY0cxXNhNYhGnG0syRocNqT3MxLeQyZreOuHq+xfPH9TbY4mN09TuS3GmUVN/VKvwYvTHLtheekJVsD7Bp9KCBylcAUIFEFDsGSlQ8sCB2G5KMsBy0VZNkpIlFJz5lt/uRWTFxNKhYXydeXr8UV/rvxg5hnzV6ymStEvf7HQjWQVIdP7tua1FPAekINZxWBW5i25vJVWZM15VlyhE2bOqqNoX4qOnXB5l4q5MAVWleocxtwQsVzl75yQiO4gMgkjhsAWBtIQWIZBb9gk8YRZYenUev7GDJAXHDOgsCx/GVBYAfLvC+v8YyxVMn/zh5EsO150WTPWStS1SBoOL7eOsmlhljWtVS9dV3KWykTEo3hsRlYStwuiOtvE5dWE4veDcHfvC/z7Ozc2ejhzHi1WNaI1IFjaB289YNKZFgyFBb9a5nKwx9+h+A+WI1lzR1vvU2bhQamoeW9E/n3enelWiiQGCFMgTMASDXUj5sKhJxIcUBxQkIteK5m/ibbAeCkwvUcfixCqSFCKhMcqE5cKwSkEQ0yFXGKsI70eSj8/mGUsrBhtSWGaBq4rsV147DCsaZ1YVEJeUIotFKh0feU2UBCK4t/bEquF6bnETFdRw6DJEvYle3lqdA8jTpJ2K8rpbWtZFV1Us/O/mlD8utf7M2lr0aGI9UCLVY3Ykg2w5mWJY0DKgpYs/PHLJq90zFCIU5mFB8UCWLbTkU5QTvED1hRIJ81owoFcoV/T8Ob0iixFRGE+L3e3skxclGvUbP5mMhhCEXAlQVdhCYXoUBjtokJcSoTHFyPDnHm9dpRD1q/ckJUOtip14SlgMKMIG57VLvCWhoDBDCQcVSjxVHRMsag0s3UyE+xL9vLw4HMIBGERIO6keXjwOYCaCdbvBz2hsgxdyLZeaLGqERteBhUwyOJ1ExUmBE2DDS/D67OpiHhOBCW4WUhJSXrMqxrgusJ7KX8p/XI2udI3jsC1DVSNK0UYlicghi8khcCBo7wPqry12dHRwfDwcPEtVkXiiX5WAY6373h3kztPbnvxM8uV0m/y5825SKVwlUIqie1XcvAKsaqjWiixACRt78GI3/bdkdAagLQOBK3gqdE9CARBw3u8BYVFVjo8NbqnZmI1akNIa1Rd0WJVI4JxcIPQIQxM08R1XVBgxmt7nX0Jm2cGbcZsRWtAcOqCAKtaKqMNc9W8PTHxhcYXFu+9kX8v/W3ee2/f0nDo6eYkKb9qQGFpWsXrZOn6ov0MU00q/8bXGBwomJyAkXWJO1PzOSkFbt5OERXiJZE4UuL4rc9dJalleMMpC+DXvYCEoKlwpHdrpyyo2SXmFCNOkrAo/ZsICJNRJ1mza7TlvkBowaobWqxqRDYGgRTIop+o4Xrrp0ouYEC6ngVzIOGyc9AkrAK0YSDSgtdGDbJBi4gwcV2vKnROgFQN3WkIhWl6L8NSmKb03pu+wJhF66zSfYXpB3YY/sssLBsdJ+0JkSc0nvWTc8P54c2+pdxIjmkRsMibzI87nqV1ygJ/vaaCditK3EkTFIU/Rlu5tFlTr+HnKIeETBKXSeJukkgswatjSaRIslJtrsWwNUdBi1WNGDzBYPHvpDdnYygMxwtmGNho5K2WgmVjlFg5BcvGKLJ8ctFppQ+ktVWuLTOF8oNHQhi+gPiiUhCZnOgUBMhOGaQHTLBNzKBDbIlNy4JpJHCOc6jy6yWWi5jKTYxNE0cpXOWScjMk3ayfOyORSvruOTkrpnOOaREc0wKx1hjxsUma69Wq1RdX1xdln3Prcqhx1pdvKz8+P4km/Ak0r3+XPRDG3t9GIhtEBCMElo8SWJAZ50ST5/S2tTw8+BxZ6RAQJrZyUShObyv963GVS0KmfBFKEHe9ZU6UEjJJ3E0Ql0nSqsr4fIdDh31BzcauGR+h5mF9+yd/8fqk9leS/HyNLJq7kWUCJOIgxgQugqxpkLUEUtU2wMIVsvRlSLJIju8wy6wcPxnULFg5E3WnJYcsRvaG/WoGBq4tQQnaV6eJdta24oBU3pxOIV7NQwFSeAErUihcvxWLNPEKApObD5KFtiVl5y4+45Qe8g3D/78SqlRIBLS1tzE2OnJUgZmqzmcPR8ju7cBNBTAjNsHVwwQXpqZ2snHOP/b8QpKuJIsiKARRw6D1xMMEF6YKjVGlyIsbUAi6OULwrFICqSRJN83u5Os8l3iFMTdBwBQsCLZgGniWkUyScJMk1dTuy8KkxYjSarbQYkT51z/6+JTOo5kc89KySsatKpaNUXjvBwy4VedvjkLx9E7VP6yC6yxv0ZiyTGQK64v3/Y+DCRKuIlAkOraEFkvQs7x2bQrihwJe80aj0JxRSUX8UGDCYpWb51G+FaPw+hYpJXG9tZMOexZ4EVjKUEgDr6W4CfgiVkuvZ83xuz+XCIyhEEZBkJTKvS+EkBdH+AE4hsQWsnoEoCzdtzhnqXhZcZz/JjsYJrOnA2VIVDANtoAX2wnaEmtBuuKc413nSNceeiVCykgi/dJMSoFQgtDeMO3hZGHfoohIqSCjsqTdDCk3Q0pmSUtvmXGzpGSGtMySkVky0i4ahwBawBH0OUWf/UrvRv4HLTAQhIwQISNIUAQLS+EtvVeAoAhiYpH7ZjDvvuk3kHkpVq/tnl5rTyWU9wdtKpQpUYbEJk3K6cc1HKTp4pDBIUMktohAOOZbBhLpP5y80GJV8cdcnMOCHySBDcqGZKvk9YQXNWAI749YmbAiavJ/x5Ilx5e+V1UfLJX7ectEOAMR77MwQPp1aSSC8IhdOqdTdB/FuTxHu0ZuROM91I60PNIxRR6nkm3CHPGCXsqPqyII5Q/1iu1Vjqk6nvHOPc7xE2Nk0kdMnDR0HKxcPeC/akF0YPzct31HOjDov6plQReYzgMtF5hzdJe67nLQCOalWAHYQpIRkozhkjH8pZCF94b/XhTepw2XrJA4OfdMVSz/FfI/S7BHwa7RwKuUGTxou7U7P0DLEeYP0jW8Tj2xdYx3s6GqfhXgCOu8z7lkdkEusd1fIjCEKFnmE9/JG635ajK5dZTtU3wNyvcb53jNzDMv56wu+j+/R4oj/OJWWR7tl9VxEvmg5mIHgUAStNoqjjnaNY0q17GyEB4ThTEo75VuVTih0j+w0rEc/ZrFf6zSNlAJTxUNIVBKIZTAiGUxA7Li5zD+NUTltcofHBNZVnuQTOIYISAYCmJnMyXbhVB+gUfvpQzlL73PFdcrv9+ycR3p5zLRB2R+bOPsG4vFSMTj4/9cjnDOivVl40z+fhEqY3ju1dwNuQInmEKc9BpxN0nSTZF0U8RlkqSbJOGkiMsUCdebB3KUy4QEqOwpb8owXeEoMbP4FSFmtXhLf13UDGM0SS+R3YkDPDr0AhljgP+4+NZGD2fOMy8tqzOzATZ0CJZFave96NWDv8R2UxiGhWkIXKmQ0iFgRjim+49qco2ND5kEUl5h2hzCATuieOGi2loOvU4Su7eNoBMma6UJLBplUWcYb9aoNhxIKV4c9sOxLVjfwRT+T3wr18g9BP15IN/dmjtbrDVIfKzcYiy/VulnZYDMhdvn3LeisC33qufX67ZWi9EatATJSpuEm2LM9UKx406SkSXPMDIgSZpjJMwxEkacpBHHNrJQxTtYlaKhRYwQMTNKixml1YrSYkZ4augwncmNrEsuoSvbiSuC7IwkeaPjN9yw4pxp31e92J04wH/17cDAoDum29rXg7qJ1TPPPMNdd92FlJLNmzezbdu2ku3xeJyvf/3r9Pb2EggEuO6661i5ciUAP/nJT3jooYcQQrBixQquv/56gsEg99xzDw8++CBtbd4c1BVXXMHpp59+1LGkHJcdh8HptFkaVQgMDAxyEQVCmFSmfh6Zrs6NvHF4B1I6mCKAlA4oSVdn7QpchhMCpyw/V1ne+lqyP93PDnc3olsQtCyyjoNyFWek17E83F2TaxxIKZ7s96QvKCDtwJP9QLeqLliGypuS+aAEQ82cTigQLpj57wDjX6k4f0waqkTIlKBQvHGGcZRL3PHFJ/9KEXc8q2fMt37iTpKMGsdvfJS8wLARLAiQGaXFipRZQ1FiVoQWM4olKr/Y9KYfYJAhngp0IeUYhpHECuxhYaR2Cbv14NGhFzAwCJoWQmgXcz2oi1hJKbnzzju5+eab6erq4pOf/CSbNm1i+fLl+X3uvfdeVq1axY033siBAwe48847ueWWWxgcHOSnP/0pd9xxB8FgkC9+8Ys89thjXHDBBQBccsklXHrppZMajwUgYPeYxeJwGnCp+HUT+O4GT8gEudA4s6obIhZZweKFMDD0Ao6bIGC20NW5kVhkxaTGdiTSLaqqZZVuqa0n94X4qwgEAcMEf2lLlxfir9ZMrF4c9oTK9H+UpvACOV4YgWUxzzLy3HTN319JSO+FA2Y1UfMtspwVln+PyguaMnNh+aWHusol4aZ80UngOnB4bKAgRo4vSG6StJxarlJQBIpcbtGC2823hmI5YTKjBIzpPTLO6dzIf9k7CFiHiQSCpOwsEsk5nWdM67z1ZsiOEzFq021aMzHqIlZ79uxh8eLFLFrk1eU6++yz2bFjR4lY7d+/n8suuwyAZcuWcfjw4XwtNykl2WwW0zTJZrN0dnZOazyfeTSKbULGUFihCK6lcC2F4y/LX4X1EtdycAMKNyCQAVCWQFoGyjJoiSwnFllBtCVKMlH7b4oH1rusedJCOp5FJRwwpLe+low5aUKi9FfDEgZxpwbRFb4ADUmJZYEtlBddKbzouTEJRrDJ1Wmy5IxCP4hMKklCeXM9YyrBmEwxprz8nzGVZKxomVRT+5lbmLQWWTstZoRWoyUvQG1GYVtQVInaEfmo7pL7QFKZIlA+DVXwyJa+BzYElhFsN/jd8C5G0kkWmq2c1XE8awNL4QhaK6pNf5WsF/mfM8C+uOKpARi2oT0Ip3fB6uKKH+PESJXcsyhcSpTd03GZHuL2GLhpBrN7xx+4pmbURawGBwfp6urKf+7q6uKll14q2eeYY47hd7/7HevXr2fPnj0cPnyYwcFB1qxZwzvf+U6uu+46gsEgp5xyCqecckr+uJ///Oc88sgjrFmzhiuvvJJY7Oj1jQwEIRdCrqhZFJ00CqKmglls08C1FNIC1wI3gCdw/ntvvSps8z9L/321b9kjS+EVHJa9aBJOCNItigPrXUaW1uYecrRaYZJOlkCRG8dRkpg1wVbtxcmsufwifx4pd0vhkCoUZ/VxpVdzbbbh5QspkniBB2MyRbxIdEal/1567xMqjZpC0LqJQbsZIybCtIoorYb3aitbtoooQQIgREUumwJwPRdn8e9+eWi9d2NlG2vEBpayoWMpsdZW4mNj3vlrmK/9WkLxW799R4cBbhJ+l4TgIsXKGpWoOjHQzq+Th/1AKN0ipB7URayqBRyWl9Xftm0b3/rWt7jxxhtZuXIlq1evxjAM4vE4O3bs4Ktf/SrRaJQvfvGLPPLII5x33nls3bqV9773vQD84Ac/4Nvf/jbXX399xbW2b9/O9u3bAbjtttu488QMAQc2tCi6TDAdgWkLDAdMW2A6YPhL77PAtMHwl9XmswwpCGYFZIEkTHeiQgkKwua/ctac2wrxTm9d15hFxyv+el8Ei/ctXj/RJouns45f9z6PKyQWBq7wmkee3r2OaIs3mexN7xVF0+WTXpmQ2+6sZTbbX0vjCggIsJUXzHDWsjCx1lLFKjSqHC/yTYwbBWcI/2UatAfbS85xdBRJmWbYiTPiJhh2Egy7cUacBMNughE3zrCTYMRNMOIkmErhJhODdquFDitGh9niv2+hw4zRYbXQbvrbrBZajDCWaeLKBuT5lCXpSkU+V9CVhZbvVQ4rvC/KrVOAYZi0t7Xmc+dqpYnPHkpgWZKA/0thmmArxbOjBhsXt9TkGtEDr3CCyLCXEOl6RtjMY+oiVl1dXQwMFLIKBwYGKlx50Wg0LzRKKW644QZ6enr4/e9/T09PTz6I4s1vfjO7d+/mvPPOo6OjI3/85s2b+dznPlf1+lu2bGHLli35z/sX2KyLZYlH5OS/0CmvQK3pCCzHFzJf7EzXex8RQWTKKQhd+b5O6XqjSnSXUGDa3qvk4uMNagK4ZrGl51t1ectO5cWx02pnOaew1+1jxEghAoIV7T0sTERx7VFk0DtWVbH+xkOIogaQApYH4MJFiicHYCTruWrO7IFjQ2lExvvz94RmYhcYL8k25yBta29nNDGKUoqUyjIik4y6SW8pk4wUv/e3jcok7hQSQAWCViNCu2/tdJjess2I0m5G8+vbzShRER7/HhX5TFVJljGy3n2MjEx6TM1A+RcJ715K/wKLiwaXJIAXJWjLoh0kucR0bx+pYDilCPllunIYCoZTrmfJ1YBkepAuM0y3yHBJYHYFh8xW6iJWxx57LIcOHaKvr48FCxbw2GOP8eEPf7hkn0QiQSgUwrIsHnzwQTZs2EA0GqW7u5uXXnqJTCZDMBjkueee49hjvQZRQ0NDedF7/PHHWbFiYsEM5y2cxtyLb/FIS2GPIxKRiCCVmvg1hKRE8Cy7uqiZjkCmk8h0HNOGoAoTppWgDBWEz19Ww3QFpguBjH8jR+AYOjidjiPuo4TyLT/lW3HeZ+V/VkGFDChUAFSwsJ8KKGQQugOK07rJH6sCRx3WuKRltkR48qLjf44PZRiyxxhxkziV4TQTotWI+KITod1ood0XoXZfeHLvY0bz5AJNlt3xAzw6/AJDdpzOQIxzOjayLrasbtevEO4p/D50hRRj2VIXsy2hM+hVrC8Wu7z4FYmhKhO/agSD7WTtBKY5C/3Ws5S6iJVpmlxzzTV89rOfRUrJhRdeyIoVK7j//vsB2Lp1KwcOHOArX/kKhmGwfPly/vIv/xKA4447jrPOOouPf/zjmKbJqlWr8lbSd7/7Xfbt24cQgoULF/KhD32oHrdTc5QBTlDhBI9sISVTh+gfehYh/MJ4ykUpSXfnyUQjS4pO6IVcm7bAkmC5BpZrYEqDQE4ApemJop1zgQrfkityf9pgugZGxksKLkcogZUFsrVzg0h/3s6z3hTZgEPWcklZWVKWTdxKM2amGTVTDJsphsw4A2acUTNFyrJJWllSVja/dIwjW0YtIkybGSmydlryYtRmRHxLqIVWI4I5SwVoouyOH+C/Dnu5QxEjyJid4r8O7wCoq2BNl7MWws8PeA0qLcNbSuDsHgiZk/9d9WpaUlReDI5ZeAqvHngApFl1mkNTe+ZlBYv//M/HZ/T8kUh4UpbVRDnY9ytcN40wChO6UmYxrRDLF53nVV3w46iFoTCF19bdKq7GUDS3k3PJeXM+Bqbh55lheIKIoL2tk9GxMUxpYDgGRlZg2N6cnmGDkRWI4s/+UhRtz6339gOR9SzIeuAYLlnLxQkqXMtFBoCAQAQFRtCE3JxgUKEsbymLrcWgZ/HlrcJCDdM8Q6O7Odj3KJnsEKFgJ0t7zqGzbd2M3M9MugHv2v8AY3Yq32EXICsdWgMRPrD84ppfbybvZc+o5LeHYTgLHUFPwNa21bgDwouHWPBMkJZ0lIVfnV2h97OReVnBYrZgoPy5HoWBQso3sCwDQ9iAgxAO4CJlhgWxs6ZxJQXKzRd6LSadhWy2qLRnEAh54uaJmsBFMiYzjKkMozLFiEwxJtOMypT/yrnkUiT9vkCGEoSdAFEnSNQJEvGX3vtAxbqYG6bdjRBzwrS4IVqcIGEnQNgJELBNAo5R1fqzpImVNb3AlxqgKHJlBsA207S7nSy3/gjHcnCMNLaRIdo5SjC2wBO6owhgvZKGj0a13KGAYTJsz5bWKgXWthmsrVKvWvk9SFSuj5nKNZsprVNY+A7vl2fOf6X3wkRirwU5ZscxSFMSWViboA3NkZmXYvXQ0ItsjCxmcbhjxq8lfMEptmTy6ymsN/zKDMJQGH5XXpEr/ucf0xLJYNtxjCI/uXRtQsHpVZGvhlSSMZVhMJvmDXuQUZlmTPkCpNLeZ5lmVKVJVGtMd7TzC4UdcFEhsAyLiBGiNT//0+K74/z3RpSQUTo3kPRf+QgEv+KEkQXhVFp1UStKZiRVahXaRVZhtopVWMX6E3juUWxvW5AoLRxTeYMHJvGzMEsFsFjcikVNBhTBNhdcs0L8io+fTOBLMZ2BWIVlZUuXjsA02l1PAKWO7KpVfjy9JzAFYcl/LhaS3L65larQE6AW4Ya5v+XuZzuQpvTyHZs9a32OMC/FKiOzPBF/jU0wKcHKCU9xE9uc6ORKxAmhaAmAZbsl4pQ/h1EQIVFUpWEi9Cw4jf1vPIx0bYRhoaSDUpKeBadN6HipFAmV8cUmlRcbT4hSRYKUJq4y3h/5JL00FgatIkybEabNiOTfe8sIbbnPRoQw1pH/0BXgOEhGSfmx655FJ/zj/M+5uSQhIOS/vK2kBiOM9XUgMyGMUJj2VWNEuyfoonXBcApiJspcnYYtOLj/EYKqhYAbwHKCWG4QywlgOhZtgRX+foVjq6Y9uALDBdITeehJ2vIV/cf5sYkysQt6kZ7lolZi6VlwmXsGj4weJKGWkjJCZK0kIvIS53RVD1wqWCk566NIGKoIispZMf5+wVQWOxP3/0+PcD+UpSyUpCoUl2wuynHI7e+vzl2huBp78dGlR1Vqvfe3XFgbjgeQoXEyizUzwrwUK0sYIBx2pg6wItqeFxwoFZ2SeZ1J/FJaZsEy8sRIFurZTYO2ljUsXwx9g0+TzY4SDLaxsPNUjMgyDrkjngD5YlNiAfniFFeZKeUCGYiCAIkIrUbufdh7LyL5bRERmJlvmvlv1+6E7yAzFGPwpXaSKo3NKAEnSOqFGAuOGyO8IO7Pzwl/CZSIoP+/bwGWgoj3sC2+N6UUe4MvYDsJDLMwmSVdm4AVY8OaK0tvQSmEA6ZtlMzhFQSw/OXn+9kC4S8t14SMzH8WVdMeBGYWzEkGvixmKWdQnGHeBXhC5QW+SF/gFMrKRXp6SwIKFfSE0A3IovWgLOVFhlp4buSAwrAEbaE2QunZOWXutrkYSaOk9JlmZpmXP2rDSBNQiqRKETWnlmDpddD1Al+FUbCUEBCIBjDdqZfGUEqRxq4uOqQY6+xiVLZ46+wduCO/m/z4EbSKUIn1kxOdViPMov5WVu/upme4g1DIoP+kOPHlU6s91yj6X+0kKVO4hoMQAltliUuJfLWdZZ2jNfEMLVxwCvvfeBil3BJrd+GCk8nao9UPClC1L9lEiLW2EB8rzCEKFwzbwHAEhm14kZ22wHQMLNvAdAxvvSN8kcztKzw3qSMQvni6WUFwnMAXwxEYjgk16nCvDAVBCFlteWuv/DW59dTVykmcmqXtVxFK57c0M8m8FKtWXsYG2o0QY9mdCEwMYSGw/IrrhaVhGhjCRBgmhiEwzEmVQCghrewSS6fghqu0gpwpJaNCiy9ABavHW7bnLCLfHdciguPmAsX2h1jyWAxbpXDEKGS8z4fOZlYJVjYVwDVSFDt+XOGQTUVqdo1q1m7PgtNoa1lTs2uAnyCNIGgECBpeVwBDeL+PRsh/j4Hpry+gkH5q89G+Pn1uV4CooQhJCLqCkANBR6CyBn++xEX47sziV85CFLZAZIU3X5jNbffXV0t7kALSYGLWrOmM9C24UmHz8/wqBO/o6480sOwKm9G3QsszQUhqsaoH81KslvCLvOC8OunIWcMXNhMhTBwRIG0ESREgaQRJiQDpAYuEMkkKg4QwSGKQBOwpuscimLSKAEFlkHIyBBEEVcArtydN3hxbw/rIMtpEBMsIIKZZq6zz9xZZmcA1bRAGjsqgXEnn761ZJVZjgWGiTgxXOPl1lgowFhiu6XXaWtZMWpxMkROVQpdb4QtSrvOtKQxMX4By7se2YAuW5Rzp1FOmM6hYesjkwv0BOlMGQxHJL5bbHFzikDlmitdUeLUI88JWELGWQAvpkVSR+FEqgr74FYuhYQvEEaw/xkmIn9LQDV/8LC+JXZWJoQwo7B5J54dX1uyamvGZl2LlEMESCgPpz4G4ZdsFKREovAyLZNHnpAiQMrz39hSFIagcItImomyiyiGi7PwrKu2izw7m0ZxVQ7/g9aHiFQJRJKjF4ipEqfVoFFuS/rbhhVHUQoWhLO8lTQxlEnDDDI26hXOUHFtmnfrXNETp58L1zRmPojrQ+Rzr+s7FlCANF1NaCGVyoPM5TmbmklwN4QmNQGAKw7d6/PcYWFO476ExL5fLtkcIBNq9XK7W2uZybcsIluwO4RoucdOmJW3wrt0hDi2Yhu9PAJb3oHcjpb/H4XZIjUwhp0BSXdzKRM8oswLz6/MiWLR+HOtP+EEvulRt45mXYhVe8lf+fFAuCs6LhBtVKcZkhtQUS7EHEcQwiAmDqIIWoAVFi1JElKRFSSK4RJWDqVwUDlK5KOX4UVMKpQQSAyUsFAKF4QvqZL7ZKpSyUdigmHRxoaHFR9g4PMmTHRHfDalySclhTCNcJGZWyXuj7HNOBI2yz7ntqzqTvMzvWZxcS9hpI2lm2R/dy7HdURKZbFUB9a5RfJ1SV6nhJ1Hn3W7CwBQCy7eCJlrLcDIMje1m7/7/RAiTQCBK1h5j7/7/hOXUVLDW7HTJGqOkjTAKE9twCZJgzU6D+PqaXYbg6wFangkSiAvMWAuJU7NkV0zib84AFVKoENQkHt2vwZgXN0cgsuMJXiHdIfdZ9wmuD/NSrL4ef3jC+wYw85FvJcEIVQITgn4PqPJJ8FqglOJfe39LSiYJChOBRCBxVYYWEeAdXSf4oucJW+G9i8y9z2/LrXNQuBX7JgZG6Yy34xo2ruGCcFDCYSwyTCBq+fvnjvXP5b9nUnNt/r4CFC6OtHFkbQqN5ugJgGx/gFyp0aVAagRemrD715uzzImYISwM/KUoFdHibfnP+feBwnmqHW94+xTOY+bPta/3ftpGl7Dy4BlE0wvIBhO8unQH+wOP0B47Np+cPV2MUYVhJmkThdB+ZUiM0dolvQZfD9D2qwjKVKgwGEmDtl9FGH0rkxOsCVyn5Zkg5qiJ2+YeWRAFfiWT4sTgidM5rZFqJsq8FCtTWsTcFtoDQdoDwXHCsj0BCh0tF6hOCCE4q/1Y7h/aiQQChLBxcAlwbscGosGeml3r/8Qtlg0aXHywla60xUDY4YGlYxxolVyx5MgWnlJyXCHLiZzEYX/vL3DdJMIwyCVxKmljmiG6O08unCMnrnkBlr5F6pSIb+5VVYSVA0ik9I6brKBKJZHjtYGvE4e74JWuByvWH3r5d4AoCJ+RE1WzQigL631RzIumZ2Faax0CdhSBgaFMDGVhuUFcw0aNtnnnoVi4S89pFFnARpmI59y+Lc8EPaHyI/290G9FyzPBmolVsSDKkJoxQdTUl3kpVre89imUa2IFbTpPfrnRw5kwx0Z62Ar8dnQvI26KdjPCWW2rOTZSO6ECSLgtvNKT4mvdfV5ItjAxjQiO2wKMlFTVULlkNFTRewuEhRAKs2QfL2EVAaP9o5jBEMLw00cFKBXAlQnWrDxrShGXubkhw3fNmb6bzhIG3Qu6GB32zCmllCeaMmdlukhlo6QndlI5+ffefv525eYFTykX5b+XOaGUlfvk1/nrlX+t3PvC/m7RmHKiOlGUt79ycKfT6mrREbb1TeO8PgITc12gMBeanxO1MKWFfF2UiV2R+JUJYYnlSrEVa9H2SgvDXUFvH/8apmMhXjSJ99gVxxes3Uq3r6Z5mJdiJRBgSJxM8Og7NxnHRnoqxWkc8ch/hrLtVbb5reUBZJtNvxskYAQwLBPHdckoQcyyySyozTdTK9pC1h7FNAv/B66bJRjqGFeoDCHy4lMsRF7ggjiiBVxcMV0IgRABDGOKyU51wBNUz0rt/OcACdGLNB2UKXGxkbiERCuDf5IsCFxeJHMCW7As89uKhbdYQKVDOjuIPTxCJN2BoQxsK00qNIwR8R78qkJUXb/80QTvCRfHPMIMaq0CTY8UO/P6kQ8tDkrKiyXFlmql23cNd9Vo4JojMS/FCkBJAytUo+qmE8EXlIJAFAmGKIhINStkXKEp2lZLzlqc5McHY9hCEBaQRuAoOG9h7ZrMLe05m737/xPXzWIYgbwFsrznHEKGlRehYnFqBndsNUIvB2j9bRhr2MTpcBk7K03m2OmJuieoJmASbG8lOBIl7QwjbQdDWITpgPYAsrW2c3z9w8/x2sEHSGT6CYe62bD0Mro7Thp3f6VkpQhKB+k4KMcFx0W6Lsp1Ua6D2acI7TRxzSwqIHFlFolDak0auyPrWZ1F7ty8OPruY1m+ruh9fn427b8XDq7hoMTEQ4wK7us6Phs0E2JeipV0DVCC6IreI7u0oERI8vv46xF+ucyc4OCts9slmVyL3xkSlJnk+DabdxHnkf4oI45BuyU5rzvJ8W3TewDnLCMTg+UdJ9FiBDj4xi/IZgaIhrpYtWQLCztPrtFd1IfQywE6f97izY+EFWbcoPPnLQz9UWLagpVj7Kw0nT9vocVchBE2kWkX4QqGzqptEA9Ad8dJRxSncoQwMEXQD+ycQLL1Mgi1Bmj9XZjgYIBsq03itAzZFY4Xkl6D4L6SIA4TcBVKuoycM0Z6WbpICIvctUXzoCXrlWfFFq/3XgXrVFMf5qVYZdodYqsPQs9IzTwPJVg0TduHqXJ8m83xbSO0tbcxOjJO2aAyhKDEPWeUuezKw7rbFpzGMRMswjtd8rX+8tSm6kDrb8PeQ9H3KHpLRetvwzUTq8yxNkN/lKD1t2E/uk3WxHprCAZk1tlk1tl0dnYyNFRmGUq8JGJXIFxAekuRK7Y+AYqrS+R+XolTHeQKiyC1qyAvlSI9XithTc2Zl2K18M07Gz2EWY0hBJYwsXwxChgBAsLELE6QzjdxLPJXikK9Bm8Xr2yw8Pf3D/Q/G0WfqhebLbyvJFevLV/5IdZNNl39m7/XoiI3R6QK8zCqEMpceCSpXM8KFBAYMZFhVVroOADWiIFhBPxzTuJJOw6ZY20yx47zgJ9LGN5LBVTFTx7pvfJC5vplm9xKi6y34w8c3Pgo6ewQ4WAnSzvOoZPa5KRllSLtSjJyKmWhNVNlXorVvMRvpeEJCBQEILcevFbDnkgEhIklLHpaFxJxR/zPJkZufyGaOnJqMvNbufuYSpkq2ZlFjEkIFl3PVqhOg2i4EAiTD5hAgi9gyq+gIpVbWJdfP52wvjlKTsgsVfrlAYqEDAaHdrL3jf+LqUJYZrgmSdRSKVJSkZYSVxeubQharGYDZb2bchZLwTIR+D3tKfR6Klg14z24vfpzpidEhidGOVHKHdMdWQCJ2fvg7B14gj2v/YhM9jCh4ELWrnw3i7o21ez8mXNNIj+RqKzXDgPbe2Cmzy0VvuKAiYlSsPhy/aIk0UgnibjM55B5AQbST8iex+SFDPYO/pRMJIFpOmRIIKQJtsurQ9tp71qHcHy34lFQSpEF0q4kq62ohqPFqtbkHkolbizybi6B4bvDisXEKBWcfINBY9rWS6EenYHpu+4Ky+aNsKsFvQNP8Nzuf0IYFqFgG+nsIM/t/idY95c1EyzneJMUEPq1izEskR0G6XNNnOOnX02uYPEV1gWsKMFxOvd6kXhukYi5vuD57s18QEBjH7uZw8+RfuUBRrJDEOwkvOZiQgsnHtRxNFKZfiyrUARJGS4qqBh1XkO25ly8FObGnMISBXaRm2/2fk2be8xLsfrDy3cVCoEWTbznGvHl3+fnWYC8+8so2lZs6RQe/LFoJ3YdcrhyllFOgHKh3vlq3XNcjI7Gntd+hDAsLDOMEALLDOOQZs9rP6qpdeUcXxtxmi5CmJjm0cfhiZYszZvyq4NI6T+xZ4jM4edIvvADMEzMYAw3O+J93kjNBCsS6iZjD2OahY7KUmYJh7oLOxUV2FUhsKVLSkoyWYn058QM12tuKRqv7xrmqVg5bpJXD/yM0OqOSYXpNgIvss6saiFZRuMfkM1MMt1LwCq1QkwjRCrd26ARNQciFwwzTlJ0cRUO6TeTzCUAT9flmH7lATBMhBnyvvKZIRQZ0q88UDOxWrn0Ynbv/T4uGQwjiJRZlHRZufTikv28aD5J0pXYuXkoEzC998U9qYUfzCF8a8zIBXdo06tuzEuxesdvruf3ax7ktdADTSFWheRXs2QZENaMVPGeL0TDi0hnB7HMcH6dKzNEwkeqK6TJWWgmoXH3yUVOerUTC/NmpaWqKkXNTfUjAmWFcY0gbmqgZuPv7jgJVsNrBx8g7Sc3r1x6cf5v3fYFKj0JN58yQZn+vGR5hKKmLsxLsYqmY5zz/Ht4VP0QNs789QRinDkjbzmfXXUzydqV7+a53f+EQxrTbMFx0yjpsHbluxs9tFmP5/YGL7NuPAtNFVWh8MQsGFmEzAyDFSzM58osZqSrpuMrT26WSpF03VIrqgaoWmQxaybEvBQrx7IxbcWp+/6IwRqds9g6ag+0QMAmIEy/qGrzhnjPZRZ1bYJ1f5mPBgzPQDSgZnzyNRiLxKxj/eXEn/5ncFwsM4ztZFASosddRsCKFSpF1GjuLCslqUlaUeUo6aUWkE8xcEH6S51iUDfmpVgppXDMLB3pJQxOujWhZykFDYuAsAga3qtYkNqDLdjmNLqramrGoq5NLOraRHd3N/39/Y0ezrwnvMT7opDc9SNkuh8z3E30+Hfn1xdTXu2+YKXlohyr4+VEeSJ1JCvKEyHliRAS/IhJb52f66bFqGmYl2JlCJOw6MBtt5hIH11LmJ4o+eIUMOblj02jqQnhJZsILzn6FwjDMDHGyUsrVKUv9DJLuzZxO0vKzXoBItJrm1IiQrKQmK2ZXczLp26LuQjhCg69pbSysoEoS471xEkHOWg0jUXlLKC8G84F5eJKl5Rjk3RsbN9d5z3UvPa/CgslpJdULVzvvVJ+dXVJSWURTVMzL8XKiSkG3mLjrDNoM0IEDSsfgafRaOpHQYTckrkhpaQvSNXnhjJFEX1HmtkSQiAwC01BjzAORS7C0fVbn8i8y1ELWuOZl2KV+mCE9hnIUXpi+CV+1PsY/X8Ypdtq492LzmZTx3E1v45GMxvIBSLgd1XOiVDfwNO8cui/SNsDhAILWLNoKz0dJx71fK5SJF1JSkqcGtfnm4io5QSMfMsQpctc1ZF5KVaBGRKqf37tp1jCoC0YZSg7xj+/9lMALVgNJH3oCZK7fsRguh+OMJmvmTjjWkO+a857X73SfN/w8/zhtf+DIUyCgRiZ7DB/eO3/AFdUFSzXT9xNSUm2we04RD6yd14+NhuO/qnXiB/1PoYlDMJmECEEYTNI2s3yo97HtFg1iPShJ7wwacPCCrXhpIe8z6AFaxxULkRbuvn3nlUk/XXTC9d+pfd+DGFimiGEEF5JJDfDK73358UqJ1BpKcnoflEaHy1WNaI3M0xrUaUEgJARoC8z3JgBaUju+hEYFsLyagMKK4xy0iR3/aimYpVz//ZmhlkU6mha92/O8ikOUCjMDbmFiLkZJJXpxzKjJesMI0gy00/SdfMWlJYoTTlarGrEolAHQ9kxwmahgG1G2vSEOho3qHmOm+hFBFtLV5oh3ERfza5R7P5tNcMNcf+WzA2VWEZFLrkmmVuJhLrJZL0is0pBVlmkpMQIHsOw0xxj1DQnOvytRrx70dk4SpJ2syilSLtZHCV596KzGz20eYvZsgjcTOlKN4PZ0lP9gClQzf1rCYMf9T5Wk/MrJVHSRjlppJ3ASQ3jpodwk4dxE2/gjB3Ejb+Bm+zDTQ0g00PIzCjSTqCcNMq1m0aoAFb3bCWjBKOuYEhFGZUGWWWwvOucRg9N0+Roy6pG5L5F/6j3MfqdUbqDOhqw0USPfzfxp//Ze2ibLSgnDdIhenztagNO1f1bbW6o5H0+ZLvUIeZmBMpO1mz89SLjB0molnUsWfInvD7wKFlnmGCggxVd59DVVpuW8/XkD4kkDw0Nc9vB+7jvbdsaPZw5jxarGrKp4zg2dRynS/s0CeWlfYwZiAYc1/0bbPdEstglV8e5oamSOfw86Vfux031Y0a6Ca/ZSmjh0cPKq57LD5JISUlxnERX2zq62tbR3t7GyMhojUY+AaQLMgtuBuFmPKvbySBcb13Jenf89bhZXCfNCU6aU5XNP5z4/6vfPcxjtFhpqjJXQr4nWtqnnFz7C69OnBeqnWstn68npxTbFpzMvxz8JUq5hIRJRjo4SN7Vvr6mbS/qQebw8yRf+L7XbyrQgsyOeJ83/tmEBctRipQrSUoXd6p6rBRIpyAUMgtONTEpiMfR12cR0p7igCopnj/RXRPqgxYrTQVzMeRbKeVFwyGL3G3FQQmy1A03QU4P9/AXPW/hvsFn6XPG6LFa2bbgZN4UWzFzNzNDpF+5n+dCy7k/fCL9RgvdMsHW9POc8sr944qVUhLlZEjbaVJ2iqydzouG4YtEdZHJkhUugUyiYj1uBlHH2n3KCIAZAjOIMsNgBsEMofx1mOGi9yGUFeL7gymGrHYGjCiddRvp/GZeipW0k/n29UChr045RS3v88v8rmXrgfQbT5LcdS8DVayR2fTta6oh314lbN8SQfk5oSqfl6Py2yjar/wkRcmkRdtLgplz56/4nLum9A8tXCNrJXETQxP+GUyGN8VWzLg4PTUW5/8ODDGwZx9dlsmlXZ2c3ho7+oFFKOmi3DTKyaB8gci9V06G15JxXg0t4JT4C4RVFku5ZJTLgP0G4okvF/bNHeekPbdaEcFxrl0NyeQivBSiunjk3lveejcbxx56BWV43ZClbx0Hlp+N1bm2TIhCMIEyaxkp2ZNKszuZZncqxcFwwUrTYlUf5qdYpWv/0Cp2oZjBKG7qMPGnvoascKGUidY44icq1hejyp7z6gj7ll3uqLsInLGDXjdX10YKiXJdFAbO2EGc+KHC9fJjaM75l9mKUgqknReFF0aHuL/vDTqVzUpDouwUz/ZnaWsJstTCj/orFRKKRSW3TjlHvO5SYGnmYNVtdv8Lk7sHYXpCYIVRhi8KZghlBsEKgREiGG0l4wowgigrVLRPqKqlgxGYyC8wY7+/CxXu8o7L4Waxh/bRuvLCCY3fVYpX0xl2pdLsTqbYl85UrQwYFMJ3GWtmmnkpVjNB+pX7PV+/GUIgEGYIRYZ0hQul7Bd7nAf+TP3+T+S8ZqQLmR3xHhA5C0VmvG6uurVCCUpJz0pxysShyIKpasnkt2eL9knnz1P8+7AU+ItqF++HmnRNM0MIM0i/NHAwsIVF1giQFQGymCStVs7tXoRjBHCMYBWrJlwQopzQTKCkWUt7G8kZCLCQmSGEFSldaQS8DsXjoJTiUNZmdyrFrmSal1NpMmV/LAawMhRiXTTMukiYlJQ8PDLKqJ2tflJNTdFiVSPcVL9njRRjBGfdJDtAeM1Wki98H0UGZZrew1O6hNdsrel1ahl5djS8OSsb5eTEIV0QkDILpFxsyt1lBQsmDTWctD8aEkHWCGIbQbIiQEYEWNnS5rlrzaC/DOU/eyIUQlghhBn2l6GSfTGDCN8N9uV9rzOUThDIjnollgyLTKCNtlCE05Ytqdt9Thcj1Imyx0otK2ljlCXoD9oOu1OpvGtvzK38IrYoEGBdNMzx0Qhrw2EiZqnL8ORYC2edrHPE6oEWqxphRroL1kgOmfWskRpSjwd8aOGJsPHPSL9yPyo7hBHsrPl1jhR5Fuw+AXIWR5HVUSwUlIlGpZCUCtGAm6lvcqwRqBAG4bu68uKSF5BgqZhYnutLmN5+nz/Yz2HXxDIDWIEAjuOQkZKOgMWnV9VuruzSrk7+v4NZVLgbSwgySuEoxYUd7TW7Rj0IrTiH9J7/BLKe61DaIF3cZefwTDyRF6fDdqVbtN00OT4aZl0kwrpomHZr/EdkdnA3mdcf5Q9P3sYJH/iPGbwjDdRRrJ555hnuuusupJRs3ryZbdu2lWyPx+N8/etfp7e3l0AgwHXXXcfKlSsB+MlPfsJDDz2EEIIVK1Zw/fXXEwwGicfj3HHHHRw+fJiFCxfy0Y9+lFhscpPOtaIe1kgtQosnSmjhiYQWnkhnZydDQ+PP8XmT9tkSF1Y1C6RcQLJ9z6FkFhCFoAoliT/51dyZa3o/4+O5bLFy4lAkMHlLJCcyhc95ASq2UnIWjBlE1LCy/9ZFYe481EdAKUylyEivXfulXbWb2k9LyepwmHcv7OLB4REGbYcFAYuLOto5oSV69BM0EcEF62AtxF//Dftck73RFbwSWcGBYQPF4ZJ9w4bguEiEdZEw66JhFgUCEwqGyg7u9gTRMDHCbTN1K5oi6iJWUkruvPNObr75Zrq6uvjkJz/Jpk2bWL58eX6fe++9l1WrVnHjjTdy4MAB7rzzTm655RYGBwf56U9/yh133EEwGOSLX/wijz32GBdccAH33XcfJ510Etu2beO+++7jvvvu4/3vf389bqmCelgjxfNigDdPUHVerBLl566UWyiVk/Gl2zOGIpMaK3OF5Sb0s3V1gyGMEgukRByqiEfBSgnR2rGARMopcovlRCiQd4M1K6e3xrBHXuU/BkYYECG6VIZ3drVPOhqwnKyfsFuctLuxJcrGWSZOOaRSvJ7JsjuZYleqjb2x83Fy33l8o9oE1kTCvjhFWBEKYk4hUjfz+qPevJwZRAgdYFEP6iJWe/bsYfHixSxatAiAs88+mx07dpSI1f79+7nssssAWLZsGYcPH2Z4eBjwxC6bzWKaJtlsls5O7xvljh07+PSnPw3A+eefz6c//emGiRVM3Bo5GkpJzw2WEw9fGJz4QS9ww7XJWSJKSWR6hPhz3y6arC9EhxVbO1MJjsgcfZfqmMEiwai0SLIDO1HSRhgBQHjhw8pBWDFiGy8vsmSKxMiY+q9rS2cn2Wn8nzSSzOHnWffy9/mbXKRpNgnDLpnQ5C3qXNLuTDQwnDwiHzbu6UVxqkhhl/x6UbpdKcVh22ZXIsGuRIKXkklSUlYcviwU4viWFta1RDk2EiFYIk6qbDkOZYFQMjPsB3GIox+rqQl1EavBwUG6ugpzN11dXbz00ksl+xxzzDH87ne/Y/369ezZs4fDhw8zODjImjVreOc738l1111HMBjklFNO4ZRTTgFgZGQkL1ydnZ2MjlaPLNq+fTvbt28H4LbbbssfUwuUdJBOGmmnvWKjTprM4TcIZpNI2/ucW59/b5d9dtJIJ4PK7V9efLX4ena86vrMgSkWThUCwwojrDCGFcawQggrghEIY5ghzGAUzJC/Puyv95bC39+wIggr5B0fiHiiZBzZWkkcfJrDT3zTEyAr5ImqdFi46Upalp42tXs5ApZp1vT/fUoIUcjpEwIw/GewQe7BLYRReCj7D9XXn/kaZsD/2QqBEW7zfmcO/IqFp24b1zJUKAQCqSDpuiQdB1dJgpTnQxUyDas/doty56psyguKP+5SuSn6VHZflmUSaJ3cPOJwJsMfhgd4fmiAPwwNMJBJV+yzKBzlhM4uTuzsYmPnAloDk8n+mhjp9qU4qWGMQBiYfbUai1m1ahVPPPEE3d3d09pnpqmLWFXLQyj3C2/bto1vfetb3HjjjaxcuZLVq1djGAbxeJwdO3bw1a9+lWg0yhe/+EUeeeQRzjvvvAlff8uWLWzZsiX/uf/A7op5FSpcYGWWzRRzV2qKMLyHhsh9I/V+hmbrcsxod6kVUhQBVpisDyFyczO5iDHjyD76citR4XlUKh4xuZWZNFD5AKkgsorw+sv9YJEBzEgX4TVbyUZWzYgFNC1rt0REDO9nL4S/ziw8pHOiUSRE3lJMwtVYaf2mR99ABFtRUmFZJq7roESQ9OgbDI2OH7yekS4pxyUlHZqxh+FE/k9SrsOexBi7xkbZFR/hULryfmOWxfGxdo6PtXF8aztdwUKQkxNPMESi5mO3VlxE5oXv40oXVXst1FShLmLV1dXFwEAhhHtgYKDiW240GuX6668HPHG74YYb6Onp4fe//z09PT20tXmTmG9+85vZvXs35513Hu3t7QwNDeV/6XP7HI3hR/5nje7sCOTcXvk5lNK5FCrCictcZv52io8zzKJowMIDfqbCvWeanNt06hR9mxf+e+EHNuTdS97SDLdjhHwhKHYn5ayd/DpRJDIgRO0CJaaK2bLIS2S3iqq7j9PqxFWKlOuQdBzshrv5Jo8jJfuScV6Mj7JrbIRXk/EK+Q4aBse1tLGutY31sXaWhCMYda4QE/TnqFN770emX6/rtQH27dvH2972Ns4991x++9vfcsopp/CBD3yAv/3bv6Wvr4/vfe97rF27lmuuuYZXXnmFaDTKv/zLv3DyySczMDDAFVdcweHDhznzzDNLjInvfve7fPnLXyabzfLmN7+Zr33ta5hm4/8GoE5ideyxx3Lo0CH6+vpYsGABjz32GB/+8IdL9kkkEoRCISzL4sEHH2TDhg1Eo1G6u7t56aWXyGQyBINBnnvuOY499lgANm3axMMPP8y2bdt4+OGHOeOMMyY/OGGUzKVQMUEfGmd7sCwqrLBvZ/cihodHavGjq2D6D/hmosj1ZZhFFkzBLQYU1uUtliKBmiBWuB0jWMdgkBpytFYnSinS0iXluqRdd1bNoEilOJhOsssXpz2JMbJl804GsCoa4/hWz3paFY1hHcXNXA+CC08kuPBETjh2bUOuv2fPHn74wx/yL//yL5xxxhn867/+K7/+9a/5v//3/3LrrbeyYsUKTjvtNO677z4eeughrrzySp555hk+85nPcO6553LLLbfwn//5n/zLv/wLADt37uQHP/gBjz76KIFAgOuvv57vfe97XHnllQ25v3LqIlamaXLNNdfw2c9+FiklF154IStWrOD+++8HYOvWrRw4cICvfOUrGIbB8uXL+cu//EsAjjvuOM466yw+/vGPY5omq1atyrv0tm3bxh133MFDDz1Ed3c3H/vYxyY0no7zP1vIexFWzev2NXt0WW0Rvpur1EVWEJ4yN1nuc2675qiM1+rEWnQ6o3aWhOt69e9mCQPZDLvGRnjl4Ks8P9RP3Kl0pS8NRzzXXmsba1vaCDfJt/tmYvXq1Zx00kkAnHDCCWzevBkhBCeddBL79u3j1Vdf5d///d8BuOiiixgYGGBkZIRHHnmEH/3oRwBccskleS/Xgw8+yJNPPpn/0p9KpejpqV2j0ulStzyr008/ndNPP71k3dathRykdevW8eUvf7nqsZdffjmXX355xfrW1lZuueWWSY+l1om6c4aSeRgTYZie+yycs26KLBv//Wwq0DubybU66erq4vXeXuKuQ6ZKcEEzEndsdsdH8/NO/dnKAKLOQDAvTsfH2mibgaCIuUYoVJibMwwj/9kwDBzHwaqS0Jz7e632d6uU4qqrruJ//+//PUMjnh66gsVcp0pwgDBMr6q6L0oYxrhzM1a4HSMwO91nc4USN18ywVCT16LLSpc98TF2x0d5MT7C/lRltFzUNDmhs5s1oQjHt7azMBjSX3xqzHnnncf3vvc9/uf//J/88pe/pLu7m7a2tvz6m2++mZ/+9Kf5IJfNmzfzrne9i49+9KP09PQwODjI2NgYxxxzTIPvxEOL1WyieE7Hf4nc3E7uc94yyn3WD4CZJteo0k30YrYsqlmjyqx0SZZF84Wb0N3nKsVryXh+3mlvMl6RwxUQgjUtrRwfaydgGPx+eIB9YyMMp5IsCIboCYXHObtmqnz605/mAx/4ACeffDLRaJS7774bgL/927/liiuu4PTTT+f888/PVwrauHEjf/d3f8fWrVuRUhIIBPjqV7/aNGIl1Dysb//arh0zev6jh+T6czZGQVjyEWlFAQalwmQ2RHgm22G3WZmp+yhuVIkZ8hoJSofYaddOSbCOFs033YTzWqCUojeT5sWxEXbFR3gpPkZaliYzCGBlpCUfFLGmpZWAYfCH0WHu2b8XUxhEAwGSto2rJJcvX80JbR0NuZ/pckaDAizmG9qyqhkib8nkEmuFkXOzmQhhlebnaOYExY0qAa9/0wQaVRYzG6L5hu0su8ZG8tbTiFPpGu4JhTk+1sb61naOa2kjWmXOZHvfQUxhEDK9L18h0yTjeutnm1gJwNKei7qhxeqIiDLBKVoWRb2VBxoEYt2YaR29NB9wE72IYGvpSjOEm+g76rGFpN3mi+ZLuQ4vxUd50Q+K6K0SzNFmBTg+1sa61nbWx9roLErGHY+BbIaoWfrYCRoGA1WCLpoFQwgCQmAJA8vwlqYQBJogfH4+MU/FqtQNlxMh771R+l6jOQKTSdgFbx4qZ0E1vjZfAVtK9iYLlSJeTSYqLLywYbA21pavFrEkHJm0a7orGGLEtgkVhaJnpSypOtEoLCGwDMNblgmTpvFMWKy+8IUvcN5553H66adXDYmcTVitSxs9BM0coThht3jOKpewa0tJWrrYUpKRsmksKKkUB1JJXoyPsGtslJcTY9hlhY5NIVgVjbHen3c6JtqCOc0vcFt6lnLP/r1kXDANg4zr4irJlp76/E0KKBGkgC9Ilphckrmm/kxYdY4//nj+/d//nX/6p3/iLW95C+eddx7HH3/8TI5txhj85U01i9jSzG+KE3bdRB9GSw+B4y4j230yI+lU01hPSin6sxl2+eK0Oz5Kwq1Mxl0ejubLGB3b0lpiAdWCE9o6uHz5arb3HWTYsekIBNjSs3RG5qtyrrpAfmk0ReULzdSYdDTg66+/zq9+9St+/etfY5om559/Pueeey6LFy+eqTHWnGe/+a5pRWwdjbkSQQdz515m6j6UUmSVJCtzL3dGi8ZOJhpwzLa9gIj4CLvGRhiskp+1IBD0Lad21sXaaA0Eaj3kcalFZGNuPskUAtO3kMw6u++WLtWemnowaX/eihUreN/73sdpp53GN7/5TX74wx/yH//xH6xdu5b/9t/+G6tWrZqBYdYWMYWILY0G8N15LlkpcfyeUM1hO0HGddmTGOPFsRF2x0c5kK5Mxm0xLdb51cnXx9roniX5TTlRKlhIniDVu4Bts/PGG2/wkY98hB07dhAKhVi1ahVf+tKXCAaDrF69mi9/+cv89//+3wG44YYb2LRpE1dffTVXX301DzzwAK+88gqhUIj+/n42bdrEvn37Kq5xzTXX8JOf/ISenh6ef/75quPYtWsX1157LcPDw2QyGd761rfmaxBOlUmJ1cGDB3nkkUd49NFHsSyLt771rXz84x+nra2N+++/n89//vN89atfPfqJmoEJRmxpNFnpknYLc0/Ngqsk+5IJdo+N8GJ8lL2JOJLyZFyDtbFWr31GrJ1lkWhTP+BzohQ0DAKGkbeYdJDD0VFKcdlll3HVVVfx/e9/H4BnnnmG3t5eVqxYQU9PD//wD//AtddeSzBYWc7KNE2++c1vct111x3xOldffTU33HDDEQvcfvjDH+ajH/0o73rXuwB47rnnpnFnHhMWq0984hMcPnyYt7zlLXz4wx/muOOOK9n+x3/8x/z0pz+d9oDqxhEitjTzG6UUGSlJuy5p6eI20bzT6/Exdhw+xK74KC/FR8lU6Yx7TLSF9bF21rW2szoaa9oQa0sIwqaZt5iChjHtAI7ZhLvzFdxfPI4cHMFY0I554ZmYG9ZM+Xy/+MUvCAQC+SLgAKeeeirgtRRZuHAh55xzDnfffTd/8Rd/UXH8Rz7yEe64446q24o577zzqlpcxRw6dKikE3yu4O50mLBYbdu2jU2bNh0xEnC2WFXlLRY0GoC065J0naZKzB3MZvKJuLvio4xVScZdHIr4BWDbOS7WSsRsvmhd07eWLGH4VpNgUUuM/tTsKMZba9ydr2D/6AEwTYiEkKNx5I8egHdfPGXBev7553nTm950xH0+8YlP8Pa3v51rrrmmYtvKlSs599xz+c53vsM73/nOKY0hx0c/+lEuuugizj77bLZu3coHPvABOjo6pnXOCf9WRyIR+vr6SiYTDx48SH9/PyeffPK0BlFvjHCnjgbUAH5irp/31AwWVNJxvArlcU+c+qok47ZbgXwZo+Nb2+losgrlVm5uyZ9fyrnzNAXcXzwOpokI+gEtwQAq662fjnV1NFavXs2ZZ57Jv/7rv1bdftNNN3HppZdyySWXTOs6H/jAB/ijP/ojfvazn/HjH/+Yf/7nf+b3v/99SaX4yTJhsbrzzjv5zGc+U7IuHA5z55138g//8A9THkAjWHDBrY0eQtPz5NAA9x16jQE7S1cgyLYlK3lT59xordJMAmVLySuJsXy+0+upasm4ph8U0cYZS1cQyWSbJifIKnLh5YSpmefEmgU5OAKRsgd3wPLWT5ETTjiBf/u3fzvqfjfddBPvfe97Oe+88yq2rV27llNPPZV77rlnyuPIsXTpUq655hquueYaTjzxxAlZfkdiwmI1MjJS0Yq+s7OT4eHhKV9c05w8OTTAN/btxhIGrcEgQ9ks39i3G1g3KwVLKkXSsRnKZkg3ODFXKsXrqUS+UsTLibGKXCzLr1C+LublO62ItuQtk86WGEPZxhSyNYQXsBE0DIKGqS2maWAsaEeOxiFYlCpgOxgL2qd8zosuuoibbrqJb3zjG/l5px07dpBMJksqp69fv56NGzfyk5/8hDPPPLPiPJ/61KembVn97Gc/Y/PmzQQCAd544w0GBgZYtmzZtM45YbFatGgRzz//PCeeWGip/oc//KGpOklqasN9h17DEgZhv9ho2DRJu9762SJWUqkSC6ojHSbpukc/sMYopejLpvPitDs+SsqtrFC+PBLN5zqtjbUSNBpbW1JA3pUX9C2mZg3UmI2YF56J/NEDqCwQsMB2wHUxL6wUj4kihODee+/lIx/5CLfddhvhcDgful7Opz71KU477bSq5znhhBM4/fTTeeqpp6puv+KKK/jlL39Jf38/y5cv5zOf+Qwf/OAHS/a5//77+eu//mvCYS814vOf//y0c3EnnBS8Y8cOvvrVr3LRRRexaNEient7+cUvfsH111+fb4M8Wzh48OCMnn+2J9Je+/RviJkWQggsy8JxHJRSxF2Hfz7tLY0eXlVcJXGkwlGSlOvlQRX/YteztcaonfWDIjyBqtYssTsYyuc6HRdrI2ZNLBl3Ju6jWJhyllM9yg/N9r+THFNNCq51NOBcZ8KW1RlnnMHNN9/MQw89xFNPPUVXVxef+tSnWLtW93KZa/SEwgxls4SLSu1kpGyaBnm5xFxbSmylcGR5dlF9SbkOexKFIrCH0qmKfWKWlS8Ae3xre0MLtxZbS/USpnqTm3Pty6TpCYWbcs7V3LBGi9MkmFSM69q1a7U4zQO2LVnJN/btJu1Ci2n6FcIl25asrPtYlFLYReWMmqEYrCMl+4o64+5LxilPFQ4aBmtbWvNRe0vDjUnGNYuqPoSM+REAUTznGjOtWT/nqvGYlFjt27ePnTt3MjY2RrH38E//9E9rPjBN4/D+oNcVogGD9YsGdJXElipfZ6/cndcIpFIcTCfz4rQnMUa2LBnXAFZFY3lxWhWN1b1oas6dFyx6zack2xzFc67ArJxz1VQyYbHavn07d999NyeffDLPPPMMp556Ks8++yybNulcpbnImzq7eFNn14zOKzw5NMC9B1+lN5OmKxhiy8IlbGiSbrED2UyhM258hLhTWaF8STjC8bF21re2sbalrcRtWg8MP9E26Lv1goYx59x5U6EvkyZWlhgdMoyqOWua2cOExerHP/4xN910Exs2bOADH/gAN954I08//TSPPvroTI5PM4fIFX51lOTJoQG+8/rLmBiEDZOhbJbv79/L5ctXN6S9edyxvWRcf96pv0rn2s5A0Jt3am3j+FgbbXVMxs3lM7UHg4hgULe7OALNPueqmRoTFqvR0VE2bNgAeCGSUkpOO+00vvzlL8/Y4DSzE0dKbN+d5yhfoMrcef/5xn5MjHy/pJBpknFhe9/BuohVVrq87AdFvBgf4UAqWeFujJhmPtfp+NZ2FgZDM265lEfmBcqqi7cHQ9hNWE6pmSiecw0ZBhkpGzbnqqkdE/6tX7BgAX19ffT09LBkyRKeeOIJWltbZ33XYM30kH4AhFMUADGRqhAD2QzRsodu0DAYqGLR1AJXSvYmxvLzTnuT8arJuMe2tOatpxWRlhkPRhB49x0yTS8AQmhX3nQpnnNt5mjAmWCmW4S8/vrrXHnllbzxxhsYhsGHPvQh/vqv/7piHA1tEfKud72LAwcO0NPTw3vf+16++MUv4jgOH/jAB6Y1AM3sQPruO1epvMVk+269qdAVDDFi2yWdaLNS1iykWylFbybNLw+/wdMjgyRdp8JyEsDKSEs+KGJ1SyvBGXat5cQpaBiEDFPPM80QuTnX+UQ9WoRYlsXtt9/O6aefztjYGG9605u4+OKL2bhxY8l+DWsRopRiw4YNdHd3A3Daaadx11134ThOPkNZM/tRSuXnlFylcKTCTSU5nE7VvIbelp6l3LN/LxnXe3hnpcRVki09U++6OmxnC0ERYyOMVKlQbgAbWjs4u2shx7W0EZ1Bz4AArHxOUyGEXIuTBmBk36P0PfltsqMHCbYtpedNV9K+6pwpn68eLUKWLFnCkiVLAGhtbWXDhg0cOHCgQqwa1iJECMH/+B//g7vvvrtwoGVpF+AspVDtoTCn5I7T9TY4Q8VeT2jr4PLlq9ned5CBbMaLBuxZOqn5qpTr8FJ8lBf9oIjeKtFeBl7octQKEEDgKkVWupzSvqBm9/KH0WG29x1k0M7QHQzzzsUrOGNBlxYmzbiM7HuU/b/4HMIMYITasBP97P/F5+DCj09ZsOrdImTfvn08/fTTvPnNb67Y1tAWIatWreLQoUPTLkaoqQ/FVlJxoIOrJLLRiUs+J7R1TEqcbCnZm4znradXk/EKcQ0ZBsf5XXEf6DtAqxnAMAws08RxXUylajYvJoAXx0b4twP7CAiDditI3HH4zusvEzbNeeeG0kycvie/7QlVIAKACESQ/vrpWFdHo1YtQuLxOO95z3v40pe+RFtbW8X2hrYIOeGEE7j11ls5//zz8+7AHBdddNGUB6CZPq4fbWf780jNUIKoFkilOJBKsis+wotjo7ycGMNWpcm4phCsisZY75cxOibakk+EfXZk0JsXK9p/OvNiuQaCIb/quCUEX9+7i6Bh6gRUzaTIjh7ECJU+5IUVJjs69bql9WoRYts273nPe/jzP/9z3v3u8RvYNqxFyK5du+jp6WHnzp0V27RY1Q+pFLaUZH1hyk4w+m42oJSiP5vxGg+OjbI7PkrCrUzGXRaO5jvjrm1pLQnSKKZ4Xsw0DDKuO6l5sUA+EMIYN69JJ6BqpkKwbSl2oh/hW1bgdTAPtk19zrYeLUKUUnzwgx9kw4YNfOxjHxt3LA1tEfK3f/u307qQZvLk5paKLSZbllehm92M2Ta74qPs9jvjVnPRdQVDHB9rY51fCLY1MLEK5cXzYsOOTUcgcMR5sUBRJYiQaU6oV5NOQNVMhZ43Xcn+X3wOiWdRKSeNcm163nTllM9ZjxYhjz76KN/5znc46aST8sEbt956K+94xztK9mtoixB5hIekMcsy6ZupRYhUynPjHSWJtlHUuiVFxnW9CuW+9XQgnazYp8W0/M64XguN7ho8+KvdR8C3mnIh5FPJqSoumlqcgPoXq2amaOpcaasBc+deptoipNbRgHOdCVtWV1xxxbjbfvCDH9RkMHOZXMCD7c8t5d7PFRfeeLhK8moywa6xEV6Mj7I3EadchgPC8JJxW71qEcsita9QLiA/11TL6uPzOQFVMz3aV52jxWkSTFisvvKVr5R8Hhoa4r777tOFbKvgSEnKdQqWku/Cmw8opTiUTuULwO6Jj5Ius8oFcEy0xa8U0c7qaKzmXWgLybeeOC1tiTGQnpnqGPMxAVWjqTcTFquFCxdWfL7hhhv45Cc/OW8DLIqj8HJzS46SJJMhhrKV3WHnKkPZTD4R98X4KGNVknEXh8Ksy1Uoj7VVlFqaLoYgL0zBKsm3Ot9Jo5ndTOuJkUwmGR0drdVYmpZcA8DiYAfHn2uajyQdx6tQ7gdFVIt8a7cC+TJGx7e201HjCuUllpPpBUZoQdJo5i4TFqt//Md/LHkYZDIZdu7cyVvf+tYZGVijqKgYPo9ceONhS8krRUVgX0slKiuUG6aXjOuHlC8KhWsqHpYQhAxzTrdi12g04zNhsSoPOwyFQlx88cWcfPLJNR9UPSgOCy924TVLdYdGIpXi9VSCXWOjvPzqHnaPDFYItiUEq/3OuOtj7ayItkwo1HuiGAJChknYt5zmY8dbjUZTYMJi9Sd/8iczOY66crBK76L5jFKKvmya3X5vp93xUVKuW7KPAJZHohwfa2ddrI21sVaCRu0645ZXh6h1wIVGMx+Y6RYh4JXea21txTRNLMviiSeeqNinoS1CvvnNb3LOOedw/PHHlwzoN7/5DVdfffW0BlFvtFDBqJ1lV3yUF8c8cRqyKwNCuoMhTu5ayKpgmHWxNmLWxJJxJ0LOctLipNHUhnq0CMnxi1/8oqLsXjENaxECXubylVeWZlevWbOGz3/+87NOrOYjadflpUShbfuhdKpin5hleeHkflBEVzBU06TggBCETdNvNFg7q0yjmY28duBRntl5N2Pxg7TGlnLqhqtYuay5W4RMlIa1CIFCK/tipJRMsACGps44UrIvGc8HRexLximvQRI0DNa2tOaj9paGa5+MawlBxDSJmJa2njQan9cOPMqvnrgN0wgQCraRTPXzqydu4618YsqCVa8WIUIItm7dihCCa6+9lg996EMV+zS0Rcj69ev5/ve/z/vf/34Mw0BKyQ9/+EPWr18/rQFoaoNUioPpZF6c9iTGyJZ9uTCAVX5QxPGxNlZFY1WLs04HU4iSEka1Pr9GMxd4ZufdmEaAgOUVsg1YEXC89dOxro5GLVqEPProoyxdupS+vj4uvvhi1q9fX1HBvaEtQj7wgQ9w2223ce211+ZrenV2dvLxj398Qsc/88wz3HXXXUgp2bx5M9u2bSvZHo/H+frXv05vby+BQIDrrruOlStXcvDgQe644478fn19fVx++eVccskl3HPPPTz44IP5fipXXHEFp59++kRvadYzkM0UOuPGR4g7lRXKl4QjfqWINta2tBKpcTIueBZa2PQi97T1pNEcnbH4QULB0hYhlhlmLN78LUJytRB7enq47LLLePzxx6ueq2EtQrq6uvjc5z7Hnj17GBgYoKuri7Vr106oiK2UkjvvvJObb76Zrq4uPvnJT7Jp06YSn+a9997LqlWruPHGGzlw4AB33nknt9xyC0uXLuXzn/98/jzXXnttSVn7Sy65hEsvvXQy9zxriTu2n4zrWU/9VSqUdwaCeXFaF2ujvcbJuABG3nryLChtPWk0k6M1tpRkqj9vWQE4bprWWHO3CEkkEkgpaW1tJZFIcP/993PLLbdU7NfQFiH79u0jFouxbt26/Lr+/n7i8TirVq064rF79uxh8eLFLFq0CICzzz6bHTt2lIjV/v37ueyyywBYtmwZhw8fZnh4uMTP+dxzz7F48eKK0k9zlax0eTkxlg+K2F8l5D5imqyLeQVgj29tZ2EwVPNk2eJSRiFtPWk00+bUDVfxqyduA8ezqBw3jSttTt1w1ZTPWY8WIb29vfnntOM4vO997+Ntb3tbxX4NbRHyN3/zN/y//+//mxcc8GL6v/CFL/CFL3zhiMf+9re/5ZlnnslHqTzyyCO89NJLfPCDH8zv86//+q/Yts1VV13Fnj17uPnmm7n11ltZs2ZNfp+vfe1rrFmzJv/Dueeee3j44YeJRCKsWbOGK6+8klgsVnH97du3s337dgBuu+029gwOTOSWp4xlmTiOe/Qdy3ClZG98lOeHBvjD0AC7R4ZwVGWF8nXtnZzQuYCTOrtZ1dpW86AI8Fx7EcuiJRTClGrWV4uwLAunipt0tjFX7gPmzr1UCwOfCLWOBpzrTNiy6u/vLxEq8KpaHD58+KjHVtPD8offtm3b+Na3vsWNN97IypUrWb16dYmL0XEcnnzySd73vvfl123dupX3vve9gNem5Nvf/jbXX399xbW2bNnCli1b8p9r2Z+pGhMN91ZK0ZtJ53s7vRQfJSUrk3FXRlpY55cxWtPSSjD3c3ElI8PDNRt3yDCImF6LdlMY2IDVHaJ/YGbFvR7Mld5Jc+U+YO7cy1T7Wa1cdo4Wp0kwYbFasGABr7zySoml88orr9DZ2XnUY7u6uhgoeuANDAxUHBeNRvNCo5TihhtuoKenJ7/96aefZvXq1SVuweL3mzdv5nOf+9xEb6dhDNvZQlDE2AgjVSqU94TCXq5TrJ3jYm20WLUPigC/x5MfGBGeYGdcjUajaQQTfgpecsklfP7zn+fSSy9l0aJF9Pb28h//8R+8+93vPuqxxx57LIcOHaKvr48FCxbw2GOP8eEPf7hkn0QiQSgUwrIsHnzwQTZs2EA0Gs1vf/TRRznnnNJvIUNDQ3nRe/zxx1mxYsVEb6dupFyHl4qCIt6oUqG81QqwPtbGOj+kfEFw6uGdRyMXHBHxE3NnwoWo0Wg0tWbCYrVlyxZaWlp46KGH8tGAV155JWedddZRjzVNk2uuuYbPfvazSCm58MILWbFiBffffz/gufMOHDjAV77yFQzDYPny5SVZ2JlMhmeffbYi+ey73/0u+/btQwjBwoULqyan1RtbSl4YGuCJQwfYFR/l1WS8IigibBisjbXlracl4ciMzgkJIGyanovPMGf9/JNGo5l/TDjAYi6x4+U9NTuXVIoDqSS74iO8ODbKy4kxbFWajGvmKpT7ZYyOibbMeBXxXO296VpQc2VeQd9H8zFX7mWqc1aayTGpyZDh4WH27NnD2NhYSdDEfOoUrJSiv6gz7u74KAm3MqJpWTia7+20tqWVkDnztfBMv/Ze2A8z1xaURqOZK0xYrB5//HH+8R//kSVLlvD666+zYsUKXn/9ddavXz/nxWrMsdk1NspuvzPuQJVk3AWBoF/GqJ0zl69AJpJ1GVvAMAj7FpTOf9Jo5jf1aBFyzTXX8JOf/ISenh6ef/75/PrBwUH+9E//lH379rFq1SruueeeikA6KSUf+chHeOihhxBCEA6Hueeee1i9evVR723CT7cf/OAHXH/99fz93/894XCYv//7v+dDH/rQhC4y28i4Ln8YHeZHB1/lf+96jk/+4Sm+9doeHhs8nBeqFtPitPYF/Nny1fzt+lP4zIZT+fMVa9jU2UX7DAZIgBdi3h4IsCgUpicUpi0Q0EKl0cxzci1CLrjgAl5++WVeeOEFbr31Vnp7ewHyLUKy2cp2QFBoEXI0rr76an72s59VrL/tttvYvHkzL730Eps3b+a2226r2OcHP/gBBw8e5Nlnn+W5557j3nvvnXCB20nlWb3lLW8pWXf++efzoQ99qKJ1yGzDVZJXkwl2jY3wYnyUfck4bpVk3GNbWlnvu/aWRWpfoXw8ciHmEcNrr6FDzDWa2c+jvc/z7T33czDZz9JoN1eu3co5i06c8vnq1SLkvPPOq2px/fjHP+aXv/wlAFdddRUXXHBBRTrRoUOHWLJkST6HtriK0dGYsFi1tbXlyx8tXLiQ3bt309raWtE2ZDaglOJQOpUvALsnPkq67D4EsDLa4pcxamN1tPWo1ssfRofZ3neQYcemwwqwpWcpJ7R1TGmMAr+KhGnpHCiNZo7xaO/zfO65/0NAmLQFovSnh/ncc/+Hj3PFlAWrXi1CxqO3t5clS5YAsGTJEvr6+ir2ufzyyzn33HP51a9+xebNm3n/+98/btmnciYsVps3b+bFF1/krLPO4pJLLuEzn/kMQgj++I//eKKnaBo+9cLTjFZJxl0cCrMu1s761jbWxtqITqJC+R9Gh7ln/15MYdASCDBi29yzfy+XL189YcHK5UCFtQWl0cxpvr3nfgLCJGJ5UwYRKwROhm/vuX9a1tXRqEWLkOmwfPlydu3axUMPPcRDDz3E5s2b+eEPf8jmzZuPeuyEn8bFLT3OP/98TjjhBNLpdIkZl8u/anZyQtVuBfK9nY5vbadjGhXKt/cdxBQGIdPLYwqZJhnXW38kscpF8OVcfBqNZu5zMNlPWyBasi5sBjmYmnoof71ahIzHokWL8m6+Q4cOlVQgKiYUCvH2t7+dt7/97SxatIj77rtvQmI15Vn57u7uCn/jxz72samerq78ybJjuPn4k/m7jadx5cpjefOChdMSKvB6SwXL3IRBw6gaOWgKQcyyWBgKsTgcoSMQ1EKl0cwjlka7SbulgQ5pN8vSSPeUz3nRRReRyWT4xje+kV+3Y8cOHn744ZL9iluEVONTn/rUUYuTV+PSSy/l7rvvBuDuu+/mXe96V8U+Tz31FAcPej27pJQ8++yzJe1LjkRNQ8hmS37xM8ODDGQzNc1D6gqGKjrzZqWky48MFHjtPLqDnkC1B4IEDS1QGs185Mq1W7GVS8rJoJQi5WSwlcuVa7dO+Zy5FiEPPPAAxx57LCeccAKf/vSnqyYtf+pTn2L//v1Vz5NrETIeV1xxBW95y1vYtWsXy5cv58477wS8+bAHHniA4447jgceeIBPfOITFcf29fXxzne+kxNPPJGTTz4Zy7K44YYbJnZ/taxgcdVVV+WVtZl550/+HVfJSc0nHY3iOatoIEDStnGV5H0r1vDmBQuJmLOzDt9cqTKg76P5mCv3MtUKFvlowFQ/SyPTjwac68xMOe8mZ6LzSZPhhLYOLl++Oh8N2BUMctnSYzhzwdTN+mo8OTTAfYdeoy+TpicUZtuSlbyps/nnCTUaTSnnLDpRi9MkmJdiBePPJ00VQwjOXNDNBQsXsbRn0Yx8Y3xyaIBv7NuNJQxipsVQNss39u0G1mnB0mg0c5p5OWcFpfNJU8UQgqhp0hUMsTgUpmOG56HuO/QaljAI+xGHYdPEEgb3HXptxq6p0Wg0zUBNLasvfvGLtTzdjJFxXVwl2dIzNV9zyDCImhYRs77tNvoyaWJluV8hw6CvSo8sjUajmUscUayuu+66CZ3k61//OuBNmM4G2gOTry5hCUHENImYVsPq8PWEwgxls4SLwtwzUtITCjdkPBqNRlMvjihWueq8c42/XrtxQvvlmha2mFZT5EFtW7KSb+zbTdr1LKqMlDhKsm3JykYPTaOZXygFtouwKyvhaGaGI4rVxo0Te6jPNUJNWpPPC6JYp6MBNZpGYTuIrI2wHZDNN0ffyBYhxXz6058mFovxP/7H/6jZvU1qzmrfvn3s3Lmzovnin/7pn9ZsQI0iYBhETJOoac54F9/p8KbOLi1OGk09aXKBypFrEXLVVVfx/e9/H4BnnnmG3t5eVqxYkW8Rcu211xIMVlbsybUIOdr0z9VXX80NN9xQ924bExar7du3c/fdd3PyySfzzDPPcOqpp/Lss8+yadOmmRzfjNIM81AajaYJsR1E1vHcfDMkUI+9cYDvvrSTg4k4S1tivP+4DZy9eNmUz9foFiEzzYSf0D/+8Y+56aabuPHGGwkGg9x444187GMfw2yCuZzJkqvLtygcoS0Q1EKl0WjAcRHJNMbwGMZYEpHJzqhQfeGZJ+hPpWgLBOlPpfjCM0/w2BsHpnzOibYIuf3223Fdt2JbcYuQZmTCT+nR0VE2bNgAeDWopJScdtppPPnkkzM2uJlC1+XTaDRAkUDFMUYTiPTMCVQx331pJ5ZhELEshBBELAvLMPjuSztn9LoTaRHy+c9/vin7FE5YrBYsWJBvprVkyRKeeOIJdu7ciWXN2yIYGo1mNiIlIp3BGCkWqPo+nA8m4iUpKOBFHh9MxKd8zhNOOGFCxsNNN93E5z73uaqCNJ0WITPNhMXqXe96FwcOeCbqe9/7Xv7xH/+R//W//hd/8id/MmOD02g0mpqgFGRtxFgSYySOSGbAbZz1sLQlRrrMFZd2XZa2xKZ8zka3CJlpJixW+/bto7W1FYDTTjuNu+66i7vuuoutW6de0l6j0WhmDKUg6yASKc+Kiqe8iL4mCOh7/3EbcKQk5Th+ixAHR0ref9yGKZ+z0S1Cyvm7v/s7li9fnn9Nlwm3CPnWt77Fb37zG0KhEOeeey7nnnvulEvjN5pc86+ZYq60PoC5cy/6PpqPGbsXx0Vk7BmN5Ctm8Ynrp3RcraMB5zqT6mclpeT555/n17/+NTt27KCnp4e3vvWt/PEf//FMjrHmaLGaOHPlXvR9NA+BvQcIP/4CgXgKOxYhfeZG7NXTfEhL6QlU1q67e2+qYqWZHJOK2TYMg5NPPpnrr7+e22+/ndbW1qYNc9RoNM1HYO8Bott3IBIpiIQQiRTR7TsI7J1CyLZSkMkixhIYw3FEqrHzUJqZZVKhfOl0mscff5xHH32UF154gY0bN/JXf/VXMzU2jUZTZ3JWjzESR7bHamP1FBF+/AWUaUDAAiEgYKFwCD/+wsSuI2UhYddpjvknTX2YsFh98Ytf5Omnn2bNmjWcc845/NVf/RVtbW0zOTaNRlNHclaPMg1UOJi3epJbqJlgGSNxVLis1I9lYowcIWRbSkTWAdtG2JXJrI3C2t9L6Nk9pO97mPDN1zZ6OHOeCYvVmjVruPLKK2dNGxCNRjM5SqwemLzVMwFke8xzAQaKHj2Oi2wvC9l2Xb/ckQNO8whUDmt/L5HHnkOZAmItjR7OvGDCc1bbtm3TQqXRzGGMkThYZZVdjmb1TJL0mRsRrufK89psOAhXkj5zY6GaxEgcYyThzUE1oVABhJ7d4wmVX4FCM/PoongajQbwrJ4Kcahm9UwDe/UyklvOQLVEIJVBRcKk3noKbmdboZrELAiSMMaS0IR1Ud944w3+7M/+jGOPPZaNGzfyjne8g927d7Nv3z6EEPzjP/5jft8bbriBb33rW4BXSX3ZsmVkMhkA+vv7WbVqVcX5X3/9dS688EI2bNjACSecwD/8wz9UHcenP/3pmicWa7HSaDTAUayeGmIvX0T8nW9F/D/vIfFHZ+H0dDV1641qyNYoVCkG20hyLUIuuOACXn75ZV544QVuvfVWent7AfItQrLZbNXjcy1CjoRlWdx+++3s3LmT3/72t3z1q1/lhRdeqPm9VEOLlUajAUqtHpHOoloiJLecUZv5KttBJIoqmjegHl8tyWxYhcjYGGMJJpGqWsJvDo5yw0Mv857/eIEbHnqZ3xwcndaYxmsR8ta3vhWAhQsXsnnzZu6+++6qx+dahDiOM+41lixZkq9u0drayoYNG/Jl+GYaXYVWo9HksVcvq12oeh16QtULkcli9g5iHerHemMAc2CE/ExVKjPp8/3m4Ci3P3mAgCFoC5gMpGxuf/IAfwO8ZenUoqwn2iLk7W9/O9dcc03FtuIWIe985zuPer19+/bx9NNP8+Y3v3lK450sWqw0Gk3tcFyvq252dguUyNiYvQPVxclHGQK3u5PYJ/6fSZ//ey8eJmAIIpbn3IpYAhzJ9148PGWxmggTaRFy6aWXcskllxzxPPF4nPe85z186UtfqlsKkxYrjUYzPfIC5cxa196ExEkI3IWdOEu6cBZ34/R0QsBiKuEnhxIZ2gLlLUIEhxKTt9JynHDCCfzbv/3bUfe76aabeO9738t5551XsW0iLUJs2+Y973kPf/7nf8673/3uKY93smix0mg0kycnULYzK6L3ypmUOC3uwllSEKdasKQlxEDK9iwqn7SrWNISmvI5L7roIm666Sa+8Y1v5FvT79ixg2QyyTHHHJPfr7hFyJlnnllxnk996lPjWlZKKT74wQ+yYcMGPvaxj015rFNBi5VGo5kYjouwnYYUi502WRvrjQHvdagfc3AEUeal9MSpw7OalnTh9CyomTiV8+frF3L7kwfAkYRNQdpV2FLx5+sXTvmcuRYhH/nIR7jtttsIh8OsWrWKL33pSxX7fupTn+K0006rep5ci5CnnnqqYtujjz7Kd77zHU466SROPfVUAG699Vbe8Y53VOz7d3/3dyXXHq8lyUSZVNX1uYKuuj5x5sq96PuYIjNoQXV2djI0NFTTc+apozhNter6bw6O8r0XD3MokWFJS4g/X79wRuerZjvastJoNKXYjm9BzaI5qKyNVRKtN3wEccq59WbOcpoIb1napsVpEmix0mjmO7kEYP81K6L4JipO3R2eMM2wW08z8+j/OY1mPqIU2C7C9qP4mn02ICdOb/RjHTqKOOUsp0VanOYS+n9So5kv5CyorN9qo5kFajLilAsl1+I0p6nb/+wzzzzDXXfdhZSSzZs3s23btpLt8Xicr3/96/T29hIIBLjuuutYuXIlBw8e5I477sjv19fXx+WXX84ll1xCPB7njjvu4PDhwyxcuJCPfvSjxGK1K7qp0cx6SgSqiZsV2k5pQMTACKJMTLXlNL+py/+0lJI777yTm2++ma6uLj75yU+yadMmli9fnt/n3nvvZdWqVdx4440cOHCAO++8k1tuuYWlS5fy+c9/Pn+ea6+9Np8bcN9993HSSSexbds27rvvPu677z7e//731+OWNJrmJddNNzcH1YwCZTuovfsJv/TqxMTJf2lxmr/UpZDtnj17WLx4MYsWLcKyLM4++2x27NhRss/+/fs56aSTAFi2bBmHDx9meHi4ZJ/nnnuOxYsXs3Chl4uwY8cOzj//fADOP//8inNqNPMGpSBrI8YSGMNxjETan4tq9MB8bAdrfx/hHS8Q+49f0f7dn8KPHiT83B6s/mGEUighcLo7SJ+0lvjWsxh5/9uJv/OtpM/YiLNikRaqCTDTLUIAVq1alc+z2rRpU9V9ZqJFSF3+9wcHB+nq6sp/7urq4qWXXirZ55hjjuF3v/sd69evZ8+ePRw+fJjBwUE6Ojry+zz66KOcc845+c8jIyN0dnYCXs7G6Gj1qsXbt29n+/btANx2220z3kTSsqw506hyrtzLXL0PlbUhk4WM7T3MA+EGjq6AytpwoA9efwP2vwFvDFTOkQkBi7pg+SJYuRixbBGBYIBAY4Y868m1CLnqqqv4/ve/D3jTL729vaxYsSLfIuTaa68lGAxWHJ9rEXLdddcd9Vq/+MUv6v73VBexqpZ3XN5dc9u2bXzrW9/ixhtvZOXKlaxevRrDKBh+juPw5JNP8r73vW/S19+yZQtbtmzJf57ppMq5koAKc+de5sp9dHV2MvhGr+fmc9zmCTO3ndKACN9aKkYJcLv8UPLFXcSOX8NwMlHYIRGHBLOOxcsWTem4A3sddu6wiY8oYu2CDWcEWLZ66o/k8VqEgFchfeHChZxzzjncfffd+XJMxeRahFTb1gzURay6uroYGBjIfx4YGMhbRDmi0SjXX3894InbDTfcQE9PT377008/zerVq0ssrfb2doaGhvKZ8PWq/qvR1JXiKhLKRCTSjR7R5MSpOCAiWLCbRCgIyZlRJ2t/L6Fn92CMJZGtUTInr8VZPjVRmQkO7HV44sEshgnBMKQSiicezMJmpixY9WoRIoRg69atCCG49tpr+dCHPjSl8U6WuojVsccey6FDh+jr62PBggU89thjfPjDHy7ZJ5FIEAqFsCyLBx98kA0bNhCNRvPby12AAJs2beLhhx9m27ZtPPzww5xxxhn1uB2NZmZRyheoJuoFZTtYfYNYhwaw3ujHPHwky6kolDxYf6eetb+XyGPPoUyBCgUQqTSRx54jdTZNI1g7d9gYJlgBz8NkBcBBsXOHPS3r6mjUokXIo48+ytKlS+nr6+Piiy9m/fr1VSu415q6iJVpmlxzzTV89rOfRUrJhRdeyIoVK7j//vsB2Lp1KwcOHOArX/kKhmGwfPnyElM2k8nw7LPPVij4tm3buOOOO3jooYfo7u6uexVgjaZmFCfpNkMVicmI0ziWU6MIPbsHZQqw/MebZaFwCD27p2nEKj6iCJZNL5qWt36q1KtFyNKlSwHo6enhsssu4/HHH587YgVw+umn59sh59i6dWv+/bp16/jyl79c9dhQKMQ3v/nNivWtra3ccssttR2oRlNPcjlQja4iMVlxyoWSN4E4lWOMJVGhsnGZJsZYsjEDqkKsXZBKKKyiYbqOt36q1KNFSCKRQEpJa2sriUSC+++/v27PYB0LqtHUm2bopjtRcVrQng+IcBd1VYpAEyJbo4hUumBZAbgusjU6/kF1ZsMZAZ54MIuDwrQ8oZKut36q1KNFSG9vL5dddhngBb29733v421ve1vV8+gWITVAtwiZOHPlXhp6H7k5qBpUMp9yW42JiBPgdrXn3XozLU4z1SKkeM4K0wTXRbiK1NknzYgbcKotQmodDTjX0T8ZjWYmcF2v/p7jNKYOn+Ng9Q4VResNIeQ4llOdxKleOMsXkTqbkmjAdJNFA4IX9afFaeLon5RGUwsc18t7chqU/zQRcaK+llMjcZYvmhlxMg2UaYBhoCwTjLoUAdKgxUqjmTw5t15enGRjLKe+oSK33lHEaXEX7uIuVKiycoEGEHgCZAhPgIQo/WwIb52YegCEZnposdJojoaUeXESjguuW/+ae744qRf2Edu7/+jitKQbd9ECLU7FCOFZRoY3l5VbkhMkTVOjxUqjKceVCMfxgyLcxrR2d1wvICLXMuPwMMIfR+6PVgHugjZPmHzrad6LU85C8l11njh5Sy1IsxstVpqqBPYeIPz4C8h4itZYhPSZG7FXL2v0sGaG4mCIRtXbO4I45VCAWNhJuqdTu/UMgTJNT4S0IM0L9P+spoLA3gNEt+9AJFIQCSESKaLbdxDYe6DRQ6sNUkImi0ikMIbHMEYSiKTfUqNeQuW4WAcPE37qRWL/+Wvav/tTYj/7DeFndmP1DiKkRAHOgjYyG9cQ33wGo3/+NsSVl5J+84k4xyyZP0JlCFTAQkVCyFgU2RFDdrSiWqOoaNj7OQQsLVTUp0XINddcQ09PDyeeeGLJ+sHBQS6++GKOO+44Lr744qppCfv27as4bqLo/11NBeHHX/DcKAHL8/MHLJRpEH78hUYPbWoohcpkEYk0xki80O8pU8ekXMfFOtTvidN/PVpVnADcTk+cEpvPYPR9byO+7QJSZ80TcRJ4VlIogIqGkK1lwhQJQVCL0njkWoRccMEFvPzyy7zwwgvceuut9Pb2AuRbhGSz2arH51qEHI2rr76an/3sZxXrb7vtNjZv3sxLL73E5s2bue2226Z3Q2VoN6CmAmMkjgqXPRgtE2Mk3pgBTRYp/XknLxEXxwUsRKb6H+mM4LhYh4ewDvVjvTGA2TdU4dYDf84pX1uvq/LnPlcRAgKmJ8CWUXDpzaNoO+fZBM7PRlD9DqLbwnpbO9bJLVM+X71ahJx33nns27evYv2Pf/xjfvnLXwJw1VVXccEFF/C5z31uyvdTjhYrTQWyPea5AIs7szousj3WuEEdiaIovYYGRBSL0+EhhFtFnDrb/KrkXmXyOS1OfpRdPi8pF3XnfxYdbSinjl8gmgjn2QT29wbABKICNex4n2HKglWvFiHj0dvby5IlSwBYsmQJfX19kz7HkdBipakgfeZGott3oHC80F7bQbiS1JkbGz00D9cXp0Y2IJy0OHn19easOAnhJclaZn45n6ykyeL8bARMECHfpRkSqIzE+dnItKyro1GLFiGNQouVpgJ79TKSW7y5K+IpVCxCqpHRgE0SrWceHspH61njilNrvvCrJ06h+o+1Hhg5cbIK4qSZMKrfgWiZmAeFt36K1KtFyHgsWrSIQ4cOsWTJEg4dOlTSPLcWaLHSVMVevQx79TK6u7sZq2cBWKW8+Sa3wZaT62L2zVNxEsITo1zlBn+pRO6zTqKdLqLbQg07ECoSrKxCdE/9kVyPFiFH4tJLL+Xuu+/mE5/4BHfffTfvete7pnwv1dBipWksruvPOfkC1YjqEP44zMPDebee1Tc4vjgVB0REZrk4CbxqDjn3nWl4rl/NjGK9rR37ewOojISggKwC11s/VerRIgTgiiuu4Je//CX9/f0sX76cz3zmM3zwgx/kE5/4BJdffjl33nknK1eu5Ic//GHV43ft2sXy5cvzn++44w7+5E/+5Oj3p1uE1J650lYDanwvUoLjV4dw3brU1LP29xJ6dg+BZBo7GiaTq749UXHq8C2nJV1NIU5TbqtRVtmhGYRprvyd5DrnTpZaRwPOdbRlpZkZcsLkW0uNcOeV9DUKBRBjCaK/fAoZi2COxOeu5ZSzlkwTZfmCpOeUmg7r5BYtTpNAi5Vm+hRXIc9ZTI0IHy/GdQk/sRNsGyMtYSSR/2U3Bu3Cbh2tpdF6s1GczJylVOTK05F4mjmGFivN5MgFQDhFFlMVC2Ui5Fx0uQZ5mek0yMu59XIBEX1DnlVXPnzTQAlB6q2nzU5xCpheDyrTT6TVIeKaeYIWK80RUVJC1q55e4xiF50KBRCpNJHHniN1NhMTLFeWhpKPJ06GQAUCGKEAjmmAlKhIGHv11OYZ6o5peHXxLAsC5rxOpNXMb7RYaQrkyhTlIvRcCcrEiKdqfqnQs3u8uSTL/xW0LBQOoWf3VBcrV2L2F5oNWr3VxcntiHkuvSXdICXhJ19EmQIjFPSK17qK9Mlra34/NSEXAJHrRmtZnktPo9FosZq3uLLIjecLUx0DIIyxZGVLddPEGEvmxzdxcfLnnJZ0oSLhku0qFCD07B5IplHRMOnpuBprSW6eyTLnZV08jWayaLGa6xRbS7m5Jikbk8tUPKzWKCKVLlhWSkEmC0LQ8rPHxhen9lghCbeKOJXjLF+Es3wRnZ2dJKYS8j1dikPG/Qg9LN13SaOZLFqs5hJF1cY9N16Dqj9MgMyJa4g8+iyks4hchXR/m1nkdnTbY4VQ8sVdqOiRxamhlNfH080ANZqaocVqtlJsKTXAjTdppPSj9fo9117foDf2MjzLqSiUvJnFCcA0sA4dJvT0SxijcWRH69zuqqzRNAgtVs1M3oXn5y3JovdNrEuAJ079w0VzTkcQp9liOUFRdJ5nQQVePUTkV7/3QuKLuiont6AFS6OpIVqsmgE/dwlZmFNqisTayTBZcfIFalaIU961VxmdV9JVGbyuyjiEH39Bi5VGU0O0WNWbXLWHJgt4mDQTFae2lqKAiNkjTipgeQm3R5lzmvVdlTWaWYIWq5ki58Lzl7PSWipmMuLkh5E3vTgVVxzPidMkw8dnXVdljWaWosWqFpQFOyhhYQzP8m/WUmL2j6Be2k/LK/uxegeOLk6Lu1AtkQYMdoII8pUgalWqqKSrsmXmk6mbpquyRjNH0GI1GYobA+YqPFQrPzSDUXk1radXjC9O+Wi9InEqTt31xKkoIKKZxSmHZUIsglR2zUPJi7sqGyNxZHussV2VNZo5iharaijlCY4rEdItROQ1qjGgz7Tr6RUjJebAiFdXr0ycSuhsI7Owc3ZYTjlyLdcDlufeMwxEJAyJmbF2c12VNRrNzDEvxar1Bw+Q3rQee8WSou60CiFVQaiakEnX0yumWJzeGMB640huvYLl1LF8KalGVH6YDIJScdKdbjWaOce8FCsxmiD6wA5SZ5/UHHXiJshR6+kVUy5OvYMI26nYLS9OuWi92WA5gSdQOXEKBnRdPY1mjjMvxQrLRKEmZpE0ERX19ABcF9ka9cRpcNR36/WPL06t0UIo+eJuVGyWiFMOy+vnpLRAaTTzivkpVjC+RdLEZE5e681Z4XiBAlkbw3aRgQDt3/vZ+OKUj9abheIEnkAFLU+gdK09jWZeMn/FKmeRzBakRIVDOEu7Cbx6CJGx84Vfjf7h/G5uzLeccgERsVl0jzmEQAX83Cc/QEKj0cxv5qdYOU5zN+EDkApzsCwgYlzLqSiUfDaKE3gRfMHAlJNzNRrN3GZeipWKNFETvhwTFadYNG81OUu6Z684gdfnKefes3QE35EI7D1A+PEXkPEUrbGIruyumXfMS7FKvOOcRg9hCuLkd8KdzeIEBQtKC9SECew94FXJMA3Qld0185R5KVYNoVycegcQ2TluOeUwBCoQQAWt0hp6mglRUtldCF3ZXTMv0U+OmUIqzKHiUPLq4iRjEWx/vsld3D27gj6ORK7vU0AL1HTRld01Gi1WtaNInNTAKG2vv4GRtSt3i0VwFndjL5lj4gReiHnA8iwoXUWiZujK7hpNHcXqmWee4a677kJKyebNm9m2bVvJ9ng8zte//nV6e3sJBAJcd911rFy5EoBEIsE//dM/8frrryOE4LrrrmPdunXcc889PPjgg7S1tQFwxRVXcPrpp9fnhpQqJOG+MYD5xkCJOOWCrWVLpCSUXLa21Gd8dUIFTMi5+HSI+YxQUtndNMF2dGV3zbyjLmIlpeTOO+/k5ptvpquri09+8pNs2rSJ5cuX5/e59957WbVqFTfeeCMHDhzgzjvv5JZbbgHgrrvu4tRTT+Vv/uZvcByHTCaTP+6SSy7h0ksvnfmbyImTX5W8XJzy99oSwThmKcmuVpy5ZjlBoc1GsFAkVjOzFFd2J55CxSK6srtm3lEXsdqzZw+LFy9m0SIvVPzss89mx44dJWK1f/9+LrvsMgCWLVvG4cOHGR4eJhgMsnPnTv7qr/7KG7BlYVl1GPYkxKk4Wk/GonQuWEC22Yu/TgZfoPIBElqg6k6usnt3dzdj/f2NHo5GU3fqIlaDg4N0dXXlP3d1dfHSSy+V7HPMMcfwu9/9jvXr17Nnzx4OHz7M4OAghmHQ1tbG1772NV599VXWrFnD1VdfTTjsdaD9+c9/ziOPPMKaNWu48soricUq/fjbt29n+/btANx22210dnZW7KOUgsND8Pob3utAL6SzlTcTi8LKxbBiMSxfjNEeIyQEoaJdLMuseo1ZhQCCAaxolM6uDoQxu5N0Lcuiu7u70cOYNnPlPmBu3Ytm5qmLWClV2XJDlFUo2LZtG9/61re48cYbWblyJatXr8YwDFzXZe/evVxzzTUcd9xx3HXXXdx333382Z/9GVu3buW9730vAD/4wQ/49re/zfXXX19xrS1btrBly5b856GhIVAKY3DUCyP3552qW07hktp6sjVaqK6gHBgerjims7PTu8ZsI1fmKBjwLKisS3dbjIE58E2+u7ubfn0fTcVcuZelS5c2egjzgrqIVVdXFwMDA/nPAwMDFZZHNBrNC41SihtuuIGenh6y2SxdXV0cd9xxAJx11lncd999AHR0dOSP37x5M5/73OcmNJ7o9sexegcwMlXEKRr2AyK6/YCI6Nwu/SOEV0UiF2I+l+9Vo9HMWuoiVsceeyyHDh2ir6+PBQsW8Nhjj/HhD3+4ZJ9EIkEoFMKyLB588EE2bNhANBolGo3S1dXFwYMHWbp0Kc8991x+rmtoaCgveo8//jgrVqyY0HiCr72Rf18QpyqW01zFEH4OVAACug6fRqNpfuoiVqZpcs011/DZz34WKSUXXnghK1as4P777wdg69atHDhwgK985SsYhsHy5cv5y7/8y/zx11xzDV/+8pdxHIeenp68Bfbd736Xffv2IYRg4cKFfOhDH5rQeLLHLi8NJZ8PD+ucBZUrczQf7lmj0cwZhKo2oTTHeeP5F2f0/E0zZ5WL4gsFpuzimyvzCvo+mo+5ci96zqo+6AoWcxHL9IvF6jBzjUYzN9BiNVfItdsIBXSpI41GM+fQYjWbKZ6H0sViNRrNHEY/4WYbAr9Y7NTnoTQajWa2ocVqtqDnoTQazTxGi1UzYxiokN9V19QCpdFo5i9arJqNXFfdkG77rtFoNDm0WDUDeh5Ko9FojogWq0ZR3HYjGNACpdFoNEdAi1U90QKl0Wg0U0KL1UwjQFkmBAO6s65Go9FMES1WM4QKaIHSaDSaWqHFqpaYXqg5C9pRwm30aDQajWbOoMVquuRq8gULoeZC50RpNBpNTdFiNRV0LpRGo9HUFS1WEyXXXVcXjdVoNJq6o5+6RyJX1XyC7d8Dew8QfvwFZDxFayxC+syN2KuX1WmwGo1GM3fRYlXOFKtJBPYeILp9B8o0IBJCJFJEt+8guQUtWBqNRjNNtFhBTZJ1w4+/4AlVTuACFgqH8OMvaLHSaDSaaTKvxaqWuVDGSBwVDpautEyMkfi0zqvRaDSaeSpWKhqueV8o2R5DJFKlwReOi2yP1ewaGo1GM1+ZlwlBKhyseVWJ9JkbEa4E2wGlwHYQriR95saaXkej0WjmI/NSrGYCe/UyklvOQLVEIJVBtURIbjlDz1dpNBpNDZiXbsCZwl69DHv1Mrq7uxnr72/0cDQajWbOoC0rjUaj0TQ9Wqw0Go1G0/RosdJoNBpN06PFSqPRaDRNjxYrjUaj0TQ9Wqw0Go1G0/RosdJoNBpN06PFSqPRaDRNjxYrjUaj0TQ9Wqw0Go1G0/RosdJoNBpN0yOUUqrRg9BoNBqN5khoy2oG+MQnPtHoIdSMuXIv+j6aj7lyL3PlPpodLVYajUajaXq0WGk0Go2m6dFiNQNs2bKl0UOoGXPlXvR9NB9z5V7myn00OzrAQqPRaDRNj7asNBqNRtP0aLHSaDQaTdNjNXoAc4n+/n6++tWvMjw8jBCCLVu28I53vKPRw5oyUko+8YlPsGDBglkdnptIJPinf/onXn/9dYQQXHfddaxbt67Rw5o0P/nJT3jooYcQQrBixQquv/56gsFgo4c1Ib72ta/x1FNP0d7ezu233w5APB7njjvu4PDhwyxcuJCPfvSjxGKxBo/0yFS7j+985zs8+eSTWJbFokWLuP7662lpaWnwSOce2rKqIaZp8t/+23/jjjvu4LOf/Sw///nP2b9/f6OHNWX+67/+i2XLljV6GNPmrrvu4tRTT+VLX/oSn//852flPQ0ODvLTn/6U2267jdtvvx0pJY899lijhzVhLrjgAm666aaSdffddx8nnXQSX/7ylznppJO47777GjO4SVDtPk4++WRuv/12vvCFL7BkyRLuvffeBo1ubqPFqoZ0dnayZs0aACKRCMuWLWNwcLDBo5oaAwMDPPXUU2zevLnRQ5kWyWSSnTt3ctFFFwFgWdas/dYrpSSbzeK6Ltlsls7OzkYPacJs3LixwmrasWMH559/PgDnn38+O3bsaMTQJkW1+zjllFMwTROAdevWzdq/+WZHuwFniL6+Pvbu3cvatWsbPZQp8a1vfYv3v//9pFKpRg9lWvT19dHW1sbXvvY1Xn31VdasWcPVV19NOBxu9NAmxYIFC3jnO9/JddddRzAY5JRTTuGUU05p9LCmxcjISF5wOzs7GR0dbfCIps9DDz3E2Wef3ehhzEm0ZTUDpNNpbr/9dq6++mqi0WijhzNpnnzySdrb2/NW4mzGdV327t3L1q1b+fu//3tCodCscDeVE4/H2bFjB1/9/7d3LzFNpWEYx/+2UHAhNLQ0UAk2aDUmrpACidaEsAMWxCBKN7Iy9Ybo0ls0uhCNCiSTYIKadKHShdeErYLGWyAaa7VSVASCjfZiSkxKW46zmExnTJzMyJg5x877W7VdtM85XTw9X7+c95dfOHfuHIlEguHhYbVjiT+5evUqer0ep9OpdpSsJGX1g6XTaU6fPo3T6aSmpkbtOAvy6tUrRkZG2LlzJ93d3Tx//pze3l61Yy2IyWTCZDJht9sBqK2t5e3btyqn+n4+nw+LxUJBQQE5OTnU1NQwNjamdqx/pbCwkFgsBkAsFqOgoEDlRAt3584dRkdH6ejoYNGiRWrHyUqyDPgDffnyhb6+PpYuXUpTU5PacRbM5XLhcrkA8Pv93Lp1i46ODpVTLYzRaMRkMjEzM4PVasXn81FWVqZ2rO9mNpsJBoPMzc1hMBjw+XwsX75c7Vj/SlVVFUNDQzQ3NzM0NITD4VA70oI8ffqUGzducPToUfLy8tSOk7XkDhY/UCAQ4PDhw5SXl2d+XbW1tVFZWalysoX7vax+5q3rExMT9PX1kU6nsVgs7NixQ/NbpL/F6/Vy//599Ho9NpsNt9tNbm6u2rH+ke7ubl68eMHs7CyFhYW0trbicDg4e/Ys4XAYs9nMvn37NP+9fOs4rl27RjqdzmS32+1s27ZN5aTZR8pKCCGE5sl/VkIIITRPykoIIYTmSVkJIYTQPCkrIYQQmidlJYQQQvOkrIRYgA8fPtDa2sr8/LzaUYT4X5CyEkIIoXlSVkIIITRPbrckskY0GuXChQu8fPmS/Px8GhsbaWhowOv1MjU1hU6n48mTJ5SWlrJ9+3ZsNhsA09PT9Pf3MzExQVFRES6Xi6qqKgCSySRXrlzh4cOHfP78mfLycg4dOpT5zLt37zIwMEAymaSxsZGNGzcCMD4+Tn9/P+/fv8dgMLB+/Xq2bt36n58TIbKFlJXICoqi0NXVhcPhoLOzk0gkwrFjx7BarQCMjIywZ88edu/ezeDgIKdOnaKnpweArq4u6urqOHjwIIFAgJMnT3LixAmsVisej4fp6WmOHz+O0WgkGAx+daPSQCBAT08PMzMz7N+/n+rqasrKyrh48SINDQ1s2LCBRCLB5OSkKudFiGwhy4AiK7x+/Zp4PE5LS0tmvHh9fX1mmm5FRQW1tbXk5OTQ1NREKpUiGAwSDAZJJBI0NzeTk5PDmjVrqKys5N69eyiKwu3bt2lvb6eoqAidTseqVau+uh/fpk2bMBgM2Gw2li1bxrt374DfhjyGQiHi8Tj5+fmsXLlSlfMiRLaQKyuRFT5+/EgsFqO9vT3zmqIorF69GrPZjMlkyryu0+kwmUyZ8RRmsxmd7o/fbcXFxUSjUWZnZ0mlUpSUlPzl5xqNxszjvLw8EokEAG63m4GBAfbu3YvFYqGlpYW1a9f+oKMV4v9HykpkBbPZjMVi+ebcLa/XSyQSyTxXFIVIJJKZUhsOh1EUJVNY4XCY0tJSlixZQm5uLqFQKPP/1j9VWlpKZ2cniqLw+PFjzpw5w/nz53+6CcVCaIUsA4qssGLFChYvXsz169dJJpMoisLk5CTj4+MAvHnzhkePHjE/P8/g4CC5ubnY7Xbsdjv5+fncvHmTdDqN3+9ndHSUdevWodPpqKurw+PxEI1GURSFsbExUqnU3+YZHh4mHo+j0+ky06L/fPUmhPg+MiJEZI1oNIrH48Hv95NOp7FarWzevJlAIPDVbsCSkhLcbjcVFRUATE1NfbUbsK2tjerqauC33YCXLl3iwYMHJBIJbDYbBw4c4NOnT+zatYvLly+j1+sBOHLkCE6nk/r6enp7e3n27Blzc3MUFxezZcuWzHsKIb6flJXIel6vl1Ao9NNOOxZCyDKgEEKIn4CUlRBCCM2TZUAhhBCaJ1dWQgghNE/KSgghhOZJWQkhhNA8KSshhBCaJ2UlhBBC834Fn7Cw0rRgSocAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 443.125x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_3b(select_size(results_3b_cnn, 'S'))\n",
    "plot_3b(select_size(results_3b_cnn, 'L'))\n",
    "plot_3b(results_3b_cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
