{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import backend as K\n",
    "import scikitplot as skplt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_1_l = [\n",
    "    Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_2_l = [\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_5_l = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_10_l = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_1_s = [\n",
    "    Conv2D(4, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_2_s = [\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_5_s = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_10_s = [\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(12, (3,3), padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns = {\n",
    "    'CNN 1 S': layers_1_s,\n",
    "    'CNN 2 S': layers_2_s,\n",
    "    'CNN 5 S': layers_5_s,\n",
    "    'CNN 10 S': layers_10_s,\n",
    "    'CNN 1 L': layers_1_l,\n",
    "    'CNN 2 L': layers_2_l,\n",
    "    'CNN 5 L': layers_5_l,\n",
    "    'CNN 10 L': layers_10_l,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_org, y_train_org), (X_test_org, y_test_org) = fashion_mnist.load_data()\n",
    "\n",
    "X_train_org = X_train_org.reshape(-1, 28, 28, 1)\n",
    "X_test_org = X_test_org.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_org = X_train_org.astype('float32')\n",
    "X_test_org = X_test_org.astype('float32')\n",
    "X_train_org /= 255\n",
    "X_test_org /= 255\n",
    "\n",
    "X_train_org, y_train_org = resample(X_train_org, y_train_org, random_state=0)\n",
    "X_test_org, y_test_org = resample(X_test_org, y_test_org, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(train_samples, test_samples):\n",
    "    X_train = X_train_org[:train_samples]\n",
    "    y_train = y_train_org[:train_samples]\n",
    "    X_test = X_test_org[:test_samples]\n",
    "    y_test = y_test_org[:test_samples]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_test_samples(total_samples, ratio):\n",
    "    train_samples = int(total_samples * ratio)\n",
    "    test_samples = total_samples - train_samples\n",
    "    return train_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_roc(y_test, y_pred, figsize=(8, 5))\n",
    "    ax.set(xlim=(-0.04, 1.04), ylim=(-0.04, 1.04))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_confusion_matrix(y_test, y_pred.argmax(axis=1), normalize=True, figsize=(7, 7))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr(y_test, y_pred):\n",
    "    ax = skplt.metrics.plot_precision_recall(y_test, y_pred, figsize=(8, 6))\n",
    "    return ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "    \n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_m(y_true, y_pred):  \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm(train_samples, test_samples):\n",
    "    X_train, y_train, X_test, y_test = get_train_test_data(train_samples, test_samples)\n",
    "    \n",
    "    X_train = X_train.reshape(-1, 784)\n",
    "    X_test = X_test.reshape(-1, 784)\n",
    "    \n",
    "    svc = SVC(C=5.0, kernel='rbf', probability=True)\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = svc.predict(X_test)\n",
    "    y_pred_proba = svc.predict_proba(X_test)\n",
    "    \n",
    "    accuracy = cross_val_score(svc, X_train, y_train, cv=5).mean()\n",
    "    val_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    roc = plot_roc(y_test, y_pred_proba)\n",
    "    pr = plot_pr(y_test, y_pred_proba)\n",
    "    cm = plot_cm(y_test, y_pred_proba)\n",
    "    \n",
    "    return accuracy, val_accuracy, roc, pr, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn(layers, train_samples, test_samples, epochs):\n",
    "    X_train, y_train, X_test, y_test = get_train_test_data(train_samples, test_samples)    \n",
    "    \n",
    "    clear_session()\n",
    "    np.random.seed(0x859)\n",
    "    tf.random.set_seed(0x859)\n",
    "    \n",
    "    model = Sequential(layers)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy', f1_m])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=True)\n",
    "    \n",
    "    loss = history.history['loss'][-1]\n",
    "    accuracy = history.history['accuracy'][-1]\n",
    "    f1 = history.history['f1_m'][-1]\n",
    "    \n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    val_f1 = history.history['val_f1_m'][-1]\n",
    "    \n",
    "    # val_loss, val_accuracy, val_f1 = model.evaluate(X_test, y_test, verbose=False)\n",
    "    \n",
    "    y_pred_proba = model.predict(X_test, verbose=False)\n",
    "    \n",
    "    roc = plot_roc(y_test, y_pred_proba)\n",
    "    pr = plot_pr(y_test, y_pred_proba)\n",
    "    cm = plot_cm(y_test, y_pred_proba)\n",
    "    \n",
    "    return loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_size(results_df, size):\n",
    "    return results_df[results_df['model'].str.endswith(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3a(data):\n",
    "    ax = sns.lmplot(x='ratio', y='accuracy', hue='model', data=data)\n",
    "    ax.set(xlim=(0.08, 0.92))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3b(data):\n",
    "    ax = sns.lmplot(x='epochs', y='accuracy', hue='model', data=data)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_3a_svm():\n",
    "    total_samples = 20000\n",
    "    ratios = np.arange(0.025, 1.0, 0.025)\n",
    "    \n",
    "#     total_samples = 300\n",
    "#     ratios = [0.2, 0.8]\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        train_samples, test_samples = calc_train_test_samples(total_samples, ratio)               \n",
    "        accuracy, val_accuracy, roc, pr, cm = evaluate_svm(train_samples, test_samples)\n",
    "        \n",
    "        yield 'SVM', train_samples, test_samples, ratio, accuracy, val_accuracy        \n",
    "        roc.savefig(f'plots/3a/svm_{ratio}_roc.svg')\n",
    "        pr.savefig(f'plots/3a/svm_{ratio}_pr.svg')\n",
    "        cm.savefig(f'plots/3a/svm_{ratio}_cm.svg')          \n",
    "        plt.close('all')\n",
    "        \n",
    "        \n",
    "results_3a_svm = pd.DataFrame(gen_3a_svm(), columns=[\n",
    "    'model', 'train_samples', 'test_samples', 'ratio', 'accuracy', 'val_accuracy'\n",
    "])\n",
    "results_3a_svm.to_csv('results/3a_svm.csv')\n",
    "results_3a_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_3a_cnn():\n",
    "    total_samples = 20000\n",
    "    epochs = 10\n",
    "    ratios = np.arange(0.025, 1.0, 0.025)\n",
    "    \n",
    "#     total_samples = 300\n",
    "#     epochs = 1\n",
    "#     ratios = [0.2, 0.8]\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        train_samples, test_samples = calc_train_test_samples(total_samples, ratio)\n",
    "        \n",
    "        for name, layers in cnns.items():   \n",
    "            loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm = evaluate_cnn(layers, train_samples, test_samples, epochs)\n",
    "            \n",
    "            yield name, train_samples, test_samples, ratio, loss, accuracy, f1, val_loss, val_accuracy, val_f1\n",
    "            \n",
    "            codename = name.lower().replace(' ', '_')\n",
    "            roc.savefig(f'plots/3a/{codename}_r{ratio}_roc.svg')\n",
    "            pr.savefig(f'plots/3a/{codename}_r{ratio}_pr.svg')\n",
    "            cm.savefig(f'plots/3a/{codename}_r{ratio}_cm.svg')             \n",
    "            plt.close('all')\n",
    "            \n",
    "results_3a_cnn = pd.DataFrame(gen_3a_cnn(), columns=[    \n",
    "    'model',\n",
    "    'train_samples', 'test_samples', 'ratio',\n",
    "    'loss', 'accuracy', 'f1', 'val_loss', 'val_accuracy', 'val_f1'\n",
    "])\n",
    "results_3a_cnn.to_csv('results/3a_cnn.csv')\n",
    "results_3a_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_3b_cnn():\n",
    "    total_samples = 60000\n",
    "    epochses = range(1, 10+1)\n",
    "    ratio = 0.8\n",
    "    \n",
    "#     total_samples = 2000\n",
    "#     epochses = [1, 2]\n",
    "    \n",
    "    train_samples, test_samples = calc_train_test_samples(total_samples, ratio)\n",
    "    \n",
    "    for epochs in epochses:        \n",
    "        for name, layers in cnns.items():   \n",
    "            loss, accuracy, f1, val_loss, val_accuracy, val_f1, roc, pr, cm = evaluate_cnn(layers, train_samples, test_samples, epochs)\n",
    "            \n",
    "            yield name, train_samples, test_samples, epochs, loss, accuracy, f1, val_loss, val_accuracy, val_f1\n",
    "            \n",
    "            codename = name.lower().replace(' ', '_')            \n",
    "            roc.savefig(f'plots/3b/{codename}_e{epochs}_roc.svg')\n",
    "            pr.savefig(f'plots/3b/{codename}_e{epochs}_pr.svg')\n",
    "            cm.savefig(f'plots/3b/{codename}_e{epochs}_cm.svg')            \n",
    "            plt.close('all')\n",
    "            \n",
    "results_3b_cnn = pd.DataFrame(gen_3b_cnn(), columns=[    \n",
    "    'model',\n",
    "    'train_samples', 'test_samples', 'epochs',\n",
    "    'loss', 'accuracy', 'f1', 'val_loss', 'val_accuracy', 'val_f1'\n",
    "])\n",
    "results_3b_cnn.to_csv('results/3b_cnn.csv')\n",
    "results_3b_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    select_size(results_3a_cnn, 'S')\n",
    ")))\n",
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    select_size(results_3a_cnn, 'L')\n",
    ")))\n",
    "plot_3a(pd.concat((\n",
    "    results_3a_svm,\n",
    "    results_3a_cnn,\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3b(select_size(results_3b_cnn, 'S'))\n",
    "plot_3b(select_size(results_3b_cnn, 'L'))\n",
    "plot_3b(results_3b_cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
