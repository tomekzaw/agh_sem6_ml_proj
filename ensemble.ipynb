{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_org, y_train_org), (X_test_org, y_test_org) = fashion_mnist.load_data()\n",
    "\n",
    "X_train_org = X_train_org.reshape(-1, 28, 28, 1)\n",
    "X_test_org = X_test_org.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train_org = X_train_org.astype('float32')\n",
    "X_test_org = X_test_org.astype('float32')\n",
    "X_train_org /= 255\n",
    "X_test_org /= 255\n",
    "\n",
    "X_train_org, y_train_org = resample(X_train_org, y_train_org, random_state=0)\n",
    "X_test_org, y_test_org = resample(X_test_org, y_test_org, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(train_samples, test_samples):\n",
    "    X_train = X_train_org[:train_samples]\n",
    "    y_train = y_train_org[:train_samples]\n",
    "    X_test = X_test_org[:test_samples]\n",
    "    y_test = y_test_org[:test_samples]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_samples, test_samples, epochs=10, optimizer='adam', n=1):   \n",
    "    X_train, y_train, X_test, y_test = get_train_test_data(train_samples, test_samples)  \n",
    "    \n",
    "    if n > 1:\n",
    "        X_train = [X_train] * n\n",
    "        X_test = [X_test] * n\n",
    "    \n",
    "    clear_session()\n",
    "    np.random.seed(0x859)\n",
    "    tf.random.set_seed(0x859)\n",
    "      \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=True)\n",
    "    \n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    return val_accuracy, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "layers_2_l = lambda name: [\n",
    "    Input((28, 28, 1), name=f'Input_{name}'),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', name=f'Conv2D_1_{name}'),\n",
    "    MaxPooling2D((2, 2), name=f'MaxPooling2D_1_{name}'),\n",
    "    Conv2D(16, (3,3), padding='same', activation='relu', name=f'Conv2D_2_{name}'),\n",
    "    MaxPooling2D((2, 2), name=f'MaxPooling2D_2_{name}'),\n",
    "    Flatten(name=f'Flatten_{name}'),\n",
    "    Dense(64, activation='relu', name=f'Dense_{name}'),\n",
    "    Dense(10, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(layers_factory, name):\n",
    "    model = Sequential(layers_factory(name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    model.trainable = False\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_layers(model, suffix):  \n",
    "    model.input.name = model.input.name + '_' + suffix\n",
    "    for layer in model.layers:\n",
    "        layer._name = layer.name + '_' + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ensemble_model(models):        \n",
    "    model_ensemble = Concatenate()([model.layers[-2].output for model in models])\n",
    "    model_ensemble = Dense(10, activation='softmax')(model_ensemble)  # or 'sigmoid'\n",
    "    model_ensemble = Model(inputs=[model.input for model in models], outputs=model_ensemble)    \n",
    "    return model_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 2s 19ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.9791 - accuracy: 0.4047 - val_loss: 1.0068 - val_accuracy: 0.6320\n",
      "Epoch 1/2\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 1/2\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 1/2\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.7306 - accuracy: 0.4683 - val_loss: 0.8807 - val_accuracy: 0.7050\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.7593 - accuracy: 0.7185 - val_loss: 0.6910 - val_accuracy: 0.7530\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 1.7204 - accuracy: 0.4635 - val_loss: 0.8386 - val_accuracy: 0.7130\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6998 - accuracy: 0.7538 - val_loss: 0.6380 - val_accuracy: 0.7810\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.5885 - accuracy: 0.7883 - val_loss: 0.5851 - val_accuracy: 0.7940\n",
      "Epoch 1/4\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/4\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/4\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/4\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 1/4\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/4\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/4\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/4\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 1/4\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 1.6901 - accuracy: 0.4868 - val_loss: 0.7770 - val_accuracy: 0.7230\n",
      "Epoch 2/4\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6391 - accuracy: 0.7785 - val_loss: 0.5848 - val_accuracy: 0.8080\n",
      "Epoch 3/4\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.5312 - accuracy: 0.8123 - val_loss: 0.5375 - val_accuracy: 0.8190\n",
      "Epoch 4/4\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4854 - accuracy: 0.8285 - val_loss: 0.5031 - val_accuracy: 0.8300\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 1.6915 - accuracy: 0.4863 - val_loss: 0.7447 - val_accuracy: 0.7560\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6024 - accuracy: 0.7945 - val_loss: 0.5542 - val_accuracy: 0.8090\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4940 - accuracy: 0.8263 - val_loss: 0.5092 - val_accuracy: 0.8270\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4477 - accuracy: 0.8425 - val_loss: 0.4762 - val_accuracy: 0.8420\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8520 - val_loss: 0.4552 - val_accuracy: 0.8430\n",
      "Epoch 1/6\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/6\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/6\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/6\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/6\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 6/6\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4459 - accuracy: 0.8407 - val_loss: 0.4944 - val_accuracy: 0.8210\n",
      "Epoch 1/6\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/6\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/6\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/6\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/6\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 6/6\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.3929 - accuracy: 0.8558 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
      "Epoch 1/6\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.7091 - accuracy: 0.4868 - val_loss: 0.7333 - val_accuracy: 0.7530\n",
      "Epoch 2/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 8ms/step - loss: 0.5803 - accuracy: 0.8117 - val_loss: 0.5388 - val_accuracy: 0.8310\n",
      "Epoch 3/6\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4667 - accuracy: 0.8420 - val_loss: 0.4929 - val_accuracy: 0.8380\n",
      "Epoch 4/6\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.8565 - val_loss: 0.4639 - val_accuracy: 0.8450\n",
      "Epoch 5/6\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3905 - accuracy: 0.8627 - val_loss: 0.4442 - val_accuracy: 0.8460\n",
      "Epoch 6/6\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3746 - accuracy: 0.8650 - val_loss: 0.4410 - val_accuracy: 0.8470\n",
      "Epoch 1/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/7\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 6/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4459 - accuracy: 0.8407 - val_loss: 0.4944 - val_accuracy: 0.8210\n",
      "Epoch 7/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4123 - accuracy: 0.8413 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 1/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 6/7\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3929 - accuracy: 0.8558 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
      "Epoch 7/7\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3629 - accuracy: 0.8677 - val_loss: 0.4937 - val_accuracy: 0.8130\n",
      "Epoch 1/7\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.5837 - accuracy: 0.5110 - val_loss: 0.7122 - val_accuracy: 0.7660\n",
      "Epoch 2/7\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.5536 - accuracy: 0.8273 - val_loss: 0.5220 - val_accuracy: 0.8330\n",
      "Epoch 3/7\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4396 - accuracy: 0.8520 - val_loss: 0.4769 - val_accuracy: 0.8440\n",
      "Epoch 4/7\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3917 - accuracy: 0.8668 - val_loss: 0.4473 - val_accuracy: 0.8600\n",
      "Epoch 5/7\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3626 - accuracy: 0.8723 - val_loss: 0.4269 - val_accuracy: 0.8570\n",
      "Epoch 6/7\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3465 - accuracy: 0.8748 - val_loss: 0.4248 - val_accuracy: 0.8560\n",
      "Epoch 7/7\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3347 - accuracy: 0.8798 - val_loss: 0.4152 - val_accuracy: 0.8610\n",
      "Epoch 1/8\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/8\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/8\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 6/8\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4459 - accuracy: 0.8407 - val_loss: 0.4944 - val_accuracy: 0.8210\n",
      "Epoch 7/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4123 - accuracy: 0.8413 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 8/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3919 - accuracy: 0.8570 - val_loss: 0.4329 - val_accuracy: 0.8310\n",
      "Epoch 1/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/8\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/8\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 6/8\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3929 - accuracy: 0.8558 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
      "Epoch 7/8\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3629 - accuracy: 0.8677 - val_loss: 0.4937 - val_accuracy: 0.8130\n",
      "Epoch 8/8\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.3413 - accuracy: 0.8752 - val_loss: 0.4141 - val_accuracy: 0.8550\n",
      "Epoch 1/8\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 1.5392 - accuracy: 0.5175 - val_loss: 0.6870 - val_accuracy: 0.7810\n",
      "Epoch 2/8\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.5299 - accuracy: 0.8357 - val_loss: 0.5050 - val_accuracy: 0.8290\n",
      "Epoch 3/8\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8625 - val_loss: 0.4639 - val_accuracy: 0.8400\n",
      "Epoch 4/8\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3708 - accuracy: 0.8745 - val_loss: 0.4371 - val_accuracy: 0.8580\n",
      "Epoch 5/8\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3422 - accuracy: 0.8798 - val_loss: 0.4170 - val_accuracy: 0.8560\n",
      "Epoch 6/8\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3262 - accuracy: 0.8823 - val_loss: 0.4172 - val_accuracy: 0.8540\n",
      "Epoch 7/8\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3139 - accuracy: 0.8898 - val_loss: 0.4060 - val_accuracy: 0.8570\n",
      "Epoch 8/8\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3041 - accuracy: 0.8915 - val_loss: 0.4026 - val_accuracy: 0.8580\n",
      "Epoch 1/9\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/9\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/9\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/9\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/9\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 6/9\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4459 - accuracy: 0.8407 - val_loss: 0.4944 - val_accuracy: 0.8210\n",
      "Epoch 7/9\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.4123 - accuracy: 0.8413 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 8/9\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3919 - accuracy: 0.8570 - val_loss: 0.4329 - val_accuracy: 0.8310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/9\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3624 - accuracy: 0.8612 - val_loss: 0.4627 - val_accuracy: 0.8270\n",
      "Epoch 1/9\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/9\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/9\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/9\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/9\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 6/9\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 0.3929 - accuracy: 0.8558 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
      "Epoch 7/9\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3629 - accuracy: 0.8677 - val_loss: 0.4937 - val_accuracy: 0.8130\n",
      "Epoch 8/9\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3413 - accuracy: 0.8752 - val_loss: 0.4141 - val_accuracy: 0.8550\n",
      "Epoch 9/9\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3087 - accuracy: 0.8815 - val_loss: 0.4230 - val_accuracy: 0.8530\n",
      "Epoch 1/9\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.7793 - accuracy: 0.4793 - val_loss: 0.7101 - val_accuracy: 0.7610\n",
      "Epoch 2/9\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.5327 - accuracy: 0.8320 - val_loss: 0.5100 - val_accuracy: 0.8330\n",
      "Epoch 3/9\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4122 - accuracy: 0.8635 - val_loss: 0.4674 - val_accuracy: 0.8420\n",
      "Epoch 4/9\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3612 - accuracy: 0.8783 - val_loss: 0.4391 - val_accuracy: 0.8550\n",
      "Epoch 5/9\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3306 - accuracy: 0.8888 - val_loss: 0.4186 - val_accuracy: 0.8590\n",
      "Epoch 6/9\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3128 - accuracy: 0.8903 - val_loss: 0.4167 - val_accuracy: 0.8590\n",
      "Epoch 7/9\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.2997 - accuracy: 0.8938 - val_loss: 0.4083 - val_accuracy: 0.8550\n",
      "Epoch 8/9\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.2896 - accuracy: 0.8947 - val_loss: 0.4040 - val_accuracy: 0.8650\n",
      "Epoch 9/9\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.2818 - accuracy: 0.8975 - val_loss: 0.4071 - val_accuracy: 0.8650\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s 17ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.4459 - accuracy: 0.8407 - val_loss: 0.4944 - val_accuracy: 0.8210\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4123 - accuracy: 0.8413 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3919 - accuracy: 0.8570 - val_loss: 0.4329 - val_accuracy: 0.8310\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3624 - accuracy: 0.8612 - val_loss: 0.4627 - val_accuracy: 0.8270\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.3367 - accuracy: 0.8773 - val_loss: 0.4856 - val_accuracy: 0.8250\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3929 - accuracy: 0.8558 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3629 - accuracy: 0.8677 - val_loss: 0.4937 - val_accuracy: 0.8130\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3413 - accuracy: 0.8752 - val_loss: 0.4141 - val_accuracy: 0.8550\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3087 - accuracy: 0.8815 - val_loss: 0.4230 - val_accuracy: 0.8530\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2993 - accuracy: 0.8915 - val_loss: 0.4124 - val_accuracy: 0.8560\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 1.5735 - accuracy: 0.5153 - val_loss: 0.6571 - val_accuracy: 0.7810\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8485 - val_loss: 0.4817 - val_accuracy: 0.8410\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3828 - accuracy: 0.8717 - val_loss: 0.4453 - val_accuracy: 0.8510\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3361 - accuracy: 0.8873 - val_loss: 0.4223 - val_accuracy: 0.8620\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3075 - accuracy: 0.8950 - val_loss: 0.4055 - val_accuracy: 0.8650\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2912 - accuracy: 0.8988 - val_loss: 0.4066 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2789 - accuracy: 0.9018 - val_loss: 0.3990 - val_accuracy: 0.8690\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2689 - accuracy: 0.9038 - val_loss: 0.3959 - val_accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2618 - accuracy: 0.9065 - val_loss: 0.3986 - val_accuracy: 0.8670\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2549 - accuracy: 0.9068 - val_loss: 0.3998 - val_accuracy: 0.8580\n",
      "Epoch 1/11\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/11\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 6/11\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.4459 - accuracy: 0.8407 - val_loss: 0.4944 - val_accuracy: 0.8210\n",
      "Epoch 7/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4123 - accuracy: 0.8413 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 8/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3919 - accuracy: 0.8570 - val_loss: 0.4329 - val_accuracy: 0.8310\n",
      "Epoch 9/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3624 - accuracy: 0.8612 - val_loss: 0.4627 - val_accuracy: 0.8270\n",
      "Epoch 10/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3367 - accuracy: 0.8773 - val_loss: 0.4856 - val_accuracy: 0.8250\n",
      "Epoch 11/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3325 - accuracy: 0.8680 - val_loss: 0.4409 - val_accuracy: 0.8400\n",
      "Epoch 1/11\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/11\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/11\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 6/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3929 - accuracy: 0.8558 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
      "Epoch 7/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3629 - accuracy: 0.8677 - val_loss: 0.4937 - val_accuracy: 0.8130\n",
      "Epoch 8/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3413 - accuracy: 0.8752 - val_loss: 0.4141 - val_accuracy: 0.8550\n",
      "Epoch 9/11\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3087 - accuracy: 0.8815 - val_loss: 0.4230 - val_accuracy: 0.8530\n",
      "Epoch 10/11\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2993 - accuracy: 0.8915 - val_loss: 0.4124 - val_accuracy: 0.8560\n",
      "Epoch 11/11\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2830 - accuracy: 0.8917 - val_loss: 0.4651 - val_accuracy: 0.8380\n",
      "Epoch 1/11\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 1.5428 - accuracy: 0.5280 - val_loss: 0.6515 - val_accuracy: 0.7800\n",
      "Epoch 2/11\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.8522 - val_loss: 0.4792 - val_accuracy: 0.8480\n",
      "Epoch 3/11\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.8788 - val_loss: 0.4443 - val_accuracy: 0.8490\n",
      "Epoch 4/11\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3226 - accuracy: 0.8917 - val_loss: 0.4253 - val_accuracy: 0.8670\n",
      "Epoch 5/11\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2948 - accuracy: 0.9000 - val_loss: 0.4090 - val_accuracy: 0.8640\n",
      "Epoch 6/11\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2782 - accuracy: 0.9025 - val_loss: 0.4114 - val_accuracy: 0.8660\n",
      "Epoch 7/11\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2658 - accuracy: 0.9062 - val_loss: 0.4043 - val_accuracy: 0.8650\n",
      "Epoch 8/11\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2554 - accuracy: 0.9107 - val_loss: 0.4024 - val_accuracy: 0.8590\n",
      "Epoch 9/11\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2485 - accuracy: 0.9087 - val_loss: 0.4047 - val_accuracy: 0.8650\n",
      "Epoch 10/11\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2415 - accuracy: 0.9137 - val_loss: 0.4067 - val_accuracy: 0.8570\n",
      "Epoch 11/11\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2371 - accuracy: 0.9115 - val_loss: 0.4059 - val_accuracy: 0.8620\n",
      "Epoch 1/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1675 - accuracy: 0.5683 - val_loss: 0.7437 - val_accuracy: 0.7050\n",
      "Epoch 2/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.7150 - accuracy: 0.7347 - val_loss: 0.6215 - val_accuracy: 0.7840\n",
      "Epoch 3/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6026 - accuracy: 0.7750 - val_loss: 0.5445 - val_accuracy: 0.7960\n",
      "Epoch 4/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5291 - accuracy: 0.8077 - val_loss: 0.5199 - val_accuracy: 0.8080\n",
      "Epoch 5/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4799 - accuracy: 0.8260 - val_loss: 0.5275 - val_accuracy: 0.8210\n",
      "Epoch 6/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4459 - accuracy: 0.8407 - val_loss: 0.4944 - val_accuracy: 0.8210\n",
      "Epoch 7/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4123 - accuracy: 0.8413 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 8/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3919 - accuracy: 0.8570 - val_loss: 0.4329 - val_accuracy: 0.8310\n",
      "Epoch 9/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3624 - accuracy: 0.8612 - val_loss: 0.4627 - val_accuracy: 0.8270\n",
      "Epoch 10/12\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3367 - accuracy: 0.8773 - val_loss: 0.4856 - val_accuracy: 0.8250\n",
      "Epoch 11/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3325 - accuracy: 0.8680 - val_loss: 0.4409 - val_accuracy: 0.8400\n",
      "Epoch 12/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3090 - accuracy: 0.8850 - val_loss: 0.4366 - val_accuracy: 0.8440\n",
      "Epoch 1/12\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0582 - accuracy: 0.6095 - val_loss: 0.7249 - val_accuracy: 0.7520\n",
      "Epoch 2/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.6385 - accuracy: 0.7685 - val_loss: 0.5636 - val_accuracy: 0.8080\n",
      "Epoch 3/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5517 - accuracy: 0.7933 - val_loss: 0.5350 - val_accuracy: 0.7920\n",
      "Epoch 4/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4709 - accuracy: 0.8313 - val_loss: 0.4799 - val_accuracy: 0.8310\n",
      "Epoch 5/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4257 - accuracy: 0.8390 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 6/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3929 - accuracy: 0.8558 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
      "Epoch 7/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3629 - accuracy: 0.8677 - val_loss: 0.4937 - val_accuracy: 0.8130\n",
      "Epoch 8/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3413 - accuracy: 0.8752 - val_loss: 0.4141 - val_accuracy: 0.8550\n",
      "Epoch 9/12\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.3087 - accuracy: 0.8815 - val_loss: 0.4230 - val_accuracy: 0.8530\n",
      "Epoch 10/12\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2993 - accuracy: 0.8915 - val_loss: 0.4124 - val_accuracy: 0.8560\n",
      "Epoch 11/12\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 0.2830 - accuracy: 0.8917 - val_loss: 0.4651 - val_accuracy: 0.8380\n",
      "Epoch 12/12\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 0.2629 - accuracy: 0.9032 - val_loss: 0.4468 - val_accuracy: 0.8450\n",
      "Epoch 1/12\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.6741 - accuracy: 0.5130 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
      "Epoch 2/12\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4749 - accuracy: 0.8530 - val_loss: 0.4696 - val_accuracy: 0.8470\n",
      "Epoch 3/12\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.3627 - accuracy: 0.8773 - val_loss: 0.4353 - val_accuracy: 0.8610\n",
      "Epoch 4/12\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3150 - accuracy: 0.8947 - val_loss: 0.4122 - val_accuracy: 0.8750\n",
      "Epoch 5/12\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2848 - accuracy: 0.9028 - val_loss: 0.3964 - val_accuracy: 0.8630\n",
      "Epoch 6/12\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2670 - accuracy: 0.9040 - val_loss: 0.3983 - val_accuracy: 0.8600\n",
      "Epoch 7/12\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2531 - accuracy: 0.9093 - val_loss: 0.3902 - val_accuracy: 0.8600\n",
      "Epoch 8/12\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2422 - accuracy: 0.9145 - val_loss: 0.3889 - val_accuracy: 0.8650\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2340 - accuracy: 0.9140 - val_loss: 0.3913 - val_accuracy: 0.8660\n",
      "Epoch 10/12\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2266 - accuracy: 0.9183 - val_loss: 0.3934 - val_accuracy: 0.8610\n",
      "Epoch 11/12\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.2212 - accuracy: 0.9183 - val_loss: 0.3922 - val_accuracy: 0.8660\n",
      "Epoch 12/12\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.2159 - accuracy: 0.9208 - val_loss: 0.3962 - val_accuracy: 0.8580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.743747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.724902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1.006750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.621467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.563583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.690960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.544457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.534985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.585144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sgd</td>\n",
       "      <td>4</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.519859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.479884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.503079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sgd</td>\n",
       "      <td>5</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.527522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.468329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.455195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sgd</td>\n",
       "      <td>6</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.494405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>adam</td>\n",
       "      <td>6</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.443655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>6</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.441028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sgd</td>\n",
       "      <td>7</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.500461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>adam</td>\n",
       "      <td>7</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.493653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>7</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.415187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sgd</td>\n",
       "      <td>8</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.432886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>adam</td>\n",
       "      <td>8</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.414080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>8</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.402647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sgd</td>\n",
       "      <td>9</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.462714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adam</td>\n",
       "      <td>9</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.422971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>9</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.407117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.485608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.412405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.399803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sgd</td>\n",
       "      <td>11</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.440886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>adam</td>\n",
       "      <td>11</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.465150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>11</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.405862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sgd</td>\n",
       "      <td>12</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.436572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>adam</td>\n",
       "      <td>12</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.446836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sgd+adam</td>\n",
       "      <td>12</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.396249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  epochs  val_accuracy  val_loss\n",
       "0        sgd       1         0.705  0.743747\n",
       "1       adam       1         0.752  0.724902\n",
       "2   sgd+adam       1         0.632  1.006750\n",
       "3        sgd       2         0.784  0.621467\n",
       "4       adam       2         0.808  0.563583\n",
       "5   sgd+adam       2         0.753  0.690960\n",
       "6        sgd       3         0.796  0.544457\n",
       "7       adam       3         0.792  0.534985\n",
       "8   sgd+adam       3         0.794  0.585144\n",
       "9        sgd       4         0.808  0.519859\n",
       "10      adam       4         0.831  0.479884\n",
       "11  sgd+adam       4         0.830  0.503079\n",
       "12       sgd       5         0.821  0.527522\n",
       "13      adam       5         0.829  0.468329\n",
       "14  sgd+adam       5         0.843  0.455195\n",
       "15       sgd       6         0.821  0.494405\n",
       "16      adam       6         0.842  0.443655\n",
       "17  sgd+adam       6         0.847  0.441028\n",
       "18       sgd       7         0.814  0.500461\n",
       "19      adam       7         0.813  0.493653\n",
       "20  sgd+adam       7         0.861  0.415187\n",
       "21       sgd       8         0.831  0.432886\n",
       "22      adam       8         0.855  0.414080\n",
       "23  sgd+adam       8         0.858  0.402647\n",
       "24       sgd       9         0.827  0.462714\n",
       "25      adam       9         0.853  0.422971\n",
       "26  sgd+adam       9         0.865  0.407117\n",
       "27       sgd      10         0.825  0.485608\n",
       "28      adam      10         0.856  0.412405\n",
       "29  sgd+adam      10         0.858  0.399803\n",
       "30       sgd      11         0.840  0.440886\n",
       "31      adam      11         0.838  0.465150\n",
       "32  sgd+adam      11         0.862  0.405862\n",
       "33       sgd      12         0.844  0.436572\n",
       "34      adam      12         0.845  0.446836\n",
       "35  sgd+adam      12         0.858  0.396249"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True, name='SGD')\n",
    "\n",
    "train_samples = 4000\n",
    "test_samples = 1000\n",
    "\n",
    "def gen_4():\n",
    "    for epochs in range(1, 13):\n",
    "        model_sgd = make_model(layers_2_l, 'sgd')\n",
    "        val_accuracy, val_loss = train_model(model_sgd, train_samples, test_samples, epochs, optimizer=sgd)\n",
    "        yield 'sgd', epochs, val_accuracy, val_loss\n",
    "        freeze_model(model_sgd)\n",
    "\n",
    "        model_adam = make_model(layers_2_l, 'adam')\n",
    "        val_accuracy, val_loss = train_model(model_adam, train_samples, test_samples, epochs, optimizer='adam')    \n",
    "        yield 'adam', epochs, val_accuracy, val_loss\n",
    "        freeze_model(model_adam)\n",
    "\n",
    "        model_ensemble = make_ensemble_model([model_sgd, model_adam])\n",
    "        accuracy, loss = train_model(model_ensemble, train_samples, test_samples, epochs, n=2, optimizer='adam')\n",
    "        yield 'sgd+adam', epochs, accuracy, loss\n",
    "        \n",
    "results_4 = pd.DataFrame(gen_4(), columns=['model', 'epochs', 'val_accuracy', 'val_loss'])\n",
    "results_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d794a53c70>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEJCAYAAABlmAtYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOy9eXgc1ZW//1b13mq1pG5ttiXvu41tGdt4kfEmGwcCOGFJCIQBMzNkYGYYICSQEPJNCAMBQgIkmcwvsQ1DMiQkYYCEgI2DwTte5X0TXmXZWlq7eu+6vz9KaqutltSSJVmS7/s8ftRdVbfq3pZ8P33PueccRQghkEgkEomkDdTL3QGJRCKR9H6kWEgkEomkXaRYSCQSiaRdpFhIJBKJpF2kWEgkEomkXaRYSCQSiaRdjJe7A91JSUnJ5e5Cu6Snp1NRUXG5u9Ft9OfxybH1Xfrz+C5lbAMHDmz1nFxZSCQSiaRdpFhIJBKJpF2kWEgkEomkXaRYSCQSiaRd+rWDWyKR9G4sFitGgw0hQFEgHPERCPgvd7ckcZBiIZFILgt2ewqninwUbj+N3x/BajUwZbqbISNT8HprLnf3JBchxUIikfQ4FouVU0U+tm4oix7z+yON7zPJGWaVK4xehvRZSCSSHiUcEqBZKdzuiXu+cLsHVbH2cK+6HovFSpI9DbstjSR7GhZL3x6TXFlIJL2cvmzX1zRBXY1GdWWYKk+Eak+YulqNG29Lxe+PxG3j90fweQUf/bWGVLeRNJeBVLeR1DQDRpPSwyPoHP3RxCbFQiLpxfS1Scfn1ajyhKmujFDlCVNTGSESRxMiYYHVaogrGFargXBI4PcJzheHOF8c0k8okOxUSXMbSXUZSHMbSXaqKGrvEhCzycLJIh+fxTGxCTLJGWohGAxcxh52DikWEkkvpS27vhCZpGeZCIYCmC0KahdNmE2rGL8Pkuxpba5iwiFBdVWYak9EXzVUhvH7Wi+8aTSirxBcBkJhH5Onu2Mm1CYmT3NTX9/AgBwTVZ5m9xRQV6NRVxPk9HH9kMEIqa6m1YcuIFZb69b1joyvNTRN4PdqeL0avgaBt0HD59X0nw0a85fksGf72bht92z34EofxKcflWO3q9iSVOxJKrboawWrTe3U77MrxtYWUiwkkl6I0ARCs1K4/Uzc83t2eFiwdBAfvVcOgNmiYLEqWKxq9KfVqmBu/Nl03GxRUJT4E1Fbq5iG+mrqamNXDXW1GrSiDYoCySkG0tyG6CrA4VSbPTuEKz0FhUwKt3suep4Nr7eGaXOSAPD7Gp/riVBVqYtSJKzfJRIGT1kYT1k4+myrTdFXH24DaS4jKS4DRqOS8CotEhH4vPrEf7EQeL2aLl5tFKM2GJU2TWxGo4K3XsNbr7X62Vltii4eFwmKPUnFalcxGGJ/hz2xApViIZH0IkJBjdMngpw8FmTR9W3b9Zvb74MBQTCg+wfaQlGahKVJVBSsVpWBuQ7Kzvr4bGPLVUwkkkF1leDYobpW72u1K6S5jLo4uI2kpOkTdFt4vTXkDLMyZGQuCAUUQSTibzG5WW0qA3LMDMjR3wtNtClcfp/gXHGIc43mK0WBCVNSsNu9bNtU3mJ8mpaBpil8frQWb4NGwN+GErSCxapEJ3ODgTZNbKoBBuaaokJ08fOEAJ9X4PNGqCT+799iVXQBSVIZOiKZ0pCXbRtbjq0rd5ZJsZBIegF1NRFOHAtQfDIYtfG3Z9c3m+GqqTb8fn3CCTT/GRBoceYZIWi8Jvbk6HFZbNsQ33Syb1clC5YO4tihWqCZ6afZqqEt009b6JNYxyYyRVVwphpwphoYMkI/1pZJTAgYPDSFjz+IP769O/Xx7dhS1coD9W/68b7l2xpfN/+mbzQHmDLdHWM+bGLKdDcmc4CrZydFj0XC+krG28pqJp5pr+l3WOWJMOVqR6tjK9zu0cW4g59xPKRYSCSXCaEJSs+FOXEsQEVpOOZcUrKKt6GhzUlHMQQYOsoS/95CEA5BIKAR8InoT79fI+gXsQITEO2aTqw2lcnTbaS6utapbLJYCKsWIgIMChi1AKFAx52/RpNCeqaJ9ExT9JjP27gLqyKMyay2OT6TWcGdaWwmCEqM2acjPoRAwM+QkSnQhomtOQajgsNpwOE0xL2fFhH4fHGExCvwNWjt/u4QXfO7kmIhkfQwzU1N3oZYs1HmACPDRlvIyDKiKBGyBjlIdNJpjqIomMxgMhtwJLfdHyGEPim2ZToxg8+poSphwgEDSSYVs6F1/0ciGGzJrCmqZNVnB6nxhUixmbj3msEUjHQR8bVu8mrqc0NIo9ofptoXocoX1l/7I1T7w43vI1Q3Hv/LzJw2x2dzGJm9wNHpsVxMoia2RFANCkkOA0mO+GJityltjg2l42a1eEixkEh6iLraCCePBThzMhh10IK+Syh3mJmhoyw4kmMnhK6cdFpDURQiBhibl0bhlpZFc8bmpeEJRvjW6lMxx42qQpJZJcmkkmTWBcTe+DOp+U+zSpLJgL3ZtelOO2uLKvnZJ59H71fjC/GzTz5HCLgqw8Kx0mqqfJFGEQhfeN0oBCEt8UmwLhJmTF4ae+KMb0xeGiGlbV9PZ+iMia0zRDR/myvQSKRr+iDFQiLpRoQQlDWamsrPtzQ1DRtlIXeouc1gs56YdHyhCA1OweRZ6RzZXRVdxYzJS6PBKTCFwi3ahDVBjT9CjT8ChDr0vFduncyqz07HPffattP88Prx/HhDxytdqgqkWI2kWg2kWY2k2gykWo2EIhGCqUrc8QVTFT73eNl/qoolI1Mx9rK4jfboqNmrs/SYWBQWFrJq1So0TWPRokUsW7Ys5rzX6+WVV17B4/EQiUS48cYbWbBgAQAPPvggVqsVVVUxGAw899xzPdVtiaRThIKCMycCnCgKttgimTnAyLBRFjKyjZdkxulKDAo8+/FRZg518eWlA7EbDXjDEd4+UMLWHZX8f1+ZzFPzc2gIaTQEIxd+BjUaQhG8jT/19/q5YKT1b/4Wo0qNL77A1PhCWE0XHOYK4Gya/K0GUm1GUq1G0hqFILVJHGxGki0G1DifqckUZkedl8MV9S3GN1Szc6LSy+pDpfzlcBX/kJfBNTmOXvO7SYTmK1BVMaKJcJevQHtELDRNY8WKFTz55JO43W6eeOIJpk2bRk5OTvSaDz/8kJycHB5//HFqa2t56KGHmDt3Lkaj3sXvf//7OJ3OnuiuRNJpOmNq6g2UVNbx1ak5/GrTCT48VBpz7j/mj8Chhrh6UMds+qGIwBu6ICjNf9qNKik2U1zBSLGZSLEY+Nn1Q0m1GnFaDBgu8dt+KBCgYKQLgMfe3x/jI7l6kJN39hQDUFIX5Nn1ZxmfYeOeqZmMSbdd0nN7kqYVqF6Du7rL798jYlFUVER2djZZWVkAzJ49m+3bt8eIhaIo+P1+hBD4/X4cDgeqKvMcSnofF0fKhsJezpysj29qcuimppxhZky9NK9ReUOIb31wkm8WjOEbc4bx5q7iFg7nUDsO53iYDAopBiMpcfLnmcxh7r1mcIzPool7rxmM0xDClta1ifcivjqWDHewYGQeimpAaBFMWoBQwMfPvziMvx2t5q39FdQHNQ6W+/jW6lPkD0nm65MzyE42d2lf+iKKEKJrXOVtsHXrVgoLC/nGN74BwPr16zl27Bj33Xdf9Bqfz8fzzz/P2bNn8fl8PPzww0ydOhXQzVAOh/6tZvHixRQUFMR9ztq1a1m7di0Azz33HMFgsDuH1SUYjUbC4Zb24P5CfxtfOARFh2vZve2CbfiqqS6SnSY+/vCCjX3QYDvjJ6UwaLC9V5szgmGNB/60l0Ol9SjAL26bxBC3g4gmMKgKTrNKd5nwG0KCDw6VsnLrqag4LZ85hC+MyyKpm4W1tb/LWn+I17ed4c97zxFqNKMZVYVbJg/gnhm5OK2mFm16C5qA2qB2Sb87s7l1UeyRlUU8Pbr4P9CePXsYMmQITz31FKWlpTz99NOMHTsWu93O008/jcvloqamhh/96EcMHDiQ8ePHt7hnQUFBjJBUVLTc+dDb0JeMvb+fnaU/jC8U0vezm81WaqpoESm7fXM502ZlMGqck3DYz9CRlsY98z48Ht/l63gC/Ne28xwqrQfgC6NTGWQOEq6rjP7eKrv5+YuHJTF/RB6a0J3TJi2Ar8ZDd39qbf1d3jHeycLBVt4oLGfDqTrCmuAPu0v464Hz3D7RzQ2j0zAZepfVw2BLZm1RJas+O93hbcjNGThwYKvnekQs3G43Hs+F3PUej4e0tLSYa9atW8eyZctQFIXs7GwyMzMpKSlh5MiRuFy6rTElJYXp06dTVFQUVywkVyaXksJbCEEo2DIZXFOSOF+DRiikf9m5/ktp7N0RP1J2/+5Kbv5KLl5/19uKu4uPj9fw4TG9v6PdVpZPzezxPugBeIFoYZ2O7anqPrIcZr6ZP4ibxvpYtauMg+U+GoIaq3aV8/6Rar4+JYP8Iclxnek9jcli4aNWtiErwOLhjk4FOl5Mj4jFiBEjOHfuHGVlZbhcLjZv3sy///u/x1yTnp7Ovn37GDduHNXV1ZSUlJCZmRn1Y9hsNvx+P3v37uXWW2/tiW5L+gDtJVATQhDwixghuFgUIglaydqNlO0FE0einKjy81/bzgPgtBj41txBve7bcm9gdLqN/1w8mG3F9bxeWM7Z2iBlDSF+sqmE9w5buTcvkwlZ9svWv9pABLPJzMpWtiGv/Ow0C0dNBfqIWBgMBpYvX84zzzyDpmksWLCA3Nxc1qxZA8CSJUu45ZZb+OUvf8mjjz4KwJ133onT6aS0tJQXX3wRgEgkQn5+PlOmTOmJbkt6OW2l8I5EMmhoEBzeXxM3R1JbGIxcyP3TLAeQ1dozkbLdTX0wwnPrzxKMCFQFvpk/kIyk3muLv9woisI1uclcPcjBR0XVvLm3gppAhGMeP99Ze5oZOQ7+YUoGOSmxqVesJhN2LYwSiSAMBryqEX+o82unoD/IiTPnOVpSy9HKAEd9Bs4LK//91bw2tyFrXeSW7hEH9+WipKTjQT09TX+w6bdFd47Pbk/l3TfPtDp5L1g6iA/eafmNy2gibjK4ptdmc/w0FvakZI4fDbB9Y8tI2en5mQwfbcHb0PFdQz2JJgTPrj/LtmLdT/H1yRncOtHd4jr5d9k63lCEtw9U8u7hymgsiarAdSNT+eqkdD3uw2QgtHEt9W+tRKutQXWm4Lh9Oab8AqpD8b+9iEAAKsugogytoozznhqO1mgcDVk4pqZxwpZJWG35/f6VWyfzvfcPtroN+X/vzCPsq01obJfdZyGRdCUBv8aZE0FGjRVtmoUsVpXhoy1REWgSCJO5c+ai2jDUJ8ePcq5PFni13m+GevtAZVQoZuQ4+PIE12XuUd/DbjJw15QMlo5O5Xd7Klh3vAZNwAfHqll3opavXJXBbTWFcPwwyndeRrHaUfxe/B/+ATQNy7BR+A7shcoyREUZeMqoq6njmJrCseTBHHMO5pgzlzrTMLCi/7sIZ7CeUXVnGBWsILkhl3umZPLylpb+tHunZOIgQFd40qRYSPoEQggqSsOcOh7k/NkQQoNhI9pO4W2xwYS8SwuqCkU0tpypZ3VRNf+2YAzf/Ms+rhuX1SIKePWGUt6+bwa92eq/53wDv9ur7+TKdph4aNaAXuGg7auk2/XP8Kaxaby2u5zCcw34wxr/s7uUsV+Yx9msGbzx6XlqfGX67qSZd1FgLMcWDrPn/Q846szVhSErn3PD0lt9jklEGCbqGG0JMjrFwOgsB1kDBqK4J6MYTVhNJgY4GlBmDmLVnrILu6EmZ7I0x4I/3DV5r6RYSHo1TauIU8dbps04daKGSVe7YgraNHGpCdSKawOsOVbNxydqqQvoYhQIazhtJj48VNoiyjnFZkIToteKRYU3xIsbS9AEmA0Kj187CIe590WS90WGpVn5wcJcdpXU89rucsYOSOVUbYhfbblQ5bDGF+JnW88SmDOEU2V+/nb1v7V6v4FWwWiXhdEDUhidYWdoqhWToXVR94dCpCbZuNFylgUL3GgmK2rIj6OhAmPSSKovwU/SHCkWkl5HdBXxeeMqoplXTVX1KmODR1hwpUNSkh1V7ZoEasGIxpbTdawpqmZ/WexO/2SLgRJPLffMGMzLn7aMOr5jag5vbD/D3EFWRrq7NvL4UglFBM9vOEtto+j9y4xshnVxdLQE8rQKrjr/DqEbnuAbbx+Ie83/7irhh9eP52+NXzaSLQZGu62MTrcx2m1llNtGsqXjIl4dimAdNhqXFsIARLDizcygvouEAqRYSHoRfp++ijh9vGWdB4dTZcgICzlDTJgtF76/d0UK7zM1AdYUVbPueA11wdjnTsyyc93IVGbmOjAbVAy2ZBSFmOCnu6blkuW08t+bTvDhIYVvzx3E1IFdVxvhUlm5q5QjFfoqa+moVBYOT7nMPeo/CCHgyD601W/D/l2ogO2eR9rcneSym3hk9gBGp9vIdpi6LMLfHwrhR3feV1ZUQKRro1akWEguK0IIys/rvojSi1cRjbWKh4ywkOY2tPqfqjMpvANhjS1n6lh9rJqD5bGrCKfFwMLhKSwemUKOM3Y7ZGv5hd7Zq8cs+MOCH31SzIPXZLNoRGqH+tQdfHKihr8d1d2bo9xW/vHqng+864+ISASxawti9dtwqujCCUVFDfjbTJLotKjMG9b3BFuKhaRbaCqXWeGLoNicLcpl+n16tbjTx4P4LlpFJKfoq4hBQ0yYzV3rBThdo/si1p2oof6iVcSkLDtLGlcRbQWoNUUdu9PTqaioIgTcMCYNl93IS5tKCEYEr2w9j8cX5rYJ7suWG+pklZ9ffKaLWLLFwLcTCLyLxgZUVeAyKJccG9DfEIEAYvPfER+9A+XnL5wwmVHmFKAsvhljmrPNJIkmLdBrItU7ghQLSZdjsCVzxOMnxRTGrGoENY2akMbINAfnT1Zx6vMgpSUtVxGDBpsZMtxMahuriM4QCGtsavRFHLpoFZFiMbBoRAqLR6Qy0HlpmUVn5Sbzw4W5/OjTYuqDGr/bU0FFQ5j7p2ddcortjtIQjPDjDXrgnQI8Oqf9wDs9NmANnotiA1LbiA24UhB1tYh17yPWvQ/1zWIWHMkoC27Q/yXrq4Xm6dDj5WrqTAbf3oAUC0mXYrJYqAuAsUKwa3dp1Ok8Li+NuojGZ+sbYq53NltFmDq5imhaxUSEXsSnaRVzqjrA6qJqPjlRQ8NFq4jJ2bovYkZOcps7TTrKuEw7zy0Zwg8+PkO5N8zqomqq/GG+OWcgFmPP7JUSQvDK1nOU1OnfX782KZ28AUlttrGaTIQ2rqH2Nz+NHtNqa6j9zU9xAtb8JVfkCkOUn0d89C5i00fQPIu1OxNlyTJ9NWFpuVmgubmyeZLEvioUIMVC0sWoZjvlx+piah37/RF2b6lg2qwMRo5xcuRIDRXmELWOMIodjlR7SfJeXKv5wvsks4rdZIg7qRtsyawpqmTVZwej3+Dunp7LUJedb75/mObpCVKsBgqGp7B4ZCoDurE+QW6KhR9fN4SnPynmRFWAbcX1fO/vp3lyXg5Oa/f/l/u/g5VsPaMH3k0flBQ3Qvti7FoYz1sr456rf2slrtET8K55T58k3ZngzgB3FtiTLmkV2NUpMboKcaoIsfr/EDs2gWj2RWPwCJSlX0aZOhvF0Paupd6aJLGzSLGQdCkGTeXw7qq45/bvruS6L+XyvQPHCIUFeDt2b7NBIclsIMmkkmRWmTcyA5MpyC82HI9eU+ML8er643xjzjCWjMti9aFSpgxI4rqRKUwf1LWriLZw20385+LBPLv+LHvPezlS4efba07x/QW53VpIZ+/5Bt7YcyHw7j9mDUwo8E4J+NBq4+8g02prULQIYu17ADECjNUG7sxmIpKJ0iQk7gxITmlVTHqb2UsIAQd2o635Pzi0J/bk+DzUpV+GsZN6dX2S7kSKhaRrEbSZgsNkUZmak9SsjvOFGs7tJSkLRgRBX5iqRrfDg/NdfO/9g3GvfXNXMS9/+Sq+PCrpslU5s5sMPDU/l1e3nuPTk7WU1IX41ppTPDU/t1tiMTzeEC9uuhB49+25g3C0s2dfnDiG9s4baF9djupMiSsYqjMFEdHAbI41xQD4fXD2FJw9Ff39xfwezWZw6SsRpUlA3JnYRk8gdGQvtSt+Fr20J8xe8Rz4Pp8PsWMjYvX/QfGJZgNXUabPRVnyJZTBw7u8L30NKRaSLsMf1gg1hNpMwWFU4Tvzclqc04TAH24Uj6iQRGLEpCGkUR+M4G08l2Q2tLmfPcVqROXylsM0GRT+Y/YA3HYjbx+spMYf4btrT3V5LEYoIvjxhhJqGj/3+6dnMdzVuiCJ4pNo7/4OCj8DwPv393HcdAe1v/1Vi2sdty/HN2go6s//CHU14CmPyWskPPpPPGW6eDQnGITzxXC+OEZE7D98hco/rorbt/q3VuKakId38ye6mcueBLYkaPppSwKbHcXYsekr7krmy3eTOmAQlSt/SnTHhcWKkr8YZfHN+mpJAkixkHQRmhD897rzLMqAiXkudmyJk4JjhptwOL7tSVUU7CYDdpMh4XTZis3Y5n72Ht6A1CqqovAPeZmk2038ekdpNBbjX2cO6LIAudd2l3GkQp+ol4xMoaCVGA9RVoJ4903E9vUXJkejEZ/BTNr8pTittriZUhtCId384kzV/w0bxcUfrxACvA1R4dBFpBzhKdUFxlMGjVl5FbOlbbNXwIf4o+5DaXXFabGCzR4jJIq96bUdbI7oa9vQEYQ+P0TtyldinlP72qs47/oG9muX4N21FWXRjSjzv4CSlJzQ534lIcVC0iW8+VkFOR4rJyprGbp0INfkZ7JnR7MUHDPcDBnR8RQcbWHUAn1qP/sNY9Jw2Yz8ZFMJIU3w8pZzeLwhbr3EWIz1J2v56xHdTzTCZeWfpmW1uEZUliP++gfEprWgNTpsFRVl9kKUG7+K4s6kRujmH/fsBY0pI8CrmmhI0BykKAokOfR/g4e3EBMA4feCpwKcqW2bvRKpdBjw6/+qLxR/bU1Y7D98hco/vR73XP17b+L60S/x3/6PKGZL3GskUiwkXcDHh6sxnFQxK/q+j/PllUyYkMrQUbmoihFNhDucgiMRLtd+9ksJXJs1OJkfWnN5pjEW47d7KqjwhvnnaZ2LxThdHeDnW88BkGxWeXzuIMzNAu9EbTXigz8hPvkAwhf6qEyfi3LTHSjZsSbB7k4ZoVjtMGgwXpMJx+3LY7bqNuG4fTnewaNQX34TfA36asXbAL4GROPP5seFz9vsfT00vY9cMIW2t5JR7UkooremgewdSLGQXBL7z3opKQyTouh/SjljTYwcaY2m4NCLzHRfXerksJcbRfFF2TaLMYatXZLD/2K6YgfP+ItiMT48Vk2VL8yjHYzF8IYiPLv+LIHGwLtH5gwk06Gb8IS3HrH6HcTf39O/fTcxaTrqzXdedoetPxQiNb8AJ7Ri9gpfMCk12/mbqJwKISAYuCAiKa62VzKqqi+lJK0ixULSac5VB9m5sQGXok9QzhyVvMltB391JfECySJADeD8hwexCPDu39Vlz7NPnEpIgdrXfxE9dmEHj8Caf13CK4yLYzE+62AshhCCV7acp6RO35301avSmTrQgQj4EX//i56zyNssAHLMVahf+jrKiLEdG3Q3Uh2KRM1eiqYhVLVDZq+2UBRF92lYrJDqbn8lo5q6fBXV35BiIekU9YEwH66tIR1dKFQXXDu7Z52Cdn9D64Fk//dbXI/+EO///CLu+U49b9kdVL74vfjPe2sVrhHj8P79fRg2GmXYaEjPatMXET8W4zT/b2EOWY62d3G9e7iSLWd0M9vVA5O4bawT7e9/Qbz/lr5jqYlho3WRGDe54wPuAZrMXtD4zb6bJuz2VzJSKNpDioWkw4QjGm9/WEV6RBeKgD3Clxe5eiRYSfi9iG3rEevXwL881vaOmiQHDBrSZc9WbEltP08hNnAtOSUqHMrw0TB0FIo9drtsy1iMIN9afYqnFuQyopWtrwdKvby+W99tlplk5CHlCHzv+4jKZjWlBw1BXXYXTJ5xxQaRXUzzlUxnHPhXOlIsJB1CCMHba6tI8+tC0WCM8KXr0lC7eZ+qOHkMsX41Ytv6qA1eBANt2qFxZWD4f692XScMStt2byHAYIRIWD9YVwN7tyP2br+wSyc7R191DG9cfQwaislojInFqPZH+M5Hp/n23IEtYjE83hDPbzyLJsCkCB7b9zqO082ijTMHoNz0Nd2BrUqH7cV0twO/PyPFQtIhPtxcg61ajwquVyIsXeLE0sVpxJsQvqZVxGo4fdH22FQ3Xk8FjtvuoXbFyy3adocd2qsa27R7+wYMQX3193D6OOLEUThxVP/ZPJX1+WLE+WLY8rEuICazvs102Bi+Pnw07rGD+c1hH/6wFo3F+OLEgQQxENYgHA5yzbB01hwq5Z8O/YkR5xuFwpWO8sWvosxa2OFgNYkkEeRflSRhtu6pI1ysv/YSYfb8JNKSEwugSxQhBJwsQmyIXUUAoKgwaRrq3Otg4lQCBgM2kwGnovaIHToRu7diMsOIsTGOZFFXCyePIo4fRZw4AieO6Vs8AUJB+Pww4vPDAHwBSM2dwc+Gf4kwBtyuNN495OGNnWejW4PvmJrDL5eNJeuRnXrupRtuR7n2Ov3ZEkk3oQgh2kvJ02cpKSm53F1oF31raUX7F15mDn/u48gOPyoKAaExYoaZvOHtp6tIdHzC24DY9qm+ijhzIvakKx0lf4meDtqV3qKtHvcQitlR052ZS5ue19zu3ZHnCSGgtKRx9XEEcfwoFJ+8YL4CDqUM5bM7nmKgO5lfbTrR4h7/kT+E6x11eJOSUay2Sx/URfSVv8vO0p/HdyljGzhwYKvn5MpC0i7nSoMc3uHHgEJYCJxj1YSEoj2EELqpZv1qxPYN+r74JlRVjwm49jqYoJcwbY2e2lFz8fM6a/dWFAWyB6FkD4JZCwAQoWCj+eoIHD/KuBNHGT8jh3v+eCDuPVbtLGHxXXko3tq45yWSrkaKhaRNaqrDbP20ASMKmhB4B4b50pSMS7qn8NYjPmtcRRSfjAVeYwgAACAASURBVD3pykCZ27iKSGu/DkN/IZ75CpO5zUSJYS3uKYmkW5BicZlor0Z1b8Dn1Vj39zqMQt/pdNYZ4P78lnmH4nFxSowG1Yj/8D59FbFjQ2yqa1WFSTMaVxFT2lxFXEkYVdpMlGhUIRynnUTSHUixuAzEq+7WlM8o0kvKLgaDGn//qBZDWBeKIrOP+xdnJpS/KG5KjJvvJDUrm8otH1/IdurObFxFLEJJvXJWEYliJsLyaYP46YaTLc4tnzYIMxEpFpIeQ4pFD2OyWFhTVBmTKbXGF4q+XzLccdlXGJGw4JO/1yEaNyIVKT6+VuDGbmr/G7+egmM1tb+5qKjNG7/UU0HPX4q3plrf0TR+iowFaAOvt4Gl4/R6Cit3XNgNtXzaIJaOy8TbIP0Vkp5DikUPE1YtrPosfnW3VZ+dZsHIPODyiYWmCTZvqCdQq3/7PyH8XLfASVYC1ebE+WJsDgeVb7VS1Oa9N3H/5DUCSDNTovgbarl+rJuCsZmENd00ZSYihULS40ix6GEigjadlhXeMMfO1HFNriOh2sldiRCCXdu8VJfp6TfPagEmTrcyPrP15ICivhaxfSNiy8dw4ijKc//dTkoMpY1qNpJ4eJslBAwj/RSSy4MUix7GoLTttKwPRHhuw1mGpFi4baKb2YOTO1XnoDMc2ufn3Cm9XxUiRNJolYUjW1ZcE+EQ7NuJtuVj2LsjJj6gvRQcMhW0RNI3kWLRwxi1AHdencsvNx5vce7r03L5+IieGuJUTYAXN5WQs8/MbRPdzB3i7FbROHE0wOeHdPNXrQhTnhnkm1MvBOhEI6u3fKyX5Ky/yBHvykCZuQBvarpMBS2R9EN6TCwKCwtZtWoVmqaxaNEili1bFnPe6/Xyyiuv4PF4iEQi3HjjjSxYsCChtn2JnacqyU5J5htzhvHmruIWu6Hqag2kGjXeOVRJTSBCcW2Qn24+x+/3VXDbBDfzhqVg7GLROHs6yP7dXkDBJyLsdzTw1NxcVEXRy3Fu/QSxZR2cL45taLGhTJuNMmshjJqAoqoEAJtMBS2R9Dt6RCw0TWPFihU8+eSTuN1unnjiCaZNm0ZOzoWSjh9++CE5OTk8/vjj1NbW8tBDDzF37lxUVW23bV8hogl+s6OM0zVnuGFCFqvumILRaERoEb1etK8Ou8nAlye4uX5MGquPVfN/Bz1U+SOcqwvxytbz/H6fh9smulkwLAWT4dJFo/x8iF1bdaEICo3Nxlq+Mzsdy/ZPiGz5GI7su7DVFfT8TOMmo8xagJI3C8XSsmaxTAUtkfQ/ekQsioqKyM7OJitLD+iaPXs227dvj5nwFUXB7/cjhMDv9+NwOFBVNaG2fYUPj1VzqkY39aQZNQyBOtzJ6VRUVHHxNGo1qtw8zsXSUal89Hk1bx+oxOMLU9YQ4hefnecP+yq4ZYKbghEpMTWXO0J1ZZhtGxtAQEQIPtGqeLD2U9zf+wARvGhH1sDBKLMXosyYl1BktUwFLZH0L3pELCorK3G7L0wwbrebY8eOxVyzdOlSnn/+ee6//358Ph8PP/wwqqom1LaJtWvXsnbtWgCee+450tNbJp27XNT4Qry5rwiAgSlW7s0fhcWoYjQa2+3nPdmZfO0ajfcPlvLGjmJK6wJUeMP89/ZS/nywijuvHsRNE7OxthEHoWgaNNRCOAxGI7VhG9s2nEWL6P6IT7Qabj3wGqPKLtRGUJyp2K5dgnX+FzAOH92pIjqJjK+vIsfWd+nP4+uusfWIWMRLbHvxxLNnzx6GDBnCU089RWlpKU8//TRjx45NqG0TBQUFFBQURN/3pqySv9p2nrqAvmvonslu6qorqaNjGSLnDjQx84ahfHKihj8d8HC+PkRFQ5CX15/gtW2n+dI4F0tHpWEzxa40Uk0GtBNFhB3pYLIiwg0cPNVAwK8nF9qi1TH9xF/IL9sDRiPK5Gt0P8SEPAJGox714fF0atwyu2ffpD+PDfr3+Pp01lm3242n2WTj8XhIS0uLuWbdunUsW7YMRVHIzs4mMzOTkpKShNr2dk5U+VldVA3AlGw7M3I6n7HVZFBYPDKVhcNT+PRkLX/cX0FJXYgaf4TXdpfz9sFKbh7r4voxqdhNBqwmE1qDj89Dgyn81Ivf34DVamBinoOFS9N46W9HSS3dwu2GMyh3PYAyLV8vRyqRSCTN6JFcCyNGjODcuXOUlZURDofZvHkz06ZNi7kmPT2dffv2AVBdXU1JSQmZmZkJte3NCCH49Y5SNAGqAvdNy+qSmsgGVWHh8BR+/sXhPDJ7ADlOPcK6NhDhjT3l/NM7n/P7veWo4Qifl6hs3VaH368HOPj9EXZsKae6JshVk5N56Kv5mB5/HnXeUikUEokkLj2ysjAYDCxfvpxnnnkGTdNYsGABubm5rFmzBoAlS5Zwyy238Mtf/pJHH30UgDvvvBOn0wkQt21fYdPpOg6U+QC4YXQag1Na7h66FAyqwrxhKcwd6mTL6Tr+sN/DqeoA9UGNN/d5KBg7mMI98SOqD+6u4mtfGYzXH/+8RCKRNNFjcRZTp05l6tSpMceWLFkSfe1yuXjyyScTbtsXCIQ1Vu0qA8BpMfDVSd3nUFP8PmYVb2PGoXVs92i8NaSAE8mDSLOaoyuKi/H7I6gyHbhEIkkAGcHdjbx90EOFV3dq3zU5A4e5aydmoUXg0F7E5o8RhVsgGEQFrgFmVBxg56hrsVlmY7Ua4gqG1WpA9HD+KYlE0jeRYtFNlNWHePtgJQDD0ywUjEjpsnuLs6f0tBuffQrVlbEnnako18xDnbWQa3KHEQiGmZjnYseW8hb3GZOXRlCR5dYkEkn7JCwWL774Itdeey1Tp07FaJQa0x6v7S4jGNG3/f7TtKxLzuskaqsR29braTdOfx570mhCyZuJMmsBjM9DMegrmHBIsHH1OabPzGDarAz2767E749gtRp0oUhVCEVkVj+JRNI+Cc/6Y8aM4c9//jO/+tWvmDVrFtdeey1jxozpzr71WfaVNrDptJ5o79ohTsZn2jt1HxEKwp5taFvWwf6doF20Chg1HmXWQpSrZ6PYY3cxCSEo3OalrjrExx+WYB5tYcrSTOxGA95whLcPlDDW4GBchtoielwikUguJmGxuPHGG7nxxhs5c+YMGzZs4OWXX8ZgMDBv3jzy8/PJzs7uzn72GZryPwFYDAr/MDUj7nUX16j2qkb8oZAehPj5YcSWdXqt6ma1DADIyEaZuUDPzZTR+mf++eEA54p1GcgcaKUhQ+Wx9/e3SFwY6iVlXCUSSe+mw/ak3Nxcvva1r5GXl8fKlSv54x//yF/+8hdGjhzJ17/+dYYOHdoN3ew7rCmq5mS1nlfp1glu0u2mFtfErVF92z2kjLmKyhe/B2XnYhvYklCm5+tmphHj2o3TKDsf4tA+vSaqPUklb4aZJKeNhaPyovEeTYkLJRKJJBE6JBYlJSWsX7+eTZs2YTQamTt3Lt/+9rdxOp2sWbOGF154gV/84hfd1ddeT10gwu/26I7kzCQTN49ztbhGr1G9Jqbeg1ZbQ+2Kl/Ua1eMm4S07B6oKE6bqZqYpM1BM7Zc1BfDWR9i1xQsCVANMm5OE2aI21vUORKMwpelJIpF0hITF4vHHH6e8vJxZs2bx7//+74waNSrm/Be/+EU++OCDLu9gX+J/95ZTF9T9CsunZmIxtgyQt2thPG+tjNu+/r03cT3+Y3zZOSgzrkVxdiytSTgs2L6pgVBQd6xPnm4nJU3GUUgkkksnYbFYtmwZ06ZNa3Mn1JW8qjhZ5efDY3r+p0lZdmbmxk+boUQibdaoVjOzUQtu7vDzhRDs3e6ltloXq+GjLeQMSWw1IpFIJO2RcG4om81GWVlZzLGSkhL27t3b5Z3qawgh+M3Osqg/4B/byP8kDAZUZ/yYi2iN6k5w/GiAs6d145I708i4ydZO3UcikUjikfDMtGLFCmw2W8wxq9XKihUrurxTfY0tZ+rYV+oF4AujUhmS2nr+J69qxHH7vXHPRWtUd5CK0hCH9ugObatd4epZdtRurNctkUiuPBIWi5qamhapwdPS0qiuru7yTvUlmud/SrYYuGNS/K2yTfhDIYwTr8Z51zeiKwzVmYLzHx/GlF+Av4OlR70NGju3eBFC94lPn5OExdojyYQlEskVRMI+i6ysLPbv38/EiROjxw4cOEBmZma3dKyv8M6hSsoa9PxPd05KJ9nSvkO58hfPYh+Yi+uxZzAOGtzpGtWRsGDHpgaCAd2hPWmanVSXjK6XSCRdT8Izy2233caLL77IwoULycrKorS0lHXr1vHAAw90Z/96NeUNIf50QC/MNCzNwpKRqe22EcUn4NhBvMcO4rM7yPznRztVo1oIwd6dXmqq9HQdQ0eayR0mHdoSiaR7SNheMX36dJ588kn8fj+7du3C7/fz3e9+l+nTp3dn/3o1rzfP/3R1YvmfxCeN24sVBeXapZ1+9smiIMUndYFxZRiYkGdrp4VEIpF0ng7ZLEaOHMnIkSO7qy99igOlXjac0iOg5wxOZkJW+/mfhM+L2PqJ/mbi1SjpWZ16tqc8zIHdekElq03h6llJ0qEtkUi6lQ6JxcmTJzl06BB1dXV6DqNGvvKVr3R5x3ozEU3w652lAJgNCvdOTcxvI7aug4C+a0ldcH2nnu3zauzc3BB1aE+bnYTVJh3aEomke0lYLNauXcvrr7/OpEmTKCwsZMqUKezdu7dP1cPuKj76vJoTVXr+p1vGu8lIan+7qxDiggnKnQkT8jr83EhEd2gH/LpQT5xqIy1dOrQlEkn3k/BX0nfffZfvfOc7PPbYY5jNZh577DEeeeQRDIYrK51EfSDCb/dUAJBhN/Kl8S3zP8Xl2AEoOQ2AMu8LKJ0oZ7p/l4/qSt2hPXi4mSEjuraet0QikbRGwmJRW1vLuHHjAFAUBU3TyMvLY+fOnd3Wud7Im/sqqAvoE/a9reR/ikd0VWE0ouQXdPi5pz4PcPp4EIA0t4GJU6VDWyKR9BwJ2zBcLhdlZWVkZmYyYMAAduzYQXJy8hVVNe90dYC/Ha0CYGKmjdmDkxNqJ2qqELu2AKBMy0dJ7liJ1aqKMPt26Q5ti1Vh2pwkDAbp0JZIJD1HwjP9zTffzNmzZ8nMzOTWW2/lpZdeIhwOc++98VNX9Df0/E+l0fxP/9RG/qcWbTd+BBE9cE+Z94UOPdfv09ixuQGhgaLA1dKhLZFILgMJiYUQgnHjxpGeng5AXl4eq1atIhwOY7VeGQnrPiuuZ895Pf/TdSNTGZqW2LiFFkGs/1B/kzMMRoxN+JlaRLBzcwN+X6NDO8+GO+PKWclJJJLeQ0JfURVF4Zvf/GbMN2mj0XjFCEUworGyMf+Tw6zytclt53+KYe8OqNQd4sqCLyS8GgE4UOijskL3j+QOMzNkpIzQlkgkl4eE7RlDhw7l3Llz7V/YD3n3UCWl9Xq09NcmZeBMIP9TE9onf9NfWG0oM+Yl3O7MiQAni3SHdkqagauutnVIaCQSiaQrSdimMWHCBP7zP/+TefPmRc1RTSxcuLDLO9ZbqPCG+ON+Pf/TkBQLS0e1n/+pCVFWAgd2A+jlUa2J7WCqrgyzd4fu0DZbFKbnS4e2RCK5vCQsFkeOHCEzM5NDhw61ONefxeL13eUEGvM//eO0zITyPzUhPl0dfa3MT8yxHfBrbN/UgBZ1aNux2aVDWyKRXF4SFovvf//73dmPXsmhMi/rT9YCMCs3mUnZSQm3FcEAYtNa/c3oiSgDB7fbRtMEO7d48Xt1cRo/2Up6ZseLIUkkEklXk7BYaJrW6jm1k6VAezMt8z91wKkNiB0boUFPNKjMTywP1KE9fjxl+hbbQUNMDBstI7QlEknvIGGxuOOOO1o994c//KFLOtOb+PvxGj6v1PM/LRvnIsvRsZ1I0YjtlDSUvGvavb74VJDjR/XnOVMNTJpmlw5tiUTSa0hYLH7+85/HvK+qquKdd97pl4kE64MRfltYDoDbbuSWCe4OtReniuDEUQCU/MUoxpamJIvFitFgw+8DqzmVuppKAExmhen5doxGKRQSiaT3kLBYZGRktHj/r//6rzzxxBP9xsFtslgIqxY0NcLTN07k/QPnmegyYE0w/1MTFwocqSjXXtfivN2ewqkiH4XbT+P3R7BaDUzMc7Fw6UC8vhrsSVdWckaJRNL7uaRwYK/XS21tbVf15bJisCWzpqiSVZ8dpMYXIsVm4s6rc1gwNp2Iry7h+4iGesS2T/U3k2eguGJF1mKxcqrIx9YNZdFjfn+EHVvKmTEng8Ejkgk01ryQSCSS3kLCYvHqq6/G2NADgQCHDh1i7ty53dKxnsRksbCmqJKfffJ59FiNL8QvN57AbFRZMtxBKBBI6F5iy8cQ1IPp1DjbZY0GG4XbT8dtu3dnJcNG5wJSLCQSSe8iYbHIzs6OeW+xWFi8eDGTJk1KqH1hYSGrVq1C0zQWLVrEsmXLYs6/9957bNiwAdB3XhUXF7NixQocDgcPPvggVqsVVVUxGAw899xziXY7IcKqhVWfHYx7btVnp1kwMg9oXyxiChxlDoBxk+Nco68k4uH3R0BIX4VEIul9JCwWt912W6cfomkaK1as4Mknn8TtdvPEE08wbdo0cnJyotfcdNNN3HTTTQDs2LGD999/H4fDET3//e9/H6fT2ek+tEVE6CuJeNT4Qnqm2URudHgvlJ4FmgoctWylKGC1GuIKhtVqAEW0OC6RSCSXm4Q9tytXruTIkSMxx44cOcJrr73WbtuioiKys7PJysrCaDQye/Zstm/f3ur1mzZtYs6cOYl27ZIxKJBiix/8lmIzkWjQtta0qjCZUeYsintNOOJjyvT4u6umTHcTiUgTlEQi6X0kvLLYtGkTd999d8yx4cOH88ILL3DPPfe02bayshK3+8IE6Xa7OXbsWNxrA4EAhYWF3HfffTHHn3nmGQAWL15MQUH8SnNr165l7Vo9avq5555rkcOqNTQBy2cO4afrilqcWz5zCC67GTWp7XtFPOVUFH4GgHVuASlDhrV67ahxENFg305PdDdU3gw3I8c6MZogOdnRatu+htFoTPj30NeQY+u79OfxddfYEhaLplKqzdE0DSHaN5vEu6a1gLOdO3cyZsyYGBPU008/jcvloqamhh/96EcMHDiQ8ePHt2hbUFAQIyQVFRXt9q2JRSPSEGIEqz47Hd0Nde81g1k0Io1KT/v30d57EzTdtBScuajNZ0cigupKwYKlg7DZDZgsgkjET3VN4v3tK6Snp3fo99CXkGPru/Tn8V3K2AYOHNjquYTFYuzYsfz+97/nrrvuQlVVNE3jj3/8I2PHtl/Mx+124/F4ou89Hg9paWlxr920aRP5+fkxx1wuFwApKSlMnz6doqKiuGJxKUR8dSwZ7mDByLxoNTyTFiCUwLZZEQ4jNqzR3wwZiTJsVJvXV3nCHDvUwLFDtcxbkoUzLbGdVhKJRHK5SNhnce+997Jv3z7uv/9+nnjiCe6//3727t3L8uXL2207YsQIzp07R1lZGeFwmM2bN8eN/PZ6vRw8eDDmnN/vx+fzRV/v3buXwYPbT8rXGUKBAPhqUf214KtNeLsse7ZBtR6BnUh22fLz4ejrgTn2TvVVIpFIepKEVxZut5sf//jHFBUV4fF4cLvdjBw5MqEkggaDgeXLl/PMM8+gaRoLFiwgNzeXNWv0b+NLliwBYNu2bUyePDmmAl9NTQ0vvvgiAJFIhPz8fKZMmdKhQXY30QJH9iSU6de2e31FqS4WzlQDVpuB+obu7J1EIpFcOgmLxcmTJ3E4HIwePTp6rKKigvr6eoYOHdpu+6lTpzJ16tSYY00i0cT8+fOZP39+zLGsrCxeeOGFRLvZ44hzxfqWWUCZXYBiaTtTbDCgUV2p+zYysmU9bYlE0jdI2Az16quvEonExgaEw+EWCQavNMSnH0RfK/OWtnt9RdkFE1RGlhQLiUTSN0hYLCoqKsjKyoo5lp2dTXl5eZd3qq8gAn7E5o/1N+Mmo2QPardNk79CNYArQ4qFRCLpGyQsFi6Xi+PHj8ccO378eKu7mq4ExLb14NMdDmqCBY6a/BWudKOsqy2RSPoMCX+1veGGG3jhhRe46aabyMrKorS0lL/85S98+ctf7s7+9Vr0PFCNju1UN0ye0W6bhvoI3gY9VkX6KyQSSV8i4RmroKCApKQkPv744+huqLvvvpuZM2d2Z/96LyeOwml9paVcex2Kof0aFM23zEp/hUQi6Ut0aMaaNWsWs2bN6q6+9CmiqwqDAWXu4oTalDeaoMwWBWeqLHAkkUj6Dh0Si+rqaoqKiqirq4tJ4dFfKuUliqivRWzfqL+Zcg1KavtlV4Um8DSKRUaWUdbXlkgkfYqExWLbtm28+uqrDBgwgDNnzpCbm8uZM2cYO3bslScWm/4OYT2leaKO7eqqCKGQLrDp0gQlkUj6GAnPWn/4wx944IEHmDVrFvfeey/PP/8869at48yZM93Zv16H0LQLsRXZOTDmqoTaxfgrsuOnQ5dIJJLeSofiLC72V8ybN4/169d3ead6NQcLofw8oOeBStScVF6qr0QcySo2e8Ifu0QikfQKEp61nE4n1dXVAGRkZHD06FFKS0tbpC3v70TzQJktKLMWJNQmHBJUeWSKD4lE0ndJeOZatGgRhw8fZubMmdxwww384Ac/QFEUvvjFL3Zn/3oVwlMOe3cAoFwzD8WeWJEiT3kY0aip6VnSBCWRSPoeCYvFsmXLoq/nzZvHhAkT8Pv9MXW0m+Iv+iti/WqaZn0lQcc2QPl53QSlKJCeKVcWEomk79Fp43l6enqMUAA88sgjl9yh3ooIhxAbVutvho9BGTw84bZN8RVpbgNGk9wyK5FI+h5d6mlNpMRqX0Xs2gJ1NUDHVhU+r0Z9bVOKD2mCkkgkfZMuFYv+HGgWjdh2JKNMm5Nwu6bEgSDjKyQSSd9F7uFMAHH2FBw7CIAypwDFZE64bdOWWaMJUl0yxYdEIumbSLFIAPFJYxCeoqBc236Bo2g7IaIri/RME6raf1deEomkfyN9Fu0g/F7ElnX6mwlTUTIHJNy2rkYj4Nc/E5llViKR9GW6VCxeeumlrrxdr0Bs/RQCPgDU+V/oUNumLbMA6TIYTyKR9GHanMH+5V/+JaGb/Nd//Regb6ftT8QUOHJlwFVXd6h905ZZm10hySEtfhKJpO/Splj827/9W0/1o3dSdAjOngJAmbcURU3cQR2JCDzljSnJs039eqeYRCLp/7QpFuPHj++pfvRKoo5tgxElP7ECR01UVYTR9HRQ0l8hkUj6PB2axU6ePMmhQ4daFD/6yle+0uUdu9yI2mrEzk0AKFfPRnGmdqh9uYyvkEgk/YiEZ7G1a9fy+uuvM2nSJAoLC5kyZQp79+5l2rRp3dm/y4bY+BFE9Am/IxHbTTTVr0hJM2C2SH+FRCLp2yQ8i7377rt85zvf4bHHHsNsNvPYY4/xyCOPYDD0v0AzoUX0pIEAg4bAyHEdah8MaNRUyZTkEomk/5CwWNTW1jJunD5pKoqCpmnk5eWxc+fObuvcZWPfLvCUAR0rcNRE8xQf0l8hkUj6AwnPZC6Xi7KyMjIzMxkwYAA7duwgOTkZo7H/TYbRAkcWG8rM+R1u3+SvUA2Qlt7/Ph+JRHLlkfBMdvPNN3P27FkyMzO59dZbeemllwiHw9x7773d2b8exWoyYQ/64K5/RgQDeM+eIWC1d+geQohoMJ47w4jBILfMSiSSvk/CYnHy5Eny8/MByMvLY9WqVYTDYaxWa7d1ridJNRkIbVyD562VaLU1qM4UHLfeg81koDoUSfg+DfUaPq9M8SGRSPoXHZrNXnjhBSwWC/n5+eTn5zNw4MDu6lePYjWZCG1cQ+1vfho9ptXWULvyZZyqijV/Cf5QqI07XKDifDN/haxfIZFI+gkJi8U999zD3Xffzf79+9m4cSPf/e53yczMZO7cuX2+DrddC+N5a2Xcc/VvrcQ9ewH+BO/V5K+wWBWSU+SWWYlE0j/o0GymqiqTJk3igQce4Cc/+QnJycm88cYb3dW3HkOJRNBqa+Ke02prUDQtoftomqCiTF+BpGcZZYoPiUTSb+iQGcrv97Nt2zY2bdrEwYMHGT9+PA8++GBCbQsLC1m1ahWaprFo0SKWLVsWc/69995jw4YNAGiaRnFxMStWrMDhcLTb9lIRBgOqMyWuYKjOFISqQgJui+rKCOFGa1VGljRBSSSS/kPCYvHSSy+xe/duhg8fzpw5c3jwwQdxOp0JtdU0jRUrVvDkk0/idrt54oknmDZtGjk5OdFrbrrpJm666SYAduzYwfvvv4/D4Uio7aXiVY04bl8e47NownH7cryqCSLt+yxkCVWJRNJfSXhGGz58OHfffXen0pAXFRWRnZ1NVlYWALNnz2b79u2tTvibNm1izpw5nWrbGfyhEKn5BTjRfRTR3VC3L8eUX0BDgs7tpi2zDqeKzS79FRKJpP+QsFhciumnsrISt9sdfe92uzl27FjcawOBAIWFhdx3330dbrt27VrWrl0LwHPPPddhYTN94RaS5i5GRMIoBiPC4USoKoncJRTUqKqsBmDw0OSEn200GvtdHZDm9OfxybF1D0IIKisrCYfD7V/cScrKyvplZU9IbGxGoxGXy9Uhv2qP2Eridby1Tu7cuZMxY8bgcDg63LagoICCgoLo+4qKis50VycShsrKhC8/fzaEaPSDO1LCCT87PT390vrZy+nP45Nj6x58Ph8mk6lbs0MYjcZuFaPLSSJjC4VCFBcXY7PZYo63FQ7RI7YSt9uNx+OJvvd4PKSlpcW9dtOmTdHgv462vZxUlOomKEXVI7clEknn0DStX6YR6k0YjUa0BHd5NtEjYjFixAjOnTtHWVkZ4XCYzZs3x01t7vV6OXjwYMy5RNtebppSkqe5DRhNcsusRNJZ5JbzjJJ98wAAGIJJREFUnqGjn3OPyLfBYGD58uU888wzaJrGggULyM3NZc2aNQAsWbIEgG3btjF58uSYFCKtte1N+Lwa9XW6SsstsxKJpD+iiP7q5QFKSkp65DmnjwfYs90HQH6BgzR34hrcn+3e0L/HJ8fWPXi9Xuz2jiXw7Cg96bO45ppr+OCDD3C5XJd0TaIkOrZ4n/Nl91n0d5riK0wmhdS0/lcMSiKRSKQX6RIRQkTzQbmzjCiqtLdKJH2dM2fOcOeddzJjxgx27drF+PHjuf322/nJT35CRUUFP//5zxk6dCiPPvoop0+fxmq18vzzzzN+/HgqKyt58MEH8Xg8TJkyJWZH55///GdWrlxJMBgkLy+PZ599ts9UG5Uri0uktjpCMCBTkksk/Y2TJ09y3333sXbtWoqKinjnnXd45513eOqpp3j11Vf5yU9+wsSJE1m7di2PP/44Dz30EAA//elPmTFjBmvWrGHJkiWcPXsWgGPHjvHee+/xzjvv8NFHH2EwGHj77bcv5xA7hJzdLpHy5iVUZb1tiaTfkJubGy0lPXr0aPLz81EUhbFjx3LmzBmKi4v59a9/DUB+fj5VVVXU1taydetWfvOb3wB67FdqaioAGzduZN++fVx//fWAnmuvLwV1ytntEmnaMmtPUkly9I3lpEQiaR+LxRJ9raoqZrM5+joSicQ1HzVtR423LVUIwW233cYTTzzRTT3uXqQZ6hKIRASVFbpYyMSBEsmVxcyZM6NmpM2bN+NyuUhOTo45/vHHH1NdracBys/P569//Wt0l1lVVRXFxcWXp/OdQM5wl0BleRitMXW5NEFJJFcWjzzyCI888ggFBQVYrVZ+9rOfAfDwww/z4IMPct111zFz5kwGDRoE6Kasb33rW9xxxx0IITAajTzzzDNdmhS1O5FxFpfAwT0+Pj8cAOC6ZU7Mlo4v1PrzXn3o3+OTY+se+lucRU8j4yx6IU3+ilSXoVNCIZFIJH0FOcN1koBfo7Zat0FJf4VEIunvSLHoJBVlcsusRCK5cpBi0UmaTFAGAx3KBSWRSCR9ESkWnUBP8aHXr3BnGjEYZIoPiUTSv5Fi0Qka6jT8Xn0TmfRXSCSSKwEpFp0gJsWHrF8hkUgaueaaa6jsQDnmvoQUi05Qfl43QVmsCskp8iOUSCT9H2lD6SCaJvA07oTKyDLKEpASSTei/f7XiDMnuvSeSu4wuOtfWj3v9Xq5//77OXfuHJqm8dBDD+FwOPjBD36Ay+Xiqquu4tSpU/zP//xPm+nI+xtSLDpItSdCU3BkerY0QUkk/Y1169aRnZ3NG2+8AUBtbS0LFy7k7bffZvDgwTzwwAPRa5vSkT/88MOsXbuW3/3ud5er292OFIsO0rQLCmT9Comku1G/+k89/syxY8fy9NNP88wzz1BQUEBSUhJDhgxh8ODBACxbtozf/va3AK2mI++PSIN7B2mKr0hOUbHa5McnkfQ3RowYwQcffMDYsWN59tlnWbNmTZvXXymmaDnbdYBQUFBdqaf4kLugJJL+yfnz57HZbNxyyy184xvfYMeOHZw6dYozZ84A8N5770WvbS0deX9E2lE6gKc8TJP/Kl2m+JBI+iWHDx/mRz/6EYqiYDKZePbZZyktLeXOO+/E5XIxZcqU6LWtpSPvj8gZrwM0bZlVVXBnyI9OIumPzJ8/n/nz58cca2hoYP369fz/7d1/VJX1HcDx9/0BXFBBuFdA/I1gmZrOgTCnKUm6zJqntNJyme0QQmuxtuY0f7U8eTqSHitnJc5TOQecDLPp5kE2tYGFktNcqExETH4IF0GB+/vZH+SdTPT648Kj8Hn9pdwvz/P5PpzzfO73+3yfz1dRFBYuXMi9994LQEhICFu2bHG3W758eUeG2qHkjncDLr2MF2zSo9d3jXlKIQRs3ryZ7Oxs7HY7w4cPZ86cOWqH1OEkWVynpkYXjRdcgKyCEqKrSUpKIikpSe0wVCUPuK9TjSyZFUJ0YZIsrtOlJbM+vhqCgnUqRyOEEB1LksV1UBTFvdmRKVSPRivPK4QQXYski+tQX+fEZm1ZMyu74gkhuiJJFtehplVJckkWQnR1mZmZLFq0SO0wOpQki+twaclsQHctAd3leYUQouuRr8keOB0K5nP/K0kuhOg4Gw5UUVpn8eoxBwUbSI6/9pvW8+bN4+zZs1itVp577jmefvppMjMzefvttwkLCyMyMhJfX18Adu3axdq1a7HZbAQHB/POO+/Qq1cv0tPTOX36NNXV1Zw8eZKlS5dSVFTkrmq7adMmfHzunLJBMrLwoLbGgavl9Qp5XiFEF5Gens5f//pXduzYwcaNG6moqGDVqlVs27aNLVu2cPz4cXfbMWPGsH37dnbt2sVPf/pT1q1b5/7s0r4XGzdu5Be/+AVjx45l9+7dGAwGdu/erUbXblqH3f0OHTrEH//4R1wuF5MmTWL69OlXtDl69CibNm3C6XTSo0cP96vzqampGAwGtFotOp2OlStXdlTY1Hy/ZBZNy0ooIUTH+XlMmCrn3bhxIzt37gTg7NmzfPLJJ/zoRz/CaDQC8Mgjj3Dy5EkAKioqmD9/PtXV1dhsNncpc4CEhAR8fHwYOnQoLpeLhIQEoKUM+qXChHeKDrn7uVwuMjIyePXVVzEajfzud78jJiaGvn37uts0NjayYcMGFi1ahMlkor6+vtUxli5dSmBgYEeE28ql/St6Buvw8ZWBmBCdXX5+Pvv27WP79u34+/szY8YMoqKiOHHiRJvtFy9eTFJSEpMnTyY/P5+33nrL/Zmfnx8AWq0Wvf5/O2tqtVqcTmf7d8aLOuTuV1JSQnh4OGFhYej1esaOHUthYWGrNl988QVxcXGYTCYAgoKCOiK0a7JaXDSc/77Eh0xBCdElXLhwgaCgIPz9/SkpKaGoqAiLxUJBQQFmsxm73c7nn3/ubt/Q0EB4eDgA2dnZaoXd7jrkDmg2m93DNwCj0XhFlq6oqMDhcLBs2TKam5uZOnUqEyZMcH++YsUKAB544AESExM7Imz3KiiQ/SuE6ComTpzIRx99RGJiIpGRkYwePZrQ0FBefvllHnnkEcLCwhgxYoR7ZPDyyy/z/PPPEx4ezujRo++46aXrpVE6YIfxgoIC/vWvf5GcnAzA3r17KSkpYd68ee42GRkZnDx5ksWLF2Oz2Xj11VdZsGABERERmM1mQkJCqK+v5/XXX+fZZ5/lnnvuueI8ubm55ObmArBy5UpsNtstxb1vdxUlxRfQ6zXM/nkkOp3339zW6/U4HA7PDe9Qnbl/0rf2UVVV5Z6+Ee3HarUSFtb6mdClFV5t6ZCRhdFopLa21v3/2tpagoODr2jTo0cPDAYDBoOBoUOHUlZWRkREBCEhIUDL1FRsbCwlJSVtJovExMRWo46ampqbjllRFM6UXQQgpJeOurpaD79xc0wm0y3FebvrzP2TvrUPq9WKTte+7zNJom+5zv//N46IiLhq+w55ZjF48GAqKiqorq7G4XCQn59PTExMqzYxMTEUFxfjdDqxWq2UlJTQp08fLBYLzc3NAFgsFg4fPtxqtUF7uXjBhaX5UokPmYISQnRtHTKy0Ol0zJs3jxUrVriXj/Xr18+9EfrkyZPp27cvo0aN4te//jVarZb777+f/v37U1VVxapVqwBwOp2MGzeu1baG7eVSlVmQl/GEEKJDnlmo5ezZszf9u1/tu0jVWQcGfw2JDwe6l7x5W2eeyoDO3T/pW/toamoiICCgXc8h01BtX2fVp6HuNC7XZSXJw/TtliiEEOJOIcmiDXW1TpzfJ2ZZMiuEEJIs2nSu8rItVOVlPCHEdYqLi8NsNnv1mNHR0V493s2SZNGGS/tXBAZp8TPIJRJC3Lz8/HxeeukltcO4ZfK1+f/YbS7qzC1vZppkyawQqvqmqImG896toRTYU8eoMVevM9fU1MTzzz9PRUUFLpeLX/7yl3Tv3p3ly5cTEhLCiBEj3NVkzWYzqamp1NbWMmrUKG5kvdDmzZvZvHkzNpuNQYMGsXbtWvz9/Tl9+jSpqak4nU4mTpzobt/Y2Mizzz5LfX09DoeDV155hSlTplBeXs5TTz3FmDFjKCoqYtiwYcycOZP09HRqamp45513+MEPfnArlwyQkcUVaqod8P3fW5bMCtH1XNpvIjc3l7y8PBISEvjtb3/Lxx9/TE5OTqsXjFevXs2YMWPYtWsXkydP5rvvvrvu8zz44IPs2LGD3NxcoqKi2LJlCwBLlizhZz/7GTt27CA0NNTd3s/Pj4yMDP72t7+RnZ3Na6+95k5Op06d4rnnniM3N5eSkhJycnLIyclhyZIlvP322165LnI3vIyfn4E+fYPoPbNl0yO/ACsOh1XtsITosoaPbt8ltG25++67+f3vf8+KFStITEykW7duDBgwwP0y8PTp0/n4448B2L9/Pxs2bABaKkj07NnTfZxp06ZhtVppamri/PnzPPDAAwAsWrSIiRMncuzYMd58800aGhpobGx018IrLCzkgw8+AOCxxx5z18VTFIWVK1fy5ZdfotFoqKys5Ny5cwD069ePoUOHAnDXXXcxbtw4NBqNV0uhS7L4XkBAEGUlzRwqPIPF4sRg0DEq1siAqCCamuo9H0AI0SkMHjyYnTt3kpeXxxtvvMF99913zfZXW1p/qTJtfn4+WVlZrFmzptXnaWlpZGRkMGzYMDIzMykoKLjmMbdu3UptbS07d+7Ex8eHuLg4rNaWL7OX19LSarXuGk/eLIUu01C0jCjKSprZv68ai6XlwlosTvbvq6aspBk/P4PKEQohOkplZSX+/v489thjJCcnc+DAAcrKytzf0D/77DN32/j4eLZu3QpAXl4e58+fv+7zXLx4kbCwMOx2O59++qn757GxsWzbtg3AfWxoKZ1uMpnw8fHhn//8J2fOnLmlft4oGVkAep0/hwpPt/nZocJaBkT1A7y7D7AQ4vZUXFzM66+/jkajwcfHhzfeeIOqqiqeeuopQkJCWpUbSktLIzU1lSlTphAfH0+fPtfe2/tyv/nNb5g2bRp9+/bl7rvv5uLFlsKlr732GqmpqWRkZDB16lR3+0cffZRnnnmGBx98kGHDhhEVFeW9Tl8HKfcBBPgHk7mp9KqfPzF3EE3Ndd4Kq5XOXDICOnf/pG/t43Ys99HY2Ei3bt1QFIWFCxcyaNAgkpKS2jHCm9de5T5kZAFoNGAw6NxTUJczGHSg6bT5VAhxHTZv3kx2djZ2u53hw4czZ84ctUPqcJIsAIezmVGxRvbvq77is1GxRpxOmYISoitLSkq6bUcSHUUecANWq4UBUf7Ejw9tGUnQMqKIHx/KgCh/rFZJFkJ0lE48M35budHrLCOL7zU11dN3kKHlYbaiAY2C02mRZbNCdDCtVovD4UCvl9tTe3E4HGi1NzZWkL/GZVpGEDKKEEJNBoMBi8WC1Wptt+0B/Pz83O8odDae+qYoClqtFoPhxl4JkGQhhLitaDQa/P392/UcspLtxskzCyGEEB5JshBCCOGRJAshhBAedeo3uIUQQniHjCxUtmDBArVDaFeduX/StztXZ+5fe/VNkoUQQgiPJFkIIYTwSLds2bJlagfR1UVGRqodQrvqzP2Tvt25OnP/2qNv8oBbCCGERzINJYQQwiNJFkIIITyS2lAqqamp4d133+X8+fNoNBoSExNbbaHYGbhcLhYsWEBISEinW6rY2NjI+vXrKS8vR6PRMH/+fIYMGaJ2WF7x+eefk5eXh0ajoV+/fqSkpODr66t2WDdt3bp1FBUVERQURHp6OtCy//Xq1as5d+4cvXr1Ii0tje7du6sc6Y1rq28fffQRBw8eRK/XExYWRkpKCt26dbvlc8kDbpVYrVaGDBnCrFmzuO+++3jvvfcYMWIEgYGBaofmNX/5y19wOBw4HA7GjRundjhe9f777zNixAhSUlJITEwkICDgjr6hXmI2m3n//fdZtWoVU6dOJT8/H4fDwcCBA9UO7aZ169aNhIQECgsLmTJlCgBZWVn069ePtLQ06urqOHz4MPfee6/Kkd64tvoGMGfOHH7yk59QWlpKcXGxV/om01AqCQ4Odq9Y8Pf3p0+fPpjNZpWj8p7a2lqKioqYNGmS2qF4XVNTE99++y33338/0LLnsTe+ud0uXC4XNpsNp9OJzWYjODhY7ZBuyT333HPFqKGwsJAJEyYAMGHCBAoLC9UI7Za11beRI0ei07Vs4jZkyBCv3VdkGuo2UF1dTWlpKVFRUWqH4jWbNm3i6aefprm5We1QvK66uprAwEDWrVtHWVkZkZGRzJ0794b3B7gdhYSE8PDDDzN//nx8fX0ZOXIkI0eOVDssr6uvr3cnweDgYBoaGlSOqH3k5eUxduxYrxxLRhYqs1gspKenM3fuXAICAtQOxysOHjxIUFBQp13H7nQ6KS0tZfLkybz55pv4+fmRk5OjdlhecfHiRQoLC3n33Xd57733sFgs7N27V+2wxE3YunUrOp2O8ePHe+V4kixU5HA4SE9PZ/z48cTFxakdjtccO3aMAwcOkJqaypo1a/jmm29Yu3at2mF5jdFoxGg0Eh0dDUB8fDylpaUqR+UdR44cITQ0lMDAQPR6PXFxcRw/flztsLwuKCiIuro6AOrq6jrVs0KAf/zjHxw8eJAXX3zRa7sNyjSUShRFYf369fTp04dp06apHY5XzZ49m9mzZwNw9OhRtm/fzosvvqhyVN7Ts2dPjEYjZ8+eJSIigiNHjtC3b1+1w/IKk8nEiRMnsFqt+Pr6cuTIEQYPHqx2WF4XExPDnj17mD59Onv27CE2NlbtkLzm0KFDbNu2jeXLl+Pn5+e148ob3CopLi5myZIl9O/f3535Z82axejRo1WOzLsuJYvOtnT21KlTrF+/HofDQWhoKCkpKXfk0su2ZGVlkZ+fj06nY+DAgSQnJ+Pj46N2WDdtzZo1/Pvf/+bChQsEBQXx+OOPExsby+rVq6mpqcFkMvGrX/3qjvz7tdW3Tz/9FIfD4e5PdHQ0SUlJt3wuSRZCCCE8kmcWQgghPJJkIYQQwiNJFkIIITySZCGEEMIjSRZCCCE8kmQhxG2kurqaxx9/HKfTqXYoQrQiyUIIIYRHkiyEEEJ4JOU+hPDAbDazceNGvv32WwwGAw899BBTp04lKyuL8vJytFotX3/9Nb1792b+/PnuvR/OnDnDhg0bOHXqFCEhIcyePZuYmBgAbDYbf/7zn9m/fz+NjY3079+fxYsXu8+5b98+MjMzsdlsPPTQQzz66KMAlJSUsGHDBioqKvD19WXcuHE888wzHX5NRBekCCGuyul0Kq+88oqSnZ2t2O12pbKyUklNTVW+/vprJTMzU3nyySeVgoICxW63K9u2bVNSUlIUu92u2O125YUXXlA++eQTxW63K0eOHFHmzJmjfPfdd4qiKMoHH3ygLF26VKmtrVWcTqdSXFys2Gw2paqqSpk5c6byhz/8QbFarUppaakya9Yspby8XFEURVm4cKGyZ88eRVEUpbm5WTl27Jhq10Z0LTINJcQ1/Oc//6GhoYEZM2a4t6mcNGkS+fn5AERGRhIfH49er2fatGnY7XZOnDjBiRMnsFgsTJ8+Hb1ez/Dhwxk9ejRffPEFLpeLv//978ydO5eQkBC0Wi133XVXq/pLM2fOxNfXl4EDBzJgwADKysqAlo2WKisraWhowGAwdJqtXMXtT6ahhLiGc+fOUVdXx9y5c90/c7lcDB06FJPJhNFodP9cq9ViNBrdpa9NJhNa7f++j/Xq1Quz2cyFCxew2+2Eh4df9bw9e/Z0/9vPzw+LxQJAcnIymZmZpKWlERoayowZM/jhD3/ore4KcVWSLIS4BpPJRGhoaJv7cWRlZVFbW+v+v8vlora21r0DW01NDS6Xy50wampq6N27Nz169MDHx4fKysob3tu6d+/evPTSS7hcLr766iveeustMjIyOsUufeL2JtNQQlxDVFQU/v7+5OTkYLPZcLlcnD59mpKSEgBOnjzJl19+idPpZMeOHfj4+BAdHU10dDQGg4HPPvsMh8PB0aNHOXjwID/+8Y/RarUkJCTw4YcfYjabcblcHD9+HLvd7jGevXv30tDQgFarde+sePnoRYj2IiXKhfDAbDbz4YcfcvToURwOBxERETzxxBMUFxe3Wg0VHh5OcnKyezvZ8vLyVquhZs2axZgxY4CW1VB/+tOfKCgowGKxMHDgQBYtWsT58+d54YUX2LJlCzqdDoBly5Yxfvx4Jk2axNq1azl8+DBWq5VevXrx5JNPuo8pRHuSZCHETcrKyqKysrJT7QIoxNXI+FUIIYRHkiyEEEJ4JNNQQgghPJKRhRBCCI8kWQghhPBIkoUQQgiPJFkIIYTwSJKFEEIIj/4LZim66ydAmIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "sns.lineplot(x='epochs', y='val_accuracy', hue='model', data=results_4, linewidth=2.5, marker='o', markersize=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
